{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import fairseq\n",
    "from fairseq import options\n",
    "from fairseq_cli.preprocess import main as preprocess\n",
    "from fairseq.data import Dictionary, TokenBlockDataset, MonolingualDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess dataset Wiki103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = os.path.join('/mnt/dl/fairseq/Language_Model/wikitext-103-v1/wikitext-103/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = os.path.join(raw_dataset, 'data_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wiki.test.tokens', 'data_bin', 'wiki.valid.tokens', 'wiki.train.tokens']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(raw_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = options.get_preprocessing_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.only_source = True\n",
    "args.trainpref = os.path.join(raw_dataset, 'wiki.train.tokens')\n",
    "args.validpref = os.path.join(raw_dataset, 'wiki.valid.tokens')\n",
    "args.testpref = os.path.join(raw_dataset, 'wiki.test.tokens')\n",
    "args.destdir = preprocessed_dataset\n",
    "args.workers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO uncomment\n",
    "# preprocess(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(preprocessed_dataset, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary.load(os.path.join(preprocessed_dataset, 'dict.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '<pad>', '</s>', '<unk>', 'the', ',', '.', 'of', 'and', 'to']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.symbols[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267744"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dictionary = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 16:52:07 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: /mnt/dl/fairseq/Language_Model/wikitext-103-v1/wikitext-103/data_bin/train\n"
     ]
    }
   ],
   "source": [
    "dataset = fairseq.data.data_utils.load_indexed_dataset(train_data_path, dictionary, args.dataset_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fairseq.data.indexed_dataset.MMapIndexedDataset at 0x7f3c8ec118b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801350"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   6,   1, ..., 157,  14,   1], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---\n",
      "= Valkyria Chronicles III =\n",
      "---\n",
      "\n",
      "---\n",
      "Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" .\n",
      "---\n",
      "The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n .\n",
      "---\n",
      "It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 .\n",
      "---\n",
      "\n",
      "---\n",
      "= = Gameplay = =\n",
      "---\n",
      "\n",
      "---\n",
      "As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main heroines , although they take a very minor role .\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    string = dictionary.string(dataset[i].unsqueeze(0))\n",
    "    print(string)\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\n",
      "---\n",
      " = Valkyria Chronicles III = \n",
      "\n",
      "---\n",
      " \n",
      "\n",
      "---\n",
      " Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \n",
      "\n",
      "---\n",
      " The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \n",
      "\n",
      "---\n",
      " It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \n",
      "\n",
      "---\n",
      " \n",
      "\n",
      "---\n",
      " = = Gameplay = = \n",
      "\n",
      "---\n",
      " \n",
      "\n",
      "---\n",
      " As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player 's approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game 's completion , additional episodes are unlocked , some of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game 's two main heroines , although they take a very minor role . \n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(raw_dataset, 'wiki.train.tokens')) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 10:\n",
    "            break\n",
    "        print(line)\n",
    "        print(\"---\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_sample = 512\n",
    "max_tokens = 2048\n",
    "shorten_method = \"none\"\n",
    "shorten_data_split_list = \"\"\n",
    "seed = 0\n",
    "split = \"train\"\n",
    "sample_break_mode = \"none\"\n",
    "split_path = os.path.join(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "shorten_dataset = fairseq.data.shorten_dataset.maybe_shorten_dataset(\n",
    "            dataset,\n",
    "            split,\n",
    "            shorten_data_split_list,\n",
    "            shorten_method,\n",
    "            tokens_per_sample,\n",
    "            seed,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_dataset is dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dataset = TokenBlockDataset(shorten_dataset, shorten_dataset.sizes,\n",
    "                                  block_size=tokens_per_sample,\n",
    "                                   pad=dictionary.pad(),\n",
    "                                   eos=dictionary.eos(),\n",
    "                                   break_mode=sample_break_mode,\n",
    "                                   include_targets=True,\n",
    "                                   split_path=split_path,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([512, 512, 512, ..., 512, 512, 141], dtype=uint16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= Valkyria Chronicles III = Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game \\'s opening theme was sung by May \\'n . It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game \\'s expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . = = Gameplay = = As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player \\'s approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game \\'s completion , additional episodes are unlocked , some of'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[0][0].unsqueeze(0)) # source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= Valkyria Chronicles III = Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game \\'s opening theme was sung by May \\'n . It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game \\'s expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . = = Gameplay = = As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player \\'s approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game \\'s completion , additional episodes are unlocked , some of them'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[0][1].unsqueeze(0)) # item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad> = Valkyria Chronicles III = Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game \\'s opening theme was sung by May \\'n . It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game \\'s expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . = = Gameplay = = As with previous <unk> Chronicles games , Valkyria Chronicles III is a tactical role @-@ playing game where players take control of a military unit and take part in missions against enemy forces . Stories are told through comic book @-@ like panels with animated character portraits , with characters speaking partially through voiced speech bubbles and partially through unvoiced text . The player progresses through a series of linear missions , gradually unlocked as maps that can be freely scanned through and replayed as they are unlocked . The route to each story location on the map varies depending on an individual player \\'s approach : when one option is selected , the other is sealed off to the player . Outside missions , the player characters rest in a camp , where units can be customized and character growth occurs . Alongside the main story missions are character @-@ specific sub missions relating to different squad members . After the game \\'s completion , additional episodes are unlocked , some'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[0][2].unsqueeze(0)) # past_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game \\'s two main heroines , although they take a very minor role . The game \\'s battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . Troops are divided into five classes : Scouts , <unk> , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games \\' method of distributing to different unit types . = = Plot = = The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task ,'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[1][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'podcast , \" we [ Bungie ] are focusing on getting our listeners and fans familiar with a bunch of the different faces at Bungie studios . \" Brought back after close to a year @-@ long hiatus , the podcast now features Bungie news and interviews with staff members about their jobs and working at the studio . Smith had the title of \" Bungie Community Manager \" at Bungie , and has given interviews with the press about the company \\'s recent products , including Halo 3 : ODST . Smith was among other writers @-@ turned @-@ game developers who held a discussion on the topic at the 2009 Game Developers Conference . Smith worked on player investment for Halo : Reach . He worked as design lead on Bungie \\'s 2014 video game Destiny .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[-1][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.bos(), dictionary.eos(), dictionary.pad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     2,      2,     12,  52468,  11394,   1141,     12,      2,      2,\n",
       "        158338,    129,  52468,     94,     45,      3,  11394,     25,    465,\n",
       "            45, 267683,      5,   6444,      6,  52468,      7,      4,  21647,\n",
       "            94,     24,      5,   1999,   1149,      9,     21,  52468,  11394,\n",
       "          1141,    757,    663,      5,     26,     11,   6744,    296,     15,\n",
       "           551,    290,     84,    436,     23,   5107,      8, 169397,     20,\n",
       "             4,   2104,  13920,      6,  10455,     10,    226,    310,     10,\n",
       "           663,      5,     31,     26,      4,    233,     84,     10,      4,\n",
       "         52468,    127,      6,  65394,      4,    161,   7432,      7,   6744,\n",
       "             8,    838,     15,     64,   2274,     21,     48,   7454,      5,\n",
       "             4,    331,    639,   2807,      9,      4,     42,     84,      8,\n",
       "          1763,      4,     13,  41313,     13,      5,     11,  23595,    411,\n",
       "          1240,   1795,      4,   1873,      7,  86993,     76,      4,   1037,\n",
       "        166355,    195,     54,   1857,   2357,    594,   1010,      8,     39,\n",
       "         13083,    113,      4,   2424,   1240,     13,      3,  11741,     13,\n",
       "             6,      2,     16,     84,    142,    424,     10,    288,      5,\n",
       "          2379,     74,     11,    213,   1412,      7,      4,    143,    994,\n",
       "            18,  52468,  11394,    360,      6,    370,     31,   2421,      4,\n",
       "          1257,    523,      7,      4,    127,      5,     31,     46,   4672,\n",
       "          1441,  17770,      5,     96,     21,    403,      4,     84,     69,\n",
       "         45644,     20,    127,  20004,      6,  12040,   3531,      3, 237830,\n",
       "             8,   2620,  51822,  38407,    125,    371,     28,    441,   8170,\n",
       "             5,    182,     22,  52468,  11394,    360,    720,  39953,  51883,\n",
       "             6,     77,    213,    131,      7,   1448,   4832,      4,   1291,\n",
       "             6,     16,     84,     17,    682,   1256,     14,   4664,     23,\n",
       "           186,  47260,      6,      2,     66,    708,     22,    752,   1201,\n",
       "            10,    663,      5,      8,     14,    723,     23,    125,    465,\n",
       "             8,    876,    630,      6,    124,    285,      5,     31,    178,\n",
       "          9140,   1689,      5,    182,     22,     33,   1944,   1290,     10,\n",
       "           203,      7,     19,    101,      6,     66,     14,     46,   2524,\n",
       "            65,   4962,      8,     33,    280,    290,   3389,    127,      6,\n",
       "          1938,      9,    489,   1201,      7,  52468,  11394,    360,      5,\n",
       "         52468,  11394,   1141,     14,     40,  12714,      5,     38,     11,\n",
       "          2184,   4677,  10928,     22,      4,     84,     17,   1944,   1290,\n",
       "            14,    145,     10,    484,      6, 169397,     63,    469,      9,\n",
       "             4,   2336,     22,      4,    424,      7,  52468,     45,  40345,\n",
       "          2690,     20,      4,   2104,    118,      6,      2,      2,     12,\n",
       "            12,   7686,     12,     12,      2,      2,    149,     22,    441,\n",
       "             3,  11394,    259,      5,  52468,  11394,   1141,     26,     11,\n",
       "          6744,    296,     15,    551,     84,     98,    485,    350,    423,\n",
       "             7,     11,    411,   1240,      8,    350,    126,     10,   2824,\n",
       "           113,   1398,    395,      6,   6851,     39,    761,    112,   2153,\n",
       "           354,     15,    166,   6796,     22,   2802,    235,   8765,      5,\n",
       "            22,    429,   2835,   3565,    112,   3850,   1714,  18553,      8,\n",
       "          3565,    112,  90738,   2045,      6,     16,    346,  10302,    112,\n",
       "            11,    127,      7,   6748,   2824,      5,   2460,  15910,     21,\n",
       "          5605,     19,    128,     37,   8075,  29108,    112,      8,  38245,\n",
       "            21,     61,     39,  15910,      6,     16,    515,      9,    185,\n",
       "           331,   1065,     18,      4,   3808,   6221,   4053,     18,     33,\n",
       "          1171,    346,     17,   1447,     45,     71,     51,   3998,     26,\n",
       "          1158,      5,      4,     68,     26,   8882,    184,      9,      4,\n",
       "           346,      6,   7673,   2824,      5,      4,    346,    429,    684,\n",
       "            10,     11,   1724,      5,     98,    732,    128,     37,  28013,\n",
       "             8,    235,   1676,   2660,      6,  17135,      4,    272,    331,\n",
       "          2824,     39,    235,     15,   1569,   4432,   2824,   6680,      9,\n",
       "           355,   3588,    307,      6,    124,      4,     84,     17,   2883,\n",
       "             5,    810,    910,     39,  15910,      5,    105,      7])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   12, 52468, 11394,  1141,    12,     2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([158338,    129,  52468,     94,     45,      3,  11394,     25,    465,\n",
       "            45, 267683,      5,   6444,      6,  52468,      7,      4,  21647,\n",
       "            94,     24,      5,   1999,   1149,      9,     21,  52468,  11394,\n",
       "          1141,    757,    663,      5,     26,     11,   6744,    296,     15,\n",
       "           551,    290,     84,    436,     23,   5107,      8, 169397,     20,\n",
       "             4,   2104,  13920,      6,  10455,     10,    226,    310,     10,\n",
       "           663,      5,     31,     26,      4,    233,     84,     10,      4,\n",
       "         52468,    127,      6,  65394,      4,    161,   7432,      7,   6744,\n",
       "             8,    838,     15,     64,   2274,     21,     48,   7454,      5,\n",
       "             4,    331,    639,   2807,      9,      4,     42,     84,      8,\n",
       "          1763,      4,     13,  41313,     13,      5,     11,  23595,    411,\n",
       "          1240,   1795,      4,   1873,      7,  86993,     76,      4,   1037,\n",
       "        166355,    195,     54,   1857,   2357,    594,   1010,      8,     39,\n",
       "         13083,    113,      4,   2424,   1240,     13,      3,  11741,     13,\n",
       "             6,      2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_dataset[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    16,     84,    142,    424,     10,    288,      5,   2379,     74,\n",
       "            11,    213,   1412,      7,      4,    143,    994,     18,  52468,\n",
       "         11394,    360,      6,    370,     31,   2421,      4,   1257,    523,\n",
       "             7,      4,    127,      5,     31,     46,   4672,   1441,  17770,\n",
       "             5,     96,     21,    403,      4,     84,     69,  45644,     20,\n",
       "           127,  20004,      6,  12040,   3531,      3, 237830,      8,   2620,\n",
       "         51822,  38407,    125,    371,     28,    441,   8170,      5,    182,\n",
       "            22,  52468,  11394,    360,    720,  39953,  51883,      6,     77,\n",
       "           213,    131,      7,   1448,   4832,      4,   1291,      6,     16,\n",
       "            84,     17,    682,   1256,     14,   4664,     23,    186,  47260,\n",
       "             6,      2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorten_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   107,    333,     11,    977,   2961,     83,    261,    158,     10,\n",
       "             4,    684,      7,      4,     84,      6,    298,     39,     46,\n",
       "           743,  13910,    776,    997,      9,      4,     84,     17,     53,\n",
       "           272,  20891,      5,    286,     61,    350,     11,    260,   1183,\n",
       "           296,      6,      2,     16,     84,     17,    521,    236,      5,\n",
       "             4,      3,    236,      5,     26,    872,     74,   1276,     28,\n",
       "             3,  11394,      6,    215,   2824,      5,    485,   5768,    185,\n",
       "          1240,    397,     11,    318,     15,    225,   4019,      7,      4,\n",
       "          6605,   3808,     45,    536,     11,    235,     26,   1158,      5,\n",
       "             4,    346,   2840,      4,    235,    168,      4,   6605,     10,\n",
       "           233,     15,    844,      6,     77,    235,    128,     78,   1096,\n",
       "           536,    406,     15,    870,      5,     38,    429,    128,     37,\n",
       "          1915,   1441,   1935,     29,      4,   6769,      7,     68,    429,\n",
       "            60,   1935,      6,   1806,    235,     56,     11,    629,      8,\n",
       "          1455,      7,    957,    912,     23,     43,   5815,  38587,      6,\n",
       "          2634,      9,    771,    429,    128,     37,   1175,      9,     11,\n",
       "           207,   1411,      6,    215,   2274,      5,    429,    211,   1442,\n",
       "            81,    224,   1079,   8392,      9,    107,      5,     96,     21,\n",
       "            43,   1301,    510,     25,  20873,     24,   2308,    489,     49,\n",
       "           109,   5355,     81,     23,   1398,   1108,      6,   1806,    235,\n",
       "            56,   1569,     13, 170889,     13,      5,   3341,   2037,      9,\n",
       "           185,    235,      6,    192,     39,   1466,     65,     13,   4661,\n",
       "         29506,     13,      5,     36,     39,  19947,   3341,     19,   1419,\n",
       "         32892,   4621,   2986,  14932,     23,      4,    331,      8,    128,\n",
       "           627,    623,     49,  34251,     11,    235,      5,      8,     13,\n",
       "           644, 170889,     13,      5,     36,     39,   3677,    497,      4,\n",
       "            84,      8,   1061,   3995,  80655,      9,     11,    235,      6,\n",
       "           600,   3403,    644, 170889,      5,    185,    235,     56,     11,\n",
       "          2037,     13,   6782,  12920,     13,      5,     11,   6590,     15,\n",
       "           228,   5560,   2464,     19,    128,     37,    106,      9,   6855,\n",
       "             8,   3667,    355,   3341,      6,   9507,     46,     50,   2430,\n",
       "         59590,     19,   3995,    107,   3029,  47497,     18,      4,   6605,\n",
       "            45,   4284,    128,  15417,     13,  16659,   3089,     13,      8,\n",
       "           748,    168,      4,   6605,    340,  47139,     27,   5815,   2288,\n",
       "          6557,      5,      4,    235,      3,    128,   4577,     65,     47,\n",
       "            13,  52468,  14502,     13,      8,    348,  32214,      5,     89,\n",
       "        238426,    128,   2219,   1441,   1398,    732,     22,     47,    587,\n",
       "          3559,      6,      2,  18885,     39,   1466,     65,    188,   2698,\n",
       "            45,  10130,      5,      3,      5,   7843,      5,  25344,      8,\n",
       "         16836,  11501,      6,  54679,    128,   6359,   2698,     23,   3672,\n",
       "            43,   1175,   3559,      6,  27327,    447,    631,     40,   2985,\n",
       "          4363,      4,  26872,   1540,     89,     10,     11,    441,    447,\n",
       "             6,    488,    661,     10,    521,      5,    988,    510,     39,\n",
       "           959,      9,      4,   3588,      5,     36,     39,   3172,     65,\n",
       "           188,    355,   8064,   2215,     23,      4,    789,   3588,      5,\n",
       "            11,   1033,  10692,     28,    144,    259,     60,   2420,      7,\n",
       "         15964,      9,    355,   1240,   2011,      6,      2,      2,     12,\n",
       "            12,   2645,     12,     12,      2,      2,     16,     84,   1118,\n",
       "           231,     76,      4,   1037, 166355,    195,      6, 136567,    430,\n",
       "          9537,  23604,      5,     46,    138,     21,     13,     16,  41313,\n",
       "            13,      5,     39,     11,  23595,    411,   1240,   1103,      7,\n",
       "         10447,      5,   1554,  28834,      5,      8,    411,  26054,    801,\n",
       "           838,   1304,     39,  25950,     28,      4,   1233,      8,  68059,\n",
       "          1642,   1149,      9,     23,   1151,      6,  46264,     23,      4,\n",
       "        136567,    411,      9,   1857,      4,     88,   3783,   2824,     19,\n",
       "             4,  10106,    430,      8,  11477,    211,     40,    315,      5,\n",
       "            61,     39,   5948,     80,      9,      4,   2855,      5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game \\'s two main heroines , although they take a very minor role . The game \\'s battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . Troops are divided into five classes : Scouts , <unk> , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games \\' method of distributing to different unit types . = = Plot = = The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task ,'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[1][0].unsqueeze(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game \\'s two main heroines , although they take a very minor role . The game \\'s battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . Troops are divided into five classes : Scouts , <unk> , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games \\' method of distributing to different unit types . = = Plot = = The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task , exemplified'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[1][1].unsqueeze(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'of them having a higher difficulty than those found in the rest of the game . There are also love simulation elements related to the game \\'s two main heroines , although they take a very minor role . The game \\'s battle system , the <unk> system , is carried over directly from <unk> Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \\' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific \" Potentials \" , skills unique to each character . They are divided into \" Personal Potential \" , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and \" Battle Potentials \" , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique \" Masters Table \" , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate \" Direct Command \" and move around the battlefield without depleting his Action Point gauge , the character <unk> can shift into her \" Valkyria Form \" and become invincible , while Imca can target multiple enemy units with her heavy weapon . Troops are divided into five classes : Scouts , <unk> , Engineers , Lancers and Armored Soldier . Troopers can switch classes by changing their assigned weapon . Changing class does not greatly affect the stats gained while in a previous class . With victory in battle , experience points are awarded to the squad , which are distributed into five different attributes shared by the entire squad , a feature differing from early games \\' method of distributing to different unit types . = = Plot = = The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \" The Nameless \" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.string(token_dataset[1][2].unsqueeze(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,      2,     12,  52468,  11394,   1141,     12,      2,      2,\n",
       "         158338,    129,  52468,     94,     45,      3,  11394,     25,    465,\n",
       "             45, 267683,      5,   6444,      6,  52468,      7,      4,  21647,\n",
       "             94,     24,      5,   1999,   1149,      9,     21,  52468,  11394,\n",
       "           1141,    757,    663,      5,     26,     11,   6744,    296,     15,\n",
       "            551,    290,     84,    436,     23,   5107,      8, 169397,     20,\n",
       "              4,   2104,  13920,      6,  10455,     10,    226,    310,     10,\n",
       "            663,      5,     31,     26,      4,    233,     84,     10,      4,\n",
       "          52468,    127,      6,  65394,      4,    161,   7432,      7,   6744,\n",
       "              8,    838,     15,     64,   2274,     21,     48,   7454,      5,\n",
       "              4,    331,    639,   2807,      9,      4,     42,     84,      8,\n",
       "           1763,      4,     13,  41313,     13,      5,     11,  23595,    411,\n",
       "           1240,   1795,      4,   1873,      7,  86993,     76,      4,   1037,\n",
       "         166355,    195,     54,   1857,   2357,    594,   1010,      8,     39,\n",
       "          13083,    113,      4,   2424,   1240,     13,      3,  11741,     13,\n",
       "              6,      2,     16,     84,    142,    424,     10,    288,      5,\n",
       "           2379,     74,     11,    213,   1412,      7,      4,    143,    994,\n",
       "             18,  52468,  11394,    360,      6,    370,     31,   2421,      4,\n",
       "           1257,    523,      7,      4,    127,      5,     31,     46,   4672,\n",
       "           1441,  17770,      5,     96,     21,    403,      4,     84,     69,\n",
       "          45644,     20,    127,  20004,      6,  12040,   3531,      3, 237830,\n",
       "              8,   2620,  51822,  38407,    125,    371,     28,    441,   8170,\n",
       "              5,    182,     22,  52468,  11394,    360,    720,  39953,  51883,\n",
       "              6,     77,    213,    131,      7,   1448,   4832,      4,   1291,\n",
       "              6,     16,     84,     17,    682,   1256,     14,   4664,     23,\n",
       "            186,  47260,      6,      2,     66,    708,     22,    752,   1201,\n",
       "             10,    663,      5,      8,     14,    723,     23,    125,    465,\n",
       "              8,    876,    630,      6,    124,    285,      5,     31,    178,\n",
       "           9140,   1689,      5,    182,     22,     33,   1944,   1290,     10,\n",
       "            203,      7,     19,    101,      6,     66,     14,     46,   2524,\n",
       "             65,   4962,      8,     33,    280,    290,   3389,    127,      6,\n",
       "           1938,      9,    489,   1201,      7,  52468,  11394,    360,      5,\n",
       "          52468,  11394,   1141,     14,     40,  12714,      5,     38,     11,\n",
       "           2184,   4677,  10928,     22,      4,     84,     17,   1944,   1290,\n",
       "             14,    145,     10,    484,      6, 169397,     63,    469,      9,\n",
       "              4,   2336,     22,      4,    424,      7,  52468,     45,  40345,\n",
       "           2690,     20,      4,   2104,    118,      6,      2,      2,     12,\n",
       "             12,   7686,     12,     12,      2,      2,    149,     22,    441,\n",
       "              3,  11394,    259,      5,  52468,  11394,   1141,     26,     11,\n",
       "           6744,    296,     15,    551,     84,     98,    485,    350,    423,\n",
       "              7,     11,    411,   1240,      8,    350,    126,     10,   2824,\n",
       "            113,   1398,    395,      6,   6851,     39,    761,    112,   2153,\n",
       "            354,     15,    166,   6796,     22,   2802,    235,   8765,      5,\n",
       "             22,    429,   2835,   3565,    112,   3850,   1714,  18553,      8,\n",
       "           3565,    112,  90738,   2045,      6,     16,    346,  10302,    112,\n",
       "             11,    127,      7,   6748,   2824,      5,   2460,  15910,     21,\n",
       "           5605,     19,    128,     37,   8075,  29108,    112,      8,  38245,\n",
       "             21,     61,     39,  15910,      6,     16,    515,      9,    185,\n",
       "            331,   1065,     18,      4,   3808,   6221,   4053,     18,     33,\n",
       "           1171,    346,     17,   1447,     45,     71,     51,   3998,     26,\n",
       "           1158,      5,      4,     68,     26,   8882,    184,      9,      4,\n",
       "            346,      6,   7673,   2824,      5,      4,    346,    429,    684,\n",
       "             10,     11,   1724,      5,     98,    732,    128,     37,  28013,\n",
       "              8,    235,   1676,   2660,      6,  17135,      4,    272,    331,\n",
       "           2824,     39,    235,     15,   1569,   4432,   2824,   6680,      9,\n",
       "            355,   3588,    307,      6,    124,      4,     84,     17,   2883,\n",
       "              5,    810,    910,     39,  15910,      5,    105,      7]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset[0][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,     12,  52468,  11394,   1141,     12,      2,      2, 158338,\n",
       "            129,  52468,     94,     45,      3,  11394,     25,    465,     45,\n",
       "         267683,      5,   6444,      6,  52468,      7,      4,  21647,     94,\n",
       "             24,      5,   1999,   1149,      9,     21,  52468,  11394,   1141,\n",
       "            757,    663,      5,     26,     11,   6744,    296,     15,    551,\n",
       "            290,     84,    436,     23,   5107,      8, 169397,     20,      4,\n",
       "           2104,  13920,      6,  10455,     10,    226,    310,     10,    663,\n",
       "              5,     31,     26,      4,    233,     84,     10,      4,  52468,\n",
       "            127,      6,  65394,      4,    161,   7432,      7,   6744,      8,\n",
       "            838,     15,     64,   2274,     21,     48,   7454,      5,      4,\n",
       "            331,    639,   2807,      9,      4,     42,     84,      8,   1763,\n",
       "              4,     13,  41313,     13,      5,     11,  23595,    411,   1240,\n",
       "           1795,      4,   1873,      7,  86993,     76,      4,   1037, 166355,\n",
       "            195,     54,   1857,   2357,    594,   1010,      8,     39,  13083,\n",
       "            113,      4,   2424,   1240,     13,      3,  11741,     13,      6,\n",
       "              2,     16,     84,    142,    424,     10,    288,      5,   2379,\n",
       "             74,     11,    213,   1412,      7,      4,    143,    994,     18,\n",
       "          52468,  11394,    360,      6,    370,     31,   2421,      4,   1257,\n",
       "            523,      7,      4,    127,      5,     31,     46,   4672,   1441,\n",
       "          17770,      5,     96,     21,    403,      4,     84,     69,  45644,\n",
       "             20,    127,  20004,      6,  12040,   3531,      3, 237830,      8,\n",
       "           2620,  51822,  38407,    125,    371,     28,    441,   8170,      5,\n",
       "            182,     22,  52468,  11394,    360,    720,  39953,  51883,      6,\n",
       "             77,    213,    131,      7,   1448,   4832,      4,   1291,      6,\n",
       "             16,     84,     17,    682,   1256,     14,   4664,     23,    186,\n",
       "          47260,      6,      2,     66,    708,     22,    752,   1201,     10,\n",
       "            663,      5,      8,     14,    723,     23,    125,    465,      8,\n",
       "            876,    630,      6,    124,    285,      5,     31,    178,   9140,\n",
       "           1689,      5,    182,     22,     33,   1944,   1290,     10,    203,\n",
       "              7,     19,    101,      6,     66,     14,     46,   2524,     65,\n",
       "           4962,      8,     33,    280,    290,   3389,    127,      6,   1938,\n",
       "              9,    489,   1201,      7,  52468,  11394,    360,      5,  52468,\n",
       "          11394,   1141,     14,     40,  12714,      5,     38,     11,   2184,\n",
       "           4677,  10928,     22,      4,     84,     17,   1944,   1290,     14,\n",
       "            145,     10,    484,      6, 169397,     63,    469,      9,      4,\n",
       "           2336,     22,      4,    424,      7,  52468,     45,  40345,   2690,\n",
       "             20,      4,   2104,    118,      6,      2,      2,     12,     12,\n",
       "           7686,     12,     12,      2,      2,    149,     22,    441,      3,\n",
       "          11394,    259,      5,  52468,  11394,   1141,     26,     11,   6744,\n",
       "            296,     15,    551,     84,     98,    485,    350,    423,      7,\n",
       "             11,    411,   1240,      8,    350,    126,     10,   2824,    113,\n",
       "           1398,    395,      6,   6851,     39,    761,    112,   2153,    354,\n",
       "             15,    166,   6796,     22,   2802,    235,   8765,      5,     22,\n",
       "            429,   2835,   3565,    112,   3850,   1714,  18553,      8,   3565,\n",
       "            112,  90738,   2045,      6,     16,    346,  10302,    112,     11,\n",
       "            127,      7,   6748,   2824,      5,   2460,  15910,     21,   5605,\n",
       "             19,    128,     37,   8075,  29108,    112,      8,  38245,     21,\n",
       "             61,     39,  15910,      6,     16,    515,      9,    185,    331,\n",
       "           1065,     18,      4,   3808,   6221,   4053,     18,     33,   1171,\n",
       "            346,     17,   1447,     45,     71,     51,   3998,     26,   1158,\n",
       "              5,      4,     68,     26,   8882,    184,      9,      4,    346,\n",
       "              6,   7673,   2824,      5,      4,    346,    429,    684,     10,\n",
       "             11,   1724,      5,     98,    732,    128,     37,  28013,      8,\n",
       "            235,   1676,   2660,      6,  17135,      4,    272,    331,   2824,\n",
       "             39,    235,     15,   1569,   4432,   2824,   6680,      9,    355,\n",
       "           3588,    307,      6,    124,      4,     84,     17,   2883,      5,\n",
       "            810,    910,     39,  15910,      5,    105,      7,    107]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset[0][1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     1,      2,      2,     12,  52468,  11394,   1141,     12,      2,\n",
       "              2, 158338,    129,  52468,     94,     45,      3,  11394,     25,\n",
       "            465,     45, 267683,      5,   6444,      6,  52468,      7,      4,\n",
       "          21647,     94,     24,      5,   1999,   1149,      9,     21,  52468,\n",
       "          11394,   1141,    757,    663,      5,     26,     11,   6744,    296,\n",
       "             15,    551,    290,     84,    436,     23,   5107,      8, 169397,\n",
       "             20,      4,   2104,  13920,      6,  10455,     10,    226,    310,\n",
       "             10,    663,      5,     31,     26,      4,    233,     84,     10,\n",
       "              4,  52468,    127,      6,  65394,      4,    161,   7432,      7,\n",
       "           6744,      8,    838,     15,     64,   2274,     21,     48,   7454,\n",
       "              5,      4,    331,    639,   2807,      9,      4,     42,     84,\n",
       "              8,   1763,      4,     13,  41313,     13,      5,     11,  23595,\n",
       "            411,   1240,   1795,      4,   1873,      7,  86993,     76,      4,\n",
       "           1037, 166355,    195,     54,   1857,   2357,    594,   1010,      8,\n",
       "             39,  13083,    113,      4,   2424,   1240,     13,      3,  11741,\n",
       "             13,      6,      2,     16,     84,    142,    424,     10,    288,\n",
       "              5,   2379,     74,     11,    213,   1412,      7,      4,    143,\n",
       "            994,     18,  52468,  11394,    360,      6,    370,     31,   2421,\n",
       "              4,   1257,    523,      7,      4,    127,      5,     31,     46,\n",
       "           4672,   1441,  17770,      5,     96,     21,    403,      4,     84,\n",
       "             69,  45644,     20,    127,  20004,      6,  12040,   3531,      3,\n",
       "         237830,      8,   2620,  51822,  38407,    125,    371,     28,    441,\n",
       "           8170,      5,    182,     22,  52468,  11394,    360,    720,  39953,\n",
       "          51883,      6,     77,    213,    131,      7,   1448,   4832,      4,\n",
       "           1291,      6,     16,     84,     17,    682,   1256,     14,   4664,\n",
       "             23,    186,  47260,      6,      2,     66,    708,     22,    752,\n",
       "           1201,     10,    663,      5,      8,     14,    723,     23,    125,\n",
       "            465,      8,    876,    630,      6,    124,    285,      5,     31,\n",
       "            178,   9140,   1689,      5,    182,     22,     33,   1944,   1290,\n",
       "             10,    203,      7,     19,    101,      6,     66,     14,     46,\n",
       "           2524,     65,   4962,      8,     33,    280,    290,   3389,    127,\n",
       "              6,   1938,      9,    489,   1201,      7,  52468,  11394,    360,\n",
       "              5,  52468,  11394,   1141,     14,     40,  12714,      5,     38,\n",
       "             11,   2184,   4677,  10928,     22,      4,     84,     17,   1944,\n",
       "           1290,     14,    145,     10,    484,      6, 169397,     63,    469,\n",
       "              9,      4,   2336,     22,      4,    424,      7,  52468,     45,\n",
       "          40345,   2690,     20,      4,   2104,    118,      6,      2,      2,\n",
       "             12,     12,   7686,     12,     12,      2,      2,    149,     22,\n",
       "            441,      3,  11394,    259,      5,  52468,  11394,   1141,     26,\n",
       "             11,   6744,    296,     15,    551,     84,     98,    485,    350,\n",
       "            423,      7,     11,    411,   1240,      8,    350,    126,     10,\n",
       "           2824,    113,   1398,    395,      6,   6851,     39,    761,    112,\n",
       "           2153,    354,     15,    166,   6796,     22,   2802,    235,   8765,\n",
       "              5,     22,    429,   2835,   3565,    112,   3850,   1714,  18553,\n",
       "              8,   3565,    112,  90738,   2045,      6,     16,    346,  10302,\n",
       "            112,     11,    127,      7,   6748,   2824,      5,   2460,  15910,\n",
       "             21,   5605,     19,    128,     37,   8075,  29108,    112,      8,\n",
       "          38245,     21,     61,     39,  15910,      6,     16,    515,      9,\n",
       "            185,    331,   1065,     18,      4,   3808,   6221,   4053,     18,\n",
       "             33,   1171,    346,     17,   1447,     45,     71,     51,   3998,\n",
       "             26,   1158,      5,      4,     68,     26,   8882,    184,      9,\n",
       "              4,    346,      6,   7673,   2824,      5,      4,    346,    429,\n",
       "            684,     10,     11,   1724,      5,     98,    732,    128,     37,\n",
       "          28013,      8,    235,   1676,   2660,      6,  17135,      4,    272,\n",
       "            331,   2824,     39,    235,     15,   1569,   4432,   2824,   6680,\n",
       "              9,    355,   3588,    307,      6,    124,      4,     84,     17,\n",
       "           2883,      5,    810,    910,     39,  15910,      5,    105]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dataset[0][2].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"future\"]\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dataset = MonolingualDataset(\n",
    "            dataset=token_dataset,\n",
    "            sizes=dataset.sizes,\n",
    "            src_vocab=dictionary,\n",
    "            tgt_vocab=output_dictionary,\n",
    "            add_eos_for_other_targets=False,\n",
    "            shuffle=False,\n",
    "            # shuffle=True,\n",
    "            targets=targets,\n",
    "            add_bos_token=False,\n",
    "            fixed_pad_length=None,\n",
    "            pad_to_bsz=batch_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     2,      2,     12,  52468,  11394,   1141,     12,      2,      2,\n",
       "        158338,    129,  52468,     94,     45,      3,  11394,     25,    465,\n",
       "            45, 267683,      5,   6444,      6,  52468,      7,      4,  21647,\n",
       "            94,     24,      5,   1999,   1149,      9,     21,  52468,  11394,\n",
       "          1141,    757,    663,      5,     26,     11,   6744,    296,     15,\n",
       "           551,    290,     84,    436,     23,   5107,      8, 169397,     20,\n",
       "             4,   2104,  13920,      6,  10455,     10,    226,    310,     10,\n",
       "           663,      5,     31,     26,      4,    233,     84,     10,      4,\n",
       "         52468,    127,      6,  65394,      4,    161,   7432,      7,   6744,\n",
       "             8,    838,     15,     64,   2274,     21,     48,   7454,      5,\n",
       "             4,    331,    639,   2807,      9,      4,     42,     84,      8,\n",
       "          1763,      4,     13,  41313,     13,      5,     11,  23595,    411,\n",
       "          1240,   1795,      4,   1873,      7,  86993,     76,      4,   1037,\n",
       "        166355,    195,     54,   1857,   2357,    594,   1010,      8,     39,\n",
       "         13083,    113,      4,   2424,   1240,     13,      3,  11741,     13,\n",
       "             6,      2,     16,     84,    142,    424,     10,    288,      5,\n",
       "          2379,     74,     11,    213,   1412,      7,      4,    143,    994,\n",
       "            18,  52468,  11394,    360,      6,    370,     31,   2421,      4,\n",
       "          1257,    523,      7,      4,    127,      5,     31,     46,   4672,\n",
       "          1441,  17770,      5,     96,     21,    403,      4,     84,     69,\n",
       "         45644,     20,    127,  20004,      6,  12040,   3531,      3, 237830,\n",
       "             8,   2620,  51822,  38407,    125,    371,     28,    441,   8170,\n",
       "             5,    182,     22,  52468,  11394,    360,    720,  39953,  51883,\n",
       "             6,     77,    213,    131,      7,   1448,   4832,      4,   1291,\n",
       "             6,     16,     84,     17,    682,   1256,     14,   4664,     23,\n",
       "           186,  47260,      6,      2,     66,    708,     22,    752,   1201,\n",
       "            10,    663,      5,      8,     14,    723,     23,    125,    465,\n",
       "             8,    876,    630,      6,    124,    285,      5,     31,    178,\n",
       "          9140,   1689,      5,    182,     22,     33,   1944,   1290,     10,\n",
       "           203,      7,     19,    101,      6,     66,     14,     46,   2524,\n",
       "            65,   4962,      8,     33,    280,    290,   3389,    127,      6,\n",
       "          1938,      9,    489,   1201,      7,  52468,  11394,    360,      5,\n",
       "         52468,  11394,   1141,     14,     40,  12714,      5,     38,     11,\n",
       "          2184,   4677,  10928,     22,      4,     84,     17,   1944,   1290,\n",
       "            14,    145,     10,    484,      6, 169397,     63,    469,      9,\n",
       "             4,   2336,     22,      4,    424,      7,  52468,     45,  40345,\n",
       "          2690,     20,      4,   2104,    118,      6,      2,      2,     12,\n",
       "            12,   7686,     12,     12,      2,      2,    149,     22,    441,\n",
       "             3,  11394,    259,      5,  52468,  11394,   1141,     26,     11,\n",
       "          6744,    296,     15,    551,     84,     98,    485,    350,    423,\n",
       "             7,     11,    411,   1240,      8,    350,    126,     10,   2824,\n",
       "           113,   1398,    395,      6,   6851,     39,    761,    112,   2153,\n",
       "           354,     15,    166,   6796,     22,   2802,    235,   8765,      5,\n",
       "            22,    429,   2835,   3565,    112,   3850,   1714,  18553,      8,\n",
       "          3565,    112,  90738,   2045,      6,     16,    346,  10302,    112,\n",
       "            11,    127,      7,   6748,   2824,      5,   2460,  15910,     21,\n",
       "          5605,     19,    128,     37,   8075,  29108,    112,      8,  38245,\n",
       "            21,     61,     39,  15910,      6,     16,    515,      9,    185,\n",
       "           331,   1065,     18,      4,   3808,   6221,   4053,     18,     33,\n",
       "          1171,    346,     17,   1447,     45,     71,     51,   3998,     26,\n",
       "          1158,      5,      4,     68,     26,   8882,    184,      9,      4,\n",
       "           346,      6,   7673,   2824,      5,      4,    346,    429,    684,\n",
       "            10,     11,   1724,      5,     98,    732,    128,     37,  28013,\n",
       "             8,    235,   1676,   2660,      6,  17135,      4,    272,    331,\n",
       "          2824,     39,    235,     15,   1569,   4432,   2824,   6680,      9,\n",
       "           355,   3588,    307,      6,    124,      4,     84,     17,   2883,\n",
       "             5,    810,    910,     39,  15910,      5,    105,      7])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset[0][\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     2,     12,  52468,  11394,   1141,     12,      2,      2, 158338,\n",
       "           129,  52468,     94,     45,      3,  11394,     25,    465,     45,\n",
       "        267683,      5,   6444,      6,  52468,      7,      4,  21647,     94,\n",
       "            24,      5,   1999,   1149,      9,     21,  52468,  11394,   1141,\n",
       "           757,    663,      5,     26,     11,   6744,    296,     15,    551,\n",
       "           290,     84,    436,     23,   5107,      8, 169397,     20,      4,\n",
       "          2104,  13920,      6,  10455,     10,    226,    310,     10,    663,\n",
       "             5,     31,     26,      4,    233,     84,     10,      4,  52468,\n",
       "           127,      6,  65394,      4,    161,   7432,      7,   6744,      8,\n",
       "           838,     15,     64,   2274,     21,     48,   7454,      5,      4,\n",
       "           331,    639,   2807,      9,      4,     42,     84,      8,   1763,\n",
       "             4,     13,  41313,     13,      5,     11,  23595,    411,   1240,\n",
       "          1795,      4,   1873,      7,  86993,     76,      4,   1037, 166355,\n",
       "           195,     54,   1857,   2357,    594,   1010,      8,     39,  13083,\n",
       "           113,      4,   2424,   1240,     13,      3,  11741,     13,      6,\n",
       "             2,     16,     84,    142,    424,     10,    288,      5,   2379,\n",
       "            74,     11,    213,   1412,      7,      4,    143,    994,     18,\n",
       "         52468,  11394,    360,      6,    370,     31,   2421,      4,   1257,\n",
       "           523,      7,      4,    127,      5,     31,     46,   4672,   1441,\n",
       "         17770,      5,     96,     21,    403,      4,     84,     69,  45644,\n",
       "            20,    127,  20004,      6,  12040,   3531,      3, 237830,      8,\n",
       "          2620,  51822,  38407,    125,    371,     28,    441,   8170,      5,\n",
       "           182,     22,  52468,  11394,    360,    720,  39953,  51883,      6,\n",
       "            77,    213,    131,      7,   1448,   4832,      4,   1291,      6,\n",
       "            16,     84,     17,    682,   1256,     14,   4664,     23,    186,\n",
       "         47260,      6,      2,     66,    708,     22,    752,   1201,     10,\n",
       "           663,      5,      8,     14,    723,     23,    125,    465,      8,\n",
       "           876,    630,      6,    124,    285,      5,     31,    178,   9140,\n",
       "          1689,      5,    182,     22,     33,   1944,   1290,     10,    203,\n",
       "             7,     19,    101,      6,     66,     14,     46,   2524,     65,\n",
       "          4962,      8,     33,    280,    290,   3389,    127,      6,   1938,\n",
       "             9,    489,   1201,      7,  52468,  11394,    360,      5,  52468,\n",
       "         11394,   1141,     14,     40,  12714,      5,     38,     11,   2184,\n",
       "          4677,  10928,     22,      4,     84,     17,   1944,   1290,     14,\n",
       "           145,     10,    484,      6, 169397,     63,    469,      9,      4,\n",
       "          2336,     22,      4,    424,      7,  52468,     45,  40345,   2690,\n",
       "            20,      4,   2104,    118,      6,      2,      2,     12,     12,\n",
       "          7686,     12,     12,      2,      2,    149,     22,    441,      3,\n",
       "         11394,    259,      5,  52468,  11394,   1141,     26,     11,   6744,\n",
       "           296,     15,    551,     84,     98,    485,    350,    423,      7,\n",
       "            11,    411,   1240,      8,    350,    126,     10,   2824,    113,\n",
       "          1398,    395,      6,   6851,     39,    761,    112,   2153,    354,\n",
       "            15,    166,   6796,     22,   2802,    235,   8765,      5,     22,\n",
       "           429,   2835,   3565,    112,   3850,   1714,  18553,      8,   3565,\n",
       "           112,  90738,   2045,      6,     16,    346,  10302,    112,     11,\n",
       "           127,      7,   6748,   2824,      5,   2460,  15910,     21,   5605,\n",
       "            19,    128,     37,   8075,  29108,    112,      8,  38245,     21,\n",
       "            61,     39,  15910,      6,     16,    515,      9,    185,    331,\n",
       "          1065,     18,      4,   3808,   6221,   4053,     18,     33,   1171,\n",
       "           346,     17,   1447,     45,     71,     51,   3998,     26,   1158,\n",
       "             5,      4,     68,     26,   8882,    184,      9,      4,    346,\n",
       "             6,   7673,   2824,      5,      4,    346,    429,    684,     10,\n",
       "            11,   1724,      5,     98,    732,    128,     37,  28013,      8,\n",
       "           235,   1676,   2660,      6,  17135,      4,    272,    331,   2824,\n",
       "            39,    235,     15,   1569,   4432,   2824,   6680,      9,    355,\n",
       "          3588,    307,      6,    124,      4,     84,     17,   2883,      5,\n",
       "           810,    910,     39,  15910,      5,    105,      7,    107])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset[0][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=lm_dataset, collate_fn=lm_dataset.collater,\n",
    "                              shuffle=False, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': tensor([0, 1, 2]), 'nsentences': 3, 'ntokens': 1536, 'net_input': {'src_tokens': tensor([[     2,      2,     12,  ...,      5,    105,      7],\n",
      "        [   107,    333,     11,  ...,      4,   2855,      5],\n",
      "        [ 15584,     23,     43,  ..., 201798,      8,  12003],\n",
      "        ...,\n",
      "        [     1,      1,      1,  ...,      1,      1,      1],\n",
      "        [     1,      1,      1,  ...,      1,      1,      1],\n",
      "        [     1,      1,      1,  ...,      1,      1,      1]]), 'src_lengths': tensor([512, 512, 512])}, 'target': tensor([[    2,    12, 52468,  ...,   105,     7,   107],\n",
      "        [  333,    11,   977,  ...,  2855,     5, 15584],\n",
      "        [   23,    43, 11484,  ...,     8, 12003,     4],\n",
      "        ...,\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1],\n",
      "        [    1,     1,     1,  ...,     1,     1,     1]])}\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_dataloader):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     2,      2,     12,  ...,      5,    105,      7],\n",
       "        [   107,    333,     11,  ...,      4,   2855,      5],\n",
       "        [ 15584,     23,     43,  ..., 201798,      8,  12003],\n",
       "        ...,\n",
       "        [     1,      1,      1,  ...,      1,      1,      1],\n",
       "        [     1,      1,      1,  ...,      1,      1,      1],\n",
       "        [     1,      1,      1,  ...,      1,      1,      1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['net_input']['src_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,    12, 52468,  ...,   105,     7,   107],\n",
       "        [  333,    11,   977,  ...,  2855,     5, 15584],\n",
       "        [   23,    43, 11484,  ...,     8, 12003,     4],\n",
       "        ...,\n",
       "        [    1,     1,     1,  ...,     1,     1,     1],\n",
       "        [    1,     1,     1,  ...,     1,     1,     1],\n",
       "        [    1,     1,     1,  ...,     1,     1,     1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 512])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['net_input']['src_tokens'].size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq.models.transformer_lm import TransformerLanguageModel, transformer_lm_baevski_wiki103\n",
    "from fairseq.tasks.language_modeling import LanguageModelingTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = options.get_parser(\"Model\", default_task='language_modeling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_lm_baevski_wiki103(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': None,\n",
       " 'argument_default': None,\n",
       " 'prefix_chars': '-',\n",
       " 'conflict_handler': 'error',\n",
       " '_registries': {'action': {None: argparse._StoreAction,\n",
       "   'store': argparse._StoreAction,\n",
       "   'store_const': argparse._StoreConstAction,\n",
       "   'store_true': argparse._StoreTrueAction,\n",
       "   'store_false': argparse._StoreFalseAction,\n",
       "   'append': argparse._AppendAction,\n",
       "   'append_const': argparse._AppendConstAction,\n",
       "   'count': argparse._CountAction,\n",
       "   'help': argparse._HelpAction,\n",
       "   'version': argparse._VersionAction,\n",
       "   'parsers': argparse._SubParsersAction,\n",
       "   'extend': argparse._ExtendAction},\n",
       "  'type': {None: <function argparse.ArgumentParser.__init__.<locals>.identity(string)>}},\n",
       " '_actions': [_HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--no-progress-bar'], dest='no_progress_bar', nargs=0, const=True, default=False, type=None, choices=None, help='disable progress bar', metavar=None),\n",
       "  _StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='log progress every N batches (when progress bar is disabled)', metavar=None),\n",
       "  _StoreAction(option_strings=['--log-format'], dest='log_format', nargs=None, const=None, default=None, type=<class 'str'>, choices=['json', 'none', 'simple', 'tqdm'], help='log format to use', metavar=None),\n",
       "  _StoreAction(option_strings=['--log-file'], dest='log_file', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='log file to copy metrics to.', metavar=None),\n",
       "  _StoreAction(option_strings=['--aim-repo'], dest='aim_repo', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to Aim repository', metavar=None),\n",
       "  _StoreAction(option_strings=['--aim-run-hash'], dest='aim_run_hash', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Aim run hash. If skipped, creates or continues run based on save_dir', metavar=None),\n",
       "  _StoreAction(option_strings=['--tensorboard-logdir'], dest='tensorboard_logdir', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to save logs for tensorboard, should match --logdir of running tensorboard (default: no tensorboard logging)', metavar=None),\n",
       "  _StoreAction(option_strings=['--wandb-project'], dest='wandb_project', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Weights and Biases project name to use for logging', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--azureml-logging'], dest='azureml_logging', nargs=0, const=True, default=False, type=None, choices=None, help='Log scalars to AzureML context', metavar=None),\n",
       "  _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='pseudo random number generator seed', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--cpu'], dest='cpu', nargs=0, const=True, default=False, type=None, choices=None, help='use CPU instead of CUDA', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--tpu'], dest='tpu', nargs=0, const=True, default=False, type=None, choices=None, help='use TPU instead of CUDA', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--bf16'], dest='bf16', nargs=0, const=True, default=False, type=None, choices=None, help='use bfloat16; implies --tpu', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--memory-efficient-bf16'], dest='memory_efficient_bf16', nargs=0, const=True, default=False, type=None, choices=None, help='use a memory-efficient version of BF16 training; implies --bf16', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--fp16'], dest='fp16', nargs=0, const=True, default=False, type=None, choices=None, help='use FP16', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--memory-efficient-fp16'], dest='memory_efficient_fp16', nargs=0, const=True, default=False, type=None, choices=None, help='use a memory-efficient version of FP16 training; implies --fp16', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--fp16-no-flatten-grads'], dest='fp16_no_flatten_grads', nargs=0, const=True, default=False, type=None, choices=None, help=\"don't flatten FP16 grads tensor\", metavar=None),\n",
       "  _StoreAction(option_strings=['--fp16-init-scale'], dest='fp16_init_scale', nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='default FP16 loss scale', metavar=None),\n",
       "  _StoreAction(option_strings=['--fp16-scale-window'], dest='fp16_scale_window', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='number of updates before increasing loss scale', metavar=None),\n",
       "  _StoreAction(option_strings=['--fp16-scale-tolerance'], dest='fp16_scale_tolerance', nargs=None, const=None, default=0.0, type=<class 'float'>, choices=None, help='pct of updates that can overflow before decreasing the loss scale', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--on-cpu-convert-precision'], dest='on_cpu_convert_precision', nargs=0, const=True, default=False, type=None, choices=None, help='if set, the floating point conversion to fp16/bf16 runs on CPU. This reduces bus transfer time and GPU memory usage.', metavar=None),\n",
       "  _StoreAction(option_strings=['--min-loss-scale'], dest='min_loss_scale', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='minimum FP16/AMP loss scale, after which training is stopped', metavar=None),\n",
       "  _StoreAction(option_strings=['--threshold-loss-scale'], dest='threshold_loss_scale', nargs=None, const=None, default=None, type=<class 'float'>, choices=None, help='threshold FP16 loss scale from below', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--amp'], dest='amp', nargs=0, const=True, default=False, type=None, choices=None, help='use automatic mixed precision', metavar=None),\n",
       "  _StoreAction(option_strings=['--amp-batch-retries'], dest='amp_batch_retries', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, help='number of retries of same batch after reducing loss scale with AMP', metavar=None),\n",
       "  _StoreAction(option_strings=['--amp-init-scale'], dest='amp_init_scale', nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='default AMP loss scale', metavar=None),\n",
       "  _StoreAction(option_strings=['--amp-scale-window'], dest='amp_scale_window', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='number of updates before increasing AMP loss scale', metavar=None),\n",
       "  _StoreAction(option_strings=['--user-dir'], dest='user_dir', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to a python module containing custom extensions (tasks and/or architectures)', metavar=None),\n",
       "  _StoreAction(option_strings=['--empty-cache-freq'], dest='empty_cache_freq', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='how often to clear the PyTorch CUDA cache (0 to disable)', metavar=None),\n",
       "  _StoreAction(option_strings=['--all-gather-list-size'], dest='all_gather_list_size', nargs=None, const=None, default=16384, type=<class 'int'>, choices=None, help='number of bytes reserved for gathering stats from workers', metavar=None),\n",
       "  _StoreAction(option_strings=['--model-parallel-size'], dest='model_parallel_size', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='total number of GPUs to parallelize model over', metavar=None),\n",
       "  _StoreAction(option_strings=['--quantization-config-path'], dest='quantization_config_path', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to quantization config file', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--profile'], dest='profile', nargs=0, const=True, default=False, type=None, choices=None, help='enable autograd profiler emit_nvtx', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--reset-logging'], dest='reset_logging', nargs=0, const=True, default=False, type=None, choices=None, help='when using Hydra, reset the logging at the beginning of training', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--suppress-crashes'], dest='suppress_crashes', nargs=0, const=True, default=False, type=None, choices=None, help='suppress crashes when training with the hydra_train entry point so that the main method can return a value (useful for sweeps)', metavar=None),\n",
       "  _StoreTrueAction(option_strings=['--use-plasma-view'], dest='use_plasma_view', nargs=0, const=True, default=False, type=None, choices=None, help='Store indices and sizes in shared memory', metavar=None),\n",
       "  _StoreAction(option_strings=['--plasma-path'], dest='plasma_path', nargs=None, const=None, default='/tmp/plasma', type=<class 'str'>, choices=None, help='path to run plasma_store, defaults to /tmp/plasma. Paths outside /tmp tend to fail.', metavar=None),\n",
       "  _StoreAction(option_strings=['--criterion'], dest='criterion', nargs=None, const=None, default='cross_entropy', type=None, choices=dict_keys(['adaptive_loss', 'composite_loss', 'cross_entropy', 'ctc', 'fastspeech2', 'hubert', 'label_smoothed_cross_entropy', 'latency_augmented_label_smoothed_cross_entropy', 'label_smoothed_cross_entropy_with_alignment', 'label_smoothed_cross_entropy_with_ctc', 'legacy_masked_lm_loss', 'masked_lm', 'model', 'nat_loss', 'sentence_prediction', 'sentence_prediction_adapters', 'sentence_ranking', 'tacotron2', 'speech_to_unit', 'speech_to_spectrogram', 'speech_unit_lm_criterion', 'wav2vec', 'vocab_parallel_cross_entropy']), help=None, metavar=None),\n",
       "  _StoreAction(option_strings=['--tokenizer'], dest='tokenizer', nargs=None, const=None, default=None, type=None, choices=dict_keys(['moses', 'nltk', 'space']), help=None, metavar=None),\n",
       "  _StoreAction(option_strings=['--bpe'], dest='bpe', nargs=None, const=None, default=None, type=None, choices=dict_keys(['byte_bpe', 'bytes', 'characters', 'fastbpe', 'gpt2', 'bert', 'hf_byte_bpe', 'sentencepiece', 'subword_nmt']), help=None, metavar=None),\n",
       "  _StoreAction(option_strings=['--optimizer'], dest='optimizer', nargs=None, const=None, default=None, type=None, choices=dict_keys(['adadelta', 'adafactor', 'adagrad', 'adam', 'adamax', 'composite', 'cpu_adam', 'lamb', 'nag', 'sgd']), help=None, metavar=None),\n",
       "  _StoreAction(option_strings=['--lr-scheduler'], dest='lr_scheduler', nargs=None, const=None, default='fixed', type=None, choices=dict_keys(['cosine', 'fixed', 'inverse_sqrt', 'manual', 'pass_through', 'polynomial_decay', 'reduce_lr_on_plateau', 'step', 'tri_stage', 'triangular']), help=None, metavar=None),\n",
       "  _StoreAction(option_strings=['--scoring'], dest='scoring', nargs=None, const=None, default='bleu', type=None, choices=dict_keys(['bert_score', 'sacrebleu', 'bleu', 'chrf', 'meteor', 'wer']), help=None, metavar=None),\n",
       "  _StoreAction(option_strings=['--task'], dest='task', nargs=None, const=None, default='language_modeling', type=None, choices=dict_keys(['multilingual_masked_lm', 'translation', 'translation_lev', 'translation_multi_simple_epoch', 'speech_unit_modeling', 'hubert_pretraining', 'multilingual_translation', 'language_modeling', 'masked_lm', 'audio_pretraining', 'audio_finetuning', 'multilingual_language_modeling', 'speech_to_text', 'simul_speech_to_text', 'simul_text_to_text', 'legacy_masked_lm', 'sentence_prediction', 'translation_from_pretrained_xlm', 'text_to_speech', 'translation_from_pretrained_bart', 'denoising', 'multilingual_denoising', 'frm_text_to_speech', 'sentence_prediction_adapters', 'online_backtranslation', 'cross_lingual_lm', 'sentence_ranking', 'semisupervised_translation', 'speech_to_speech', 'dummy_lm', 'dummy_masked_lm', 'dummy_mt']), help='task', metavar='TASK')],\n",
       " '_option_string_actions': {'-h': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  '--help': _HelpAction(option_strings=['-h', '--help'], dest='help', nargs=0, const=None, default='==SUPPRESS==', type=None, choices=None, help='show this help message and exit', metavar=None),\n",
       "  '--no-progress-bar': _StoreTrueAction(option_strings=['--no-progress-bar'], dest='no_progress_bar', nargs=0, const=True, default=False, type=None, choices=None, help='disable progress bar', metavar=None),\n",
       "  '--log-interval': _StoreAction(option_strings=['--log-interval'], dest='log_interval', nargs=None, const=None, default=100, type=<class 'int'>, choices=None, help='log progress every N batches (when progress bar is disabled)', metavar=None),\n",
       "  '--log-format': _StoreAction(option_strings=['--log-format'], dest='log_format', nargs=None, const=None, default=None, type=<class 'str'>, choices=['json', 'none', 'simple', 'tqdm'], help='log format to use', metavar=None),\n",
       "  '--log-file': _StoreAction(option_strings=['--log-file'], dest='log_file', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='log file to copy metrics to.', metavar=None),\n",
       "  '--aim-repo': _StoreAction(option_strings=['--aim-repo'], dest='aim_repo', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to Aim repository', metavar=None),\n",
       "  '--aim-run-hash': _StoreAction(option_strings=['--aim-run-hash'], dest='aim_run_hash', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Aim run hash. If skipped, creates or continues run based on save_dir', metavar=None),\n",
       "  '--tensorboard-logdir': _StoreAction(option_strings=['--tensorboard-logdir'], dest='tensorboard_logdir', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to save logs for tensorboard, should match --logdir of running tensorboard (default: no tensorboard logging)', metavar=None),\n",
       "  '--wandb-project': _StoreAction(option_strings=['--wandb-project'], dest='wandb_project', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='Weights and Biases project name to use for logging', metavar=None),\n",
       "  '--azureml-logging': _StoreTrueAction(option_strings=['--azureml-logging'], dest='azureml_logging', nargs=0, const=True, default=False, type=None, choices=None, help='Log scalars to AzureML context', metavar=None),\n",
       "  '--seed': _StoreAction(option_strings=['--seed'], dest='seed', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='pseudo random number generator seed', metavar=None),\n",
       "  '--cpu': _StoreTrueAction(option_strings=['--cpu'], dest='cpu', nargs=0, const=True, default=False, type=None, choices=None, help='use CPU instead of CUDA', metavar=None),\n",
       "  '--tpu': _StoreTrueAction(option_strings=['--tpu'], dest='tpu', nargs=0, const=True, default=False, type=None, choices=None, help='use TPU instead of CUDA', metavar=None),\n",
       "  '--bf16': _StoreTrueAction(option_strings=['--bf16'], dest='bf16', nargs=0, const=True, default=False, type=None, choices=None, help='use bfloat16; implies --tpu', metavar=None),\n",
       "  '--memory-efficient-bf16': _StoreTrueAction(option_strings=['--memory-efficient-bf16'], dest='memory_efficient_bf16', nargs=0, const=True, default=False, type=None, choices=None, help='use a memory-efficient version of BF16 training; implies --bf16', metavar=None),\n",
       "  '--fp16': _StoreTrueAction(option_strings=['--fp16'], dest='fp16', nargs=0, const=True, default=False, type=None, choices=None, help='use FP16', metavar=None),\n",
       "  '--memory-efficient-fp16': _StoreTrueAction(option_strings=['--memory-efficient-fp16'], dest='memory_efficient_fp16', nargs=0, const=True, default=False, type=None, choices=None, help='use a memory-efficient version of FP16 training; implies --fp16', metavar=None),\n",
       "  '--fp16-no-flatten-grads': _StoreTrueAction(option_strings=['--fp16-no-flatten-grads'], dest='fp16_no_flatten_grads', nargs=0, const=True, default=False, type=None, choices=None, help=\"don't flatten FP16 grads tensor\", metavar=None),\n",
       "  '--fp16-init-scale': _StoreAction(option_strings=['--fp16-init-scale'], dest='fp16_init_scale', nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='default FP16 loss scale', metavar=None),\n",
       "  '--fp16-scale-window': _StoreAction(option_strings=['--fp16-scale-window'], dest='fp16_scale_window', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='number of updates before increasing loss scale', metavar=None),\n",
       "  '--fp16-scale-tolerance': _StoreAction(option_strings=['--fp16-scale-tolerance'], dest='fp16_scale_tolerance', nargs=None, const=None, default=0.0, type=<class 'float'>, choices=None, help='pct of updates that can overflow before decreasing the loss scale', metavar=None),\n",
       "  '--on-cpu-convert-precision': _StoreTrueAction(option_strings=['--on-cpu-convert-precision'], dest='on_cpu_convert_precision', nargs=0, const=True, default=False, type=None, choices=None, help='if set, the floating point conversion to fp16/bf16 runs on CPU. This reduces bus transfer time and GPU memory usage.', metavar=None),\n",
       "  '--min-loss-scale': _StoreAction(option_strings=['--min-loss-scale'], dest='min_loss_scale', nargs=None, const=None, default=0.0001, type=<class 'float'>, choices=None, help='minimum FP16/AMP loss scale, after which training is stopped', metavar=None),\n",
       "  '--threshold-loss-scale': _StoreAction(option_strings=['--threshold-loss-scale'], dest='threshold_loss_scale', nargs=None, const=None, default=None, type=<class 'float'>, choices=None, help='threshold FP16 loss scale from below', metavar=None),\n",
       "  '--amp': _StoreTrueAction(option_strings=['--amp'], dest='amp', nargs=0, const=True, default=False, type=None, choices=None, help='use automatic mixed precision', metavar=None),\n",
       "  '--amp-batch-retries': _StoreAction(option_strings=['--amp-batch-retries'], dest='amp_batch_retries', nargs=None, const=None, default=2, type=<class 'int'>, choices=None, help='number of retries of same batch after reducing loss scale with AMP', metavar=None),\n",
       "  '--amp-init-scale': _StoreAction(option_strings=['--amp-init-scale'], dest='amp_init_scale', nargs=None, const=None, default=128, type=<class 'int'>, choices=None, help='default AMP loss scale', metavar=None),\n",
       "  '--amp-scale-window': _StoreAction(option_strings=['--amp-scale-window'], dest='amp_scale_window', nargs=None, const=None, default=None, type=<class 'int'>, choices=None, help='number of updates before increasing AMP loss scale', metavar=None),\n",
       "  '--user-dir': _StoreAction(option_strings=['--user-dir'], dest='user_dir', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to a python module containing custom extensions (tasks and/or architectures)', metavar=None),\n",
       "  '--empty-cache-freq': _StoreAction(option_strings=['--empty-cache-freq'], dest='empty_cache_freq', nargs=None, const=None, default=0, type=<class 'int'>, choices=None, help='how often to clear the PyTorch CUDA cache (0 to disable)', metavar=None),\n",
       "  '--all-gather-list-size': _StoreAction(option_strings=['--all-gather-list-size'], dest='all_gather_list_size', nargs=None, const=None, default=16384, type=<class 'int'>, choices=None, help='number of bytes reserved for gathering stats from workers', metavar=None),\n",
       "  '--model-parallel-size': _StoreAction(option_strings=['--model-parallel-size'], dest='model_parallel_size', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='total number of GPUs to parallelize model over', metavar=None),\n",
       "  '--quantization-config-path': _StoreAction(option_strings=['--quantization-config-path'], dest='quantization_config_path', nargs=None, const=None, default=None, type=<class 'str'>, choices=None, help='path to quantization config file', metavar=None),\n",
       "  '--profile': _StoreTrueAction(option_strings=['--profile'], dest='profile', nargs=0, const=True, default=False, type=None, choices=None, help='enable autograd profiler emit_nvtx', metavar=None),\n",
       "  '--reset-logging': _StoreTrueAction(option_strings=['--reset-logging'], dest='reset_logging', nargs=0, const=True, default=False, type=None, choices=None, help='when using Hydra, reset the logging at the beginning of training', metavar=None),\n",
       "  '--suppress-crashes': _StoreTrueAction(option_strings=['--suppress-crashes'], dest='suppress_crashes', nargs=0, const=True, default=False, type=None, choices=None, help='suppress crashes when training with the hydra_train entry point so that the main method can return a value (useful for sweeps)', metavar=None),\n",
       "  '--use-plasma-view': _StoreTrueAction(option_strings=['--use-plasma-view'], dest='use_plasma_view', nargs=0, const=True, default=False, type=None, choices=None, help='Store indices and sizes in shared memory', metavar=None),\n",
       "  '--plasma-path': _StoreAction(option_strings=['--plasma-path'], dest='plasma_path', nargs=None, const=None, default='/tmp/plasma', type=<class 'str'>, choices=None, help='path to run plasma_store, defaults to /tmp/plasma. Paths outside /tmp tend to fail.', metavar=None),\n",
       "  '--criterion': _StoreAction(option_strings=['--criterion'], dest='criterion', nargs=None, const=None, default='cross_entropy', type=None, choices=dict_keys(['adaptive_loss', 'composite_loss', 'cross_entropy', 'ctc', 'fastspeech2', 'hubert', 'label_smoothed_cross_entropy', 'latency_augmented_label_smoothed_cross_entropy', 'label_smoothed_cross_entropy_with_alignment', 'label_smoothed_cross_entropy_with_ctc', 'legacy_masked_lm_loss', 'masked_lm', 'model', 'nat_loss', 'sentence_prediction', 'sentence_prediction_adapters', 'sentence_ranking', 'tacotron2', 'speech_to_unit', 'speech_to_spectrogram', 'speech_unit_lm_criterion', 'wav2vec', 'vocab_parallel_cross_entropy']), help=None, metavar=None),\n",
       "  '--tokenizer': _StoreAction(option_strings=['--tokenizer'], dest='tokenizer', nargs=None, const=None, default=None, type=None, choices=dict_keys(['moses', 'nltk', 'space']), help=None, metavar=None),\n",
       "  '--bpe': _StoreAction(option_strings=['--bpe'], dest='bpe', nargs=None, const=None, default=None, type=None, choices=dict_keys(['byte_bpe', 'bytes', 'characters', 'fastbpe', 'gpt2', 'bert', 'hf_byte_bpe', 'sentencepiece', 'subword_nmt']), help=None, metavar=None),\n",
       "  '--optimizer': _StoreAction(option_strings=['--optimizer'], dest='optimizer', nargs=None, const=None, default=None, type=None, choices=dict_keys(['adadelta', 'adafactor', 'adagrad', 'adam', 'adamax', 'composite', 'cpu_adam', 'lamb', 'nag', 'sgd']), help=None, metavar=None),\n",
       "  '--lr-scheduler': _StoreAction(option_strings=['--lr-scheduler'], dest='lr_scheduler', nargs=None, const=None, default='fixed', type=None, choices=dict_keys(['cosine', 'fixed', 'inverse_sqrt', 'manual', 'pass_through', 'polynomial_decay', 'reduce_lr_on_plateau', 'step', 'tri_stage', 'triangular']), help=None, metavar=None),\n",
       "  '--scoring': _StoreAction(option_strings=['--scoring'], dest='scoring', nargs=None, const=None, default='bleu', type=None, choices=dict_keys(['bert_score', 'sacrebleu', 'bleu', 'chrf', 'meteor', 'wer']), help=None, metavar=None),\n",
       "  '--task': _StoreAction(option_strings=['--task'], dest='task', nargs=None, const=None, default='language_modeling', type=None, choices=dict_keys(['multilingual_masked_lm', 'translation', 'translation_lev', 'translation_multi_simple_epoch', 'speech_unit_modeling', 'hubert_pretraining', 'multilingual_translation', 'language_modeling', 'masked_lm', 'audio_pretraining', 'audio_finetuning', 'multilingual_language_modeling', 'speech_to_text', 'simul_speech_to_text', 'simul_text_to_text', 'legacy_masked_lm', 'sentence_prediction', 'translation_from_pretrained_xlm', 'text_to_speech', 'translation_from_pretrained_bart', 'denoising', 'multilingual_denoising', 'frm_text_to_speech', 'sentence_prediction_adapters', 'online_backtranslation', 'cross_lingual_lm', 'sentence_ranking', 'semisupervised_translation', 'speech_to_speech', 'dummy_lm', 'dummy_masked_lm', 'dummy_mt']), help='task', metavar='TASK')},\n",
       " '_action_groups': [<argparse._ArgumentGroup at 0x7f3c8ec11a00>,\n",
       "  <argparse._ArgumentGroup at 0x7f3c8ec11220>],\n",
       " '_mutually_exclusive_groups': [],\n",
       " '_defaults': {},\n",
       " '_negative_number_matcher': re.compile(r'^-\\d+$|^-\\d*\\.\\d+$', re.UNICODE),\n",
       " '_has_negative_number_optionals': [],\n",
       " 'prog': 'ipykernel_launcher.py',\n",
       " 'usage': None,\n",
       " 'epilog': None,\n",
       " 'formatter_class': argparse.HelpFormatter,\n",
       " 'fromfile_prefix_chars': None,\n",
       " 'add_help': True,\n",
       " 'allow_abbrev': False,\n",
       " 'exit_on_error': True,\n",
       " '_positionals': <argparse._ArgumentGroup at 0x7f3c8ec11a00>,\n",
       " '_optionals': <argparse._ArgumentGroup at 0x7f3c8ec11220>,\n",
       " '_subparsers': None,\n",
       " 'decoder_layers': 16,\n",
       " 'decoder_attention_heads': 8,\n",
       " 'dropout': 0.3,\n",
       " 'adaptive_input': True,\n",
       " 'tie_adaptive_weights': True,\n",
       " 'adaptive_input_cutoff': '20000,60000',\n",
       " 'adaptive_softmax_cutoff': '20000,60000',\n",
       " 'adaptive_softmax_dropout': 0.2,\n",
       " 'attention_dropout': 0.1,\n",
       " 'activation_dropout': 0.1,\n",
       " 'no_decoder_final_norm': True,\n",
       " 'tie_adaptive_proj': True,\n",
       " 'decoder_embed_dim': 1024,\n",
       " 'decoder_ffn_embed_dim': 4096,\n",
       " 'adaptive_softmax_factor': 4,\n",
       " 'decoder_learned_pos': False,\n",
       " 'activation_fn': 'relu',\n",
       " 'decoder_layerdrop': 0,\n",
       " 'decoder_layers_to_keep': None,\n",
       " 'quant_noise_pq': 0,\n",
       " 'quant_noise_pq_block_size': 8,\n",
       " 'quant_noise_scalar': 0,\n",
       " 'base_layers': 0,\n",
       " 'base_sublayers': 1,\n",
       " 'base_shuffle': False,\n",
       " 'add_bos_token': False,\n",
       " 'no_token_positional_embeddings': False,\n",
       " 'share_decoder_input_output_embed': False,\n",
       " 'character_embeddings': False,\n",
       " 'decoder_output_dim': 1024,\n",
       " 'decoder_input_dim': 1024,\n",
       " 'decoder_normalize_before': True,\n",
       " 'adaptive_input_factor': 4,\n",
       " 'no_scale_embedding': False,\n",
       " 'layernorm_embedding': False,\n",
       " 'checkpoint_activations': False,\n",
       " 'offload_activations': False,\n",
       " 'scale_fc': False,\n",
       " 'scale_attn': False,\n",
       " 'scale_heads': False,\n",
       " 'scale_resids': False}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/dl/fairseq/Language_Model/wikitext-103-v1/wikitext-103/data_bin/train'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data = preprocessed_dataset\n",
    "args.output_dictionary_size = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 16:52:11 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n"
     ]
    }
   ],
   "source": [
    "task = LanguageModelingTask.setup_task(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerLanguageModel.build_model(model_args, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerLanguageModel(\n",
       "  (decoder): TransformerDecoder(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (embed_tokens): AdaptiveInput(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Embedding(20000, 1024, padding_idx=1)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Embedding(40000, 256)\n",
       "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Embedding(207744, 64)\n",
       "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x TransformerDecoderLayerBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (adaptive_softmax): AdaptiveSoftmax(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (lsm): LogSoftmax(dim=1)\n",
       "      (head): TiedHeadModule(\n",
       "        (word_proj): TiedLinear()\n",
       "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
       "      )\n",
       "      (tail): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): TiedLinear()\n",
       "          (1): Dropout(p=0.2, inplace=False)\n",
       "          (2): TiedLinear()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerLanguageModel(\n",
       "  (decoder): TransformerDecoder(\n",
       "    (dropout_module): FairseqDropout()\n",
       "    (embed_tokens): AdaptiveInput(\n",
       "      (embeddings): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Embedding(20000, 1024, padding_idx=1)\n",
       "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Embedding(40000, 256)\n",
       "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Embedding(207744, 64)\n",
       "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (embed_positions): SinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x TransformerDecoderLayerBase(\n",
       "        (dropout_module): FairseqDropout()\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (dropout_module): FairseqDropout()\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_dropout_module): FairseqDropout()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (adaptive_softmax): AdaptiveSoftmax(\n",
       "      (dropout_module): FairseqDropout()\n",
       "      (lsm): LogSoftmax(dim=1)\n",
       "      (head): TiedHeadModule(\n",
       "        (word_proj): TiedLinear()\n",
       "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
       "      )\n",
       "      (tail): ModuleList(\n",
       "        (0-1): 2 x Sequential(\n",
       "          (0): TiedLinear()\n",
       "          (1): Dropout(p=0.2, inplace=False)\n",
       "          (2): TiedLinear()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env_nlp/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model(batch['net_input']['src_tokens'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
