{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import io\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import codecs\n",
    "from sentencepiece import SentencePieceProcessor, SentencePieceTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bsd_ja_en\n",
    "ja_fname = os.path.join(\"/mnt/dl/NLP/bsd_ja_en/data/train.ja\")\n",
    "en_fname = os.path.join(\"/mnt/dl/NLP/bsd_ja_en/data/train.en\")\n",
    "savepath = os.path.join(\"/mnt/dl/NLP/bsd_ja_en/data/sentencepiece\")\n",
    "os.makedirs(savepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = tempfile.NamedTemporaryFile(mode=\"w+\", suffix=\".en-ja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmpg7624l8y.en-ja'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /mnt/dl/NLP/bsd_ja_en/data/train.en\n",
      "  input_format: \n",
      "  model_prefix: \n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1024\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: /mnt/dl/NLP/bsd_ja_en/data/train.en\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 20000 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=990025\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9554% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=64\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999554\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 20000 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=527484\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 25119 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 20000\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 15096\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 15096 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=8734 obj=10.2656 num_tokens=29842 num_tokens/piece=3.41676\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=7252 obj=8.09481 num_tokens=29997 num_tokens/piece=4.13638\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5439 obj=8.10092 num_tokens=32583 num_tokens/piece=5.99062\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5435 obj=8.07342 num_tokens=32591 num_tokens/piece=5.9965\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4076 obj=8.24162 num_tokens=36482 num_tokens/piece=8.95044\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4076 obj=8.2052 num_tokens=36477 num_tokens/piece=8.94921\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3057 obj=8.43358 num_tokens=41332 num_tokens/piece=13.5204\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3057 obj=8.38661 num_tokens=41330 num_tokens/piece=13.5198\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2292 obj=8.6813 num_tokens=46743 num_tokens/piece=20.394\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2292 obj=8.6317 num_tokens=46744 num_tokens/piece=20.3944\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1719 obj=8.99988 num_tokens=52727 num_tokens/piece=30.6731\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1719 obj=8.94289 num_tokens=52726 num_tokens/piece=30.6725\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1289 obj=9.38271 num_tokens=58536 num_tokens/piece=45.4119\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1289 obj=9.31594 num_tokens=58541 num_tokens/piece=45.4158\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=1126 obj=9.52682 num_tokens=61395 num_tokens/piece=54.5249\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=1126 obj=9.49609 num_tokens=61395 num_tokens/piece=54.5249\n"
     ]
    }
   ],
   "source": [
    "en_model_fname = os.path.join(savepath, \"train.en.m\")\n",
    "en_writer = codecs.open(en_model_fname, \"wb\")\n",
    "en_spm = SentencePieceTrainer.train(input=en_fname, \n",
    "                                    vocab_size=1024, \n",
    "                                    model_writer=en_writer\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sp = SentencePieceProcessor(model_file=en_model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7f64a8440f00> >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.bos_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.unk_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(en_fname, \"r\") as f:\n",
    "    sent = f.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So let's pretend we have to export a product to Japan today.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.get_piece_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.GetPieceSize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.PieceToId(\"unk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.PieceToId(\"bos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.PieceToId(\"<s>\"), en_sp.PieceToId(\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.PieceToId(\"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.IdToPiece(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‚ñÅOh'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.IdToPiece(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.PieceToId(\"‚ñÅgo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict()\n",
    "for i in range(en_sp.get_piece_size()): \n",
    "    vocab[en_sp.IdToPiece(i)] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '00',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '9',\n",
       " '</s>',\n",
       " '<s>',\n",
       " '<unk>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'able',\n",
       " 'ac',\n",
       " 'ack',\n",
       " 'age',\n",
       " 'ake',\n",
       " 'al',\n",
       " 'ally',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ance',\n",
       " 'ant',\n",
       " 'ar',\n",
       " 'ashi',\n",
       " 'ate',\n",
       " 'ation',\n",
       " 'ative',\n",
       " 'b',\n",
       " 'body',\n",
       " 'c',\n",
       " 'ccording',\n",
       " 'ce',\n",
       " 'cha',\n",
       " 'chi',\n",
       " 'clock',\n",
       " 'com',\n",
       " 'ctual',\n",
       " 'd',\n",
       " 'dditional',\n",
       " 'e',\n",
       " 'ec',\n",
       " 'ed',\n",
       " 'el',\n",
       " 'en',\n",
       " 'end',\n",
       " 'ent',\n",
       " 'er',\n",
       " 'ers',\n",
       " 'es',\n",
       " 'ever',\n",
       " 'f',\n",
       " 'fully',\n",
       " 'g',\n",
       " 'ge',\n",
       " 'giving',\n",
       " 'h',\n",
       " 'ha',\n",
       " 'house',\n",
       " 'i',\n",
       " 'ic',\n",
       " 'id',\n",
       " 'ies',\n",
       " 'if',\n",
       " 'ight',\n",
       " 'il',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'in',\n",
       " 'ing',\n",
       " 'ion',\n",
       " 'ir',\n",
       " 'is',\n",
       " 'ite',\n",
       " 'ity',\n",
       " 'ive',\n",
       " 'ize',\n",
       " 'j',\n",
       " 'k',\n",
       " 'ki',\n",
       " 'l',\n",
       " 'la',\n",
       " 'le',\n",
       " 'less',\n",
       " 'li',\n",
       " 'll',\n",
       " 'lo',\n",
       " 'ly',\n",
       " 'm',\n",
       " 'mail',\n",
       " 'ment',\n",
       " 'n',\n",
       " 'nce',\n",
       " 'ne',\n",
       " 'o',\n",
       " 'ock',\n",
       " 'ok',\n",
       " 'ol',\n",
       " 'on',\n",
       " 'op',\n",
       " 'or',\n",
       " 'ose',\n",
       " 'ough',\n",
       " 'ous',\n",
       " 'out',\n",
       " 'ow',\n",
       " 'p',\n",
       " 'per',\n",
       " 'q',\n",
       " 'r',\n",
       " 'ra',\n",
       " 're',\n",
       " 'related',\n",
       " 'round',\n",
       " 'ry',\n",
       " 's',\n",
       " 'san',\n",
       " 'sh',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'source',\n",
       " 'special',\n",
       " 'spect',\n",
       " 'st',\n",
       " 'struction',\n",
       " 't',\n",
       " 'ta',\n",
       " 'tern',\n",
       " 'th',\n",
       " 'ther',\n",
       " 'time',\n",
       " 'ting',\n",
       " 'u',\n",
       " 'ul',\n",
       " 'um',\n",
       " 'un',\n",
       " 'unds',\n",
       " 'up',\n",
       " 'ur',\n",
       " 'ure',\n",
       " 'v',\n",
       " 've',\n",
       " 'very',\n",
       " 'w',\n",
       " 'wa',\n",
       " 'work',\n",
       " 'x',\n",
       " 'xcuse',\n",
       " 'y',\n",
       " 'z',\n",
       " '‚Äô',\n",
       " '‚ñÅ',\n",
       " '‚ñÅ\"',\n",
       " '‚ñÅ1',\n",
       " '‚ñÅ10',\n",
       " '‚ñÅ15',\n",
       " '‚ñÅ2',\n",
       " '‚ñÅ20',\n",
       " '‚ñÅ3',\n",
       " '‚ñÅ5',\n",
       " '‚ñÅA',\n",
       " '‚ñÅActually',\n",
       " '‚ñÅAfter',\n",
       " '‚ñÅAlright',\n",
       " '‚ñÅAlso',\n",
       " '‚ñÅAmerica',\n",
       " '‚ñÅAnd',\n",
       " '‚ñÅAny',\n",
       " '‚ñÅAnyway',\n",
       " '‚ñÅAre',\n",
       " '‚ñÅB',\n",
       " '‚ñÅBut',\n",
       " '‚ñÅBye',\n",
       " '‚ñÅC',\n",
       " '‚ñÅCEO',\n",
       " '‚ñÅCan',\n",
       " '‚ñÅCertainly',\n",
       " '‚ñÅChina',\n",
       " '‚ñÅCompany',\n",
       " '‚ñÅCorporation',\n",
       " '‚ñÅD',\n",
       " '‚ñÅDid',\n",
       " '‚ñÅDo',\n",
       " '‚ñÅE',\n",
       " '‚ñÅElaine',\n",
       " '‚ñÅEnglish',\n",
       " '‚ñÅEveryone',\n",
       " '‚ñÅExactly',\n",
       " '‚ñÅF',\n",
       " '‚ñÅFirst',\n",
       " '‚ñÅFor',\n",
       " '‚ñÅFriday',\n",
       " '‚ñÅG',\n",
       " '‚ñÅGood',\n",
       " '‚ñÅGot',\n",
       " '‚ñÅGreat',\n",
       " '‚ñÅH',\n",
       " '‚ñÅHR',\n",
       " '‚ñÅHave',\n",
       " '‚ñÅHe',\n",
       " '‚ñÅHello',\n",
       " '‚ñÅHey',\n",
       " '‚ñÅHi',\n",
       " '‚ñÅHmm',\n",
       " '‚ñÅHow',\n",
       " '‚ñÅHowever',\n",
       " '‚ñÅI',\n",
       " '‚ñÅIt',\n",
       " '‚ñÅJapan',\n",
       " '‚ñÅJapanese',\n",
       " '‚ñÅJohn',\n",
       " '‚ñÅJu',\n",
       " '‚ñÅK',\n",
       " '‚ñÅL',\n",
       " '‚ñÅLet',\n",
       " '‚ñÅLike',\n",
       " '‚ñÅM',\n",
       " '‚ñÅMay',\n",
       " '‚ñÅMaybe',\n",
       " '‚ñÅMonday',\n",
       " '‚ñÅMr',\n",
       " '‚ñÅNaka',\n",
       " '‚ñÅNew',\n",
       " '‚ñÅNext',\n",
       " '‚ñÅNo',\n",
       " '‚ñÅNot',\n",
       " '‚ñÅNow',\n",
       " '‚ñÅO',\n",
       " '‚ñÅOK',\n",
       " '‚ñÅOf',\n",
       " '‚ñÅOh',\n",
       " '‚ñÅOk',\n",
       " '‚ñÅOkay',\n",
       " '‚ñÅOn',\n",
       " '‚ñÅOur',\n",
       " '‚ñÅP',\n",
       " '‚ñÅPlease',\n",
       " '‚ñÅProduct',\n",
       " '‚ñÅR',\n",
       " '‚ñÅReally',\n",
       " '‚ñÅRight',\n",
       " '‚ñÅS',\n",
       " '‚ñÅSam',\n",
       " '‚ñÅSato',\n",
       " '‚ñÅShe',\n",
       " '‚ñÅShould',\n",
       " '‚ñÅSo',\n",
       " '‚ñÅSome',\n",
       " '‚ñÅSorry',\n",
       " '‚ñÅSure',\n",
       " '‚ñÅT',\n",
       " '‚ñÅTaka',\n",
       " '‚ñÅTanaka',\n",
       " '‚ñÅThank',\n",
       " '‚ñÅThat',\n",
       " '‚ñÅThe',\n",
       " '‚ñÅThen',\n",
       " '‚ñÅThere',\n",
       " '‚ñÅThey',\n",
       " '‚ñÅThi',\n",
       " '‚ñÅThursday',\n",
       " '‚ñÅToday',\n",
       " '‚ñÅTokyo',\n",
       " '‚ñÅTom',\n",
       " '‚ñÅTuesday',\n",
       " '‚ñÅUnfortunately',\n",
       " '‚ñÅW',\n",
       " '‚ñÅWe',\n",
       " '‚ñÅWednesday',\n",
       " '‚ñÅWell',\n",
       " '‚ñÅWhat',\n",
       " '‚ñÅWhen',\n",
       " '‚ñÅWhere',\n",
       " '‚ñÅWhich',\n",
       " '‚ñÅWho',\n",
       " '‚ñÅWhy',\n",
       " '‚ñÅWill',\n",
       " '‚ñÅWould',\n",
       " '‚ñÅWow',\n",
       " '‚ñÅYamamoto',\n",
       " '‚ñÅYeah',\n",
       " '‚ñÅYes',\n",
       " '‚ñÅYou',\n",
       " '‚ñÅa',\n",
       " '‚ñÅabout',\n",
       " '‚ñÅaccept',\n",
       " '‚ñÅaccount',\n",
       " '‚ñÅactually',\n",
       " '‚ñÅadd',\n",
       " '‚ñÅaddress',\n",
       " '‚ñÅadvance',\n",
       " '‚ñÅadvice',\n",
       " '‚ñÅaffect',\n",
       " '‚ñÅafter',\n",
       " '‚ñÅafternoon',\n",
       " '‚ñÅagain',\n",
       " '‚ñÅago',\n",
       " '‚ñÅagree',\n",
       " '‚ñÅahead',\n",
       " '‚ñÅall',\n",
       " '‚ñÅalmost',\n",
       " '‚ñÅalong',\n",
       " '‚ñÅalready',\n",
       " '‚ñÅalso',\n",
       " '‚ñÅalways',\n",
       " '‚ñÅam',\n",
       " '‚ñÅamount',\n",
       " '‚ñÅan',\n",
       " '‚ñÅand',\n",
       " '‚ñÅanother',\n",
       " '‚ñÅanswer',\n",
       " '‚ñÅany',\n",
       " '‚ñÅanyone',\n",
       " '‚ñÅanything',\n",
       " '‚ñÅapologize',\n",
       " '‚ñÅapplication',\n",
       " '‚ñÅapply',\n",
       " '‚ñÅappointment',\n",
       " '‚ñÅappreciate',\n",
       " '‚ñÅapprov',\n",
       " '‚ñÅare',\n",
       " '‚ñÅaround',\n",
       " '‚ñÅas',\n",
       " '‚ñÅask',\n",
       " '‚ñÅassist',\n",
       " '‚ñÅat',\n",
       " '‚ñÅattend',\n",
       " '‚ñÅaudit',\n",
       " '‚ñÅavailable',\n",
       " '‚ñÅaway',\n",
       " '‚ñÅb',\n",
       " '‚ñÅback',\n",
       " '‚ñÅbad',\n",
       " '‚ñÅbase',\n",
       " '‚ñÅbe',\n",
       " '‚ñÅbecause',\n",
       " '‚ñÅbeen',\n",
       " '‚ñÅbefore',\n",
       " '‚ñÅbelieve',\n",
       " '‚ñÅbest',\n",
       " '‚ñÅbetter',\n",
       " '‚ñÅbetween',\n",
       " '‚ñÅbig',\n",
       " '‚ñÅbit',\n",
       " '‚ñÅboard',\n",
       " '‚ñÅbook',\n",
       " '‚ñÅboss',\n",
       " '‚ñÅboth',\n",
       " '‚ñÅbr',\n",
       " '‚ñÅbreak',\n",
       " '‚ñÅbring',\n",
       " '‚ñÅbudget',\n",
       " '‚ñÅbuilding',\n",
       " '‚ñÅbusiness',\n",
       " '‚ñÅbusy',\n",
       " '‚ñÅbut',\n",
       " '‚ñÅbuy',\n",
       " '‚ñÅby',\n",
       " '‚ñÅc',\n",
       " '‚ñÅcall',\n",
       " '‚ñÅcame',\n",
       " '‚ñÅcan',\n",
       " '‚ñÅcandidate',\n",
       " '‚ñÅcar',\n",
       " '‚ñÅcard',\n",
       " '‚ñÅcareful',\n",
       " '‚ñÅcase',\n",
       " '‚ñÅcatch',\n",
       " '‚ñÅcertain',\n",
       " '‚ñÅchance',\n",
       " '‚ñÅchange',\n",
       " '‚ñÅcharge',\n",
       " '‚ñÅcheap',\n",
       " '‚ñÅcheck',\n",
       " '‚ñÅchild',\n",
       " '‚ñÅchoose',\n",
       " '‚ñÅclass',\n",
       " '‚ñÅclean',\n",
       " '‚ñÅclick',\n",
       " '‚ñÅclient',\n",
       " '‚ñÅclose',\n",
       " '‚ñÅco',\n",
       " '‚ñÅcoffee',\n",
       " '‚ñÅcollect',\n",
       " '‚ñÅcome',\n",
       " '‚ñÅcoming',\n",
       " '‚ñÅcommuting',\n",
       " '‚ñÅcompanies',\n",
       " '‚ñÅcompany',\n",
       " '‚ñÅcompare',\n",
       " '‚ñÅcomplain',\n",
       " '‚ñÅcomplete',\n",
       " '‚ñÅcomputer',\n",
       " '‚ñÅcon',\n",
       " '‚ñÅconcern',\n",
       " '‚ñÅconduct',\n",
       " '‚ñÅconference',\n",
       " '‚ñÅconfident',\n",
       " '‚ñÅconfirm',\n",
       " '‚ñÅconnect',\n",
       " '‚ñÅconsider',\n",
       " '‚ñÅconsult',\n",
       " '‚ñÅcontact',\n",
       " '‚ñÅcontain',\n",
       " '‚ñÅcontent',\n",
       " '‚ñÅcontinue',\n",
       " '‚ñÅcontract',\n",
       " '‚ñÅconversation',\n",
       " '‚ñÅcorporate',\n",
       " '‚ñÅcorrect',\n",
       " '‚ñÅcost',\n",
       " '‚ñÅcou',\n",
       " '‚ñÅcould',\n",
       " '‚ñÅcourse',\n",
       " '‚ñÅcover',\n",
       " '‚ñÅcredit',\n",
       " '‚ñÅcurrent',\n",
       " '‚ñÅcustomer',\n",
       " '‚ñÅcustomers',\n",
       " '‚ñÅdata',\n",
       " '‚ñÅdatabase',\n",
       " '‚ñÅdate',\n",
       " '‚ñÅday',\n",
       " '‚ñÅdays',\n",
       " '‚ñÅde',\n",
       " '‚ñÅdeadline',\n",
       " '‚ñÅdeal',\n",
       " '‚ñÅdecide',\n",
       " '‚ñÅdecision',\n",
       " '‚ñÅdefinite',\n",
       " '‚ñÅdelay',\n",
       " '‚ñÅdeliver',\n",
       " '‚ñÅdepartment',\n",
       " '‚ñÅdepend',\n",
       " '‚ñÅdesign',\n",
       " '‚ñÅdesk',\n",
       " '‚ñÅdetail',\n",
       " '‚ñÅdevelop',\n",
       " '‚ñÅdid',\n",
       " '‚ñÅdidn',\n",
       " '‚ñÅdifference',\n",
       " '‚ñÅdifferent',\n",
       " '‚ñÅdifficult',\n",
       " '‚ñÅdinner',\n",
       " '‚ñÅdirect',\n",
       " '‚ñÅdis',\n",
       " '‚ñÅdiscount',\n",
       " '‚ñÅdiscuss',\n",
       " '‚ñÅdistribut',\n",
       " '‚ñÅdivision',\n",
       " '‚ñÅdo',\n",
       " '‚ñÅdocument',\n",
       " '‚ñÅdoes',\n",
       " '‚ñÅdoesn',\n",
       " '‚ñÅdoing',\n",
       " '‚ñÅdollars',\n",
       " '‚ñÅdon',\n",
       " '‚ñÅdouble',\n",
       " '‚ñÅdown',\n",
       " '‚ñÅdraft',\n",
       " '‚ñÅdrink',\n",
       " '‚ñÅdue',\n",
       " '‚ñÅdur',\n",
       " '‚ñÅeach',\n",
       " '‚ñÅearlier',\n",
       " '‚ñÅearly',\n",
       " '‚ñÅeasier',\n",
       " '‚ñÅeasy',\n",
       " '‚ñÅeat',\n",
       " '‚ñÅeither',\n",
       " '‚ñÅelse',\n",
       " '‚ñÅemail',\n",
       " '‚ñÅemergency',\n",
       " '‚ñÅemployee',\n",
       " '‚ñÅemployees',\n",
       " '‚ñÅend',\n",
       " '‚ñÅenjoy',\n",
       " '‚ñÅenough',\n",
       " '‚ñÅenter',\n",
       " '‚ñÅentire',\n",
       " '‚ñÅenvironment',\n",
       " '‚ñÅequipment',\n",
       " '‚ñÅestimate',\n",
       " '‚ñÅeven',\n",
       " '‚ñÅevery',\n",
       " '‚ñÅeveryone',\n",
       " '‚ñÅeverything',\n",
       " '‚ñÅex',\n",
       " '‚ñÅexactly',\n",
       " '‚ñÅexample',\n",
       " '‚ñÅexpect',\n",
       " '‚ñÅexpense',\n",
       " '‚ñÅexpensive',\n",
       " '‚ñÅexperience',\n",
       " '‚ñÅexplain',\n",
       " '‚ñÅexport',\n",
       " '‚ñÅf',\n",
       " '‚ñÅfacility',\n",
       " '‚ñÅfactory',\n",
       " '‚ñÅfamiliar',\n",
       " '‚ñÅfamily',\n",
       " '‚ñÅfar',\n",
       " '‚ñÅfavor',\n",
       " '‚ñÅfeel',\n",
       " '‚ñÅfew',\n",
       " '‚ñÅfield',\n",
       " '‚ñÅfigure',\n",
       " '‚ñÅfile',\n",
       " '‚ñÅfinal',\n",
       " '‚ñÅfind',\n",
       " '‚ñÅfine',\n",
       " '‚ñÅfinish',\n",
       " '‚ñÅfirst',\n",
       " '‚ñÅfive',\n",
       " '‚ñÅflight',\n",
       " '‚ñÅfloor',\n",
       " '‚ñÅfocus',\n",
       " '‚ñÅfollow',\n",
       " '‚ñÅfood',\n",
       " '‚ñÅfor',\n",
       " '‚ñÅforward',\n",
       " '‚ñÅfound',\n",
       " '‚ñÅfour',\n",
       " '‚ñÅfree',\n",
       " '‚ñÅfriend',\n",
       " '‚ñÅfrom',\n",
       " '‚ñÅfront',\n",
       " '‚ñÅfun',\n",
       " '‚ñÅfuture',\n",
       " '‚ñÅga',\n",
       " '‚ñÅgeneral',\n",
       " '‚ñÅget',\n",
       " '‚ñÅgift',\n",
       " '‚ñÅgive',\n",
       " '‚ñÅglad',\n",
       " '‚ñÅgo',\n",
       " '‚ñÅgoing',\n",
       " '‚ñÅgood',\n",
       " '‚ñÅgot',\n",
       " '‚ñÅgra',\n",
       " '‚ñÅgreat',\n",
       " '‚ñÅgroup',\n",
       " '‚ñÅgrow',\n",
       " '‚ñÅguess',\n",
       " '‚ñÅguest',\n",
       " '‚ñÅguys',\n",
       " '‚ñÅhad',\n",
       " '‚ñÅhalf',\n",
       " '‚ñÅhand',\n",
       " '‚ñÅhappen',\n",
       " '‚ñÅhappy',\n",
       " '‚ñÅhard',\n",
       " '‚ñÅhas',\n",
       " '‚ñÅhave',\n",
       " '‚ñÅhaving',\n",
       " '‚ñÅhe',\n",
       " '‚ñÅhead',\n",
       " '‚ñÅhear',\n",
       " '‚ñÅheard',\n",
       " '‚ñÅhelp',\n",
       " '‚ñÅhelpful',\n",
       " '‚ñÅher',\n",
       " '‚ñÅhere',\n",
       " '‚ñÅhi',\n",
       " '‚ñÅhigh',\n",
       " '‚ñÅhim',\n",
       " '‚ñÅhire',\n",
       " '‚ñÅhis',\n",
       " '‚ñÅhold',\n",
       " '‚ñÅholiday',\n",
       " '‚ñÅhome',\n",
       " '‚ñÅhonest',\n",
       " '‚ñÅhope',\n",
       " '‚ñÅhotel',\n",
       " '‚ñÅhour',\n",
       " '‚ñÅhow',\n",
       " '‚ñÅhundred',\n",
       " '‚ñÅidea',\n",
       " '‚ñÅimagin',\n",
       " '‚ñÅimport',\n",
       " '‚ñÅimportant',\n",
       " '‚ñÅimprove',\n",
       " '‚ñÅin',\n",
       " '‚ñÅinclude',\n",
       " '‚ñÅincrease',\n",
       " '‚ñÅindustry',\n",
       " '‚ñÅinformation',\n",
       " '‚ñÅinspection',\n",
       " '‚ñÅinstall',\n",
       " '‚ñÅinstead',\n",
       " '‚ñÅinsurance',\n",
       " '‚ñÅinter',\n",
       " '‚ñÅinterested',\n",
       " '‚ñÅinternal',\n",
       " '‚ñÅinterview',\n",
       " '‚ñÅinto',\n",
       " '‚ñÅinvest',\n",
       " '‚ñÅinvoice',\n",
       " '‚ñÅinvolved',\n",
       " '‚ñÅis',\n",
       " '‚ñÅissue',\n",
       " '‚ñÅit',\n",
       " '‚ñÅjob',\n",
       " '‚ñÅjoin',\n",
       " '‚ñÅjust',\n",
       " '‚ñÅkeep',\n",
       " '‚ñÅkind',\n",
       " '‚ñÅknow',\n",
       " '‚ñÅknowledge',\n",
       " '‚ñÅlab',\n",
       " '‚ñÅlanguage',\n",
       " '‚ñÅlaptop',\n",
       " '‚ñÅlarge',\n",
       " '‚ñÅlast',\n",
       " '‚ñÅlate',\n",
       " '‚ñÅlater',\n",
       " '‚ñÅlead',\n",
       " '‚ñÅlearn',\n",
       " '‚ñÅleast',\n",
       " '‚ñÅleave',\n",
       " '‚ñÅleaving',\n",
       " '‚ñÅleft',\n",
       " '‚ñÅlet',\n",
       " '‚ñÅlevel',\n",
       " '‚ñÅlife',\n",
       " '‚ñÅlike',\n",
       " '‚ñÅlimit',\n",
       " '‚ñÅlist',\n",
       " '‚ñÅlittle',\n",
       " '‚ñÅlive',\n",
       " '‚ñÅlocal',\n",
       " '‚ñÅlog',\n",
       " '‚ñÅlogistic',\n",
       " '‚ñÅlong',\n",
       " '‚ñÅlook',\n",
       " '‚ñÅlooking',\n",
       " '‚ñÅlot',\n",
       " '‚ñÅlove',\n",
       " '‚ñÅlow',\n",
       " '‚ñÅluck',\n",
       " '‚ñÅlunch',\n",
       " '‚ñÅma',\n",
       " '‚ñÅmade',\n",
       " '‚ñÅmajor',\n",
       " '‚ñÅmak',\n",
       " '‚ñÅmake',\n",
       " '‚ñÅmanage',\n",
       " '‚ñÅmanagement',\n",
       " '‚ñÅmanager',\n",
       " '‚ñÅmanufacturing',\n",
       " '‚ñÅmany',\n",
       " '‚ñÅmarket',\n",
       " '‚ñÅmaterial',\n",
       " '‚ñÅmatter',\n",
       " '‚ñÅmay',\n",
       " '‚ñÅmaybe',\n",
       " '‚ñÅme',\n",
       " '‚ñÅmean',\n",
       " '‚ñÅmeet',\n",
       " '‚ñÅmeeting',\n",
       " '‚ñÅmiddle',\n",
       " '‚ñÅmight',\n",
       " '‚ñÅmillion',\n",
       " '‚ñÅmind',\n",
       " '‚ñÅminutes',\n",
       " '‚ñÅmistake',\n",
       " '‚ñÅmo',\n",
       " '‚ñÅmoment',\n",
       " '‚ñÅmoney',\n",
       " '‚ñÅmonth',\n",
       " '‚ñÅmore',\n",
       " '‚ñÅmorning',\n",
       " '‚ñÅmost',\n",
       " '‚ñÅmove',\n",
       " '‚ñÅmuch',\n",
       " '‚ñÅmust',\n",
       " '‚ñÅmy',\n",
       " '‚ñÅmyself',\n",
       " '‚ñÅname',\n",
       " '‚ñÅnear',\n",
       " '‚ñÅneed',\n",
       " '‚ñÅnegotia',\n",
       " '‚ñÅnever',\n",
       " '‚ñÅnew',\n",
       " '‚ñÅnext',\n",
       " '‚ñÅnice',\n",
       " '‚ñÅnight',\n",
       " '‚ñÅno',\n",
       " '‚ñÅnot',\n",
       " '‚ñÅnotice',\n",
       " '‚ñÅnow',\n",
       " '‚ñÅnumber',\n",
       " '‚ñÅof',\n",
       " '‚ñÅoff',\n",
       " '‚ñÅoffer',\n",
       " '‚ñÅoffice',\n",
       " '‚ñÅokay',\n",
       " '‚ñÅold',\n",
       " '‚ñÅon',\n",
       " '‚ñÅonce',\n",
       " '‚ñÅone',\n",
       " '‚ñÅonline',\n",
       " '‚ñÅonly',\n",
       " '‚ñÅopen',\n",
       " '‚ñÅoperation',\n",
       " '‚ñÅopinion',\n",
       " '‚ñÅopportunity',\n",
       " '‚ñÅoption',\n",
       " '‚ñÅor',\n",
       " '‚ñÅorder',\n",
       " '‚ñÅorganize',\n",
       " '‚ñÅoriginal',\n",
       " '‚ñÅother',\n",
       " '‚ñÅour',\n",
       " '‚ñÅout',\n",
       " '‚ñÅover',\n",
       " '‚ñÅown',\n",
       " '‚ñÅp',\n",
       " '‚ñÅpackage',\n",
       " '‚ñÅpaid',\n",
       " '‚ñÅpaper',\n",
       " '‚ñÅpark',\n",
       " '‚ñÅpart',\n",
       " '‚ñÅparticular',\n",
       " '‚ñÅpass',\n",
       " '‚ñÅpast',\n",
       " '‚ñÅpay',\n",
       " '‚ñÅpeople',\n",
       " '‚ñÅper',\n",
       " '‚ñÅpercent',\n",
       " '‚ñÅperfect',\n",
       " '‚ñÅperformance',\n",
       " '‚ñÅperiod',\n",
       " '‚ñÅperson',\n",
       " '‚ñÅphone',\n",
       " '‚ñÅpick',\n",
       " '‚ñÅpiece',\n",
       " '‚ñÅplace',\n",
       " '‚ñÅplan',\n",
       " '‚ñÅplanning',\n",
       " '‚ñÅplay',\n",
       " '‚ñÅplease',\n",
       " '‚ñÅpleasure',\n",
       " '‚ñÅpoint',\n",
       " '‚ñÅposition',\n",
       " '‚ñÅpossible',\n",
       " '‚ñÅpotential',\n",
       " '‚ñÅprefer',\n",
       " '‚ñÅprepar',\n",
       " '‚ñÅpresentation',\n",
       " '‚ñÅpresident',\n",
       " '‚ñÅpretty',\n",
       " '‚ñÅprevent',\n",
       " '‚ñÅprevious',\n",
       " '‚ñÅprice',\n",
       " '‚ñÅprint',\n",
       " '‚ñÅpro',\n",
       " '‚ñÅprobably',\n",
       " '‚ñÅproblem',\n",
       " '‚ñÅprocedure',\n",
       " '‚ñÅproceed',\n",
       " '‚ñÅprocess',\n",
       " '‚ñÅproduct',\n",
       " '‚ñÅproducts',\n",
       " '‚ñÅprogram',\n",
       " '‚ñÅproject',\n",
       " '‚ñÅpromot',\n",
       " '‚ñÅproposal',\n",
       " '‚ñÅprovide',\n",
       " '‚ñÅpublic',\n",
       " '‚ñÅpurchase',\n",
       " '‚ñÅpurchasing',\n",
       " '‚ñÅput',\n",
       " '‚ñÅquarter',\n",
       " '‚ñÅquestion',\n",
       " '‚ñÅquestions',\n",
       " '‚ñÅquick',\n",
       " '‚ñÅquite',\n",
       " '‚ñÅquote',\n",
       " '‚ñÅre',\n",
       " '‚ñÅread',\n",
       " '‚ñÅreally',\n",
       " '‚ñÅreason',\n",
       " '‚ñÅreceive',\n",
       " '‚ñÅrecently',\n",
       " '‚ñÅrecommend',\n",
       " '‚ñÅrecord',\n",
       " '‚ñÅrefund',\n",
       " '‚ñÅregard',\n",
       " '‚ñÅregular',\n",
       " '‚ñÅrelationship',\n",
       " '‚ñÅrelease',\n",
       " '‚ñÅremember',\n",
       " '‚ñÅreport',\n",
       " '‚ñÅrequest',\n",
       " '‚ñÅrequire',\n",
       " '‚ñÅresearch',\n",
       " '‚ñÅrestaurant',\n",
       " '‚ñÅresult',\n",
       " '‚ñÅreturn',\n",
       " '‚ñÅreview',\n",
       " '‚ñÅright',\n",
       " '‚ñÅroom',\n",
       " '‚ñÅrun',\n",
       " '‚ñÅsafe',\n",
       " '‚ñÅsaid',\n",
       " '‚ñÅsales',\n",
       " '‚ñÅsame',\n",
       " '‚ñÅsave',\n",
       " '‚ñÅsaw',\n",
       " '‚ñÅsay',\n",
       " '‚ñÅsc',\n",
       " '‚ñÅschedule',\n",
       " '‚ñÅschool',\n",
       " '‚ñÅseason',\n",
       " '‚ñÅseat',\n",
       " '‚ñÅsecond',\n",
       " '‚ñÅsection',\n",
       " '‚ñÅsecurity',\n",
       " '‚ñÅsee',\n",
       " '‚ñÅseem',\n",
       " '‚ñÅselect',\n",
       " '‚ñÅsell',\n",
       " '‚ñÅseminar',\n",
       " '‚ñÅsend',\n",
       " '‚ñÅsense',\n",
       " '‚ñÅsent',\n",
       " '‚ñÅserious',\n",
       " '‚ñÅserve',\n",
       " '‚ñÅservice',\n",
       " '‚ñÅset',\n",
       " '‚ñÅshare',\n",
       " '‚ñÅshe',\n",
       " '‚ñÅshipment',\n",
       " '‚ñÅshipping',\n",
       " '‚ñÅshort',\n",
       " '‚ñÅshould',\n",
       " '‚ñÅshow',\n",
       " '‚ñÅsimilar',\n",
       " '‚ñÅsince',\n",
       " '‚ñÅsit',\n",
       " '‚ñÅsituation',\n",
       " '‚ñÅskills',\n",
       " '‚ñÅsmall',\n",
       " '‚ñÅso',\n",
       " '‚ñÅsoftware',\n",
       " '‚ñÅsome',\n",
       " '‚ñÅsomeone',\n",
       " '‚ñÅsomething',\n",
       " '‚ñÅsomewhere',\n",
       " '‚ñÅsoon',\n",
       " '‚ñÅsorry',\n",
       " '‚ñÅsound',\n",
       " '‚ñÅspace',\n",
       " '‚ñÅspeak',\n",
       " '‚ñÅspecific',\n",
       " '‚ñÅspend',\n",
       " '‚ñÅstaff',\n",
       " '‚ñÅstand',\n",
       " '‚ñÅstart',\n",
       " '‚ñÅstay',\n",
       " '‚ñÅstill',\n",
       " '‚ñÅstop',\n",
       " '‚ñÅstore',\n",
       " '‚ñÅstrong',\n",
       " '‚ñÅstudent',\n",
       " '‚ñÅstudy',\n",
       " '‚ñÅsub',\n",
       " '‚ñÅsubmit',\n",
       " '‚ñÅsuccess',\n",
       " '‚ñÅsuch',\n",
       " '‚ñÅsuggest',\n",
       " '‚ñÅsuit',\n",
       " '‚ñÅsummer',\n",
       " '‚ñÅsupport',\n",
       " '‚ñÅsure',\n",
       " '‚ñÅswitch',\n",
       " '‚ñÅsystem',\n",
       " '‚ñÅtake',\n",
       " '‚ñÅtaking',\n",
       " '‚ñÅtalk',\n",
       " '‚ñÅtask',\n",
       " '‚ñÅteach',\n",
       " '‚ñÅteam',\n",
       " '‚ñÅtech',\n",
       " '‚ñÅtechnology',\n",
       " '‚ñÅtell',\n",
       " '‚ñÅten',\n",
       " '‚ñÅterm',\n",
       " '‚ñÅthan',\n",
       " '‚ñÅthank',\n",
       " '‚ñÅthat',\n",
       " '‚ñÅthe',\n",
       " '‚ñÅtheir',\n",
       " '‚ñÅthem',\n",
       " '‚ñÅthen',\n",
       " '‚ñÅthere',\n",
       " '‚ñÅthese',\n",
       " '‚ñÅthey',\n",
       " '‚ñÅthing',\n",
       " '‚ñÅthings',\n",
       " '‚ñÅthink',\n",
       " '‚ñÅthirty',\n",
       " '‚ñÅthis',\n",
       " '‚ñÅthose',\n",
       " '‚ñÅthough',\n",
       " '‚ñÅthought',\n",
       " '‚ñÅthousand',\n",
       " '‚ñÅthree',\n",
       " '‚ñÅthrough',\n",
       " '‚ñÅtime',\n",
       " '‚ñÅto',\n",
       " '‚ñÅtoday',\n",
       " '‚ñÅtogether',\n",
       " '‚ñÅtold',\n",
       " '‚ñÅtomorrow',\n",
       " '‚ñÅtoo',\n",
       " '‚ñÅtrack',\n",
       " '‚ñÅtrad',\n",
       " '‚ñÅtrain',\n",
       " '‚ñÅtraining',\n",
       " '‚ñÅtrans',\n",
       " '‚ñÅtransfer',\n",
       " '‚ñÅtravel',\n",
       " '‚ñÅtrip',\n",
       " '‚ñÅtrouble',\n",
       " '‚ñÅtruck',\n",
       " '‚ñÅtrue',\n",
       " '‚ñÅtry',\n",
       " '‚ñÅturn',\n",
       " '‚ñÅtwenty',\n",
       " '‚ñÅtwo',\n",
       " '‚ñÅtype',\n",
       " '‚ñÅunder',\n",
       " '‚ñÅunderstand',\n",
       " '‚ñÅuniversity',\n",
       " '‚ñÅunt',\n",
       " '‚ñÅup',\n",
       " '‚ñÅupdate',\n",
       " '‚ñÅus',\n",
       " '‚ñÅuse',\n",
       " '‚ñÅused',\n",
       " '‚ñÅusual',\n",
       " '‚ñÅvacation',\n",
       " '‚ñÅvalue',\n",
       " '‚ñÅvari',\n",
       " '‚ñÅversion',\n",
       " '‚ñÅvi',\n",
       " '‚ñÅvisit',\n",
       " '‚ñÅvolume',\n",
       " '‚ñÅwait',\n",
       " '‚ñÅwalk',\n",
       " '‚ñÅwant',\n",
       " '‚ñÅwanted',\n",
       " '‚ñÅwas',\n",
       " '‚ñÅwatch',\n",
       " '‚ñÅwater',\n",
       " '‚ñÅway',\n",
       " '‚ñÅwe',\n",
       " '‚ñÅwebsite',\n",
       " '‚ñÅweek',\n",
       " '‚ñÅwell',\n",
       " '‚ñÅwent',\n",
       " '‚ñÅwere',\n",
       " '‚ñÅwhat',\n",
       " '‚ñÅwhen',\n",
       " '‚ñÅwhere',\n",
       " '‚ñÅwhich',\n",
       " '‚ñÅwhile',\n",
       " '‚ñÅwho',\n",
       " '‚ñÅwhy',\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So let's pretend we have to export a product to Japan today.\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 162, 11, 4, 101, 50, 9, 400, 35, 36, 10, 785, 13, 189, 10, 434, 173, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅSo',\n",
       " '‚ñÅlet',\n",
       " \"'\",\n",
       " 's',\n",
       " '‚ñÅp',\n",
       " 're',\n",
       " 't',\n",
       " 'end',\n",
       " '‚ñÅwe',\n",
       " '‚ñÅhave',\n",
       " '‚ñÅto',\n",
       " '‚ñÅexport',\n",
       " '‚ñÅa',\n",
       " '‚ñÅproduct',\n",
       " '‚ñÅto',\n",
       " '‚ñÅJapan',\n",
       " '‚ñÅtoday',\n",
       " '.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[en_sp.IdToPiece(i) for i in en_sp.encode(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 162, 11, 4, 101, 50, 9, 400, 35, 36, 10, 785, 13, 189, 10, 434, 173, 3]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.EncodeAsIds(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅSo',\n",
       " '‚ñÅlet',\n",
       " \"'\",\n",
       " 's',\n",
       " '‚ñÅp',\n",
       " 're',\n",
       " 't',\n",
       " 'end',\n",
       " '‚ñÅwe',\n",
       " '‚ñÅhave',\n",
       " '‚ñÅto',\n",
       " '‚ñÅexport',\n",
       " '‚ñÅa',\n",
       " '‚ñÅproduct',\n",
       " '‚ñÅto',\n",
       " '‚ñÅJapan',\n",
       " '‚ñÅtoday',\n",
       " '.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.EncodeAsPieces(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So let's pretend we have to export a product to Japan today.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.DecodePieces(en_sp.EncodeAsPieces(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So let's pretend we have to export a product to Japan today.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.DecodeIds(en_sp.encode(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 162, 11, 4, 101, 50, 9, 400, 35, 36, 10, 785, 13, 189, 10, 434, 173, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.SampleEncodeAsIds(sent, nbest_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅSo',\n",
       " '‚ñÅlet',\n",
       " \"'\",\n",
       " 's',\n",
       " '‚ñÅ',\n",
       " 'p',\n",
       " 're',\n",
       " 't',\n",
       " 'end',\n",
       " '‚ñÅwe',\n",
       " '‚ñÅhave',\n",
       " '‚ñÅto',\n",
       " '‚ñÅexport',\n",
       " '‚ñÅa',\n",
       " '‚ñÅproduct',\n",
       " '‚ñÅto',\n",
       " '‚ñÅJapan',\n",
       " '‚ñÅtoday',\n",
       " '.']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.SampleEncodeAsPieces(sent, nbest_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98,\n",
       " 162,\n",
       " 11,\n",
       " 4,\n",
       " 101,\n",
       " 30,\n",
       " 14,\n",
       " 9,\n",
       " 90,\n",
       " 18,\n",
       " 35,\n",
       " 36,\n",
       " 10,\n",
       " 785,\n",
       " 13,\n",
       " 189,\n",
       " 10,\n",
       " 434,\n",
       " 173,\n",
       " 3]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.SampleEncodeAsIds(sent, nbest_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅSo',\n",
       " '‚ñÅlet',\n",
       " \"'\",\n",
       " 's',\n",
       " '‚ñÅ',\n",
       " 'p',\n",
       " 're',\n",
       " 't',\n",
       " 'en',\n",
       " 'd',\n",
       " '‚ñÅwe',\n",
       " '‚ñÅhave',\n",
       " '‚ñÅto',\n",
       " '‚ñÅexport',\n",
       " '‚ñÅ',\n",
       " 'a',\n",
       " '‚ñÅproduct',\n",
       " '‚ñÅto',\n",
       " '‚ñÅJapan',\n",
       " '‚ñÅtoday',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sp.SampleEncodeAsPieces(sent, nbest_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /mnt/dl/NLP/bsd_ja_en/data/train.ja\n",
      "  input_format: \n",
      "  model_prefix: \n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 2048\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: /mnt/dl/NLP/bsd_ja_en/data/train.ja\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 20000 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=443656\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=1713\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 20000 sentences.\n",
      "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=158424\n",
      "unigram_model_trainer.cc(274) LOG(INFO) Initialized 88910 seed sentencepieces\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 20000\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 18142\n",
      "unigram_model_trainer.cc(564) LOG(INFO) Using 18142 sentences for EM training\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=38006 obj=67.0044 num_tokens=139729 num_tokens/piece=3.6765\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=34113 obj=59.1155 num_tokens=140133 num_tokens/piece=4.10791\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=25463 obj=61.1356 num_tokens=147873 num_tokens/piece=5.80737\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=25318 obj=60.4057 num_tokens=147931 num_tokens/piece=5.84292\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=18948 obj=63.656 num_tokens=157790 num_tokens/piece=8.32753\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=18932 obj=62.9387 num_tokens=157920 num_tokens/piece=8.34143\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=14193 obj=66.4044 num_tokens=169056 num_tokens/piece=11.9112\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=14189 obj=65.7148 num_tokens=169075 num_tokens/piece=11.9159\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=10640 obj=69.6261 num_tokens=180435 num_tokens/piece=16.9582\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=10639 obj=68.8478 num_tokens=180450 num_tokens/piece=16.9612\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=7979 obj=72.6928 num_tokens=192275 num_tokens/piece=24.0976\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=7979 obj=72.1167 num_tokens=192286 num_tokens/piece=24.099\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=5984 obj=76.6391 num_tokens=204854 num_tokens/piece=34.2336\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=5983 obj=76.2847 num_tokens=204862 num_tokens/piece=34.2407\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=4487 obj=80.6698 num_tokens=218603 num_tokens/piece=48.7192\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=4487 obj=80.0506 num_tokens=218615 num_tokens/piece=48.7219\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=3365 obj=85.2678 num_tokens=234617 num_tokens/piece=69.7227\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=3365 obj=84.4932 num_tokens=234620 num_tokens/piece=69.7236\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2523 obj=90.7613 num_tokens=253883 num_tokens/piece=100.627\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2523 obj=89.7294 num_tokens=253885 num_tokens/piece=100.628\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=2252 obj=92.9134 num_tokens=263403 num_tokens/piece=116.964\n",
      "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=2252 obj=92.4713 num_tokens=263402 num_tokens/piece=116.964\n"
     ]
    }
   ],
   "source": [
    "ja_model_fname = os.path.join(savepath, \"train.ja.m\")\n",
    "ja_writer = codecs.open(ja_model_fname, \"wb\")\n",
    "ja_spm = SentencePieceTrainer.train(input=ja_fname, model_writer=ja_writer,\n",
    "                                    vocab_size=1024 * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp = SentencePieceProcessor()\n",
    "ja_sp.Load(ja_model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7f64a8440a80> >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ja_fname) as f:\n",
    "    ja_sent = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åß„ÅØ„ÄÅ‰ªäÊó•Êó•Êú¨„Å∏ÂïÜÂìÅ„ÇíËº∏Âá∫„Åô„Çã„Å®‰ªÆÂÆö„Åó„Åæ„Åó„Çá„ÅÜ„ÄÇ\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 5, 194, 205, 236, 145, 9, 1988, 53, 32, 14, 983, 203, 507, 4]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp.encode(ja_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98, 5, 194, 205, 236, 145, 9, 1988, 53, 32, 14, 983, 203, 507, 4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp.EncodeAsIds(ja_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['‚ñÅ„Åß„ÅØ',\n",
       " '„ÄÅ',\n",
       " '‰ªäÊó•',\n",
       " 'Êó•Êú¨',\n",
       " '„Å∏',\n",
       " 'ÂïÜÂìÅ',\n",
       " '„Çí',\n",
       " 'Ëº∏',\n",
       " 'Âá∫',\n",
       " '„Åô„Çã',\n",
       " '„Å®',\n",
       " '‰ªÆ',\n",
       " 'ÂÆö',\n",
       " '„Åó„Åæ„Åó„Çá„ÅÜ',\n",
       " '„ÄÇ']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp.EncodeAsPieces(ja_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åß„ÅØ„ÄÅ‰ªäÊó•Êó•Êú¨„Å∏ÂïÜÂìÅ„ÇíËº∏Âá∫„Åô„Çã„Å®‰ªÆÂÆö„Åó„Åæ„Åó„Çá„ÅÜ„ÄÇ'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp.DecodeIds(ja_sp.encode(ja_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'„Åß„ÅØ„ÄÅ‰ªäÊó•Êó•Êú¨„Å∏ÂïÜÂìÅ„ÇíËº∏Âá∫„Åô„Çã„Å®‰ªÆÂÆö„Åó„Åæ„Åó„Çá„ÅÜ„ÄÇ'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_sp.DecodePieces(ja_sp.EncodeAsPieces(ja_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastBPE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
