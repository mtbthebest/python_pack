{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import re\n",
    "import codecs\n",
    "import shutil\n",
    "import io\n",
    "import tempfile\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fairseq\n",
    "from fairseq.data.encoders.gpt2_bpe import GPT2BPE, GPT2BPEConfig\n",
    "from fairseq.tasks import TASK_REGISTRY\n",
    "from sentencepiece import SentencePieceProcessor\n",
    "from fairseq.binarizer import VocabularyDatasetBinarizer, FileBinarizer, AlignmentDatasetBinarizer, BinarizeSummary\n",
    "from fairseq.data import data_utils\n",
    "from fairseq.data import Dictionary\n",
    "from fairseq.data import StripTokenDataset, AppendTokenDataset, TruncateDataset, RandomCropDataset, AppendTokenDataset, PrependTokenDataset, ConcatDataset, PadDataset, TokenBlockDataset, \\\n",
    "    MonolingualDataset, LanguagePairDataset, MaskTokensDataset, NumelDataset, ConcatSentencesDataset, NestedDictionaryDataset, RawLabelDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['multilingual_masked_lm', 'translation', 'translation_lev', 'translation_multi_simple_epoch', 'speech_unit_modeling', 'hubert_pretraining', 'multilingual_translation', 'language_modeling', 'masked_lm', 'audio_pretraining', 'audio_finetuning', 'multilingual_language_modeling', 'speech_to_text', 'simul_speech_to_text', 'simul_text_to_text', 'legacy_masked_lm', 'sentence_prediction', 'translation_from_pretrained_xlm', 'text_to_speech', 'translation_from_pretrained_bart', 'denoising', 'multilingual_denoising', 'frm_text_to_speech', 'sentence_prediction_adapters', 'online_backtranslation', 'cross_lingual_lm', 'sentence_ranking', 'semisupervised_translation', 'speech_to_speech', 'dummy_lm', 'dummy_masked_lm', 'dummy_mt'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK_REGISTRY.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multilingual_masked_lm': fairseq.tasks.multilingual_masked_lm.MultiLingualMaskedLMTask,\n",
       " 'translation': fairseq.tasks.translation.TranslationTask,\n",
       " 'translation_lev': fairseq.tasks.translation_lev.TranslationLevenshteinTask,\n",
       " 'translation_multi_simple_epoch': fairseq.tasks.translation_multi_simple_epoch.TranslationMultiSimpleEpochTask,\n",
       " 'speech_unit_modeling': fairseq.tasks.speech_ulm_task.SpeechUnitLanguageModelingTask,\n",
       " 'hubert_pretraining': fairseq.tasks.hubert_pretraining.HubertPretrainingTask,\n",
       " 'multilingual_translation': fairseq.tasks.multilingual_translation.MultilingualTranslationTask,\n",
       " 'language_modeling': fairseq.tasks.language_modeling.LanguageModelingTask,\n",
       " 'masked_lm': fairseq.tasks.masked_lm.MaskedLMTask,\n",
       " 'audio_pretraining': fairseq.tasks.audio_pretraining.AudioPretrainingTask,\n",
       " 'audio_finetuning': fairseq.tasks.audio_finetuning.AudioFinetuningTask,\n",
       " 'multilingual_language_modeling': fairseq.tasks.multilingual_language_modeling.MultilingualLanguageModelingTask,\n",
       " 'speech_to_text': fairseq.tasks.speech_to_text.SpeechToTextTask,\n",
       " 'simul_speech_to_text': fairseq.tasks.simultaneous_translation.SimulSpeechToTextTask,\n",
       " 'simul_text_to_text': fairseq.tasks.simultaneous_translation.SimulTextToTextTask,\n",
       " 'legacy_masked_lm': fairseq.tasks.legacy_masked_lm.LegacyMaskedLMTask,\n",
       " 'sentence_prediction': fairseq.tasks.sentence_prediction.SentencePredictionTask,\n",
       " 'translation_from_pretrained_xlm': fairseq.tasks.translation_from_pretrained_xlm.TranslationFromPretrainedXLMTask,\n",
       " 'text_to_speech': fairseq.tasks.text_to_speech.TextToSpeechTask,\n",
       " 'translation_from_pretrained_bart': fairseq.tasks.translation_from_pretrained_bart.TranslationFromPretrainedBARTTask,\n",
       " 'denoising': fairseq.tasks.denoising.DenoisingTask,\n",
       " 'multilingual_denoising': fairseq.tasks.multilingual_denoising.MultilingualDenoisingTask,\n",
       " 'frm_text_to_speech': fairseq.tasks.frm_text_to_speech.FrmTextToSpeechTask,\n",
       " 'sentence_prediction_adapters': fairseq.tasks.sentence_prediction_adapters.SentencePredictionAdapterTask,\n",
       " 'online_backtranslation': fairseq.tasks.online_backtranslation.OnlineBackTranslationTask,\n",
       " 'cross_lingual_lm': fairseq.tasks.cross_lingual_lm.CrossLingualLMTask,\n",
       " 'sentence_ranking': fairseq.tasks.sentence_ranking.SentenceRankingTask,\n",
       " 'semisupervised_translation': fairseq.tasks.semisupervised_translation.SemisupervisedTranslationTask,\n",
       " 'speech_to_speech': fairseq.tasks.speech_to_speech.SpeechToSpeechTask,\n",
       " 'dummy_lm': fairseq.benchmark.dummy_lm.DummyLMTask,\n",
       " 'dummy_masked_lm': fairseq.benchmark.dummy_masked_lm.DummyMaskedLMTask,\n",
       " 'dummy_mt': fairseq.benchmark.dummy_mt.DummyMTTask}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TASK_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TASK_REGISTRY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation data\n",
    "\n",
    "<p> Japanese English dataset  bsd_ja_en</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/mnt/dl/NLP/bsd_ja_en/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_task = TASK_REGISTRY[\"translation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_spm = SentencePieceProcessor(os.path.join(dataset_path, \"sentencepiece/train.en.m\"))\n",
    "ja_spm = SentencePieceProcessor(os.path.join(dataset_path, \"sentencepiece/train.ja.m\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = os.path.join(dataset_path, \"translation\")\n",
    "os.makedirs(new_path, exist_ok=True)\n",
    "for name in [\"train\", \"validation\", \"test\"]:\n",
    "    with open(os.path.join(dataset_path, f\"{name}.en\")) as src, open(os.path.join(dataset_path, f\"{name}.ja\")) as tgt, \\\n",
    "        open(os.path.join(new_path, f\"{name}.en-ja.en\"), \"w\") as new_src, open(os.path.join(new_path, f\"{name}.en-ja.ja\"), \"w\") as new_tgt:\n",
    "        for line in src:\n",
    "            new_src.write(\" \".join(en_spm.EncodeAsPieces(line)) + \"\\n\")\n",
    "        for line in tgt:\n",
    "            new_tgt.write(\" \".join(ja_spm.EncodeAsPieces(line)) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dict = translation_task.build_dictionary([os.path.join(new_path, f\"train.en-ja.en\")], \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1064"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_dict.symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8777"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict.get_count(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict.index(\"bos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<unk>'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict.symbols[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'▁'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ja_dict = translation_task.build_dictionary([os.path.join(new_path, f\"train.en-ja.ja\")], \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_dict[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'次'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_dict[410]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ja_dict.index('次')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_dict.save(os.path.join(new_path, \"en_dict.en-ja.en\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_ja_trans_savepath = os.path.join(new_path, \"data-bin\")\n",
    "os.makedirs(en_ja_trans_savepath, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--dataset_impl'], dest='dataset_impl', nargs=None, const=None, default=None, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.add_argument(\"--dataset_impl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args(\"--dataset_impl mmap\".split(\" \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mmap'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.dataset_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = VocabularyDatasetBinarizer(en_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fairseq.binarizer.VocabularyDatasetBinarizer at 0x7f0dc17002e0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([133,  12,  54,   6, 164,  37, 113, 190,  15,   4,   2],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.binarize_line(\"▁You ' re ▁ very ▁we l com e .\", BinarizeSummary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"▁You ' re ▁ very ▁we l com e . </s>\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(en_dict[i] for i in binarizer.binarize_line(\"▁You ' re ▁ very ▁we l com e .\", BinarizeSummary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build binary dataset\n",
    "# train.en-ja.en.bin and  train.en-ja.en.idx\n",
    "final_summary = FileBinarizer.multiprocess_dataset(\n",
    "        \"/mnt/dl/NLP/bsd_ja_en/data/translation/train.en-ja.en\",\n",
    "        args.dataset_impl,\n",
    "        binarizer,\n",
    "        \"/mnt/dl/NLP/bsd_ja_en/data/translation/data-bin/train.en-ja.en\",\n",
    "        vocab_size=len(en_dict),\n",
    "        num_workers=8,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary.num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 20:54:32 | INFO | fairseq.data.data_utils | loaded 20,000 examples from: /mnt/dl/NLP/bsd_ja_en/data/translation/data-bin/train.en-ja.en\n"
     ]
    }
   ],
   "source": [
    "# Load dataset for training \n",
    "en_dataset = data_utils.load_indexed_dataset(\"/mnt/dl/NLP/bsd_ja_en/data/translation/data-bin/train.en-ja.en\",\n",
    "                                             dictionary=en_dict, dataset_impl=args.dataset_impl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "         11, 447, 180,   4,   2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"▁So ▁let ' s ▁p re t end ▁we ▁have ▁to ▁export ▁a ▁product ▁to ▁Japan ▁today .\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict.string(en_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "         11, 447, 180,   4,   2], dtype=torch.int32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict.encode_line(en_dict.string(en_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, '</s>', 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dict.eos_index, en_dict[2], en_dict.eos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = StripTokenDataset(en_dataset, en_dict.eos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "          11, 447, 180,   4,   2]),\n",
       " tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "          11, 447, 180,   4]))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_dataset[0], d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_d1 = TruncateDataset(d1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_d1 = TruncateDataset(d1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([], dtype=torch.int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_d1 = AppendTokenDataset(d1, en_dict.eos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "         11, 447, 180,   4,   2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepend_d1 = PrependTokenDataset(d1, en_dict.bos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14,\n",
       "        202,  11, 447, 180,   4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepend_d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_d1 = RandomCropDataset(d1,  5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  5,  85,  54,  10, 343]),\n",
       " tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "          11, 447, 180,   4]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_d1[0], d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  5,  85,  54,  10, 343]),\n",
       " tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "          11, 447, 180,   4]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_d1[0], d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([165,  46,  13,  16]), tensor([165,  46,  13,  16]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_d1[1], d1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  7, 245,  75,  64,  92]),\n",
       " tensor([229,   7, 245,  75,  64,  92,   4]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_d1[56], d1[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_d1 = ConcatDataset([en_dataset, en_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(concat_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "         11, 447, 180,   4,   2])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_d1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "         11, 447, 180,   4,   2])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_d1[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_d1 = PadDataset(concat_d1, en_dict.pad(), left_pad=False, pad_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98, 170,  12,   5,  85,  54,  10, 343,  37,  36,  11, 794,  14, 202,\n",
       "         11, 447, 180,   4,   2])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_d1[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modeling\n",
    "<p> Wiki-103 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dst_path = \"/mnt/dl/NLP/wikitext-103-v1/wikitext-103/subword_bpe/\"\n",
    "wiki_base_fname = \"wiki.%s.tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_task = TASK_REGISTRY[\"language_modeling\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dict = lm_task.build_dictionary([os.path.join(lm_dst_path, wiki_base_fname % \"train\")], workers=8, padding_factor=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41144"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_vocab_binarizer = VocabularyDatasetBinarizer(lm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_bin_dst_path = os.path.join(lm_dst_path, \"data-bin\")\n",
    "os.makedirs(lm_bin_dst_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_file_binarizer = FileBinarizer.multiprocess_dataset(\n",
    "    os.path.join(lm_dst_path, wiki_base_fname % \"train\"),\n",
    "    dataset_impl=args.dataset_impl,\n",
    "    binarizer=lm_vocab_binarizer, \n",
    "    output_prefix=os.path.join(lm_bin_dst_path, wiki_base_fname % \"train\"),\n",
    "    vocab_size=len(lm_dict),\n",
    "    num_workers=8\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_dict.save(os.path.join(lm_dst_path, \"wiki.vocab\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 02:42:55 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: /mnt/dl/NLP/wikitext-103-v1/wikitext-103/subword_bpe/data-bin/wiki.train.tokens\n"
     ]
    }
   ],
   "source": [
    "wiki_dataset = data_utils.load_indexed_dataset(os.path.join(lm_bin_dst_path, wiki_base_fname % \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801350"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   12, 33606,  6456, 15155,  1309,    12,     2])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dict.string(wiki_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= Valky@@ ria Chronicles III ='"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dict.string(wiki_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sen@@ jō no Valky@@ ria 3 : <unk> Chronicles ( Japanese : 戦@@ 場@@ の@@ ヴ@@ ァ@@ ル@@ キ@@ ュ@@ リ@@ ア@@ 3 , lit . Valky@@ ria of the Battlefield 3 ) , commonly referred to as Valky@@ ria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Medi@@ a@@ .@@ Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valky@@ ria series . Emp@@ lo@@ ying the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nam@@ eless \" , a penal military unit serving the nation of Gal@@ lia during the Second Europ@@ an War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" .'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dict.string(wiki_dataset[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   7,   1, ..., 166,  14,   1], dtype=int32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_dataset.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_block_dataset = TokenBlockDataset(wiki_dataset, sizes=wiki_dataset.sizes, \n",
    "                                       block_size=16, pad=lm_dict.pad(), \n",
    "                                       eos=lm_dict.eos(), include_targets=True, \n",
    "                                       break_mode=\"none\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6925646"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_block_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2,     2,    12, 33606,  6456, 15155,  1309,    12,     2,     2,\n",
       "          6082, 30056,   129, 33606,  6456,    92]),\n",
       " tensor([    2,    12, 33606,  6456, 15155,  1309,    12,     2,     2,  6082,\n",
       "         30056,   129, 33606,  6456,    92,    45]),\n",
       " tensor([    1,     2,     2,    12, 33606,  6456, 15155,  1309,    12,     2,\n",
       "             2,  6082, 30056,   129, 33606,  6456]))"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source, item, past_target\n",
    "wiki_block_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,    12, 33606,  6456, 15155,  1309,    12,     2,     2,  6082,\n",
       "        30056,   129, 33606,  6456,    92,    45,     3, 15155,    25,   523,\n",
       "           45, 40160, 40063, 37383, 39585, 37913, 36050, 39860, 39862, 37864,\n",
       "        38910,    92,     5,  6820,     6, 33606,  6456,     7,     4, 30939,\n",
       "           92,    24,     5,  2390,  1356,     9,    19, 33606,  6456, 15155,\n",
       "         1309,   880,   747,     5,    26,    11,  8547,   315,    15,   619,\n",
       "          309,    84,   485,    23,  6390,     8, 17065,   611,  2266, 14573,\n",
       "           21,     4,  2552, 18918,     6, 13789,    10,   237,   337,    10,\n",
       "          747,     5,    31,    26,     4,   246,    84,    10,     4, 33606,\n",
       "         6456,   126,     6, 22740,  1149,  3999,     4,   163,  7273,     7,\n",
       "         8547,     8,   938,    15,    63,  2766,    19,    47,  9595,     5,\n",
       "            4,   353,   705,  3451,     9,     4,    42,    84,     8,  2116,\n",
       "            4,    13, 12860,  8246,    13,     5,    11, 34100,   453,  1450,\n",
       "         2064,     4,  1987,     7,  3190,  7675,    78,     4,  1213, 37369,\n",
       "           32,   200,    54,  2233,  2874,   669,  1178,     8,    38, 17711,\n",
       "          113,     4,  2963,  1450,    13,     3, 15326,    13,     6,     2])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.hstack([wiki_dataset[0], wiki_dataset[1], wiki_dataset[2], wiki_dataset[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   45,     3, 15155,    25,   523,    45, 40160, 40063, 37383, 39585,\n",
       "         37913, 36050, 39860, 39862, 37864, 38910]),\n",
       " tensor([    3, 15155,    25,   523,    45, 40160, 40063, 37383, 39585, 37913,\n",
       "         36050, 39860, 39862, 37864, 38910,    92]),\n",
       " tensor([   92,    45,     3, 15155,    25,   523,    45, 40160, 40063, 37383,\n",
       "         39585, 37913, 36050, 39860, 39862, 37864]))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_block_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_train_dataset = MonolingualDataset(wiki_block_dataset, sizes=wiki_block_dataset.sizes,\n",
    "                                        src_vocab=lm_dict, tgt_vocab=lm_dict, \n",
    "                                        shuffle=False, targets=[\"future\"], \n",
    "                                        add_bos_token=False, fixed_pad_length=None, \n",
    "                                        pad_to_bsz=None\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'source': tensor([    2,     2,    12, 33606,  6456, 15155,  1309,    12,     2,     2,\n",
       "          6082, 30056,   129, 33606,  6456,    92]),\n",
       " 'target': tensor([    2,    12, 33606,  6456, 15155,  1309,    12,     2,     2,  6082,\n",
       "         30056,   129, 33606,  6456,    92,    45])}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'source': tensor([   45,     3, 15155,    25,   523,    45, 40160, 40063, 37383, 39585,\n",
       "         37913, 36050, 39860, 39862, 37864, 38910]),\n",
       " 'target': tensor([    3, 15155,    25,   523,    45, 40160, 40063, 37383, 39585, 37913,\n",
       "         36050, 39860, 39862, 37864, 38910,    92])}"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "wiki_train_shuffle_dataset = MonolingualDataset(wiki_block_dataset, sizes=wiki_block_dataset.sizes,\n",
    "                                        src_vocab=lm_dict, tgt_vocab=lm_dict, \n",
    "                                        shuffle=True, targets=[\"future\"], \n",
    "                                        add_bos_token=False, fixed_pad_length=None, \n",
    "                                        pad_to_bsz=None\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 10,\n",
       " 'source': tensor([   2,   16,   84,  143,  478,   10,  307,    5, 2904,   72,   11,  225,\n",
       "         1676,    7,    4,  139]),\n",
       " 'target': tensor([  16,   84,  143,  478,   10,  307,    5, 2904,   72,   11,  225, 1676,\n",
       "            7,    4,  139, 1109])}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_shuffle_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   2,   16,   84,  143,  478,   10,  307,    5, 2904,   72,   11,  225,\n",
       "         1676,    7,    4,  139]),\n",
       " tensor([  16,   84,  143,  478,   10,  307,    5, 2904,   72,   11,  225, 1676,\n",
       "            7,    4,  139, 1109]),\n",
       " tensor([   1,    2,   16,   84,  143,  478,   10,  307,    5, 2904,   72,   11,\n",
       "          225, 1676,    7,    4]))"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_block_dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'id': -1,\n",
       "  'source': tensor([  642,    19,   552,   419,    18, 17159,    17,   538,   309,    84,\n",
       "          10405,     6,     2]),\n",
       "  'target': tensor([   19,   552,   419,    18, 17159,    17,   538,   309,    84, 10405,\n",
       "              6,     2,     2])},\n",
       " 13)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_train_shuffle_dataset[-1], len(wiki_train_shuffle_dataset[-1][\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked Language\n",
    "Wiki 103 with sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_raw_dst_path = '/mnt/dl/NLP/wikitext-103-v1/wikitext-103'\n",
    "wiki_pieces_dst_path = '/mnt/dl/NLP/wikitext-103-v1/wikitext-103/sentencepieces/'\n",
    "wiki_bin_dst_path = '/mnt/dl/NLP/wikitext-103-v1/wikitext-103/sentencepieces/data-bin'\n",
    "os.makedirs(wiki_bin_dst_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_bpe_cfg = GPT2BPEConfig(gpt2_encoder_json=os.path.join(wiki_pieces_dst_path, \"encoder.json\"),\n",
    "                             gpt2_vocab_bpe=os.path.join(wiki_pieces_dst_path, \"vocab.bpe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_bpe = GPT2BPE(gpt2_bpe_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15496'"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_bpe.encode(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming train dataset\n",
      "Transforming valid dataset\n",
      "Transforming test dataset\n"
     ]
    }
   ],
   "source": [
    "# Transform dataset\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    print(f\"Transforming {split} dataset\")\n",
    "    with (open(os.path.join(wiki_raw_dst_path, wiki_base_fname % split), \"r\") as rf, \n",
    "          open(os.path.join(wiki_pieces_dst_path, wiki_base_fname % split), \"w\") as wf):\n",
    "        for i, line in enumerate(rf):\n",
    "            line = line.strip()\n",
    "            new_line = gpt2_bpe.encode(line)\n",
    "            print(new_line, file=wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_task = TASK_REGISTRY[\"masked_lm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_dict = masked_lm_task.load_dictionary(os.path.join(wiki_pieces_dst_path, \"dict.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_vocab_binarizer = VocabularyDatasetBinarizer(masked_lm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_binarizer = FileBinarizer.multiprocess_dataset(os.path.join(wiki_pieces_dst_path, \"wiki.train.tokens\"),\n",
    "                                                         dataset_impl=args.dataset_impl, binarizer=masked_lm_vocab_binarizer,\n",
    "                                                         output_prefix=os.path.join(wiki_bin_dst_path, wiki_base_fname % \"train\"),\n",
    "                                                         vocab_size=len(masked_lm_dict), num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_idx = masked_lm_dict.add_symbol(\"<mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dict.count[mask_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 06:43:11 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: /mnt/dl/NLP/wikitext-103-v1/wikitext-103/sentencepieces/data-bin/wiki.train.tokens\n"
     ]
    }
   ],
   "source": [
    "masked_lm_dataset = data_utils.load_indexed_dataset(os.path.join(wiki_bin_dst_path, wiki_base_fname % \"train\"), \n",
    "                                                    masked_lm_dict, dataset_impl=args.dataset_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   8,   1, ..., 172,  15,   1], dtype=int32)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dataset.sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2])"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5214,   468, 44068,  6374, 41674,  6395,  5457,     2])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_token_dataset = TokenBlockDataset(masked_lm_dataset, masked_lm_dataset.sizes, \n",
    "                                            block_size=sample_size - 1, pad=masked_lm_dict.pad(), \n",
    "                                            eos=masked_lm_dict.eos(), break_mode=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2,  5214,   468, 44068,  6374, 41674,  6395,  5457,     2,     2,\n",
       "         24365,   267, 38183,   117,   468]),\n",
       " 15)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_dataset[0], len(masked_lm_token_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bos as [CLS] for bert models\n",
    "masked_lm_token_cls_dataset = PrependTokenDataset(masked_lm_token_dataset, masked_lm_dict.bos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     2,  5214,   468, 44068,  6374, 41674,  6395,  5457,     2,\n",
       "             2, 24365,   267, 38183,   117,   468]),\n",
       " 16)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_cls_dataset[0], len(masked_lm_token_cls_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_dataset_src, masked_lm_dataset_tgt = MaskTokensDataset.apply_mask(masked_lm_token_cls_dataset, \n",
    "                                                                            vocab=masked_lm_dict,\n",
    "                                                                            pad_idx=masked_lm_dict.pad(),\n",
    "                                                                            mask_idx=mask_idx,\n",
    "                                                                            seed=0,\n",
    "                                                                            mask_prob=0.15,\n",
    "                                                                            leave_unmasked_prob= 0.1,\n",
    "                                                                            random_token_prob= 0.1,\n",
    "                                                                            freq_weighted_replacement=False,\n",
    "                                                                            mask_whole_words=None,\n",
    "                                                                            mask_multiple_length= 1,\n",
    "                                                                            mask_stdev= .0,\n",
    "                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     2,  5214,   468, 44068, 50264, 41674,  6395,  5457,     2,\n",
       "            2, 24365, 50264, 38183,   117,   468])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dataset_src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'28 569 18354 <mask> 17740 6711 796 10445 <mask> 13090 645 569'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dict.string(masked_lm_dataset_src[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5214,   468, 44068, 50264, 41674,  6395,  5457, 24365, 50264, 38183,\n",
       "          117,   468,     2], dtype=torch.int32)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dict.encode_line('28 569 18354 <mask> 17740 6711 796 10445 <mask> 13090 645 569')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= Valky<mask> Chronicles III =Sen<mask>ō no V'"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_bpe.decode('28 569 18354 <mask> 17740 6711 796 10445 <mask> 13090 645 569')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'= Valkyria Chronicles III =Senjō no V'"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_bpe.decode(masked_lm_dict.string(masked_lm_token_cls_dataset[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    0,     2,  5214,   468, 44068, 50264, 41674,  6395,  5457,     2,\n",
       "             2, 24365, 50264, 38183,   117,   468]),\n",
       " tensor([   1,    1,    1,    1,    1, 6374,    1,    1,    1,    1,    1,    1,\n",
       "          267,    1,    1,    1]))"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dataset_src[0], masked_lm_dataset_tgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     2,  5214,   468, 44068,  6374, 41674,  6395,  5457,     2,\n",
       "            2, 24365,   267, 38183,   117,   468])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_cls_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumelDataset(masked_lm_dataset_src, )[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NumelDataset(masked_lm_dataset_src, )[len(masked_lm_dataset_src) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try break mode in token block used for pretraining\n",
    "masked_lm_token_dataset = TokenBlockDataset(masked_lm_dataset, masked_lm_dataset.sizes, \n",
    "                                            block_size=sample_size - 1, pad=masked_lm_dict.pad(), \n",
    "                                            eos=masked_lm_dict.eos(), break_mode=\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2,  5214,   468, 44068,  6374, 41674,  6395,  5457,     2,     2])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24365,   267, 38183,   117,   468, 44068,  6374,   155,  4832, 28696,\n",
       "         6435, 15698, 41674,    36,  2898,  4832, 47416, 23133, 18164, 42393,\n",
       "        21402, 20024, 48018, 50033, 49080, 49587, 49432, 48947, 49017,   246,\n",
       "         2156,  6474,   479,   468, 44068,  6374,     9,     5, 36954,   155,\n",
       "         4839,  2156, 10266,  4997,     7,    25,   468, 44068,  6374, 41674,\n",
       "         6395,   751,  1429,  2156,    16,    10, 15714,   774,   787,    12,\n",
       "         1039,   816,   569,   177,  2226,    30, 43561,     8,  2454,     4,\n",
       "        36753,    13,     5, 15592, 39435,   479, 30939,    11,   644,  1466,\n",
       "           11,  1429,  2156,    24,    16,     5,   371,   177,    11,     5,\n",
       "          468, 44068,  6374,   651,   479, 23564,   154,     5,   276, 24904,\n",
       "            9, 15714,     8,   588,   787,    12,  1039,    86, 23841,    25,\n",
       "           63, 20193,  2156,     5,   527,  1237, 12980,     7,     5,    78,\n",
       "          177,     8,  3905,     5,    22,  8603, 13802,    22,  2156,    10,\n",
       "        14914,   831,  1933,  2754,     5,  1226,     9,  7155,   493,   148,\n",
       "            5,  4665,  5122, 12560,  1771,    54,  3008,  3556,   909,  1414,\n",
       "            8,    32, 30259,   136,     5, 16659,  1933,    22, 28696,  6435,\n",
       "        15698, 22546,    22,   479,     2])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  133,   177,   880,   709,    11,  1824,  2156,  3406,    81,    10,\n",
       "          739,  4745,     9,     5,   173,   626,    15,   468, 44068,  6374,\n",
       "        41674,  3082,   479,   616,    24, 12544,     5,  2526,  1575,     9,\n",
       "            5,   651,  2156,    24,    67, 12796,  1533, 11431,  2156,   215,\n",
       "           25,   442,     5,   177,    55, 36341,    13,   651, 19298,   479,\n",
       "        35177,  6004, 28696,  6435, 15698,  8768,   267,  1438,     8, 17964,\n",
       "        15225, 23552, 17040, 36066,   258,  1835,    31,   986, 11410,  2156,\n",
       "          552,    19,   468, 44068,  6374, 41674,  3082,   736, 29072,  3592,\n",
       "        10548,  6498,   479,    83,   739,   165,     9,  6737,  7521,     5,\n",
       "         8543,   479,    20,   177,   128,    29,  1273,  4782,    21, 26115,\n",
       "           30,   392,   128,   282,   479,     2])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([106])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_dataset[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_token_cls_dataset2 = PrependTokenDataset(masked_lm_token_dataset, masked_lm_dict.bos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     2,  5214,   468, 44068,  6374, 41674,  6395,  5457,     2,\n",
       "            2])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_cls_dataset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 24365,   267, 38183,   117,   468, 44068,  6374,   155,  4832,\n",
       "        28696,  6435, 15698, 41674,    36,  2898,  4832, 47416, 23133, 18164,\n",
       "        42393, 21402, 20024, 48018, 50033, 49080, 49587, 49432, 48947, 49017,\n",
       "          246,  2156,  6474,   479,   468, 44068,  6374,     9,     5, 36954,\n",
       "          155,  4839,  2156, 10266,  4997,     7,    25,   468, 44068,  6374,\n",
       "        41674,  6395,   751,  1429,  2156,    16,    10, 15714,   774,   787,\n",
       "           12,  1039,   816,   569,   177,  2226,    30, 43561,     8,  2454,\n",
       "            4, 36753,    13,     5, 15592, 39435,   479, 30939,    11,   644,\n",
       "         1466,    11,  1429,  2156,    24,    16,     5,   371,   177,    11,\n",
       "            5,   468, 44068,  6374,   651,   479, 23564,   154,     5,   276,\n",
       "        24904,     9, 15714,     8,   588,   787,    12,  1039,    86, 23841,\n",
       "           25,    63, 20193,  2156,     5,   527,  1237, 12980,     7,     5,\n",
       "           78,   177,     8,  3905,     5,    22,  8603, 13802,    22,  2156,\n",
       "           10, 14914,   831,  1933,  2754,     5,  1226,     9,  7155,   493,\n",
       "          148,     5,  4665,  5122, 12560,  1771,    54,  3008,  3556,   909,\n",
       "         1414,     8,    32, 30259,   136,     5, 16659,  1933,    22, 28696,\n",
       "         6435, 15698, 22546,    22,   479,     2])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_token_cls_dataset2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lm_dataset_src, masked_lm_dataset_tgt = MaskTokensDataset.apply_mask(masked_lm_token_cls_dataset2, \n",
    "                                                                            vocab=masked_lm_dict,\n",
    "                                                                            pad_idx=masked_lm_dict.pad(),\n",
    "                                                                            mask_idx=mask_idx,\n",
    "                                                                            seed= 0,\n",
    "                                                                            mask_prob=0.15,\n",
    "                                                                            leave_unmasked_prob= 0.1,\n",
    "                                                                            random_token_prob= 0.1,\n",
    "                                                                            freq_weighted_replacement=False,\n",
    "                                                                            mask_whole_words=None,\n",
    "                                                                            mask_multiple_length= 1,\n",
    "                                                                            mask_stdev= .0,\n",
    "                                                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,     2,  5214,   468, 50264,  6374, 41674,  6395,  5457,     2,\n",
       "            2])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_lm_dataset_src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0, 24365,   267, 38183,   117,   468, 44068,  6374,   155,  4832,\n",
       "        28696,  6435, 15698, 41674,    36,  2898,  4832, 47416, 23133, 18164,\n",
       "        42393, 21402, 20024, 48018, 50033, 49080, 49587, 49432, 50264, 50264,\n",
       "          246, 50264,  6474,   479,   468, 44068,  6374,     9,     5, 36954,\n",
       "          155,  4839,  2156, 10266,  4997,     7,    25,   468, 44068, 50264,\n",
       "        41674, 50264,   751,  1429,  2156,    16,    10, 15714,   774,   787,\n",
       "           12,  1039,   816, 50264,   177,  2226,    30, 43561,     8,  2454,\n",
       "            4, 36753,    13,     5, 15592, 39435,   479, 30939,    11,   644,\n",
       "        50264,    11,  1429,  2156,    24, 50264,     5,   371,   177,    11,\n",
       "            5,   468, 44068, 50264,   651,   479, 23564, 50264,     5,   276,\n",
       "        24904,     9, 15714,     8, 50264,   787,    12,  1039, 50264, 23841,\n",
       "           25,    63, 20193,  2156,     5,   527,  1237, 50264,     7,     5,\n",
       "           78, 50264, 50264,  3905,     5,    22,  8603, 50264, 50264,  2156,\n",
       "        18865,   162,   831,  1933,  2754,     5,  1226,     9,  7155,   493,\n",
       "          148,     5,  4665,  5122, 12560,  1771,    54,  3008,  3556,   909,\n",
       "         1414, 50264,    32, 50264,   136,     5, 16659,  1933,    22, 28696,\n",
       "         6435, 15698, 50264,    22,   479,     2])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# During training this segment of text will be cut off to fit the transformer input size\n",
    "masked_lm_dataset_src[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RACE finetuning. Sentence Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process race files\n",
    "race_raw_path = \"/mnt/dl/NLP/RACE\"\n",
    "race_raw_processed = \"/mnt/dl/NLP/RACE/processed\"\n",
    "os.makedirs(race_raw_processed, exist_ok=True)\n",
    "splits = [\"train\"]\n",
    "levels = [\"high\", \"middle\"]\n",
    "for split in splits:\n",
    "    os.makedirs(os.path.join(race_raw_processed, split), exist_ok=True)\n",
    "    split_path = os.path.join(race_raw_path, split)\n",
    "    save_inputs = dict()\n",
    "    for col in [\"input0\", \"input1\", \"input2\", \"input3\", \"input4\", \"label\"]:\n",
    "        save_inputs[col] = codecs.open(os.path.join(race_raw_processed, split, col + \".txt\"), \"w\")\n",
    "    samples = []\n",
    "    for level in levels:\n",
    "        level_path = os.path.join(split_path, level)\n",
    "        for fname in sorted(os.listdir(level_path), key=lambda x: int(x.replace(\".txt\", \"\"))):\n",
    "            curr_file = os.path.join(level_path, fname)\n",
    "            with open(curr_file, encoding=\"utf-8\") as f:\n",
    "                contents = json.load(f)\n",
    "                answers = contents[\"answers\"]\n",
    "                questions = contents[\"questions\"]\n",
    "                article = contents[\"article\"].replace(\"\\n\", \" \")\n",
    "                for i, answer in enumerate(answers):\n",
    "                    label = ord(answer) - ord(\"A\")\n",
    "                    question = questions[i]\n",
    "                    options = contents[\"options\"][i]\n",
    "                    print(article, file=save_inputs[\"input0\"])\n",
    "                    print(str(label), file=save_inputs[\"label\"])\n",
    "                    for j, option in enumerate(options):\n",
    "                        if \"_\" in question:\n",
    "                            qa = question.replace(\"_\", option)\n",
    "                        else:\n",
    "                            qa = \" \".join([question, option])\n",
    "                        qa = re.sub(\"\\s+\", \" \", qa)\n",
    "                        if qa[-1] == qa[-3] == \".\":\n",
    "                            qa = qa[:-3] + qa[-2: len(qa)]\n",
    "                        print(qa, file=save_inputs[f\"input{j+1}\"])\n",
    "    for _, f in save_inputs.items():\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_data_path = \"/mnt/dl/NLP/RACE/processed/sentencepiece/\"\n",
    "os.makedirs(race_data_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/dl/NLP/RACE/processed/train/input0.txt\n",
      "/mnt/dl/NLP/RACE/processed/train/input1.txt\n",
      "/mnt/dl/NLP/RACE/processed/train/input2.txt\n",
      "/mnt/dl/NLP/RACE/processed/train/input3.txt\n",
      "/mnt/dl/NLP/RACE/processed/train/input4.txt\n",
      "/mnt/dl/NLP/RACE/processed/train/label.txt\n"
     ]
    }
   ],
   "source": [
    "gpt2_bpe_cfg = GPT2BPEConfig(gpt2_encoder_json=os.path.join(race_data_path, \"encoder.json\"), \n",
    "                             gpt2_vocab_bpe=os.path.join(race_data_path, \"vocab.bpe\"))\n",
    "gpt2_bpe = GPT2BPE(cfg=gpt2_bpe_cfg)\n",
    "for _, fname in save_inputs.items():\n",
    "    fname = fname.name\n",
    "    print(fname)\n",
    "    if \"label\" in fname:\n",
    "        shutil.copyfile(fname, os.path.join(race_data_path, \"train.label.txt\"))\n",
    "        continue\n",
    "    with open(fname) as rf, open(os.path.join(race_data_path, f\"train.{os.path.basename(fname)}\"), \"w\") as wf:\n",
    "        for line in rf:\n",
    "            print(gpt2_bpe.encode(line), file=wf)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skipping this building scheme\n",
    "task_race_lm = TASK_REGISTRY[\"sentence_ranking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_race_dict = Dictionary.load(os.path.join(race_data_path, \"dict.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_idx = task_race_dict.add_symbol(\"<mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/dl/NLP/RACE/processed/sentencepiece/'"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train.input0.txt',\n",
       " 'train.input1.txt',\n",
       " 'train.input2.txt',\n",
       " 'train.input3.txt',\n",
       " 'train.input4.txt']"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_race_files = list(filter(lambda x: \"input\" in x, os.listdir(race_data_path)))\n",
    "task_race_files.sort()\n",
    "task_race_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_race_bin_path = os.path.join(race_data_path, \"data-bin\")\n",
    "os.makedirs(task_race_bin_path, exist_ok=True)\n",
    "binarizer = VocabularyDatasetBinarizer(task_race_dict)\n",
    "for fname in task_race_files:\n",
    "    FileBinarizer.multiprocess_dataset(\n",
    "        os.path.join(race_data_path, fname), dataset_impl=args.dataset_impl,\n",
    "        binarizer=binarizer, \n",
    "        output_prefix=os.path.join(task_race_bin_path, fname.replace(\".txt\", \"\")),\n",
    "        vocab_size=len(task_race_dict),\n",
    "        num_workers=8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 04:44:11 | INFO | fairseq.data.data_utils | loaded 87,866 examples from: /mnt/dl/NLP/RACE/processed/sentencepiece/data-bin/train.input0\n",
      "2023-11-19 04:44:11 | INFO | fairseq.data.data_utils | loaded 87,866 examples from: /mnt/dl/NLP/RACE/processed/sentencepiece/data-bin/train.input1\n",
      "2023-11-19 04:44:11 | INFO | fairseq.data.data_utils | loaded 87,866 examples from: /mnt/dl/NLP/RACE/processed/sentencepiece/data-bin/train.input2\n",
      "2023-11-19 04:44:11 | INFO | fairseq.data.data_utils | loaded 87,866 examples from: /mnt/dl/NLP/RACE/processed/sentencepiece/data-bin/train.input3\n",
      "2023-11-19 04:44:11 | INFO | fairseq.data.data_utils | loaded 87,866 examples from: /mnt/dl/NLP/RACE/processed/sentencepiece/data-bin/train.input4\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "datasets = dict()\n",
    "for i in range(5):\n",
    "    datasets[f\"input{i}\"] = data_utils.load_indexed_dataset(os.path.join(task_race_bin_path, f\"train.input{i}\"),\n",
    "                                                            dictionary=task_race_dict, dataset_impl=args.dataset_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fairseq.data.indexed_dataset.MMapIndexedDataset at 0x7f0dfde1b700>"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"input0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([381, 381, 381, ..., 240, 240, 240], dtype=int32)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"input0\"].sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,  6138,\n",
       "            7,   356,    23,   383,     8,     7,  2842,   106,     4,    91,\n",
       "         3829,     7,  8933,   850,   227,     5,   276,  1964,    11,   430,\n",
       "         6464,     4,    91,    74,   393,   206,     9,  2159,   932,   396,\n",
       "          546,   198,    11,   484,   430,  6464,     4,   374,     5,    97,\n",
       "          865,     6,    38,   437,    45,    10, 14172,  5961,     4,    38,\n",
       "          206,  3482,    16, 15305,     8, 26262,     4,   318,    38,   101,\n",
       "          402,     8,    38,    33,   615,   418,     7,   185,    24,     6,\n",
       "           38,   907,    24,    23,   683,     4,    38,   393,   356,   198,\n",
       "           13,    10,   205,   425,    50,    10,   357,   432,     4,  1525,\n",
       "          768,   127,  1623,     8,    38,   393,   213,  3482,   561,     4,\n",
       "        22008,  3482,   561,    74,    28,   350,  8661,    13,   258,     9,\n",
       "          201,     4,   520,    24,   606,     7,  3482,     6,    52,   213,\n",
       "           84,   430,  1319,     4,  7411,    38,  1394,   127,   979,  5905,\n",
       "            7,   907,   103,   689,    11,     5,  2792,    45,   444,    31,\n",
       "           84,   184,     4,   125,    37,    16,   460, 11640,    12, 11261,\n",
       "            4,   152,    21,    39,   527,     4,   509,   183,    38,    26,\n",
       "            7,   123,     6,    22,    38,  1034,    47,   351,    75,  4309,\n",
       "           99,    38,    33,   174,    47,     7,   907,    72,    22,   440,\n",
       "           60,    26,  5905,     4,    22,   100,   351,    75,  4309,     4,\n",
       "          370,   236,   130, 37027,  2156,   411,  7689,     8,    10,  6881,\n",
       "            9,  4884,    72,    91,   439,   878,   159,     5,  2014,     7,\n",
       "            5,  2792,     4,   287,    37,  2075,     6,    37,    26,     7,\n",
       "         1003,    81,     8,    81,   456,     6,    22,  9983, 37027,  2156,\n",
       "          411,  7689,     8,    10,  6881,     9,  4884,    72,    96,     5,\n",
       "         1786,    37,  8715,   960,    53,    37,  2294,   484,   498,     4,\n",
       "         3128,    37,   794,    80,   604,  2190,   751,    10,  5418,  2792,\n",
       "          454,    10, 20976,  2294,   106,     4,   509,     9,   106,    21,\n",
       "         7340,  2581,     4,  1892,    37,  2294,     7,   492,  2724,  3205,\n",
       "            7,    10, 39882,   271,     4,  1892,    37,  1145,   103,     9,\n",
       "           39,   964,     8,    37,   702,    19,   106,    13,    10,   150,\n",
       "            4,   520,    37,  1348,     5,  2792,     6,    37,    56,  9885,\n",
       "          960,  4682,   411,  7689,     4,   287,    37,  3203,   184,     6,\n",
       "           39,   652,  1059,  5074,  3624,     8,  5074,  3624,     4,   520,\n",
       "           37,   794,   162,    37,    26,     6,    22,   100,   437,  6661,\n",
       "            6, 20675,     4,    38,    33,  9885,     7,   907, 37027,     8,\n",
       "            5,  4884,     4,    38,   129,  8715,     7,   907,   411,  7689,\n",
       "            6,    53,    38,   348,  1882,   130,     9,   106,    72, 50118,\n",
       "            2])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"input0\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = datasets[\"input0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepend eos to input 0\n",
    "input0 = PrependTokenDataset(input0, task_race_dict.eos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_q = []\n",
    "q_inp_length = 128\n",
    "max_positions = 512\n",
    "for i in range(1, 5):\n",
    "    input_dataset = datasets[f\"input{i}\"]\n",
    "    # Prepend bos\n",
    "    input_dataset = PrependTokenDataset(input_dataset, task_race_dict.bos())\n",
    "    # Shorten the question input\n",
    "    input_dataset = TruncateDataset(input_dataset, q_inp_length)\n",
    "    # Concat the questions + articles\n",
    "    input_dataset = ConcatSentencesDataset(input_dataset, input0)\n",
    "    # Truncation for limiting in the networks \n",
    "    input_dataset = TruncateDataset(input_dataset, max_positions)\n",
    "    input_q.append(input_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  133,  1623,  3829,  3482,   142,    37,    34,   203,   418,   479,\n",
       "        50118,     2])"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"input1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,   203,   418,\n",
       "          479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "         5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "         2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "          276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "            9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "            4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "        14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "            4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "            7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "           38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "          357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "          213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "         8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "         3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "         1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "         2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "          460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "          509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "           47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "          907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "          351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "         7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "          159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "            6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "           22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "         4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "         2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "          751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "          509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "            7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "           37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "          106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "            6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "           37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "         5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "           22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "            7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "            7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "            9,   106,    72, 50118,     2])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_q[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  133,  1623,  3829,  3482,   142,    37,    34,   203,   418,   479,\n",
       "        50118])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip the token eos from the question and merge with article is a better solution\n",
    "StripTokenDataset(datasets[\"input1\"], task_race_dict.eos())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dataset = {f\"net_input{idx}\": input_q[idx - 1] for idx in range(1, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dataset = NestedDictionaryDataset(race_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net_input1',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,   203,   418,\n",
       "                        479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "                       5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "                       2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "                        276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "                          9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "                          4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "                      14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "                          4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "                          7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "                         38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "                        357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "                        213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "                       8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "                       3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "                       1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "                       2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "                        460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "                        509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "                         47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "                        907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "                        351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "                       7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "                        159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "                          6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "                         22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "                       4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "                       2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "                        751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "                        509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "                          7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "                         37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "                        106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "                          6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "                         37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "                       5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "                         22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "                          7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "                          7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "                          9,   106,    72, 50118,     2])),\n",
       "             ('net_input2',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,  3829,     5,  6464,\n",
       "                        479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "                       5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "                       2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "                        276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "                          9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "                          4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "                      14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "                          4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "                          7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "                         38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "                        357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "                        213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "                       8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "                       3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "                       1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "                       2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "                        460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "                        509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "                         47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "                        907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "                        351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "                       7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "                        159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "                          6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "                         22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "                       4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "                       2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "                        751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "                        509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "                          7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "                         37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "                        106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "                          6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "                         37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "                       5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "                         22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "                          7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "                          7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "                          9,   106,    72, 50118,     2])),\n",
       "             ('net_input3',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,  3829,     7,  8933,\n",
       "                          5,   850,   227,     5,   276,  1964,   479, 50118,     2,     2,\n",
       "                       2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,  6138,\n",
       "                          7,   356,    23,   383,     8,     7,  2842,   106,     4,    91,\n",
       "                       3829,     7,  8933,   850,   227,     5,   276,  1964,    11,   430,\n",
       "                       6464,     4,    91,    74,   393,   206,     9,  2159,   932,   396,\n",
       "                        546,   198,    11,   484,   430,  6464,     4,   374,     5,    97,\n",
       "                        865,     6,    38,   437,    45,    10, 14172,  5961,     4,    38,\n",
       "                        206,  3482,    16, 15305,     8, 26262,     4,   318,    38,   101,\n",
       "                        402,     8,    38,    33,   615,   418,     7,   185,    24,     6,\n",
       "                         38,   907,    24,    23,   683,     4,    38,   393,   356,   198,\n",
       "                         13,    10,   205,   425,    50,    10,   357,   432,     4,  1525,\n",
       "                        768,   127,  1623,     8,    38,   393,   213,  3482,   561,     4,\n",
       "                      22008,  3482,   561,    74,    28,   350,  8661,    13,   258,     9,\n",
       "                        201,     4,   520,    24,   606,     7,  3482,     6,    52,   213,\n",
       "                         84,   430,  1319,     4,  7411,    38,  1394,   127,   979,  5905,\n",
       "                          7,   907,   103,   689,    11,     5,  2792,    45,   444,    31,\n",
       "                         84,   184,     4,   125,    37,    16,   460, 11640,    12, 11261,\n",
       "                          4,   152,    21,    39,   527,     4,   509,   183,    38,    26,\n",
       "                          7,   123,     6,    22,    38,  1034,    47,   351,    75,  4309,\n",
       "                         99,    38,    33,   174,    47,     7,   907,    72,    22,   440,\n",
       "                         60,    26,  5905,     4,    22,   100,   351,    75,  4309,     4,\n",
       "                        370,   236,   130, 37027,  2156,   411,  7689,     8,    10,  6881,\n",
       "                          9,  4884,    72,    91,   439,   878,   159,     5,  2014,     7,\n",
       "                          5,  2792,     4,   287,    37,  2075,     6,    37,    26,     7,\n",
       "                       1003,    81,     8,    81,   456,     6,    22,  9983, 37027,  2156,\n",
       "                        411,  7689,     8,    10,  6881,     9,  4884,    72,    96,     5,\n",
       "                       1786,    37,  8715,   960,    53,    37,  2294,   484,   498,     4,\n",
       "                       3128,    37,   794,    80,   604,  2190,   751,    10,  5418,  2792,\n",
       "                        454,    10, 20976,  2294,   106,     4,   509,     9,   106,    21,\n",
       "                       7340,  2581,     4,  1892,    37,  2294,     7,   492,  2724,  3205,\n",
       "                          7,    10, 39882,   271,     4,  1892,    37,  1145,   103,     9,\n",
       "                         39,   964,     8,    37,   702,    19,   106,    13,    10,   150,\n",
       "                          4,   520,    37,  1348,     5,  2792,     6,    37,    56,  9885,\n",
       "                        960,  4682,   411,  7689,     4,   287,    37,  3203,   184,     6,\n",
       "                         39,   652,  1059,  5074,  3624,     8,  5074,  3624,     4,   520,\n",
       "                         37,   794,   162,    37,    26,     6,    22,   100,   437,  6661,\n",
       "                          6, 20675,     4,    38,    33,  9885,     7,   907, 37027,     8,\n",
       "                          5,  4884,     4,    38,   129,  8715,     7,   907,   411,  7689,\n",
       "                          6,    53,    38,   348,  1882,   130,     9,   106,    72, 50118,\n",
       "                          2])),\n",
       "             ('net_input4',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,  1085,     7,\n",
       "                        109,    53,  3482,   479, 50118,     2,     2,  2387,  1623,    16,\n",
       "                         10,  2421, 14172,  5961,     4,    91,  6138,     7,   356,    23,\n",
       "                        383,     8,     7,  2842,   106,     4,    91,  3829,     7,  8933,\n",
       "                        850,   227,     5,   276,  1964,    11,   430,  6464,     4,    91,\n",
       "                         74,   393,   206,     9,  2159,   932,   396,   546,   198,    11,\n",
       "                        484,   430,  6464,     4,   374,     5,    97,   865,     6,    38,\n",
       "                        437,    45,    10, 14172,  5961,     4,    38,   206,  3482,    16,\n",
       "                      15305,     8, 26262,     4,   318,    38,   101,   402,     8,    38,\n",
       "                         33,   615,   418,     7,   185,    24,     6,    38,   907,    24,\n",
       "                         23,   683,     4,    38,   393,   356,   198,    13,    10,   205,\n",
       "                        425,    50,    10,   357,   432,     4,  1525,   768,   127,  1623,\n",
       "                          8,    38,   393,   213,  3482,   561,     4, 22008,  3482,   561,\n",
       "                         74,    28,   350,  8661,    13,   258,     9,   201,     4,   520,\n",
       "                         24,   606,     7,  3482,     6,    52,   213,    84,   430,  1319,\n",
       "                          4,  7411,    38,  1394,   127,   979,  5905,     7,   907,   103,\n",
       "                        689,    11,     5,  2792,    45,   444,    31,    84,   184,     4,\n",
       "                        125,    37,    16,   460, 11640,    12, 11261,     4,   152,    21,\n",
       "                         39,   527,     4,   509,   183,    38,    26,     7,   123,     6,\n",
       "                         22,    38,  1034,    47,   351,    75,  4309,    99,    38,    33,\n",
       "                        174,    47,     7,   907,    72,    22,   440,    60,    26,  5905,\n",
       "                          4,    22,   100,   351,    75,  4309,     4,   370,   236,   130,\n",
       "                      37027,  2156,   411,  7689,     8,    10,  6881,     9,  4884,    72,\n",
       "                         91,   439,   878,   159,     5,  2014,     7,     5,  2792,     4,\n",
       "                        287,    37,  2075,     6,    37,    26,     7,  1003,    81,     8,\n",
       "                         81,   456,     6,    22,  9983, 37027,  2156,   411,  7689,     8,\n",
       "                         10,  6881,     9,  4884,    72,    96,     5,  1786,    37,  8715,\n",
       "                        960,    53,    37,  2294,   484,   498,     4,  3128,    37,   794,\n",
       "                         80,   604,  2190,   751,    10,  5418,  2792,   454,    10, 20976,\n",
       "                       2294,   106,     4,   509,     9,   106,    21,  7340,  2581,     4,\n",
       "                       1892,    37,  2294,     7,   492,  2724,  3205,     7,    10, 39882,\n",
       "                        271,     4,  1892,    37,  1145,   103,     9,    39,   964,     8,\n",
       "                         37,   702,    19,   106,    13,    10,   150,     4,   520,    37,\n",
       "                       1348,     5,  2792,     6,    37,    56,  9885,   960,  4682,   411,\n",
       "                       7689,     4,   287,    37,  3203,   184,     6,    39,   652,  1059,\n",
       "                       5074,  3624,     8,  5074,  3624,     4,   520,    37,   794,   162,\n",
       "                         37,    26,     6,    22,   100,   437,  6661,     6, 20675,     4,\n",
       "                         38,    33,  9885,     7,   907, 37027,     8,     5,  4884,     4,\n",
       "                         38,   129,  8715,     7,   907,   411,  7689,     6,    53,    38,\n",
       "                        348,  1882,   130,     9,   106,    72, 50118,     2]))])"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dataset = {f\"net_input{idx}\": {\"tokens\": PadDataset( input_q[idx - 1], task_race_dict.pad(), \n",
    "                                                         left_pad=False, ),\n",
    "                                    \"sizes\": NumelDataset(input_q[idx - 1])} for idx in range(1, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dataset = NestedDictionaryDataset(race_dataset, \n",
    "                                       sizes=[np.maximum.reduce([iq.sizes for iq in input_q])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net_input1.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,   203,   418,\n",
       "                        479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "                       5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "                       2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "                        276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "                          9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "                          4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "                      14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "                          4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "                          7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "                         38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "                        357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "                        213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "                       8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "                       3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "                       1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "                       2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "                        460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "                        509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "                         47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "                        907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "                        351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "                       7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "                        159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "                          6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "                         22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "                       4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "                       2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "                        751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "                        509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "                          7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "                         37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "                        106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "                          6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "                         37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "                       5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "                         22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "                          7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "                          7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "                          9,   106,    72, 50118,     2])),\n",
       "             ('net_input1.sizes', 395),\n",
       "             ('net_input2.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,  3829,     5,  6464,\n",
       "                        479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "                       5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "                       2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "                        276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "                          9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "                          4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "                      14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "                          4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "                          7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "                         38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "                        357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "                        213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "                       8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "                       3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "                       1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "                       2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "                        460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "                        509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "                         47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "                        907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "                        351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "                       7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "                        159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "                          6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "                         22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "                       4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "                       2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "                        751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "                        509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "                          7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "                         37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "                        106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "                          6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "                         37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "                       5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "                         22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "                          7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "                          7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "                          9,   106,    72, 50118,     2])),\n",
       "             ('net_input2.sizes', 395),\n",
       "             ('net_input3.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,  3829,     7,  8933,\n",
       "                          5,   850,   227,     5,   276,  1964,   479, 50118,     2,     2,\n",
       "                       2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,  6138,\n",
       "                          7,   356,    23,   383,     8,     7,  2842,   106,     4,    91,\n",
       "                       3829,     7,  8933,   850,   227,     5,   276,  1964,    11,   430,\n",
       "                       6464,     4,    91,    74,   393,   206,     9,  2159,   932,   396,\n",
       "                        546,   198,    11,   484,   430,  6464,     4,   374,     5,    97,\n",
       "                        865,     6,    38,   437,    45,    10, 14172,  5961,     4,    38,\n",
       "                        206,  3482,    16, 15305,     8, 26262,     4,   318,    38,   101,\n",
       "                        402,     8,    38,    33,   615,   418,     7,   185,    24,     6,\n",
       "                         38,   907,    24,    23,   683,     4,    38,   393,   356,   198,\n",
       "                         13,    10,   205,   425,    50,    10,   357,   432,     4,  1525,\n",
       "                        768,   127,  1623,     8,    38,   393,   213,  3482,   561,     4,\n",
       "                      22008,  3482,   561,    74,    28,   350,  8661,    13,   258,     9,\n",
       "                        201,     4,   520,    24,   606,     7,  3482,     6,    52,   213,\n",
       "                         84,   430,  1319,     4,  7411,    38,  1394,   127,   979,  5905,\n",
       "                          7,   907,   103,   689,    11,     5,  2792,    45,   444,    31,\n",
       "                         84,   184,     4,   125,    37,    16,   460, 11640,    12, 11261,\n",
       "                          4,   152,    21,    39,   527,     4,   509,   183,    38,    26,\n",
       "                          7,   123,     6,    22,    38,  1034,    47,   351,    75,  4309,\n",
       "                         99,    38,    33,   174,    47,     7,   907,    72,    22,   440,\n",
       "                         60,    26,  5905,     4,    22,   100,   351,    75,  4309,     4,\n",
       "                        370,   236,   130, 37027,  2156,   411,  7689,     8,    10,  6881,\n",
       "                          9,  4884,    72,    91,   439,   878,   159,     5,  2014,     7,\n",
       "                          5,  2792,     4,   287,    37,  2075,     6,    37,    26,     7,\n",
       "                       1003,    81,     8,    81,   456,     6,    22,  9983, 37027,  2156,\n",
       "                        411,  7689,     8,    10,  6881,     9,  4884,    72,    96,     5,\n",
       "                       1786,    37,  8715,   960,    53,    37,  2294,   484,   498,     4,\n",
       "                       3128,    37,   794,    80,   604,  2190,   751,    10,  5418,  2792,\n",
       "                        454,    10, 20976,  2294,   106,     4,   509,     9,   106,    21,\n",
       "                       7340,  2581,     4,  1892,    37,  2294,     7,   492,  2724,  3205,\n",
       "                          7,    10, 39882,   271,     4,  1892,    37,  1145,   103,     9,\n",
       "                         39,   964,     8,    37,   702,    19,   106,    13,    10,   150,\n",
       "                          4,   520,    37,  1348,     5,  2792,     6,    37,    56,  9885,\n",
       "                        960,  4682,   411,  7689,     4,   287,    37,  3203,   184,     6,\n",
       "                         39,   652,  1059,  5074,  3624,     8,  5074,  3624,     4,   520,\n",
       "                         37,   794,   162,    37,    26,     6,    22,   100,   437,  6661,\n",
       "                          6, 20675,     4,    38,    33,  9885,     7,   907, 37027,     8,\n",
       "                          5,  4884,     4,    38,   129,  8715,     7,   907,   411,  7689,\n",
       "                          6,    53,    38,   348,  1882,   130,     9,   106,    72, 50118,\n",
       "                          2])),\n",
       "             ('net_input3.sizes', 401),\n",
       "             ('net_input4.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,  1085,     7,\n",
       "                        109,    53,  3482,   479, 50118,     2,     2,  2387,  1623,    16,\n",
       "                         10,  2421, 14172,  5961,     4,    91,  6138,     7,   356,    23,\n",
       "                        383,     8,     7,  2842,   106,     4,    91,  3829,     7,  8933,\n",
       "                        850,   227,     5,   276,  1964,    11,   430,  6464,     4,    91,\n",
       "                         74,   393,   206,     9,  2159,   932,   396,   546,   198,    11,\n",
       "                        484,   430,  6464,     4,   374,     5,    97,   865,     6,    38,\n",
       "                        437,    45,    10, 14172,  5961,     4,    38,   206,  3482,    16,\n",
       "                      15305,     8, 26262,     4,   318,    38,   101,   402,     8,    38,\n",
       "                         33,   615,   418,     7,   185,    24,     6,    38,   907,    24,\n",
       "                         23,   683,     4,    38,   393,   356,   198,    13,    10,   205,\n",
       "                        425,    50,    10,   357,   432,     4,  1525,   768,   127,  1623,\n",
       "                          8,    38,   393,   213,  3482,   561,     4, 22008,  3482,   561,\n",
       "                         74,    28,   350,  8661,    13,   258,     9,   201,     4,   520,\n",
       "                         24,   606,     7,  3482,     6,    52,   213,    84,   430,  1319,\n",
       "                          4,  7411,    38,  1394,   127,   979,  5905,     7,   907,   103,\n",
       "                        689,    11,     5,  2792,    45,   444,    31,    84,   184,     4,\n",
       "                        125,    37,    16,   460, 11640,    12, 11261,     4,   152,    21,\n",
       "                         39,   527,     4,   509,   183,    38,    26,     7,   123,     6,\n",
       "                         22,    38,  1034,    47,   351,    75,  4309,    99,    38,    33,\n",
       "                        174,    47,     7,   907,    72,    22,   440,    60,    26,  5905,\n",
       "                          4,    22,   100,   351,    75,  4309,     4,   370,   236,   130,\n",
       "                      37027,  2156,   411,  7689,     8,    10,  6881,     9,  4884,    72,\n",
       "                         91,   439,   878,   159,     5,  2014,     7,     5,  2792,     4,\n",
       "                        287,    37,  2075,     6,    37,    26,     7,  1003,    81,     8,\n",
       "                         81,   456,     6,    22,  9983, 37027,  2156,   411,  7689,     8,\n",
       "                         10,  6881,     9,  4884,    72,    96,     5,  1786,    37,  8715,\n",
       "                        960,    53,    37,  2294,   484,   498,     4,  3128,    37,   794,\n",
       "                         80,   604,  2190,   751,    10,  5418,  2792,   454,    10, 20976,\n",
       "                       2294,   106,     4,   509,     9,   106,    21,  7340,  2581,     4,\n",
       "                       1892,    37,  2294,     7,   492,  2724,  3205,     7,    10, 39882,\n",
       "                        271,     4,  1892,    37,  1145,   103,     9,    39,   964,     8,\n",
       "                         37,   702,    19,   106,    13,    10,   150,     4,   520,    37,\n",
       "                       1348,     5,  2792,     6,    37,    56,  9885,   960,  4682,   411,\n",
       "                       7689,     4,   287,    37,  3203,   184,     6,    39,   652,  1059,\n",
       "                       5074,  3624,     8,  5074,  3624,     4,   520,    37,   794,   162,\n",
       "                         37,    26,     6,    22,   100,   437,  6661,     6, 20675,     4,\n",
       "                         38,    33,  9885,     7,   907, 37027,     8,     5,  4884,     4,\n",
       "                         38,   129,  8715,     7,   907,   411,  7689,     6,    53,    38,\n",
       "                        348,  1882,   130,     9,   106,    72, 50118,     2])),\n",
       "             ('net_input4.sizes', 398)])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_task_labels = [int(x) for x in open(os.path.join(race_data_path, \"train.label.txt\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dataset = RawLabelDataset(race_task_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dataset = {f\"net_input{idx}\": {\"tokens\": PadDataset( input_q[idx - 1], task_race_dict.pad(), \n",
    "                                                         left_pad=False, ),\n",
    "                                    \"sizes\": NumelDataset(input_q[idx - 1])} for idx in range(1, 5)}\n",
    "race_dataset.update({\"target\": label_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dataset = NestedDictionaryDataset(race_dataset, \n",
    "                                       sizes=[np.maximum.reduce([iq.sizes for iq in input_q])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('net_input1.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,   203,   418,\n",
       "                        479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "                       5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "                       2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "                        276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "                          9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "                          4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "                      14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "                          4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "                          7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "                         38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "                        357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "                        213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "                       8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "                       3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "                       1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "                       2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "                        460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "                        509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "                         47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "                        907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "                        351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "                       7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "                        159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "                          6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "                         22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "                       4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "                       2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "                        751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "                        509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "                          7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "                         37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "                        106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "                          6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "                         37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "                       5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "                         22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "                          7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "                          7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "                          9,   106,    72, 50118,     2])),\n",
       "             ('net_input1.sizes', 395),\n",
       "             ('net_input2.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,  3829,     5,  6464,\n",
       "                        479, 50118,     2,     2,  2387,  1623,    16,    10,  2421, 14172,\n",
       "                       5961,     4,    91,  6138,     7,   356,    23,   383,     8,     7,\n",
       "                       2842,   106,     4,    91,  3829,     7,  8933,   850,   227,     5,\n",
       "                        276,  1964,    11,   430,  6464,     4,    91,    74,   393,   206,\n",
       "                          9,  2159,   932,   396,   546,   198,    11,   484,   430,  6464,\n",
       "                          4,   374,     5,    97,   865,     6,    38,   437,    45,    10,\n",
       "                      14172,  5961,     4,    38,   206,  3482,    16, 15305,     8, 26262,\n",
       "                          4,   318,    38,   101,   402,     8,    38,    33,   615,   418,\n",
       "                          7,   185,    24,     6,    38,   907,    24,    23,   683,     4,\n",
       "                         38,   393,   356,   198,    13,    10,   205,   425,    50,    10,\n",
       "                        357,   432,     4,  1525,   768,   127,  1623,     8,    38,   393,\n",
       "                        213,  3482,   561,     4, 22008,  3482,   561,    74,    28,   350,\n",
       "                       8661,    13,   258,     9,   201,     4,   520,    24,   606,     7,\n",
       "                       3482,     6,    52,   213,    84,   430,  1319,     4,  7411,    38,\n",
       "                       1394,   127,   979,  5905,     7,   907,   103,   689,    11,     5,\n",
       "                       2792,    45,   444,    31,    84,   184,     4,   125,    37,    16,\n",
       "                        460, 11640,    12, 11261,     4,   152,    21,    39,   527,     4,\n",
       "                        509,   183,    38,    26,     7,   123,     6,    22,    38,  1034,\n",
       "                         47,   351,    75,  4309,    99,    38,    33,   174,    47,     7,\n",
       "                        907,    72,    22,   440,    60,    26,  5905,     4,    22,   100,\n",
       "                        351,    75,  4309,     4,   370,   236,   130, 37027,  2156,   411,\n",
       "                       7689,     8,    10,  6881,     9,  4884,    72,    91,   439,   878,\n",
       "                        159,     5,  2014,     7,     5,  2792,     4,   287,    37,  2075,\n",
       "                          6,    37,    26,     7,  1003,    81,     8,    81,   456,     6,\n",
       "                         22,  9983, 37027,  2156,   411,  7689,     8,    10,  6881,     9,\n",
       "                       4884,    72,    96,     5,  1786,    37,  8715,   960,    53,    37,\n",
       "                       2294,   484,   498,     4,  3128,    37,   794,    80,   604,  2190,\n",
       "                        751,    10,  5418,  2792,   454,    10, 20976,  2294,   106,     4,\n",
       "                        509,     9,   106,    21,  7340,  2581,     4,  1892,    37,  2294,\n",
       "                          7,   492,  2724,  3205,     7,    10, 39882,   271,     4,  1892,\n",
       "                         37,  1145,   103,     9,    39,   964,     8,    37,   702,    19,\n",
       "                        106,    13,    10,   150,     4,   520,    37,  1348,     5,  2792,\n",
       "                          6,    37,    56,  9885,   960,  4682,   411,  7689,     4,   287,\n",
       "                         37,  3203,   184,     6,    39,   652,  1059,  5074,  3624,     8,\n",
       "                       5074,  3624,     4,   520,    37,   794,   162,    37,    26,     6,\n",
       "                         22,   100,   437,  6661,     6, 20675,     4,    38,    33,  9885,\n",
       "                          7,   907, 37027,     8,     5,  4884,     4,    38,   129,  8715,\n",
       "                          7,   907,   411,  7689,     6,    53,    38,   348,  1882,   130,\n",
       "                          9,   106,    72, 50118,     2])),\n",
       "             ('net_input2.sizes', 395),\n",
       "             ('net_input3.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,  3829,     7,  8933,\n",
       "                          5,   850,   227,     5,   276,  1964,   479, 50118,     2,     2,\n",
       "                       2387,  1623,    16,    10,  2421, 14172,  5961,     4,    91,  6138,\n",
       "                          7,   356,    23,   383,     8,     7,  2842,   106,     4,    91,\n",
       "                       3829,     7,  8933,   850,   227,     5,   276,  1964,    11,   430,\n",
       "                       6464,     4,    91,    74,   393,   206,     9,  2159,   932,   396,\n",
       "                        546,   198,    11,   484,   430,  6464,     4,   374,     5,    97,\n",
       "                        865,     6,    38,   437,    45,    10, 14172,  5961,     4,    38,\n",
       "                        206,  3482,    16, 15305,     8, 26262,     4,   318,    38,   101,\n",
       "                        402,     8,    38,    33,   615,   418,     7,   185,    24,     6,\n",
       "                         38,   907,    24,    23,   683,     4,    38,   393,   356,   198,\n",
       "                         13,    10,   205,   425,    50,    10,   357,   432,     4,  1525,\n",
       "                        768,   127,  1623,     8,    38,   393,   213,  3482,   561,     4,\n",
       "                      22008,  3482,   561,    74,    28,   350,  8661,    13,   258,     9,\n",
       "                        201,     4,   520,    24,   606,     7,  3482,     6,    52,   213,\n",
       "                         84,   430,  1319,     4,  7411,    38,  1394,   127,   979,  5905,\n",
       "                          7,   907,   103,   689,    11,     5,  2792,    45,   444,    31,\n",
       "                         84,   184,     4,   125,    37,    16,   460, 11640,    12, 11261,\n",
       "                          4,   152,    21,    39,   527,     4,   509,   183,    38,    26,\n",
       "                          7,   123,     6,    22,    38,  1034,    47,   351,    75,  4309,\n",
       "                         99,    38,    33,   174,    47,     7,   907,    72,    22,   440,\n",
       "                         60,    26,  5905,     4,    22,   100,   351,    75,  4309,     4,\n",
       "                        370,   236,   130, 37027,  2156,   411,  7689,     8,    10,  6881,\n",
       "                          9,  4884,    72,    91,   439,   878,   159,     5,  2014,     7,\n",
       "                          5,  2792,     4,   287,    37,  2075,     6,    37,    26,     7,\n",
       "                       1003,    81,     8,    81,   456,     6,    22,  9983, 37027,  2156,\n",
       "                        411,  7689,     8,    10,  6881,     9,  4884,    72,    96,     5,\n",
       "                       1786,    37,  8715,   960,    53,    37,  2294,   484,   498,     4,\n",
       "                       3128,    37,   794,    80,   604,  2190,   751,    10,  5418,  2792,\n",
       "                        454,    10, 20976,  2294,   106,     4,   509,     9,   106,    21,\n",
       "                       7340,  2581,     4,  1892,    37,  2294,     7,   492,  2724,  3205,\n",
       "                          7,    10, 39882,   271,     4,  1892,    37,  1145,   103,     9,\n",
       "                         39,   964,     8,    37,   702,    19,   106,    13,    10,   150,\n",
       "                          4,   520,    37,  1348,     5,  2792,     6,    37,    56,  9885,\n",
       "                        960,  4682,   411,  7689,     4,   287,    37,  3203,   184,     6,\n",
       "                         39,   652,  1059,  5074,  3624,     8,  5074,  3624,     4,   520,\n",
       "                         37,   794,   162,    37,    26,     6,    22,   100,   437,  6661,\n",
       "                          6, 20675,     4,    38,    33,  9885,     7,   907, 37027,     8,\n",
       "                          5,  4884,     4,    38,   129,  8715,     7,   907,   411,  7689,\n",
       "                          6,    53,    38,   348,  1882,   130,     9,   106,    72, 50118,\n",
       "                          2])),\n",
       "             ('net_input3.sizes', 401),\n",
       "             ('net_input4.tokens',\n",
       "              tensor([    0,   133,  1623,  3829,  3482,   142,    37,    34,  1085,     7,\n",
       "                        109,    53,  3482,   479, 50118,     2,     2,  2387,  1623,    16,\n",
       "                         10,  2421, 14172,  5961,     4,    91,  6138,     7,   356,    23,\n",
       "                        383,     8,     7,  2842,   106,     4,    91,  3829,     7,  8933,\n",
       "                        850,   227,     5,   276,  1964,    11,   430,  6464,     4,    91,\n",
       "                         74,   393,   206,     9,  2159,   932,   396,   546,   198,    11,\n",
       "                        484,   430,  6464,     4,   374,     5,    97,   865,     6,    38,\n",
       "                        437,    45,    10, 14172,  5961,     4,    38,   206,  3482,    16,\n",
       "                      15305,     8, 26262,     4,   318,    38,   101,   402,     8,    38,\n",
       "                         33,   615,   418,     7,   185,    24,     6,    38,   907,    24,\n",
       "                         23,   683,     4,    38,   393,   356,   198,    13,    10,   205,\n",
       "                        425,    50,    10,   357,   432,     4,  1525,   768,   127,  1623,\n",
       "                          8,    38,   393,   213,  3482,   561,     4, 22008,  3482,   561,\n",
       "                         74,    28,   350,  8661,    13,   258,     9,   201,     4,   520,\n",
       "                         24,   606,     7,  3482,     6,    52,   213,    84,   430,  1319,\n",
       "                          4,  7411,    38,  1394,   127,   979,  5905,     7,   907,   103,\n",
       "                        689,    11,     5,  2792,    45,   444,    31,    84,   184,     4,\n",
       "                        125,    37,    16,   460, 11640,    12, 11261,     4,   152,    21,\n",
       "                         39,   527,     4,   509,   183,    38,    26,     7,   123,     6,\n",
       "                         22,    38,  1034,    47,   351,    75,  4309,    99,    38,    33,\n",
       "                        174,    47,     7,   907,    72,    22,   440,    60,    26,  5905,\n",
       "                          4,    22,   100,   351,    75,  4309,     4,   370,   236,   130,\n",
       "                      37027,  2156,   411,  7689,     8,    10,  6881,     9,  4884,    72,\n",
       "                         91,   439,   878,   159,     5,  2014,     7,     5,  2792,     4,\n",
       "                        287,    37,  2075,     6,    37,    26,     7,  1003,    81,     8,\n",
       "                         81,   456,     6,    22,  9983, 37027,  2156,   411,  7689,     8,\n",
       "                         10,  6881,     9,  4884,    72,    96,     5,  1786,    37,  8715,\n",
       "                        960,    53,    37,  2294,   484,   498,     4,  3128,    37,   794,\n",
       "                         80,   604,  2190,   751,    10,  5418,  2792,   454,    10, 20976,\n",
       "                       2294,   106,     4,   509,     9,   106,    21,  7340,  2581,     4,\n",
       "                       1892,    37,  2294,     7,   492,  2724,  3205,     7,    10, 39882,\n",
       "                        271,     4,  1892,    37,  1145,   103,     9,    39,   964,     8,\n",
       "                         37,   702,    19,   106,    13,    10,   150,     4,   520,    37,\n",
       "                       1348,     5,  2792,     6,    37,    56,  9885,   960,  4682,   411,\n",
       "                       7689,     4,   287,    37,  3203,   184,     6,    39,   652,  1059,\n",
       "                       5074,  3624,     8,  5074,  3624,     4,   520,    37,   794,   162,\n",
       "                         37,    26,     6,    22,   100,   437,  6661,     6, 20675,     4,\n",
       "                         38,    33,  9885,     7,   907, 37027,     8,     5,  4884,     4,\n",
       "                         38,   129,  8715,     7,   907,   411,  7689,     6,    53,    38,\n",
       "                        348,  1882,   130,     9,   106,    72, 50118,     2])),\n",
       "             ('net_input4.sizes', 398),\n",
       "             ('target', 2)])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> For other GLUE tasks like rte cola same procedures as RACE </strong>\n",
    "<br />\n",
    "<strong> Network input:  [BOS] Question [EOS] Article</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLUE: RTE Sentence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte_raw_dataset = os.path.join(\"/mnt/dl/NLP/GLUE/RTE/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte_processed_dataset = os.path.join(rte_raw_dataset, \"processed\")\n",
    "os.makedirs(rte_processed_dataset, exist_ok=True)\n",
    "rte_bin_dataset = os.path.join(rte_processed_dataset, \"data-bin\")\n",
    "os.makedirs(rte_bin_dataset, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n",
       "      <td>Weapons of Mass Destruction Found in Iraq.</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A place of sorrow, after Pope John Paul II die...</td>\n",
       "      <td>Pope Benedict XVI is the new leader of the Rom...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herceptin was already approved to treat the si...</td>\n",
       "      <td>Herceptin can be used to treat breast cancer.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judie Vivian, chief executive at ProMedica, a ...</td>\n",
       "      <td>The previous name of Ho Chi Minh City was Saigon.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is due in court later charged with the m...</td>\n",
       "      <td>Paul Stewart Hutchinson is accused of having s...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>There is none. They found as many weapons in t...</td>\n",
       "      <td>Weapons of mass destruction found in Iraq.</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>Dr. Eric Goosby, a pioneer in the fight agains...</td>\n",
       "      <td>Pepfar is committed to fighting AIDS.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>NASA's Saturn exploration spacecraft, Cassini ...</td>\n",
       "      <td>Titan is the fifteenth of Saturn's known satel...</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>Brooklyn Borough Hall featured a Who's Who in ...</td>\n",
       "      <td>The Brooklyn Book Festival is held in Brooklyn...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>Turkey is unlikely to become involved in, or a...</td>\n",
       "      <td>U.S. to use Turkish military bases.</td>\n",
       "      <td>not_entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2490 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1   \n",
       "0     No Weapons of Mass Destruction Found in Iraq Yet.  \\\n",
       "1     A place of sorrow, after Pope John Paul II die...   \n",
       "2     Herceptin was already approved to treat the si...   \n",
       "3     Judie Vivian, chief executive at ProMedica, a ...   \n",
       "4     A man is due in court later charged with the m...   \n",
       "...                                                 ...   \n",
       "2485  There is none. They found as many weapons in t...   \n",
       "2486  Dr. Eric Goosby, a pioneer in the fight agains...   \n",
       "2487  NASA's Saturn exploration spacecraft, Cassini ...   \n",
       "2488  Brooklyn Borough Hall featured a Who's Who in ...   \n",
       "2489  Turkey is unlikely to become involved in, or a...   \n",
       "\n",
       "                                              sentence2           label  \n",
       "0            Weapons of Mass Destruction Found in Iraq.  not_entailment  \n",
       "1     Pope Benedict XVI is the new leader of the Rom...      entailment  \n",
       "2         Herceptin can be used to treat breast cancer.      entailment  \n",
       "3     The previous name of Ho Chi Minh City was Saigon.      entailment  \n",
       "4     Paul Stewart Hutchinson is accused of having s...  not_entailment  \n",
       "...                                                 ...             ...  \n",
       "2485         Weapons of mass destruction found in Iraq.  not_entailment  \n",
       "2486              Pepfar is committed to fighting AIDS.      entailment  \n",
       "2487  Titan is the fifteenth of Saturn's known satel...  not_entailment  \n",
       "2488  The Brooklyn Book Festival is held in Brooklyn...      entailment  \n",
       "2489                U.S. to use Turkish military bases.  not_entailment  \n",
       "\n",
       "[2490 rows x 3 columns]"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(rte_raw_dataset, \"train.tsv\"), delimiter=\"\\t\")[[\"sentence1\", \"sentence2\", \"label\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_entailment', 'entailment', nan], dtype=object)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_targets = df[\"label\"].unique()\n",
    "rte_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df[\"label\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['not_entailment', 'entailment'], dtype=object)"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_targets = df[\"label\"].unique()\n",
    "rte_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'not_entailment': 0, 'entailment': 1}"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_targets = dict(zip(rte_targets, range(len(rte_targets))))\n",
    "rte_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13089/1999977124.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"label\"] = df[\"label\"].apply(lambda x: rte_targets[x])\n"
     ]
    }
   ],
   "source": [
    "df[\"label\"] = df[\"label\"].apply(lambda x: rte_targets[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n",
       "      <td>Weapons of Mass Destruction Found in Iraq.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A place of sorrow, after Pope John Paul II die...</td>\n",
       "      <td>Pope Benedict XVI is the new leader of the Rom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herceptin was already approved to treat the si...</td>\n",
       "      <td>Herceptin can be used to treat breast cancer.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judie Vivian, chief executive at ProMedica, a ...</td>\n",
       "      <td>The previous name of Ho Chi Minh City was Saigon.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is due in court later charged with the m...</td>\n",
       "      <td>Paul Stewart Hutchinson is accused of having s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>There is none. They found as many weapons in t...</td>\n",
       "      <td>Weapons of mass destruction found in Iraq.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>Dr. Eric Goosby, a pioneer in the fight agains...</td>\n",
       "      <td>Pepfar is committed to fighting AIDS.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>NASA's Saturn exploration spacecraft, Cassini ...</td>\n",
       "      <td>Titan is the fifteenth of Saturn's known satel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>Brooklyn Borough Hall featured a Who's Who in ...</td>\n",
       "      <td>The Brooklyn Book Festival is held in Brooklyn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>Turkey is unlikely to become involved in, or a...</td>\n",
       "      <td>U.S. to use Turkish military bases.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1   \n",
       "0     No Weapons of Mass Destruction Found in Iraq Yet.  \\\n",
       "1     A place of sorrow, after Pope John Paul II die...   \n",
       "2     Herceptin was already approved to treat the si...   \n",
       "3     Judie Vivian, chief executive at ProMedica, a ...   \n",
       "4     A man is due in court later charged with the m...   \n",
       "...                                                 ...   \n",
       "2485  There is none. They found as many weapons in t...   \n",
       "2486  Dr. Eric Goosby, a pioneer in the fight agains...   \n",
       "2487  NASA's Saturn exploration spacecraft, Cassini ...   \n",
       "2488  Brooklyn Borough Hall featured a Who's Who in ...   \n",
       "2489  Turkey is unlikely to become involved in, or a...   \n",
       "\n",
       "                                              sentence2  label  \n",
       "0            Weapons of Mass Destruction Found in Iraq.      0  \n",
       "1     Pope Benedict XVI is the new leader of the Rom...      1  \n",
       "2         Herceptin can be used to treat breast cancer.      1  \n",
       "3     The previous name of Ho Chi Minh City was Saigon.      1  \n",
       "4     Paul Stewart Hutchinson is accused of having s...      0  \n",
       "...                                                 ...    ...  \n",
       "2485         Weapons of mass destruction found in Iraq.      0  \n",
       "2486              Pepfar is committed to fighting AIDS.      1  \n",
       "2487  Titan is the fifteenth of Saturn's known satel...      0  \n",
       "2488  The Brooklyn Book Festival is held in Brooklyn...      1  \n",
       "2489                U.S. to use Turkish military bases.      0  \n",
       "\n",
       "[2489 rows x 3 columns]"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/dl/NLP/GLUE/RTE/processed'"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_bpe_cfg = GPT2BPEConfig(gpt2_encoder_json=os.path.join(rte_processed_dataset, \"encoder.json\"), \n",
    "                             gpt2_vocab_bpe=os.path.join(rte_processed_dataset, \"vocab.bpe\"))\n",
    "gpt2_bpe = GPT2BPE(cfg=gpt2_bpe_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13089/4179477655.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"input0\"] = df[\"sentence1\"].apply(lambda x: gpt2_bpe.encode(str(x)))\n",
      "/tmp/ipykernel_13089/4179477655.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"input1\"] = df[\"sentence2\"].apply(lambda x: gpt2_bpe.encode(x))\n"
     ]
    }
   ],
   "source": [
    "df[\"input0\"] = df[\"sentence1\"].apply(lambda x: gpt2_bpe.encode(str(x)))\n",
    "df[\"input1\"] = df[\"sentence2\"].apply(lambda x: gpt2_bpe.encode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>input0</th>\n",
       "      <th>input1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Weapons of Mass Destruction Found in Iraq Yet.</td>\n",
       "      <td>Weapons of Mass Destruction Found in Iraq.</td>\n",
       "      <td>0</td>\n",
       "      <td>2949 18944 286 5674 25034 4062 287 3908 6430 13</td>\n",
       "      <td>41818 286 5674 25034 4062 287 3908 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A place of sorrow, after Pope John Paul II die...</td>\n",
       "      <td>Pope Benedict XVI is the new leader of the Rom...</td>\n",
       "      <td>1</td>\n",
       "      <td>32 1295 286 24140 11 706 13258 1757 3362 2873 ...</td>\n",
       "      <td>46172 28697 49090 318 262 649 3554 286 262 799...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Herceptin was already approved to treat the si...</td>\n",
       "      <td>Herceptin can be used to treat breast cancer.</td>\n",
       "      <td>1</td>\n",
       "      <td>9360 984 259 373 1541 6325 284 2190 262 6639 3...</td>\n",
       "      <td>9360 984 259 460 307 973 284 2190 9296 4890 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Judie Vivian, chief executive at ProMedica, a ...</td>\n",
       "      <td>The previous name of Ho Chi Minh City was Saigon.</td>\n",
       "      <td>1</td>\n",
       "      <td>26141 494 25313 666 11 4039 4640 379 1041 9921...</td>\n",
       "      <td>464 2180 1438 286 9544 21380 1855 71 2254 373 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A man is due in court later charged with the m...</td>\n",
       "      <td>Paul Stewart Hutchinson is accused of having s...</td>\n",
       "      <td>0</td>\n",
       "      <td>32 582 318 2233 287 2184 1568 5047 351 262 512...</td>\n",
       "      <td>12041 13671 43792 318 5371 286 1719 21512 257 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>There is none. They found as many weapons in t...</td>\n",
       "      <td>Weapons of mass destruction found in Iraq.</td>\n",
       "      <td>0</td>\n",
       "      <td>1858 318 4844 13 1119 1043 355 867 3777 287 42...</td>\n",
       "      <td>41818 286 2347 8166 1043 287 3908 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>Dr. Eric Goosby, a pioneer in the fight agains...</td>\n",
       "      <td>Pepfar is committed to fighting AIDS.</td>\n",
       "      <td>1</td>\n",
       "      <td>6187 13 7651 1514 418 1525 11 257 29570 287 26...</td>\n",
       "      <td>47 538 16370 318 5364 284 4330 20408 13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487</th>\n",
       "      <td>NASA's Saturn exploration spacecraft, Cassini ...</td>\n",
       "      <td>Titan is the fifteenth of Saturn's known satel...</td>\n",
       "      <td>0</td>\n",
       "      <td>29998 338 23135 13936 16807 11 14154 5362 837 ...</td>\n",
       "      <td>51 18642 318 262 5515 20283 286 23135 338 1900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2488</th>\n",
       "      <td>Brooklyn Borough Hall featured a Who's Who in ...</td>\n",
       "      <td>The Brooklyn Book Festival is held in Brooklyn...</td>\n",
       "      <td>1</td>\n",
       "      <td>45534 6213 48114 4789 8096 257 5338 338 5338 2...</td>\n",
       "      <td>464 12232 4897 11117 318 2714 287 12232 48114 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>Turkey is unlikely to become involved in, or a...</td>\n",
       "      <td>U.S. to use Turkish military bases.</td>\n",
       "      <td>0</td>\n",
       "      <td>31632 318 7485 284 1716 2950 287 11 393 1249 4...</td>\n",
       "      <td>52 13 50 13 284 779 9663 2422 12536 13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1   \n",
       "0     No Weapons of Mass Destruction Found in Iraq Yet.  \\\n",
       "1     A place of sorrow, after Pope John Paul II die...   \n",
       "2     Herceptin was already approved to treat the si...   \n",
       "3     Judie Vivian, chief executive at ProMedica, a ...   \n",
       "4     A man is due in court later charged with the m...   \n",
       "...                                                 ...   \n",
       "2485  There is none. They found as many weapons in t...   \n",
       "2486  Dr. Eric Goosby, a pioneer in the fight agains...   \n",
       "2487  NASA's Saturn exploration spacecraft, Cassini ...   \n",
       "2488  Brooklyn Borough Hall featured a Who's Who in ...   \n",
       "2489  Turkey is unlikely to become involved in, or a...   \n",
       "\n",
       "                                              sentence2  label   \n",
       "0            Weapons of Mass Destruction Found in Iraq.      0  \\\n",
       "1     Pope Benedict XVI is the new leader of the Rom...      1   \n",
       "2         Herceptin can be used to treat breast cancer.      1   \n",
       "3     The previous name of Ho Chi Minh City was Saigon.      1   \n",
       "4     Paul Stewart Hutchinson is accused of having s...      0   \n",
       "...                                                 ...    ...   \n",
       "2485         Weapons of mass destruction found in Iraq.      0   \n",
       "2486              Pepfar is committed to fighting AIDS.      1   \n",
       "2487  Titan is the fifteenth of Saturn's known satel...      0   \n",
       "2488  The Brooklyn Book Festival is held in Brooklyn...      1   \n",
       "2489                U.S. to use Turkish military bases.      0   \n",
       "\n",
       "                                                 input0   \n",
       "0       2949 18944 286 5674 25034 4062 287 3908 6430 13  \\\n",
       "1     32 1295 286 24140 11 706 13258 1757 3362 2873 ...   \n",
       "2     9360 984 259 373 1541 6325 284 2190 262 6639 3...   \n",
       "3     26141 494 25313 666 11 4039 4640 379 1041 9921...   \n",
       "4     32 582 318 2233 287 2184 1568 5047 351 262 512...   \n",
       "...                                                 ...   \n",
       "2485  1858 318 4844 13 1119 1043 355 867 3777 287 42...   \n",
       "2486  6187 13 7651 1514 418 1525 11 257 29570 287 26...   \n",
       "2487  29998 338 23135 13936 16807 11 14154 5362 837 ...   \n",
       "2488  45534 6213 48114 4789 8096 257 5338 338 5338 2...   \n",
       "2489  31632 318 7485 284 1716 2950 287 11 393 1249 4...   \n",
       "\n",
       "                                                 input1  \n",
       "0                 41818 286 5674 25034 4062 287 3908 13  \n",
       "1     46172 28697 49090 318 262 649 3554 286 262 799...  \n",
       "2        9360 984 259 460 307 973 284 2190 9296 4890 13  \n",
       "3     464 2180 1438 286 9544 21380 1855 71 2254 373 ...  \n",
       "4     12041 13671 43792 318 5371 286 1719 21512 257 ...  \n",
       "...                                                 ...  \n",
       "2485               41818 286 2347 8166 1043 287 3908 13  \n",
       "2486            47 538 16370 318 5364 284 4330 20408 13  \n",
       "2487  51 18642 318 262 5515 20283 286 23135 338 1900...  \n",
       "2488  464 12232 4897 11117 318 2714 287 12232 48114 ...  \n",
       "2489             52 13 50 13 284 779 9663 2422 12536 13  \n",
       "\n",
       "[2489 rows x 5 columns]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inp_type in [\"input0\", \"input1\", \"label\"]:\n",
    "    with open(os.path.join(rte_processed_dataset, f\"train.{inp_type}.txt\"), \"w\") as f:\n",
    "        for line in df[inp_type]:\n",
    "            print(line, file=f)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte_dict = Dictionary.load(os.path.join(rte_processed_dataset, \"dict.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fairseq.data.dictionary.Dictionary at 0x7f0d854e82b0>"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50264"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_dict.add_symbol(\"<mask>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte_binarizer = VocabularyDatasetBinarizer(rte_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/dl/NLP/GLUE/RTE/processed/train.input0.txt\n",
      "/mnt/dl/NLP/GLUE/RTE/processed/train.input1.txt\n",
      "/mnt/dl/NLP/GLUE/RTE/processed/train.label.txt\n"
     ]
    }
   ],
   "source": [
    "for inp_type in [\"input0\", \"input1\", \"label\"]:\n",
    "    input_file = os.path.join(rte_processed_dataset, f\"train.{inp_type}.txt\")\n",
    "    print(input_file)\n",
    "    FileBinarizer.multiprocess_dataset(num_workers=4, dataset_impl=args.dataset_impl, binarizer=rte_binarizer, \n",
    "                                       output_prefix=os.path.join(rte_bin_dataset, f\"train.{inp_type}\"),\n",
    "                                       vocab_size=len(rte_dict), input_file=input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 07:08:09 | INFO | fairseq.data.data_utils | loaded 2,489 examples from: /mnt/dl/NLP/GLUE/RTE/processed/data-bin/train.input0\n"
     ]
    }
   ],
   "source": [
    "input0 = data_utils.load_indexed_dataset(os.path.join(rte_bin_dataset, f\"train.input0\"), \n",
    "                                         dictionary=rte_dict,\n",
    "                                         dataset_impl=args.dataset_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Weapons of Mass Destruction Found in Iraq Yet.'"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_bpe.decode(rte_dict.string(input0[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-19 07:08:10 | INFO | fairseq.data.data_utils | loaded 2,489 examples from: /mnt/dl/NLP/GLUE/RTE/processed/data-bin/train.input1\n"
     ]
    }
   ],
   "source": [
    "input1 = data_utils.load_indexed_dataset(os.path.join(rte_bin_dataset, f\"train.input1\"), \n",
    "                                         dictionary=rte_dict,\n",
    "                                         dataset_impl=args.dataset_impl\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48637,     9,  5370, 43207, 11911,    11,  3345,     4,     2])"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 = PrependTokenDataset(input0, rte_dict.bos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = PrependTokenDataset(input1, rte_dict.eos())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte_tokens = ConcatSentencesDataset(StripTokenDataset(input0, rte_dict.eos()), input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  3084, 28054,     9,  5370, 43207, 11911,    11,  3345,  3507,\n",
       "            4,     2, 48637,     9,  5370, 43207, 11911,    11,  3345,     4,\n",
       "            2])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "rte_tokens = TruncateDataset(rte_tokens, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  3084, 28054,     9,  5370, 43207, 11911,    11,  3345,  3507,\n",
       "            4,     2, 48637,     9,  5370, 43207, 11911,    11,  3345,     4,\n",
       "            2])"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rte_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilanguage Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps:\n",
    "1. Binarize\n",
    "2. Load dictionary for each language\n",
    "3. Add token __{lang}__ to each dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
