{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "from collections import OrderedDict\n",
    "import yaml\n",
    "import re\n",
    "from yaml import Loader\n",
    "import functools\n",
    "import torch\n",
    "\n",
    "from seq2seq.utils import generate_seed\n",
    "from seq2seq.data.tokenizer import Tokenizer\n",
    "from seq2seq.data.dataset import ParallelDataset, LazyParallelDataset,  TextDataset\n",
    "from seq2seq.models.gnmt import GNMT\n",
    "from seq2seq.train.loss import LabelSmoothing\n",
    "from seq2seq.data import config as seq2seq_config\n",
    "from seq2seq.inference.translator import Translator\n",
    "from seq2seq.train.trainer import Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(config_filename):\n",
    "    with open(config_filename) as f:\n",
    "        config = yaml.load(f, Loader)\n",
    "    \n",
    "    def fix_config(sub_config, config):\n",
    "        for k, val in sub_config.items():\n",
    "            if isinstance(val, str) and \"${\" in val:\n",
    "                substitutes = []\n",
    "                for re_key in re.findall(r\"(\\$\\{.+?\\})\", val):\n",
    "                    substitutes.append(re_key)\n",
    "                    re_keys = re.search(r\"\\$\\{(.+?)\\}\", re_key).groups()\n",
    "                    for key in re_keys:\n",
    "                        subst_val = config\n",
    "                        for name in key.split(\"@@@\"):\n",
    "                            subst_val = subst_val[name]\n",
    "                        sub_config[k] = sub_config[k].replace(re_key, subst_val)\n",
    "            elif isinstance(val, dict):\n",
    "                fix_config(val, config)\n",
    "    fix_config(config, config)\n",
    "    os.makedirs(config['checkpoint']['save_dir'], exist_ok=True)\n",
    "    \n",
    "    return config\n",
    "\n",
    "config = load_config(\"./config.yaml\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config\n",
    "# /media/mtb/1268324a-8d38-4c4f-9b71-2a4ddc231fe6/dl/nmt/en-fr/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DL_PATH = os.environ.get(\"DL_PATH\")\n",
    "lang = config[\"setup\"][\"lang\"]\n",
    "src_lang = lang['src']\n",
    "tgt_lang = lang[\"tgt\"]\n",
    "SAVEPATH = os.path.join(DL_PATH, \"nmt\", f\"{src_lang}-{tgt_lang}\", \"data\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generat seed. Add epoch\n",
    "datagen_seeds = generate_seed(config['training'][\"epochs\"], seed=0) \n",
    "train_seed = generate_seed(1, config['training'][\"seed\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(train_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "pad_vocab = 8\n",
    "\n",
    "vocab_fname = config[\"setup\"][\"dataset\"]['vocab']\n",
    "bpe_fname = config[\"setup\"][\"dataset\"]['bpe']\n",
    "tokenizer = Tokenizer(vocab_fname=vocab_fname, bpe_fname=bpe_fname, lang=lang, pad=pad_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['training'][\"max_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src_fname = config['setup']['dataset']['src']['train']\n",
    "train_tgt_fname = config['setup']['dataset']['tgt']['train']\n",
    "train_max_len = config['training'][\"train_max_len\"]\n",
    "train_min_len = config['training'][\"train_min_len\"]\n",
    "# TODO\n",
    "train_data = LazyParallelDataset(src_fname=train_src_fname,\n",
    "                             tgt_fname=train_tgt_fname,\n",
    "                             tokenizer=tokenizer,\n",
    "                             min_len=train_min_len,\n",
    "                             max_len=train_max_len,\n",
    "                             sort=False,\n",
    "                             max_size=config['training'][\"max_size\"]\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_src_fname = config['setup']['dataset']['src']['valid']\n",
    "valid_tgt_fname = config['setup']['dataset']['tgt']['valid']\n",
    "valid_max_len = config['training'][\"valid_max_len\"]\n",
    "valid_min_len = config['training'][\"valid_min_len\"]\n",
    "valid_data = ParallelDataset(src_fname=valid_src_fname,\n",
    "                             tgt_fname=valid_tgt_fname,\n",
    "                             tokenizer=tokenizer,\n",
    "                             min_len=valid_min_len,\n",
    "                             max_len=valid_max_len,\n",
    "                             sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_src_fname = config['setup']['dataset']['src']['test']\n",
    "test_max_len = config['training'][\"test_max_len\"]\n",
    "test_min_len = config['training'][\"test_min_len\"]\n",
    "test_data = TextDataset(src_fname=test_src_fname,\n",
    "                        tokenizer=tokenizer,\n",
    "                        min_len=test_min_len,\n",
    "                        max_len=test_max_len,\n",
    "                        sort=True,\n",
    "                        max_size=1408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['setup']['dataset']['src']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['setup']['dataset']['tgt']['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(config['model']) | {\"vocab_size\": tokenizer.vocab_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNMT(**model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_criterion(padding_idx, smoothing=False):\n",
    "    \n",
    "    if smoothing == 0:\n",
    "        print(\"Using cross entropy loss\")\n",
    "        criterion = torch.nn.CrossEntropyLoss(ignore_index=padding_idx, size_average=False)\n",
    "    else:\n",
    "        print(\"Using smoothing Label\")\n",
    "        criterion = LabelSmoothing(padding_idx, smoothing=smoothing)\n",
    "\n",
    "    return criterion\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = build_criterion(seq2seq_config.PAD, config['loss']['smoothing']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_data.get_loader(batch_size=config[\"training\"]['batch_size'],\n",
    "                                     seeds=datagen_seeds,\n",
    "                                     batch_first=config['model']['batch_first'],\n",
    "                                     shuffle=True, \n",
    "                                     batching=config['training']['batching'],\n",
    "                                     batching_opt={'num_buckets': config['training']['num_buckets']},\n",
    "                                     num_workers=config['training']['num_workers'],\n",
    "                                     drop_last=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = valid_data.get_loader(batch_size=8,\n",
    "                                     batch_first=config['model']['batch_first'],\n",
    "                                     shuffle=False, \n",
    "                                     num_workers=0,\n",
    "                                     drop_last=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = test_data.get_loader(batch_size=16,\n",
    "                                     batch_first=config['model']['batch_first'],\n",
    "                                     shuffle=False, \n",
    "                                     pad=True,\n",
    "                                     num_workers=0,\n",
    "                                     drop_last=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(model=model, \n",
    "                        tokenizer=tokenizer,\n",
    "                        loader=test_loader,\n",
    "                        beam_size=config['test']['beam_size'],\n",
    "                        max_seq_len=config['training']['test_max_len'],\n",
    "                        len_norm_const=config['test']['len_norm_const'],\n",
    "                        len_norm_factor=config['test']['len_norm_factor'],\n",
    "                        cov_penalty_factor=config['test']['cov_penalty_factor'],\n",
    "                        print_freq=10,\n",
    "                        reference=config['setup']['dataset']['tgt']['test']\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.sampler.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "total_train_iters = len(train_loader) // config['training']['train_iter_size']  * (config[\"training\"]['epochs'] - config['training']['start_epoch'])\n",
    "total_train_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info = {\n",
    "    \"model_config\": model_config,\n",
    "    \"config\": config,\n",
    "    \"tokenizer\": tokenizer.get_state()\n",
    "}\n",
    "loss_scaling = {\n",
    "    \"init_scale\": 8192,\n",
    "    \"upscale_interval\": 128\n",
    "}\n",
    "opt_config = copy.copy(config['optimizer'])\n",
    "scheduler_config = config['scheduler']\n",
    "\n",
    "trainer_options = dict(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    grad_clip=config['training']['grad_clip'],\n",
    "    save_dir=config['checkpoint']['save_dir'],\n",
    "    save_freq=config['checkpoint']['save_freq'],\n",
    "    save_info=save_info,\n",
    "    opt_config=opt_config,\n",
    "    scheduler_config=scheduler_config,\n",
    "    train_iterations=total_train_iters,\n",
    "    iter_size=config['training']['train_iter_size'],\n",
    "    keep_checkpoints=config['checkpoint']['keep_checkpoints'],\n",
    "    loss_scaling=loss_scaling,\n",
    "    print_freq=10,\n",
    "    intra_epoch_eval=0,\n",
    "    translator=translator,\n",
    "    prealloc_mode=\"once\",\n",
    "    warmup=1,\n",
    "    math=\"fp32\"\n",
    ")\n",
    "trainer = Seq2SeqTrainer(**trainer_options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config['checkpoint']['resume']:\n",
    "    checkpoint_file = config['checkpoint']['resume'] \n",
    "    if os.path.isdir(checkpoint_file):\n",
    "        checkpoint_file = os.path.join(checkpoint_file, 'model_best.pth')\n",
    "    if os.path.isfile(checkpoint_file):\n",
    "        trainer.load(checkpoint_file)\n",
    "        trainer.optimizer.last_epoch = 0\n",
    "    else:\n",
    "        raise ValueError(f\"No checkpoint file for {checkpoint_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, val_loss, best_loss = [float(\"inf\")] * 3\n",
    "training_perf = []\n",
    "break_training = False\n",
    "test_bleu = None\n",
    "start_epoch = config['training']['start_epoch']\n",
    "print(f\"Start epoch {start_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(0, config['training']['epochs']):\n",
    "#     print(f\"Starting epoch {epoch}\")\n",
    "#     train_loader.sampler.set_epoch(epoch)\n",
    "#     trainer.epoch = epoch\n",
    "    \n",
    "#     train_loss, train_perf = trainer.optimize(train_loader)\n",
    "#     # TODO\n",
    "#     continue\n",
    "    \n",
    "#     training_perf.append(train_perf)\n",
    "    \n",
    "#     val_loss, val_perf = trainer.evaluate(valid_loader)\n",
    "#     if val_loss < best_loss:\n",
    "#         trainer.save(is_best=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(start_epoch, config['training']['epochs']):\n",
    "    print(f\"Starting epoch {epoch}\")\n",
    "    train_loader.sampler.set_epoch(epoch)\n",
    "    trainer.epoch = epoch\n",
    "    \n",
    "    train_loss, train_perf = trainer.optimize(train_loader)\n",
    "    training_perf.append(train_perf)\n",
    "    \n",
    "    val_loss, val_perf = trainer.evaluate(valid_loader)\n",
    "    if val_loss < best_loss:\n",
    "        trainer.save(is_best=True)\n",
    "        best_loss = val_loss\n",
    "    eval_fname = f'eval_epoch_{epoch}'\n",
    "    eval_path = os.path.join(config['checkpoint']['save_dir'], eval_fname)\n",
    "    _, eval_stats = translator.run(calc_bleu=True, epoch=epoch, eval_path=eval_path)\n",
    "    test_bleu = eval_stats['bleu']\n",
    "    \n",
    "    acc_log = []\n",
    "    acc_log += [f'Summary: Epoch: {epoch}']\n",
    "    acc_log += [f'Training Loss: {train_loss:.4f}']\n",
    "    acc_log += [f'Validation Loss: {val_loss:.4f}']\n",
    "    acc_log += [f'Test BLEU: {test_bleu:.2f}']\n",
    "    \n",
    "    perf_log = []\n",
    "    perf_log += [f'Performance: Epoch: {epoch}']\n",
    "    # perf_log += [f'Training: {train_perf:.0f} Tok/s']\n",
    "    perf_log += [f'Validation: {val_perf:.0f} Tok/s']\n",
    "    \n",
    "    print(\"*\" * 100)\n",
    "    print(f\"Finished epoch {epoch}\")\n",
    "    print('\\t'.join(acc_log))\n",
    "    print('\\t'.join(perf_log))\n",
    "    print(\"*\" * 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
