{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import nn\n",
    "from positional_encoding import LearnedPositionalEmbedding, SinusoidalPositionalEmbedding\n",
    "from utils import Embedding\n",
    "from config import Config as config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(generator, vocab_size, batch_size=8, length=32, padding_idx=0, \n",
    "                  unk_idx=1, bos_idx=2, eos_idx=3,):\n",
    "    min_pad_idx = max(1, length // 2)\n",
    "    tensor = torch.randint(1, vocab_size, size=(batch_size, length), generator=generator, dtype=torch.long)\n",
    "    mask_idx = torch.randint(min_pad_idx, length, size=(batch_size, 1), generator=generator)\n",
    "    mask = torch.arange(length) >= mask_idx\n",
    "    tensor.masked_fill_(mask, padding_idx)\n",
    "    tensor_length = (~mask).sum(dim=1)\n",
    "    tensor[torch.arange(batch_size), 0] = bos_idx\n",
    "    tensor[torch.arange(batch_size), tensor_length - 1] = eos_idx\n",
    "    return tensor, tensor_length    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "torch.manual_seed(config.seed)\n",
    "generator.manual_seed(config.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor, src_length = generate_data(generator, config.encoder.vocab_size, batch_size=config.batch_size,\n",
    "                                      length=config.seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor.ne(0).sum(dim=1), src_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tensor, tgt_length = generate_data(generator, \n",
    "                                       config.decoder.vocab_size, \n",
    "                                       batch_size=config.batch_size,\n",
    "                                       length=config.seq_length\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tensor.size()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_pos_embed = LearnedPositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                               embedding_dim=config.encoder.embed_dim,\n",
    "                                               padding_idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_pos_embed(src_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_pos_embed(src_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_pos_embed = LearnedPositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                               embedding_dim=config.decoder.embed_dim,\n",
    "                                               padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_pos_embed(tgt_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_pos_embed(tgt_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tensor.size(), src_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed = SinusoidalPositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                               embedding_dim=config.encoder.embed_dim,\n",
    "                                               padding_idx=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed = SinusoidalPositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                               embedding_dim=config.encoder.embed_dim,\n",
    "                                               padding_idx=0)\n",
    "enc_pos_embed = enc_pos_embed.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed._float_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed(src_tensor).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed.weights.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_pos_embed = SinusoidalPositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                               embedding_dim=config.encoder.embed_dim,\n",
    "                                               padding_idx=0)\n",
    "dec_pos_embed = SinusoidalPositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                               embedding_dim=config.decoder.embed_dim,\n",
    "                                               padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_token_embed = Embedding(num_embeddings=config.encoder.vocab_size,\n",
    "                            embedding_dim=config.encoder.embed_dim,\n",
    "                            padding_idx=0)\n",
    "dec_token_embed = Embedding(num_embeddings=config.decoder.vocab_size,\n",
    "                            embedding_dim=config.decoder.embed_dim,\n",
    "                            padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_token_embed.weight"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransformerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor = src_tensor.cuda()\n",
    "tgt_tensor = tgt_tensor.cuda()\n",
    "transformer.train()\n",
    "transformer.cuda()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transformer(src_tensor, src_length, tgt_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[:, -1:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(transformer.parameters()).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = transformer(src_tensor, src_length, tgt_tensor)\n",
    "out.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.enc_token_embed.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate( src_tensor, src_lengths, tgt_tensor, incremental_state):\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_out, enc_key_pad = transformer.encoder(src_tensor, src_length)\n",
    "        inps = tgt_tensor[:, :1]\n",
    "        for i in range(5):\n",
    "            out = transformer.decoder(inps, enc_out, enc_key_pad, incremental_state)\n",
    "            scores = torch.softmax(out, -1)\n",
    "            max_idx = scores.argmax(dim=-1)\n",
    "            inps = torch.column_stack([inps, max_idx])\n",
    "            print(inps)\n",
    "\n",
    "incremental_state = dict()\n",
    "generate(src_tensor, src_length, tgt_tensor, incremental_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.decoder.embed_pos.weights.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dataset import LazyParallelDataset\n",
    "from tokenizer import Tokenizer\n",
    "import os\n",
    "from config import Config as config\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = config.dataset.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_fname=os.path.join(dataset_path, config.train.dataset.vocab_fname, ),\n",
    "                      bpe_fname=os.path.join(dataset_path, config.train.dataset.bpe_fname,),\n",
    "                      lang={'src': config.dataset.src.name,\n",
    "                            'tgt': config.dataset.tgt.name}\n",
    "                      )\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tok2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src_fname = os.path.join(dataset_path, config.dataset.src.train_fname )\n",
    "train_tgt_fname = os.path.join(dataset_path, config.dataset.tgt.train_fname  )\n",
    "train_max_len = config.dataset.src.max_seq_len\n",
    "train_min_len = config.dataset.src.min_seq_len\n",
    "train_data = LazyParallelDataset(src_fname=train_src_fname,\n",
    "                             tgt_fname=train_tgt_fname,\n",
    "                             tokenizer=tokenizer,\n",
    "                             min_len=train_min_len,\n",
    "                             max_len=train_max_len,\n",
    "                             sort=False,\n",
    "                             max_size=config.dataset.size\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.raw_src[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.raw_tgt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.raw_src[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.raw_tgt[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.bpe.process_line(\"This is not taking a stand against the three intellectuals quoted here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.tokenize(\"This is not taking a stand against the three intellectuals quoted here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tokenizer.idx2tok[i] for i  in [2,   148,    35,    68,  1511,    17,  6984,   373,     7,   664,\n",
    "        17338,  1787, 25129,  1875,     5,     3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = tokenizer.tokenize(\"This is not taking a stand against the three intellectuals quoted here.\")\n",
    "tokenizer.detokenize(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_seeds(generator, epochs):\n",
    "    seeds = torch.randint(0, int(9e6), size=(epochs, ), generator=generator).tolist()\n",
    "    return seeds\n",
    "        \n",
    "seeds = get_epoch_seeds(generator, config.train.epochs)\n",
    "seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = train_data.get_loader(batch_size=2,\n",
    "                                     seeds=seeds,\n",
    "                                     batch_first=True,\n",
    "                                     shuffle=True, \n",
    "                                     batching=\"bucketing\",\n",
    "                                     batching_opt={'num_buckets': 5},\n",
    "                                     num_workers=0,\n",
    "                                     drop_last=True\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.sampler.set_epoch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,  ( (src_tensor, src_length), (tgt_tensor, tgt_length), (dec_tgt_tensor, dec_tgt_length)) in enumerate(train_loader):\n",
    "    print(tokenizer.detokenize(src_tensor.numpy()[0]))\n",
    "    print(tokenizer.detokenize(tgt_tensor.numpy()[0]))\n",
    "    print(tokenizer.detokenize(dec_tgt_tensor.numpy()[0]))\n",
    "    # print(dec_tgt_tensor.numpy())\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tgt_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss import SoftmaxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(12).view(4, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.roll(-1, -1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:, 0] = 5\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor, src_length = generate_data(generator, config.encoder.vocab_size, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SoftmaxLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.randn(src_tensor.size(0), src_tensor.size(1), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tensor.size(), out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = loss( out, src_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trainer import Trainer\n",
    "import torch\n",
    "# TODO elimnate TODO in step lamb\n",
    "# TODO total_batch_size = 256 in config\n",
    "# TODO check initialization of net\n",
    "# TODO check Qlinear in multi head ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = torch.tensor([[2, 4, 5, 0, 0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(num_embeddings=10, embedding_dim=6, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in embed.weight:\n",
    "    print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "def fair_Embedding(num_embeddings, embedding_dim, padding_idx):\n",
    "    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
    "    nn.init.normal_(m.weight, mean=0, std=embedding_dim**-0.5)\n",
    "    nn.init.constant_(m.weight[padding_idx], 0)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = fair_Embedding(num_embeddings=10, embedding_dim=6, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in embed.weight:\n",
    "    print(w.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from config_fairseq import config\n",
    "from trainer_fairseq import get_epoch_seeds, Trainer as FairSeqTrainer, get_dataloader\n",
    "from trainer import Trainer\n",
    "import torch\n",
    "from utils import Embedding\n",
    "from torch import nn\n",
    "def fair_Embedding(num_embeddings, embedding_dim, padding_idx):\n",
    "    m = nn.Embedding(num_embeddings, embedding_dim, padding_idx=padding_idx)\n",
    "    nn.init.normal_(m.weight, mean=0, std=embedding_dim**-0.5)\n",
    "    nn.init.constant_(m.weight[padding_idx], 0)\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "seeds = get_epoch_seeds(generator, config.train.epochs)\n",
    "train_loader, tokenizer = get_dataloader(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer = FairSeqTrainer(train_loader=train_loader, tokenizer=tokenizer,\n",
    "                  generator=generator, seeds=seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.model.encoder.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.model.encoder.embed_tokens.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.model.encoder.embed_tokens.weight[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.model.encoder.embed_tokens.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.model.encoder.embed_positions(torch.tensor([[1, 2, 3, 0, 0]]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fair_trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in encoder.embed_tokens.parameters():\n",
    "    print(m.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = encoder.layers[0]\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.quant_noise_block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(layer.final_layer_norm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.fc1_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.parameters():\n",
    "    if m.grad is None:\n",
    "        print(m.grad is None, m.size())\n",
    "        print(type(m))\n",
    "        print(id(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.self_attn.parameters():\n",
    "    print(m.grad is None, m.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.self_attn_layer_norm.parameters():\n",
    "    print(m.grad is None, m.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.fc1.parameters():\n",
    "    print(m.grad is None, m.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.fc2.parameters():\n",
    "    print(m.grad is None, m.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.final_layer_norm.parameters():\n",
    "    print(m.grad is None, m.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in layer.activation_dropout_module.parameters():\n",
    "    print(m.grad is None, m.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for buffer in layer.self_attn.buffers():\n",
    "    print(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in layer.children():\n",
    "    for param in child.parameters():\n",
    "        print(param.grad is None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in layer.self_attn.__dict__.items():\n",
    "    print(id(v), id(v) == 140143996381760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.quant_noise_block_size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()\n",
    "print(len(trainer.train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load(\"/mnt/dl/transformer/checkpoint-ep-00.pth\")\n",
    "# trainer.model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in trainer.model.parameters():\n",
    "#     print(param.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trainer.generate_torch_former(sample=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.squeeze().argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positional_encoding import PositionalEmbedding\n",
    "from config import Config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_pos = PositionalEmbedding(num_embeddings=config.seq_length,\n",
    "                                                 embedding_dim=config.encoder.embed_dim,\n",
    "                                                 padding_idx=config.padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[2, 3, 4, 5, 0, 0, 0, 0],\n",
    "                  [2, 4, 5, 3, 2, 5, 2, 0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_pos(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.embed_dec_pos.weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = torch.load(\"/mnt/dl/transformer/checkpoint-ep-00.pth\")\n",
    "# trainer.model.load_state_dict(state['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.scheduler.last_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from trainer import Trainer\n",
    "import time\n",
    "import torch\n",
    "# TODO elimnate TODO in step lamb\n",
    "from positional_encoding import SinusoidalPositionalEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.embed_enc_pos(torch.tensor([[1, 2, 3, 0, 0,]]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(trainer.lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x = np.arange(1, 1001)\n",
    "y = 1 - np.exp(-(x+100)/250)\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - exp(-(t + b) / a)\n",
    "# t = 0 => lr1 = 1 - exp(-b/a) => log(1 / 1 - lr1) = b / a\n",
    "# t = 1000 => lr2 = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = 1e-3\n",
    "lr1 = 5e-5\n",
    "s = 1000\n",
    "c = 5\n",
    "ratio = np.log(lr2 / (lr2 - lr1))\n",
    "a = 1000. / (c - ratio)\n",
    "b = a * ratio\n",
    "x = np.arange(1, 1001)\n",
    "y = lr2 * ( 1 - np.exp(-(x + b) / a ))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[-1] * 0.99**100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def get_lrs_warmup_stage(lr, warmup_lr, last_epoch):\n",
    "        constant = 5\n",
    "        ratio = math.log(lr / (lr - warmup_lr))\n",
    "        a = 2000. / (constant - ratio)\n",
    "        b = a * ratio\n",
    "        return lr * ( 1 - math.exp(-(last_epoch + b) / a ))\n",
    "y = [get_lrs_warmup_stage(1e-3, 1e-5, i) for i in range(1, 1001)]\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(1, 1001), y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = 3e-3\n",
    "lr1 = 5e-5\n",
    "s = 1000\n",
    "c = 5\n",
    "ratio = np.log(lr2 / (lr2 - lr1))\n",
    "a = 1000. / (c - ratio)\n",
    "b = a * ratio\n",
    "x = np.arange(1, 1001)\n",
    "y = lr2 *  (1 - ((x + 1)/10000) ** 0.5)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(1, 1000)\n",
    "lr = 1e-3\n",
    "y = lr *  np.exp(x * np.log(0.9992))\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100/101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.98**0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 1000)\n",
    "lr = 1e-4\n",
    "y = lr * ( 1 - (x / 12000) ** 0.9)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 1000)\n",
    "lr = 3e-3\n",
    "y = lr * ( 1 - (x / 12000) ** 0.1)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from config_fairseq import config\n",
    "from trainer_fairseq import get_epoch_seeds, Trainer, get_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairseq Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "seeds = get_epoch_seeds(generator, config.train.epochs)\n",
    "train_loader, tokenizer = get_dataloader(seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer.reset(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(train_loader=train_loader, tokenizer=tokenizer,\n",
    "                  generator=generator, seeds=seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('/mnt/dl/transformer_fairseq/checkpoint-ep-06.pth')\n",
    "trainer.model.load_state_dict(state['model'])\n",
    "trainer.optimizer.load_state_dict(state['optimizer'])\n",
    "trainer.scheduler.load_state_dict(state['scheduler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(start_epoch=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.net.training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from config import Config as cfg\n",
    "# from trainer import get_epoch_seeds, Trainer, get_dataloader\n",
    "from trainer_fp16 import get_epoch_seeds, Trainer, get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "seeds = get_epoch_seeds(generator, cfg.train.epochs)\n",
    "train_loader, tokenizer = get_dataloader(cfg, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(cfg=cfg, train_loader=train_loader, tokenizer=tokenizer,\n",
    "                  generator=generator, seeds=seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint = os.path.join(cfg.savepath, 'checkpoint99 (copy).pth')\n",
    "state = torch.load(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model\n",
    "optimizer = trainer.optimizer\n",
    "scheduler = trainer.scheduler\n",
    "model.load_state_dict(state['model'])\n",
    "optimizer.load_state_dict(state['optimizer'])\n",
    "scheduler.load_state_dict(state['scheduler'])\n",
    "\n",
    "src = state['src']\n",
    "tgt = state['tgt']\n",
    "dec_tgt = state['dec_tgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(src, tgt)\n",
    "    loss = trainer.loss_fn(out, dec_tgt)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state['losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(src, tgt)\n",
    "loss = trainer.loss_fn(out, dec_tgt)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fp_16opt.step(loss, None, optimizer, True, scheduler, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from config import Config as cfg\n",
    "# from trainer import get_epoch_seeds, Trainer, get_dataloader\n",
    "# from trainer_fp16 import get_epoch_seeds, Trainer, get_dataloader\n",
    "from trainer_scaler import get_epoch_seeds, Trainer, get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator()\n",
    "seeds = get_epoch_seeds(generator, cfg.train.epochs)\n",
    "train_loader, tokenizer = get_dataloader(cfg, seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(cfg=cfg, train_loader=train_loader, tokenizer=tokenizer,\n",
    "                  generator=generator, seeds=seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.resume(ckp='checkpoint-ep-09.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn((2, 10))\n",
    "target = torch.randint(0, 10, (2, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.cross_entropy(input, target, reduce='sum') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.cross_entropy(input, target, reduce='sum') / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.empty(10).fill_(1000.)\n",
    "torch.nn.functional.cross_entropy(input, \n",
    "                                  target, \n",
    "                                  reduce='sum', \n",
    "                                  weight=weight\n",
    "                                  ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = trainer.get_sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['text']['src'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['text']['tgt'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['text']['dec_tgt'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['tensors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['tensors']['src'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['tensors']['tgt'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.encoder.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, t = samples['tensors']['src'][:1], samples['tensors']['tgt'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.concat([s, s.new_zeros(1, 64-s.size(1))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.concat([t, t.new_zeros(1, 64-t.size(1))], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = s.clone().expand(256, -1)\n",
    "t1 = t.clone().expand(256, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(s1.cuda(), t1.cuda()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from config import Config as cfg\n",
    "# from trainer import get_epoch_seeds, Trainer, get_dataloader\n",
    "# from trainer_fp16 import get_epoch_seeds, Trainer, get_dataloader\n",
    "from trainer_scaler import get_epoch_seeds, Trainer, get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vocabulary /mnt/dl/Translation/WMT_15/en-fr/vocab.bpe.40000\n",
      "Vocabulary size 40282\n",
      "Bucket 0 had length 360175\n",
      "Bucket 1 had length 1109303\n",
      "Bucket 2 had length 1136269\n",
      "Bucket 3 had length 733587\n",
      "Bucket 4 had length 382284\n",
      "New samples  3721344\n",
      "Number of train steps for training is 10902\n"
     ]
    }
   ],
   "source": [
    "generator = torch.Generator()\n",
    "seeds = get_epoch_seeds(generator, cfg.train.epochs)\n",
    "train_loader, tokenizer = get_dataloader(cfg, seeds)\n",
    "\n",
    "\n",
    "trainer = Trainer(cfg=cfg, train_loader=train_loader, tokenizer=tokenizer,\n",
    "                generator=generator, seeds=seeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "trainer.model.load_state_dict(torch.load(os.path.join(trainer.savepath, \"checkpoint10.pth\"))['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting sample...\n"
     ]
    }
   ],
   "source": [
    "sample = trainer.get_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tensors': {'src': tensor([[    2,   296,  4895,     8, 18550,     4,   222,   936,    28,    91,\n",
       "             380,     4,    17,  1393,     8,  2932,   568,  8219,   954,  5812,\n",
       "           20891,     7,  1108,   312, 19147,     8,  6026,     4,   414,  5688,\n",
       "             902,     4,    10,     7,   514,     8,     7,   279,   418,     4,\n",
       "              59,    55, 17131,   711,    59,   106,    81,  4689,     5,     3]]),\n",
       "  'tgt': tensor([[    2,   117,   380,     4,    34, 11464,    22,  2932,   568,  3206,\n",
       "            2339, 25286, 22736,   766,     6,     9, 16117,   559,     6,    14,\n",
       "            1266,     4,    47, 13757,     6,     9,  4800, 27112,    23,  6026,\n",
       "               4,     6,   220,  5688,   902,    11,    23,   461,     6,    14,\n",
       "             437,   318,     5,     3,     0,     0,     0,     0,     0,     0,\n",
       "               0]]),\n",
       "  'dec_tgt': tensor([[  117,   380,     4,    34, 11464,    22,  2932,   568,  3206,  2339,\n",
       "           25286, 22736,   766,     6,     9, 16117,   559,     6,    14,  1266,\n",
       "               4,    47, 13757,     6,     9,  4800, 27112,    23,  6026,     4,\n",
       "               6,   220,  5688,   902,    11,    23,   461,     6,    14,   437,\n",
       "             318,     5,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "               0]])},\n",
       " 'text': {'src': array(['International Day of Families, 15 May : In 1999, a representative of ATD Fourth World spoke alongside the First Lady of Venezuela, Mr. Desai, and the President of the General Assembly, at an observance held at United Nations Headquarters.'],\n",
       "        dtype='<U238'),\n",
       "  'tgt': array([\"En 1999, une reprsentante d'ATD Quart Monde intervient lors de la commmoration de l'ONU, aux cts de la Premire Dame du Venezuela, de M. Desai et du Prsident de l'Assemble gnrale.\"],\n",
       "        dtype='<U187'),\n",
       "  'dec_tgt': array([\"En 1999, une reprsentante d'ATD Quart Monde intervient lors de la commmoration de l'ONU, aux cts de la Premire Dame du Venezuela, de M. Desai et du Prsident de l'Assemble gnrale.\"],\n",
       "        dtype='<U187')}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src:  We recall that the hybrid creation of the Peacebuilding Commission as an intergovernmental advisory body by concurrent resolutions of the General Assembly and the Security Council on 20 December 2005 makes it a unique institutional mechanism and the first of its kind in the United Nations.\n",
      "Tgt:  Nous rappelons qu'ayant t cre par l'adoption simultane de rsolutions de l'Assemble gnrale et du Conseil de scurit le 20 dcembre 2005, la Commission de consolidation de la paix est un dispositif institutionnel hors pair et le premier de cette nature au sein de l'ONU.\n",
      "Starting translation... \n",
      "\n",
      "Translation is:  Nous rappelons que la cration hybride de la Commission de consolidation de la paix comme organe consultatif intergouvernemental par les rsolutions de l'Assemble gnrale et du Conseil de scurit le 20 dcembre 2005 constitue un mcanisme institutionnel unique et le premier de son genre dans l'ONU.\n"
     ]
    }
   ],
   "source": [
    "trainer.translate_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([    2,  4419,  6213,  2417,     4,    74,    49, 12262,    20,     7,\n",
       "         19482,  2350,    21,  2433, 10597,  8178, 10357,     4,  9067,  1634,\n",
       "             4, 36270,   602,  5658,     4, 36587,  3494,    19,   260,    42,\n",
       "         22064,   390, 12833,     7, 31222,   202,     7, 19482,  2350,     5,\n",
       "             3]),\n",
       " tensor([    2,    64,   263,     6,     9,  1144, 10425,    16,    14,  1811,\n",
       "            32,    14,  2687,     6,  8355,    21, 24133,     6,  1414, 23240,\n",
       "          1478,     4,  9291, 18851,     4, 22439,   190,  5658,     4, 29087,\n",
       "            19,    77,   733,    65,  1120,    24,   290,   766,     6,    14,\n",
       "           508,    12, 27268,  5759,    32,    14,  2687,     6,  8355,    43,\n",
       "             3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train_loader.dataset[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.load(\"/mnt/dl/transformer_lamb/checkpoint11.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from config import Config as cfg\n",
    "from trainer_fp16 import get_epoch_seeds, Trainer, get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2**15 - 1]).half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32768.], dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65504.], dtype=torch.float16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x +  32744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "64768. - 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0xffe0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex(65504)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(nan, dtype=torch.float16)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(-11111111).half() / 255888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99954222235786"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65504/(2**16 - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32752"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65504 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16376"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32752 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8188"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16376 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4094"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8188 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4094 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2047 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131008"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "65504  + 65504"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9990234375"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "131008 / 2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
