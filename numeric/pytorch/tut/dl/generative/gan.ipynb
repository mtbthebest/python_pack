{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env_dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import scipy.linalg as sl\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch import nn, distributions as dist, autograd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomHorizontalFlip, RandomVerticalFlip, ToTensor, Normalize\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "from mnist import MNISTTrain, MNISTTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "zdim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNISTTrain(transform=Compose([\n",
    "    ToTensor(),\n",
    "    # RandomHorizontalFlip(0.1),\n",
    "    # RandomVerticalFlip(0.1),\n",
    "    Normalize(127., 128.0)\n",
    "]))\n",
    "val_ds = MNISTTest(transform=Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(127., 128.0)\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.aminmax(\n",
       "min=tensor(-0.9922),\n",
       "max=tensor(1.))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].aminmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, \n",
    "                stride=2, padding=0, outpout_padding=0):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, \n",
    "                                       out_channels, \n",
    "                                       kernel_size=kernel_size, \n",
    "                                       stride=stride, \n",
    "                                       padding=padding,\n",
    "                                       output_padding=outpout_padding\n",
    "                                       )\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        x = F.dropout(x, 0.1)\n",
    "        return x\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self, zdim=50):\n",
    "        super().__init__()\n",
    "        self.zdim = zdim\n",
    "        self.dense = nn.Linear(zdim, 7*7*256)\n",
    "        self.bn1 = nn.BatchNorm1d(7*7*256)\n",
    "        self.act1 = nn.GELU()\n",
    "        self.upsample1 = Upsample(256, 128, kernel_size=3, padding=1, stride=1)\n",
    "        self.upsample2 = Upsample(128, 64, kernel_size=3, padding=1, stride=1)\n",
    "        self.upsample3 = Upsample(64, 32, kernel_size=3, padding=1, stride=2, outpout_padding=1)\n",
    "        self.upsample4 =nn.ConvTranspose2d(32, \n",
    "                                       1, \n",
    "                                       kernel_size=3, \n",
    "                                       stride=2, \n",
    "                                       padding=1,\n",
    "                                       output_padding=1\n",
    "                                       )\n",
    "        self.normalizer = nn.Tanh()\n",
    "        \n",
    "    def forward(self, z):\n",
    "        x = self.dense(z)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = x.view((x.size(0),  256, 7, 7,))\n",
    "        x = self.upsample1(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.upsample3(x)\n",
    "        x = self.upsample4(x)\n",
    "        x = self.normalizer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=\"same\"),\n",
    "            # nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
    "            # nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "        \n",
    "        )\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(256, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(96, 1),\n",
    "            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.squeeze((-2, -1))\n",
    "        x = self.dense(x)\n",
    "        return x\n",
    "    \n",
    "# Generator()(torch.randn((2, 50))).size()\n",
    "# Discriminator()(torch.randn((2, 1, 28, 28))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GanTrainer:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 train_loader, \n",
    "                 val_loader=None, \n",
    "                 epochs=0,\n",
    "                 zdim=50, \n",
    "                 dsteps=10,\n",
    "                 savepath=None, \n",
    "                 batch_size=1,\n",
    "                 eval_epoch=1000000,\n",
    "                 device=torch.device(\"cuda\")\n",
    "                 ):\n",
    "        self.gmodel = Generator(zdim)\n",
    "        self.dmodel = Discriminator()\n",
    "        if device.type == \"cuda\":\n",
    "            self.gmodel.cuda()\n",
    "            self.dmodel.cuda()\n",
    "            \n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.eval_epoch = eval_epoch\n",
    "        self.dsteps = dsteps\n",
    "        self.zdim = zdim\n",
    "        self.device = device\n",
    "        self.n_samples = 0\n",
    "        \n",
    "        \n",
    "        self.doptimizer = torch.optim.Adam(self.dmodel.parameters(), lr=1e-5)    \n",
    "        self.goptimizer = torch.optim.Adam(self.gmodel.parameters(), lr=1e-5)  \n",
    "        \n",
    "        self.noise_sampler = dist.Normal(0., 1.)\n",
    "        self.test_images_z = self.noise_sampler.sample((64, zdim)).to(self.device)\n",
    "        \n",
    "        self.savepath = savepath\n",
    "        if self.savepath is not None:\n",
    "            os.makedirs(self.savepath, exist_ok=True)\n",
    "        \n",
    "    def fit(self, epoch, loader):\n",
    "        losses = {\"generator\": [], \"discriminator\": []}\n",
    "        for step, (imgs, label) in enumerate(loader):\n",
    "            if step > 0 and step % self.dsteps == 0:\n",
    "                gloss = self.fit_generator()\n",
    "                losses[\"generator\"].append(float(gloss))\n",
    "                \n",
    "            imgs = imgs.to(self.device)\n",
    "            dloss = self.fit_discriminator(imgs)\n",
    "            losses[\"discriminator\"].append(float(dloss))\n",
    "            if step % 30 == 0:\n",
    "                print(f\"Epoch: {epoch}, step: {step}, dloss: {np.mean(losses['discriminator'])}, gloss: {np.mean(losses['generator'])}\")\n",
    "           \n",
    "            if step == 1000:\n",
    "                break\n",
    "        return losses\n",
    "    \n",
    "    def get_noise_sample(self, sample_size=-1):\n",
    "        if sample_size == -1:\n",
    "            sample_size = self.batch_size\n",
    "        zsamples = self.noise_sampler.sample((sample_size, self.zdim)).to(self.device)\n",
    "        return zsamples\n",
    "        \n",
    "    def fit_generator(self):\n",
    "        self.gmodel.train()\n",
    "        self.dmodel.train()\n",
    "        \n",
    "        zsamples = self.get_noise_sample()\n",
    "        labels = zsamples.new_ones((self.batch_size, 1)).float()\n",
    "        \n",
    "        zimgs = self.gmodel(zsamples)\n",
    "        zlogits = self.dmodel(zimgs)\n",
    "        gloss = F.binary_cross_entropy_with_logits(zlogits, labels, reduction=\"mean\")\n",
    "        if torch.isnan(gloss):\n",
    "            return 0.\n",
    "        self.goptimizer.zero_grad()\n",
    "        gloss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.gmodel.parameters(), 1.)\n",
    "        \n",
    "        self.goptimizer.step()\n",
    "        self.doptimizer.zero_grad()\n",
    "        \n",
    "        return gloss.item()         \n",
    "    \n",
    "    def fit_discriminator(self, real_imgs):\n",
    "        self.gmodel.train()\n",
    "        self.dmodel.train()\n",
    "        \n",
    "        # with torch.no_grad():\n",
    "        fake_imgs = self.gmodel(self.get_noise_sample(real_imgs.size(0)))\n",
    "        \n",
    "        imgs = torch.cat([real_imgs, fake_imgs.detach()], 0)\n",
    "        \n",
    "        real_labels = real_imgs.new_ones((real_imgs.size(0), )).float()\n",
    "        fake_labels = fake_imgs.new_zeros((fake_imgs.size(0), )).float()\n",
    "        \n",
    "        labels = torch.cat([real_labels, fake_labels], 0)\n",
    "        \n",
    "        logits = self.dmodel(imgs)\n",
    "        logits = logits.squeeze(-1)\n",
    "        \n",
    "        dloss = F.binary_cross_entropy_with_logits(logits, labels, reduction=\"mean\")\n",
    "        self.doptimizer.zero_grad()\n",
    "        dloss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.dmodel.parameters(), 1.)\n",
    "        self.doptimizer.step()\n",
    "        self.goptimizer.zero_grad()\n",
    "        \n",
    "        return dloss.item()\n",
    "    \n",
    "    def train(self):\n",
    "        self.train_losses = {\"generator\": [], \"discriminator\": []}\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            losses = self.fit(epoch, train_loader)\n",
    "            self.train_losses[\"discriminator\"].extend(losses[\"discriminator\"])\n",
    "            self.train_losses[\"generator\"].extend(losses[\"generator\"])\n",
    "            if epoch % self.eval_epoch == 0:\n",
    "                # self.evaluate(epoch)\n",
    "                self.generate_imgs( )\n",
    "        self.generate_imgs()\n",
    "        return \n",
    "    \n",
    "    def evaluate(self, epoch=None):\n",
    "        # TODO\n",
    "        if self.val_loader is None:\n",
    "            return\n",
    "        if epoch is None:\n",
    "            epoch = 0\n",
    "        self.dmodel.eval()\n",
    "        self.gmodel.eval()\n",
    "        with torch.no_grad():\n",
    "            k = 0\n",
    "            acc = []\n",
    "            for (img, label) in self.val_loader:\n",
    "                real_img = img.cuda()\n",
    "                fake_img = self.gmodel(self.get_noise_sample(img.size(0)))\n",
    "                imgs = torch.cat([real_img, fake_img], 0)\n",
    "                logits = self.dmodel(imgs)\n",
    "                real_labels = real_img.new_ones((real_img.size(0), )).float()\n",
    "                fake_labels = fake_img.new_zeros((fake_img.size(0), )).float()\n",
    "                \n",
    "                labels = torch.cat([real_labels, fake_labels], 0)\n",
    "                logits = logits.squeeze(-1)\n",
    "                \n",
    "                probs = torch.sigmoid(logits)\n",
    "                args = probs.ge(torch.tensor(0.5)).long()\n",
    "                acc.append((args.eq(labels).sum() / labels.size(0)).item())\n",
    "                \n",
    "                if k == 20:\n",
    "                    break\n",
    "                k += 1\n",
    "        print(f\"Evaluation epoch {epoch} , acc: {np.mean(acc)}\")\n",
    "        self.dmodel.train()\n",
    "        self.gmodel.train()\n",
    "    \n",
    "    def generate_imgs(self):\n",
    "        savepath = os.path.join(self.savepath, f\"samples{self.n_samples}\")\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        nsample = self.test_images_z.size(0)\n",
    "        self.gmodel.eval()\n",
    "        with torch.no_grad():\n",
    "            xgen = self.gmodel(self.test_images_z)\n",
    "            \n",
    "            imgs = xgen.permute((0, 2, 3, 1))\n",
    "            imgs = imgs.squeeze(-1)\n",
    "            \n",
    "            imgs *= 128.\n",
    "            imgs += 127.\n",
    "            \n",
    "            imgs = list(imgs.unbind())\n",
    "            for n in range(nsample):\n",
    "                fname = os.path.join(savepath, f\"img{n}.jpeg\")\n",
    "                imgs[n] = imgs[n].detach().cpu().long().numpy().astype(np.uint8)\n",
    "                \n",
    "                self.save_img(imgs[n], fname)\n",
    "        self.gmodel.train()\n",
    "\n",
    "        self.n_samples += 1\n",
    "    \n",
    "    def save_img(self, imgs, fname):\n",
    "        Image.fromarray(imgs, mode=\"L\").resize((128, 128)).save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GanTrainer(\n",
    "                 train_loader, \n",
    "                 val_loader=val_loader, \n",
    "                 zdim=64, \n",
    "                 dsteps=5,\n",
    "                 savepath=\"/mnt/dl/generation/gan\", \n",
    "                 batch_size=batch_size,\n",
    "                 device=torch.device(\"cuda\"),\n",
    "                 epochs=15,\n",
    "                 eval_epoch=1,\n",
    "                 \n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env_dl/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/env_dl/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, step: 0, dloss: 0.7053989171981812, gloss: nan\n",
      "Epoch: 1, step: 30, dloss: 0.6463747928219457, gloss: 0.7354837556680044\n",
      "Epoch: 1, step: 60, dloss: 0.5918319547762636, gloss: 0.7323682258526484\n",
      "Epoch: 1, step: 90, dloss: 0.5413798568667946, gloss: 0.7310748365190294\n",
      "Epoch: 1, step: 120, dloss: 0.49567642881850565, gloss: 0.7312271073460579\n",
      "Epoch: 1, step: 150, dloss: 0.45557340407213626, gloss: 0.7320914606253306\n",
      "Epoch: 1, step: 180, dloss: 0.42123712714535094, gloss: 0.7332954721318351\n",
      "Epoch: 1, step: 210, dloss: 0.39187675446130654, gloss: 0.7348449074086689\n",
      "Epoch: 1, step: 240, dloss: 0.3666338616386983, gloss: 0.7365101960798105\n",
      "Epoch: 1, step: 270, dloss: 0.3447502476482814, gloss: 0.7382444993213371\n",
      "Epoch: 1, step: 300, dloss: 0.32559705745936235, gloss: 0.7401560326417287\n",
      "Epoch: 1, step: 330, dloss: 0.30860870797468454, gloss: 0.7422077204241897\n",
      "Epoch: 1, step: 360, dloss: 0.29339432966098233, gloss: 0.7441107498274909\n",
      "Epoch: 1, step: 390, dloss: 0.27969105141547024, gloss: 0.7461609825109824\n",
      "Epoch: 1, step: 420, dloss: 0.2672597836004017, gloss: 0.7481280650411334\n",
      "Epoch: 1, step: 450, dloss: 0.25593328705582014, gloss: 0.7502858168549008\n",
      "Epoch: 2, step: 0, dloss: 0.08963929116725922, gloss: nan\n",
      "Epoch: 2, step: 30, dloss: 0.08588029876832039, gloss: 0.7858254015445709\n",
      "Epoch: 2, step: 60, dloss: 0.08282628044730327, gloss: 0.7873469392458597\n",
      "Epoch: 2, step: 90, dloss: 0.07996045495127584, gloss: 0.7893657750553555\n",
      "Epoch: 2, step: 120, dloss: 0.0773413915279483, gloss: 0.790692093471686\n",
      "Epoch: 2, step: 150, dloss: 0.07484345059126418, gloss: 0.7920052568117778\n",
      "Epoch: 2, step: 180, dloss: 0.07250611208255778, gloss: 0.7938905424541898\n",
      "Epoch: 2, step: 210, dloss: 0.07028967246271987, gloss: 0.7955162610326495\n",
      "Epoch: 2, step: 240, dloss: 0.06816933256152755, gloss: 0.7971137836575508\n",
      "Epoch: 2, step: 270, dloss: 0.0661567489846826, gloss: 0.7985090502986202\n",
      "Epoch: 2, step: 300, dloss: 0.06424963815861762, gloss: 0.7998318235079448\n",
      "Epoch: 2, step: 330, dloss: 0.062441748097043746, gloss: 0.8010493589170051\n",
      "Epoch: 2, step: 360, dloss: 0.06073143399240568, gloss: 0.8025823732217153\n",
      "Epoch: 2, step: 390, dloss: 0.05911391642887879, gloss: 0.803931366174649\n",
      "Epoch: 2, step: 420, dloss: 0.057565243175859405, gloss: 0.8051927054212207\n",
      "Epoch: 2, step: 450, dloss: 0.056098383663432824, gloss: 0.8065338638093736\n",
      "Epoch: 3, step: 0, dloss: 0.03349323198199272, gloss: nan\n",
      "Epoch: 3, step: 30, dloss: 0.03265655629577175, gloss: 0.829332689444224\n",
      "Epoch: 3, step: 60, dloss: 0.031884670685060686, gloss: 0.8315312465031942\n",
      "Epoch: 3, step: 90, dloss: 0.031116692185565665, gloss: 0.8326755629645454\n",
      "Epoch: 3, step: 120, dloss: 0.030366617970722765, gloss: 0.8340190226833025\n",
      "Epoch: 3, step: 150, dloss: 0.029643032909525153, gloss: 0.8347336888313294\n",
      "Epoch: 3, step: 180, dloss: 0.028971977531909943, gloss: 0.8357731335692935\n",
      "Epoch: 3, step: 210, dloss: 0.028329551361183418, gloss: 0.8368359051999592\n",
      "Epoch: 3, step: 240, dloss: 0.027709223770563535, gloss: 0.8377161584794521\n",
      "Epoch: 3, step: 270, dloss: 0.02711744840184701, gloss: 0.8384526868661245\n",
      "Epoch: 3, step: 300, dloss: 0.026551726481496694, gloss: 0.8395035296678544\n",
      "Epoch: 3, step: 330, dloss: 0.026002298348394765, gloss: 0.8403909802436829\n",
      "Epoch: 3, step: 360, dloss: 0.025479056493190846, gloss: 0.8412124953336186\n",
      "Epoch: 3, step: 390, dloss: 0.024969117191936965, gloss: 0.8421603869169186\n",
      "Epoch: 3, step: 420, dloss: 0.024477398084949992, gloss: 0.8429536230507351\n",
      "Epoch: 3, step: 450, dloss: 0.024002355731974154, gloss: 0.8440228409237331\n",
      "Epoch: 4, step: 0, dloss: 0.016458585858345032, gloss: nan\n",
      "Epoch: 4, step: 30, dloss: 0.016309450981357405, gloss: 0.8589210708936056\n",
      "Epoch: 4, step: 60, dloss: 0.016008548759168288, gloss: 0.8590481529633204\n",
      "Epoch: 4, step: 90, dloss: 0.015707720756776386, gloss: 0.8597700794537863\n",
      "Epoch: 4, step: 120, dloss: 0.01541074353832105, gloss: 0.8609688406189283\n",
      "Epoch: 4, step: 150, dloss: 0.015120955615841, gloss: 0.8616884926954905\n",
      "Epoch: 4, step: 180, dloss: 0.014849315191624244, gloss: 0.8617130087481605\n",
      "Epoch: 4, step: 210, dloss: 0.014592486791206762, gloss: 0.8623399294558025\n",
      "Epoch: 4, step: 240, dloss: 0.014336851413875695, gloss: 0.8632447421550751\n",
      "Epoch: 4, step: 270, dloss: 0.01408812403678894, gloss: 0.8641757965087891\n",
      "Epoch: 4, step: 300, dloss: 0.01384534977339332, gloss: 0.8647451728582383\n",
      "Epoch: 4, step: 330, dloss: 0.013615169266964733, gloss: 0.8652122725139965\n",
      "Epoch: 4, step: 360, dloss: 0.013387738729612979, gloss: 0.8658478880921999\n",
      "Epoch: 4, step: 390, dloss: 0.013172788688403261, gloss: 0.8665779515718802\n",
      "Epoch: 4, step: 420, dloss: 0.012960119356540631, gloss: 0.8674161178725106\n",
      "Epoch: 4, step: 450, dloss: 0.012753470375423553, gloss: 0.8679007490475973\n",
      "Epoch: 5, step: 0, dloss: 0.00963833462446928, gloss: nan\n",
      "Epoch: 5, step: 30, dloss: 0.0093937557070486, gloss: 0.8792021373907725\n",
      "Epoch: 5, step: 60, dloss: 0.00923671045142119, gloss: 0.879671091834704\n",
      "Epoch: 5, step: 90, dloss: 0.00908702027543888, gloss: 0.8802705605824789\n",
      "Epoch: 5, step: 120, dloss: 0.00894931019553222, gloss: 0.8806759516398112\n",
      "Epoch: 5, step: 150, dloss: 0.008806645814699447, gloss: 0.8816376864910126\n",
      "Epoch: 5, step: 180, dloss: 0.008670982601151941, gloss: 0.8824693063894907\n",
      "Epoch: 5, step: 210, dloss: 0.008541174427169194, gloss: 0.8828409030323937\n",
      "Epoch: 5, step: 240, dloss: 0.008415002256044461, gloss: 0.8836933684845766\n",
      "Epoch: 5, step: 270, dloss: 0.008294506625674417, gloss: 0.8835367461045583\n",
      "Epoch: 5, step: 300, dloss: 0.0081728541515025, gloss: 0.8842055221398671\n",
      "Epoch: 5, step: 330, dloss: 0.00805636620278445, gloss: 0.8847863087148378\n",
      "Epoch: 5, step: 360, dloss: 0.007941565800127974, gloss: 0.885150722331471\n",
      "Epoch: 5, step: 390, dloss: 0.007831188496392782, gloss: 0.885509620874356\n",
      "Epoch: 5, step: 420, dloss: 0.007722629752948066, gloss: 0.8857030194430124\n",
      "Epoch: 5, step: 450, dloss: 0.007616245325142621, gloss: 0.8861506786611345\n",
      "Epoch: 6, step: 0, dloss: 0.0059236520901322365, gloss: nan\n",
      "Epoch: 6, step: 30, dloss: 0.005864744465197286, gloss: 0.8950829903284708\n",
      "Epoch: 6, step: 60, dloss: 0.005778732251559124, gloss: 0.8942778557538986\n",
      "Epoch: 6, step: 90, dloss: 0.005702062781163297, gloss: 0.8936692939864265\n",
      "Epoch: 6, step: 120, dloss: 0.005623280290083205, gloss: 0.8953375617663065\n",
      "Epoch: 6, step: 150, dloss: 0.005548289767312293, gloss: 0.8947277665138245\n",
      "Epoch: 6, step: 180, dloss: 0.005476104041551194, gloss: 0.895807671878073\n",
      "Epoch: 6, step: 210, dloss: 0.005404539997755634, gloss: 0.8956944261278424\n",
      "Epoch: 6, step: 240, dloss: 0.005334923718186458, gloss: 0.8960584675272306\n",
      "Epoch: 6, step: 270, dloss: 0.005266263993367608, gloss: 0.8964074375452818\n",
      "Epoch: 6, step: 300, dloss: 0.005198498606137263, gloss: 0.896795908610026\n",
      "Epoch: 6, step: 330, dloss: 0.005134085343807396, gloss: 0.8972650558659525\n",
      "Epoch: 6, step: 360, dloss: 0.00506880610582736, gloss: 0.8975924659106467\n",
      "Epoch: 6, step: 390, dloss: 0.005005068158792794, gloss: 0.897754158729162\n",
      "Epoch: 6, step: 420, dloss: 0.0049424676408199265, gloss: 0.8982060736133939\n",
      "Epoch: 6, step: 450, dloss: 0.004882718902081251, gloss: 0.8983074122005039\n",
      "Epoch: 7, step: 0, dloss: 0.0038974254857748747, gloss: nan\n",
      "Epoch: 7, step: 30, dloss: 0.003865009699497492, gloss: 0.907679945230484\n",
      "Epoch: 7, step: 60, dloss: 0.003832591262447541, gloss: 0.9076714466015497\n",
      "Epoch: 7, step: 90, dloss: 0.0037849772757349107, gloss: 0.9071551561355591\n",
      "Epoch: 7, step: 120, dloss: 0.0037356867697397786, gloss: 0.9073908279339472\n",
      "Epoch: 7, step: 150, dloss: 0.0036901564488421804, gloss: 0.9074014882246654\n",
      "Epoch: 7, step: 180, dloss: 0.0036454641257633986, gloss: 0.9073595570193397\n",
      "Epoch: 7, step: 210, dloss: 0.0036011264290907795, gloss: 0.9077489915348235\n",
      "Epoch: 7, step: 240, dloss: 0.0035580316378785244, gloss: 0.9085947747031847\n",
      "Epoch: 7, step: 270, dloss: 0.0035151014855385816, gloss: 0.9091315335697598\n",
      "Epoch: 7, step: 300, dloss: 0.0034735871430956744, gloss: 0.9095670382181803\n",
      "Epoch: 7, step: 330, dloss: 0.0034333389967094734, gloss: 0.9097060958544413\n",
      "Epoch: 7, step: 360, dloss: 0.0033930402218139734, gloss: 0.9098943256669574\n",
      "Epoch: 7, step: 390, dloss: 0.0033544158370084013, gloss: 0.9103248119354248\n",
      "Epoch: 7, step: 420, dloss: 0.0033159054845633457, gloss: 0.910676353034519\n",
      "Epoch: 7, step: 450, dloss: 0.0032785014737760874, gloss: 0.9110341495937772\n",
      "Epoch: 8, step: 0, dloss: 0.002727080136537552, gloss: nan\n",
      "Epoch: 8, step: 30, dloss: 0.0026525355379788144, gloss: 0.9162454803784689\n",
      "Epoch: 8, step: 60, dloss: 0.002625195305702872, gloss: 0.9172702431678772\n",
      "Epoch: 8, step: 90, dloss: 0.0025909657405873577, gloss: 0.9179987907409668\n",
      "Epoch: 8, step: 120, dloss: 0.0025639125638572146, gloss: 0.9182175695896149\n",
      "Epoch: 8, step: 150, dloss: 0.0025328531697861208, gloss: 0.9185488084952037\n",
      "Epoch: 8, step: 180, dloss: 0.0025050318671277216, gloss: 0.9189063161611557\n",
      "Epoch: 8, step: 210, dloss: 0.0024774654004811113, gloss: 0.9191224759533292\n",
      "Epoch: 8, step: 240, dloss: 0.0024492774096885658, gloss: 0.9193169039984544\n",
      "Epoch: 8, step: 270, dloss: 0.002422401714190236, gloss: 0.9197762431921782\n",
      "Epoch: 8, step: 300, dloss: 0.002395624710259297, gloss: 0.9201666871706645\n",
      "Epoch: 8, step: 330, dloss: 0.002370421126135977, gloss: 0.9207251234488054\n",
      "Epoch: 8, step: 360, dloss: 0.0023444446649949304, gloss: 0.9210938670568996\n",
      "Epoch: 8, step: 390, dloss: 0.002319518309098471, gloss: 0.9213379896604098\n",
      "Epoch: 8, step: 420, dloss: 0.0022950277847930294, gloss: 0.9215845054104215\n",
      "Epoch: 8, step: 450, dloss: 0.002271574811685723, gloss: 0.9217468897501627\n",
      "Epoch: 9, step: 0, dloss: 0.0019164918921887875, gloss: nan\n",
      "Epoch: 9, step: 30, dloss: 0.0018635885714883766, gloss: 0.9276962478955587\n",
      "Epoch: 9, step: 60, dloss: 0.001845808182537678, gloss: 0.9248637755711874\n",
      "Epoch: 9, step: 90, dloss: 0.0018254017360140008, gloss: 0.9264548950725131\n",
      "Epoch: 9, step: 120, dloss: 0.001805977810228105, gloss: 0.9262881154815356\n",
      "Epoch: 9, step: 150, dloss: 0.001788890262177547, gloss: 0.9265850881735483\n",
      "Epoch: 9, step: 180, dloss: 0.0017711453613161383, gloss: 0.927447959780693\n",
      "Epoch: 9, step: 210, dloss: 0.0017527904917631668, gloss: 0.9279058674971262\n",
      "Epoch: 9, step: 240, dloss: 0.0017352074827164164, gloss: 0.9289884480337302\n",
      "Epoch: 9, step: 270, dloss: 0.0017178219290299003, gloss: 0.929289126837695\n",
      "Epoch: 9, step: 300, dloss: 0.0017006272752537234, gloss: 0.9300601581732432\n",
      "Epoch: 9, step: 330, dloss: 0.001683865820502249, gloss: 0.9307503691225341\n",
      "Epoch: 9, step: 360, dloss: 0.001666948175086147, gloss: 0.9311198285884328\n",
      "Epoch: 9, step: 390, dloss: 0.0016496123646593194, gloss: 0.9314460632128593\n",
      "Epoch: 9, step: 420, dloss: 0.0016335851162773802, gloss: 0.9319982613836016\n",
      "Epoch: 9, step: 450, dloss: 0.0016177657471779742, gloss: 0.9324340522289276\n",
      "Epoch: 10, step: 0, dloss: 0.0013469918631017208, gloss: nan\n",
      "Epoch: 10, step: 30, dloss: 0.001347681075604933, gloss: 0.9379904965559641\n",
      "Epoch: 10, step: 60, dloss: 0.0013324081302299852, gloss: 0.9401615262031555\n",
      "Epoch: 10, step: 90, dloss: 0.0013171819378980077, gloss: 0.9408527943823073\n",
      "Epoch: 10, step: 120, dloss: 0.00130425429275675, gloss: 0.9399100790421168\n",
      "Epoch: 10, step: 150, dloss: 0.0012912490244782128, gloss: 0.9397227903207143\n",
      "Epoch: 10, step: 180, dloss: 0.001278106611381537, gloss: 0.9408066885338889\n",
      "Epoch: 10, step: 210, dloss: 0.0012648028858950565, gloss: 0.9413806058111645\n",
      "Epoch: 10, step: 240, dloss: 0.001252816299737829, gloss: 0.9418389809628328\n",
      "Epoch: 10, step: 270, dloss: 0.0012395145810583806, gloss: 0.9419668327879023\n",
      "Epoch: 10, step: 300, dloss: 0.0012273536314352407, gloss: 0.9417905161778132\n",
      "Epoch: 10, step: 330, dloss: 0.0012152270266921274, gloss: 0.9421248472098148\n",
      "Epoch: 10, step: 360, dloss: 0.0012037735396913587, gloss: 0.9427562778194746\n",
      "Epoch: 10, step: 390, dloss: 0.0011925399803635105, gloss: 0.9429933520463797\n",
      "Epoch: 10, step: 420, dloss: 0.0011811665717773405, gloss: 0.9432886299632844\n",
      "Epoch: 10, step: 450, dloss: 0.0011700362275806804, gloss: 0.9434140496783786\n",
      "Epoch: 11, step: 0, dloss: 0.0009689549915492535, gloss: nan\n",
      "Epoch: 11, step: 30, dloss: 0.0009774433264899398, gloss: 0.9485645691553751\n",
      "Epoch: 11, step: 60, dloss: 0.0009699597178011766, gloss: 0.9487973600625992\n",
      "Epoch: 11, step: 90, dloss: 0.0009622968091107495, gloss: 0.9495301246643066\n",
      "Epoch: 11, step: 120, dloss: 0.0009526818772308405, gloss: 0.949555459121863\n",
      "Epoch: 11, step: 150, dloss: 0.0009434583738742286, gloss: 0.9500618378321329\n",
      "Epoch: 11, step: 180, dloss: 0.0009342367373000398, gloss: 0.9514287230041292\n",
      "Epoch: 11, step: 210, dloss: 0.0009250032102525834, gloss: 0.951669237443379\n",
      "Epoch: 11, step: 240, dloss: 0.0009156049082357112, gloss: 0.9521890617907047\n",
      "Epoch: 11, step: 270, dloss: 0.0009067261216103536, gloss: 0.9523583087656233\n",
      "Epoch: 11, step: 300, dloss: 0.0008981131263575408, gloss: 0.9525929252306621\n",
      "Epoch: 11, step: 330, dloss: 0.0008899922478448858, gloss: 0.9530090554194017\n",
      "Epoch: 11, step: 360, dloss: 0.0008816290869302738, gloss: 0.9530185080236859\n",
      "Epoch: 11, step: 390, dloss: 0.0008738685625276583, gloss: 0.9536049022124364\n",
      "Epoch: 11, step: 420, dloss: 0.0008654785500131459, gloss: 0.9538219287281945\n",
      "Epoch: 11, step: 450, dloss: 0.0008575778582056948, gloss: 0.9543939418262906\n",
      "Epoch: 12, step: 0, dloss: 0.0007416151347570121, gloss: nan\n",
      "Epoch: 12, step: 30, dloss: 0.0007301846353877936, gloss: 0.961946964263916\n",
      "Epoch: 12, step: 60, dloss: 0.000720352016496243, gloss: 0.9620331873496374\n",
      "Epoch: 12, step: 90, dloss: 0.0007111054223419709, gloss: 0.9624324076705508\n",
      "Epoch: 12, step: 120, dloss: 0.0007036636311229903, gloss: 0.9613746926188469\n",
      "Epoch: 12, step: 150, dloss: 0.0006968936653937282, gloss: 0.9618553340435028\n",
      "Epoch: 12, step: 180, dloss: 0.0006900595164039681, gloss: 0.961632662349277\n",
      "Epoch: 12, step: 210, dloss: 0.0006837163887966548, gloss: 0.9610925373576936\n",
      "Epoch: 12, step: 240, dloss: 0.0006771929167439056, gloss: 0.961198054254055\n",
      "Epoch: 12, step: 270, dloss: 0.0006704920141638095, gloss: 0.9614166838151438\n",
      "Epoch: 12, step: 300, dloss: 0.0006644101600716528, gloss: 0.9621441175540288\n",
      "Epoch: 12, step: 330, dloss: 0.0006580993542278866, gloss: 0.9621139936374895\n",
      "Epoch: 12, step: 360, dloss: 0.0006519862335533874, gloss: 0.9627995159890916\n",
      "Epoch: 12, step: 390, dloss: 0.0006458724597635706, gloss: 0.9631845141068484\n",
      "Epoch: 12, step: 420, dloss: 0.0006401552087317647, gloss: 0.9634885326737449\n",
      "Epoch: 12, step: 450, dloss: 0.0006344573194896204, gloss: 0.9635311345259349\n",
      "Epoch: 13, step: 0, dloss: 0.0005341111682355404, gloss: nan\n",
      "Epoch: 13, step: 30, dloss: 0.0005371277201770534, gloss: 0.9668810069561005\n",
      "Epoch: 13, step: 60, dloss: 0.0005337022202944414, gloss: 0.9672526270151138\n",
      "Epoch: 13, step: 90, dloss: 0.0005284939959113087, gloss: 0.9685526854462094\n",
      "Epoch: 13, step: 120, dloss: 0.0005230252820544314, gloss: 0.9697375570734342\n",
      "Epoch: 13, step: 150, dloss: 0.0005185540697293738, gloss: 0.9697820762793223\n",
      "Epoch: 13, step: 180, dloss: 0.0005134097835916038, gloss: 0.9699627922640907\n",
      "Epoch: 13, step: 210, dloss: 0.0005089267002809263, gloss: 0.970628579457601\n",
      "Epoch: 13, step: 240, dloss: 0.0005041107396968096, gloss: 0.97123255332311\n",
      "Epoch: 13, step: 270, dloss: 0.0004993041860656229, gloss: 0.9713742203182645\n",
      "Epoch: 13, step: 300, dloss: 0.0004947791546095855, gloss: 0.9711185793081919\n",
      "Epoch: 13, step: 330, dloss: 0.0004905816242330935, gloss: 0.9710996756047914\n",
      "Epoch: 13, step: 360, dloss: 0.00048655640068489777, gloss: 0.9712376536594497\n",
      "Epoch: 13, step: 390, dloss: 0.0004823876516101525, gloss: 0.9716784755388895\n",
      "Epoch: 13, step: 420, dloss: 0.0004780899817367348, gloss: 0.971819621466455\n",
      "Epoch: 13, step: 450, dloss: 0.00047376815127952234, gloss: 0.9721903747982449\n",
      "Epoch: 14, step: 0, dloss: 0.000403199577704072, gloss: nan\n",
      "Epoch: 14, step: 30, dloss: 0.0004034508498490698, gloss: 0.9794519543647766\n",
      "Epoch: 14, step: 60, dloss: 0.0003999057340389881, gloss: 0.977234274148941\n",
      "Epoch: 14, step: 90, dloss: 0.00039651547494641207, gloss: 0.9757900072468652\n",
      "Epoch: 14, step: 120, dloss: 0.0003923750626816114, gloss: 0.9772192115585009\n",
      "Epoch: 14, step: 150, dloss: 0.0003888458663070365, gloss: 0.9764850695927938\n",
      "Epoch: 14, step: 180, dloss: 0.00038526604612594605, gloss: 0.9769768714904785\n",
      "Epoch: 14, step: 210, dloss: 0.00038182657414504383, gloss: 0.9779435282661801\n",
      "Epoch: 14, step: 240, dloss: 0.00037811537798787797, gloss: 0.9778560139238834\n",
      "Epoch: 14, step: 270, dloss: 0.00037476865959618365, gloss: 0.9772960223533489\n",
      "Epoch: 14, step: 300, dloss: 0.0003714016704445711, gloss: 0.977785837650299\n",
      "Epoch: 14, step: 330, dloss: 0.000368097192098547, gloss: 0.9777232083407316\n",
      "Epoch: 14, step: 360, dloss: 0.00036487776874448495, gloss: 0.9778563421633508\n",
      "Epoch: 14, step: 390, dloss: 0.0003617347148574574, gloss: 0.9776755540798872\n",
      "Epoch: 14, step: 420, dloss: 0.00035849403964096765, gloss: 0.9780424329496565\n",
      "Epoch: 14, step: 450, dloss: 0.00035538954383842314, gloss: 0.9781116651164161\n",
      "Epoch: 15, step: 0, dloss: 0.00030820321990177035, gloss: nan\n",
      "Epoch: 15, step: 30, dloss: 0.0003028015743174981, gloss: 0.9786602457364401\n",
      "Epoch: 15, step: 60, dloss: 0.00029981968834706137, gloss: 0.978105957309405\n",
      "Epoch: 15, step: 90, dloss: 0.00029780830488192265, gloss: 0.979888853099611\n",
      "Epoch: 15, step: 120, dloss: 0.0002954081925159428, gloss: 0.9821675394972166\n",
      "Epoch: 15, step: 150, dloss: 0.0002925572623899638, gloss: 0.9813498536745707\n",
      "Epoch: 15, step: 180, dloss: 0.00028998944737938185, gloss: 0.981796243124538\n",
      "Epoch: 15, step: 210, dloss: 0.0002872028089596303, gloss: 0.9819108176799047\n",
      "Epoch: 15, step: 240, dloss: 0.0002845539459021553, gloss: 0.9825243453184763\n",
      "Epoch: 15, step: 270, dloss: 0.00028196517597175997, gloss: 0.9824012904255478\n",
      "Epoch: 15, step: 300, dloss: 0.0002794971007333939, gloss: 0.9824518064657847\n",
      "Epoch: 15, step: 330, dloss: 0.0002771062214417085, gloss: 0.9830197863506548\n",
      "Epoch: 15, step: 360, dloss: 0.0002747814501074615, gloss: 0.9831144081221687\n",
      "Epoch: 15, step: 390, dloss: 0.00027239259884423575, gloss: 0.9832288982012333\n",
      "Epoch: 15, step: 420, dloss: 0.0002700989728438449, gloss: 0.983225493204026\n",
      "Epoch: 15, step: 450, dloss: 0.00026776982306016446, gloss: 0.9833780997329288\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8730295330>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainer.train_losses[\"discriminator\"])\n",
    "plt.plot(trainer.train_losses[\"generator\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
