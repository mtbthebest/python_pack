{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from collections import OrderedDict, defaultdict\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import ToTensor, Compose, Normalize, Resize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "from oxford_flowers import  Oxford102FlowersTrain, Oxford102FlowersTest, normalize_mean, normalize_std\n",
    "from mnist import  MNISTTrain, MNISTTest\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]= \"1\"\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# train_loader = DataLoader(dataset=Oxford102FlowersTrain(transform=Compose([ToTensor(),])),\n",
    "# train_loader = DataLoader(dataset=Oxford102FlowersTrain(which=[\"train\"], transform=Compose([ToTensor(), \n",
    "#                                                                                             Resize((256, 256)),  \n",
    "#                                                                                             ])),\n",
    "#                           batch_size=batch_size,) \n",
    "                        #   shuffle=False,  num_workers=2)\n",
    "# test_loader = DataLoader(dataset=MNISTTest(transform=Compose([ToTensor(),])),\n",
    "#                           batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for x, x_target, label in train_loader:\n",
    "#    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x.size(), x_target.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 * 5\n",
    "train_loader = DataLoader(dataset=MNISTTrain(transform=Compose([ToTensor(),])),\n",
    "                          batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(dataset=MNISTTest(transform=Compose([ToTensor(),])),\n",
    "                          batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 16, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_activation(act_name):\n",
    "    return {\"relu\": nn.ReLU(), \"elu\": nn.ELU(), \"gelu\": nn.GELU(), \"tanh\": nn.Tanh()}[act_name]\n",
    "\n",
    "\n",
    "class Masked2dConvolution(nn.Conv2d):\n",
    "    \n",
    "    def __init__(self, mask_type, in_channels, out_channels, kernel_size, stride=1, padding=\"same\"):\n",
    "        self.mask_type = mask_type\n",
    "        self.mask = self.get_mask(mask_type, mask_size=kernel_size)\n",
    "\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, padding, groups=1, bias=True,)\n",
    "    \n",
    "    def get_mask(self, mask_type, mask_size):\n",
    "        mask = torch.zeros(mask_size[0] * mask_size[1]).float()\n",
    "        middle = mask.size(0) // 2 \n",
    "        if mask_type == \"B\":\n",
    "            middle = middle + 1\n",
    "        mask[:middle] = 1.\n",
    "        return mask.unsqueeze(0).unsqueeze(0).view(1, 1, mask_size[0], mask_size[1]).contiguous()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        weight = self.weight * self.mask.to(self.weight)\n",
    "        return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)  \n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, filter_size, activation=\"relu\") -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(filter_size, filter_size // 2, (1, 1), padding=\"same\")\n",
    "        self.activation1 = get_activation(activation)\n",
    "        self.masked_conv = Masked2dConvolution(\"B\", filter_size // 2, filter_size // 2, (3, 3), padding=\"same\")\n",
    "        self.activation2 = get_activation(activation)\n",
    "        self.conv2 = nn.Conv2d(filter_size // 2, filter_size, (1, 1),  padding=\"same\")\n",
    "        self.activation3 = get_activation(activation)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_ = self.conv1(x)\n",
    "        x_ = self.activation1(x_)\n",
    "        x_ = self.masked_conv(x_)\n",
    "        x_ = self.activation2(x_)\n",
    "        x_ = self.conv2(x_)\n",
    "        x_ = self.activation3(x_)\n",
    "        return x + x_\n",
    "        \n",
    "    \n",
    "Masked2dConvolution(\"B\", 3, 32, (1, 1))(torch.randn(2,3, 16, 16)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, filter_size=128, nlayers=5):\n",
    "        super().__init__()\n",
    "        self.masked_conv = Masked2dConvolution(\"A\", 1, filter_size, (7, 7))\n",
    "        self.residual_blocks = nn.ModuleList([ResidualBlock(filter_size) for _ in range(nlayers)])\n",
    "        self.after_residual = nn.ModuleList([Masked2dConvolution(\"B\", filter_size, filter_size, (1, 1)), nn.ReLU()] + \\\n",
    "             [Masked2dConvolution(\"B\", filter_size, filter_size, (1, 1)), nn.ReLU()])\n",
    "        self.out = nn.Conv2d(filter_size, 256, (1, 1), padding=\"same\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.masked_conv(x)\n",
    "        for block in self.residual_blocks:\n",
    "            x = block(x)\n",
    "        for residual in self.after_residual:\n",
    "            x = residual(x)\n",
    "        x = self.out(x)\n",
    "        \n",
    "        return x.unsqueeze(2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_dist(probs, temperature):\n",
    "    probs = probs ** (1 / temperature)\n",
    "    probs = probs / probs.sum(axis=1).unsqueeze(1)\n",
    "    return torch.multinomial(probs, 1)\n",
    "\n",
    "def generate(model, nsamples = 2, temperature=1.0):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        height, width, channels = 28, 28, 1\n",
    "        imgs = torch.zeros((nsamples, channels, height, width)).cuda()\n",
    "        \n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                for k in range(channels):\n",
    "                    logits = model(imgs)\n",
    "                    probs = torch.softmax(logits[:, :, k, i, j], dim=-1)\n",
    "                    pixel = sample_dist(probs, temperature)\n",
    "                    imgs[:, k, i, j] = pixel.flatten() / 255.0\n",
    "        return (imgs.clone().detach().cpu().permute(0, 2, 3, 1).contiguous().numpy() * 255.0).astype(np.uint8)\n",
    "\n",
    "def save_samples(samples, savepath):\n",
    "    for i in range(samples.shape[0]):\n",
    "        Image.fromarray(samples[i].reshape(28, 28).astype(np.uint8)).save(os.path.join(savepath, f\"{i:03d}.png\"))\n",
    "\n",
    "class Criterion(nn.Module):\n",
    "    \n",
    "    def forward(self, input, target):\n",
    "        b, f, c, h, w = input.size()\n",
    "        x = input.permute(0, 3, 4, 2, 1).contiguous().view(-1, f)\n",
    "        x_hat = target.permute(0, 2, 3, 1).view(-1, )\n",
    "        \n",
    "        return F.cross_entropy(x, x_hat, reduction=\"mean\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(model_name):\n",
    "    savepath = os.path.join(f\"/mnt/dl/models/{model_name}\")\n",
    "    model_savepath = os.path.join(savepath, \"models\")\n",
    "    eval_savepath = os.path.join(savepath, \"eval\")\n",
    "    \n",
    "    os.makedirs(model_savepath, exist_ok=True)\n",
    "    os.makedirs(eval_savepath, exist_ok=True)\n",
    "    \n",
    "    model = PixelCNN().cuda()\n",
    "    criterion = Criterion()\n",
    "    model.train()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.9998) \n",
    "    epochs = 500\n",
    "    \n",
    "    losses = []\n",
    "    it = 0\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        print(\"Starting Epoch \", i, \"...\")\n",
    "        for j, (img, label) in enumerate(train_loader):\n",
    "            img = img.cuda()\n",
    "            target = img.clone().long()\n",
    "            img /= 255.0\n",
    "            out = model(img)\n",
    "            loss = criterion(out, target)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            it += 1\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 10.)\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            if it % 50 == 0:\n",
    "                print(f\"Epoch: {i}, batch: {j}, loss: {np.mean(losses[-100:])}\")\n",
    "        if i % 2 == 0:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            samples = generate(model, 50, temperature=1)\n",
    "            samples_savepath = os.path.join(eval_savepath, f\"{i}\")\n",
    "            os.makedirs(samples_savepath, exist_ok=True)\n",
    "            save_samples(samples, samples_savepath)\n",
    "            model.train()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            torch.save({\"model\": model.state_dict(), \"optimizer\": optimizer.state_dict(),\n",
    "                        \"scheduler\": scheduler.state_dict()},\n",
    "                       os.path.join(model_savepath, f\"checkpoint{i:04d}.pt\"))\n",
    "            \n",
    "               \n",
    "            \n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch  0 ...\n",
      "Epoch: 0, batch: 49, loss: 3.330314028263092\n",
      "Epoch: 0, batch: 99, loss: 2.539150809049606\n",
      "Epoch: 0, batch: 149, loss: 1.614557752609253\n",
      "Epoch: 0, batch: 199, loss: 1.417636708021164\n",
      "Epoch: 0, batch: 249, loss: 1.319697256088257\n",
      "Epoch: 0, batch: 299, loss: 1.2628645968437195\n",
      "Epoch: 0, batch: 349, loss: 1.2357085621356965\n",
      "Starting Epoch  1 ...\n",
      "Epoch: 1, batch: 24, loss: 1.211790043115616\n",
      "Epoch: 1, batch: 74, loss: 1.1934005188941956\n",
      "Epoch: 1, batch: 124, loss: 1.1820778703689576\n",
      "Epoch: 1, batch: 174, loss: 1.1674720895290376\n",
      "Epoch: 1, batch: 224, loss: 1.1577508985996245\n",
      "Epoch: 1, batch: 274, loss: 1.151179577112198\n",
      "Epoch: 1, batch: 324, loss: 1.1398503494262695\n",
      "Epoch: 1, batch: 374, loss: 1.1239033818244935\n",
      "Starting Epoch  2 ...\n",
      "Epoch: 2, batch: 49, loss: 1.1189468121528625\n",
      "Epoch: 2, batch: 99, loss: 1.1100415694713592\n",
      "Epoch: 2, batch: 149, loss: 1.0982978177070617\n",
      "Epoch: 2, batch: 199, loss: 1.0931641674041748\n",
      "Epoch: 2, batch: 249, loss: 1.0898297929763794\n",
      "Epoch: 2, batch: 299, loss: 1.0817794942855834\n",
      "Epoch: 2, batch: 349, loss: 1.0725278353691101\n",
      "Starting Epoch  3 ...\n",
      "Epoch: 3, batch: 24, loss: 1.0665497159957886\n",
      "Epoch: 3, batch: 74, loss: 1.0603999662399293\n",
      "Epoch: 3, batch: 124, loss: 1.0569583940505982\n",
      "Epoch: 3, batch: 174, loss: 1.0510974943637847\n",
      "Epoch: 3, batch: 224, loss: 1.04410191655159\n",
      "Epoch: 3, batch: 274, loss: 1.0395267474651337\n",
      "Epoch: 3, batch: 324, loss: 1.0334484839439393\n",
      "Epoch: 3, batch: 374, loss: 1.02979361474514\n",
      "Starting Epoch  4 ...\n",
      "Epoch: 4, batch: 49, loss: 1.0249745345115662\n",
      "Epoch: 4, batch: 99, loss: 1.0201908242702484\n",
      "Epoch: 4, batch: 149, loss: 1.0212596768140794\n",
      "Epoch: 4, batch: 199, loss: 1.0146142500638962\n",
      "Epoch: 4, batch: 249, loss: 1.002420760989189\n",
      "Epoch: 4, batch: 299, loss: 1.0008984208106995\n",
      "Epoch: 4, batch: 349, loss: 0.9995892834663391\n",
      "Starting Epoch  5 ...\n",
      "Epoch: 5, batch: 24, loss: 0.9955768531560898\n",
      "Epoch: 5, batch: 74, loss: 0.9957848072052002\n",
      "Epoch: 5, batch: 124, loss: 0.9904994308948517\n",
      "Epoch: 5, batch: 174, loss: 0.9828074413537979\n",
      "Epoch: 5, batch: 224, loss: 0.982027217745781\n",
      "Epoch: 5, batch: 274, loss: 0.9806515502929688\n",
      "Epoch: 5, batch: 324, loss: 0.9770016753673554\n",
      "Epoch: 5, batch: 374, loss: 0.9771968096494674\n",
      "Starting Epoch  6 ...\n",
      "Epoch: 6, batch: 49, loss: 0.972501602768898\n",
      "Epoch: 6, batch: 99, loss: 0.9654482913017273\n",
      "Epoch: 6, batch: 149, loss: 0.9662730211019516\n",
      "Epoch: 6, batch: 199, loss: 0.96487548828125\n",
      "Epoch: 6, batch: 249, loss: 0.960519779920578\n",
      "Epoch: 6, batch: 299, loss: 0.9551025027036667\n",
      "Epoch: 6, batch: 349, loss: 0.9682759094238281\n",
      "Starting Epoch  7 ...\n",
      "Epoch: 7, batch: 24, loss: 0.9666432309150695\n",
      "Epoch: 7, batch: 74, loss: 0.9487375277280807\n",
      "Epoch: 7, batch: 124, loss: 0.9484002721309662\n",
      "Epoch: 7, batch: 174, loss: 0.9457323908805847\n",
      "Epoch: 7, batch: 224, loss: 0.9455309790372849\n",
      "Epoch: 7, batch: 274, loss: 0.9442500060796738\n",
      "Epoch: 7, batch: 324, loss: 0.9416616004705429\n",
      "Epoch: 7, batch: 374, loss: 0.9377285861968994\n",
      "Starting Epoch  8 ...\n",
      "Epoch: 8, batch: 49, loss: 0.9376294898986817\n",
      "Epoch: 8, batch: 99, loss: 0.937609179019928\n",
      "Epoch: 8, batch: 149, loss: 0.9320896607637406\n",
      "Epoch: 8, batch: 199, loss: 0.9300913971662521\n",
      "Epoch: 8, batch: 249, loss: 0.9285797768831253\n",
      "Epoch: 8, batch: 299, loss: 0.9273685967922211\n",
      "Epoch: 8, batch: 349, loss: 0.9237857210636139\n",
      "Starting Epoch  9 ...\n",
      "Epoch: 9, batch: 24, loss: 0.9233889323472977\n",
      "Epoch: 9, batch: 74, loss: 0.9246271753311157\n",
      "Epoch: 9, batch: 124, loss: 0.9205765014886856\n",
      "Epoch: 9, batch: 174, loss: 0.917246857881546\n",
      "Epoch: 9, batch: 224, loss: 0.9170636141300201\n",
      "Epoch: 9, batch: 274, loss: 0.9152653068304062\n",
      "Epoch: 9, batch: 324, loss: 0.9112985634803772\n",
      "Epoch: 9, batch: 374, loss: 0.9102940809726715\n",
      "Starting Epoch  10 ...\n",
      "Epoch: 10, batch: 49, loss: 0.9091053676605224\n",
      "Epoch: 10, batch: 99, loss: 0.9065995860099793\n",
      "Epoch: 10, batch: 149, loss: 0.9043540865182876\n",
      "Epoch: 10, batch: 199, loss: 0.9231777936220169\n",
      "Epoch: 10, batch: 249, loss: 0.9217295908927917\n",
      "Epoch: 10, batch: 299, loss: 0.9023377066850662\n",
      "Epoch: 10, batch: 349, loss: 0.9156085360050201\n",
      "Starting Epoch  11 ...\n",
      "Epoch: 11, batch: 24, loss: 0.9131931221485138\n",
      "Epoch: 11, batch: 74, loss: 0.8983671033382415\n",
      "Epoch: 11, batch: 124, loss: 0.896695539355278\n",
      "Epoch: 11, batch: 174, loss: 0.8956899333000183\n",
      "Epoch: 11, batch: 224, loss: 0.8964070749282836\n",
      "Epoch: 11, batch: 274, loss: 0.901025727391243\n",
      "Epoch: 11, batch: 324, loss: 0.8999568957090378\n",
      "Epoch: 11, batch: 374, loss: 0.8998046368360519\n",
      "Starting Epoch  12 ...\n",
      "Epoch: 12, batch: 49, loss: 0.8950883316993713\n",
      "Epoch: 12, batch: 99, loss: 0.8875655746459961\n",
      "Epoch: 12, batch: 149, loss: 0.8897255408763886\n",
      "Epoch: 12, batch: 199, loss: 0.8903177416324616\n",
      "Epoch: 12, batch: 249, loss: 0.8890998524427414\n",
      "Epoch: 12, batch: 299, loss: 0.8880819302797317\n",
      "Epoch: 12, batch: 349, loss: 0.8886537027359008\n",
      "Starting Epoch  13 ...\n",
      "Epoch: 13, batch: 24, loss: 0.8919590556621552\n",
      "Epoch: 13, batch: 74, loss: 0.8890115976333618\n",
      "Epoch: 13, batch: 124, loss: 0.8811102628707885\n",
      "Epoch: 13, batch: 174, loss: 0.8921596223115921\n",
      "Epoch: 13, batch: 224, loss: 0.8912273275852204\n",
      "Epoch: 13, batch: 274, loss: 0.878503121137619\n",
      "Epoch: 13, batch: 324, loss: 0.8764623481035233\n",
      "Epoch: 13, batch: 374, loss: 0.8733950281143188\n",
      "Starting Epoch  14 ...\n",
      "Epoch: 14, batch: 49, loss: 0.8734238195419312\n",
      "Epoch: 14, batch: 99, loss: 0.8743931013345718\n",
      "Epoch: 14, batch: 149, loss: 0.8722957313060761\n",
      "Epoch: 14, batch: 199, loss: 0.8692997902631759\n",
      "Epoch: 14, batch: 249, loss: 0.8696897584199905\n",
      "Epoch: 14, batch: 299, loss: 0.8676804888248444\n",
      "Epoch: 14, batch: 349, loss: 0.8671235287189484\n",
      "Starting Epoch  15 ...\n",
      "Epoch: 15, batch: 24, loss: 0.8673928189277649\n",
      "Epoch: 15, batch: 74, loss: 0.8676442867517471\n",
      "Epoch: 15, batch: 124, loss: 0.8684854352474213\n",
      "Epoch: 15, batch: 174, loss: 0.8727622139453888\n",
      "Epoch: 15, batch: 224, loss: 0.86838503241539\n",
      "Epoch: 15, batch: 274, loss: 0.8637743276357651\n",
      "Epoch: 15, batch: 324, loss: 0.8644172310829162\n",
      "Epoch: 15, batch: 374, loss: 0.8592006874084472\n",
      "Starting Epoch  16 ...\n",
      "Epoch: 16, batch: 49, loss: 0.8779558849334717\n",
      "Epoch: 16, batch: 99, loss: 0.8763400393724442\n",
      "Epoch: 16, batch: 149, loss: 0.8550085836648941\n",
      "Epoch: 16, batch: 199, loss: 0.8583192896842956\n",
      "Epoch: 16, batch: 249, loss: 0.860718246102333\n",
      "Epoch: 16, batch: 299, loss: 0.8559724849462509\n",
      "Epoch: 16, batch: 349, loss: 0.852067301273346\n",
      "Starting Epoch  17 ...\n",
      "Epoch: 17, batch: 24, loss: 0.8512185591459275\n",
      "Epoch: 17, batch: 74, loss: 0.8505649811029434\n",
      "Epoch: 17, batch: 124, loss: 0.8499680477380752\n",
      "Epoch: 17, batch: 174, loss: 0.8855977946519852\n",
      "Epoch: 17, batch: 224, loss: 0.8878449231386185\n",
      "Epoch: 17, batch: 274, loss: 0.8475585508346558\n",
      "Epoch: 17, batch: 324, loss: 0.844041781425476\n",
      "Epoch: 17, batch: 374, loss: 0.84662566781044\n",
      "Starting Epoch  18 ...\n",
      "Epoch: 18, batch: 49, loss: 0.8457147371768952\n",
      "Epoch: 18, batch: 99, loss: 0.8457028555870056\n",
      "Epoch: 18, batch: 149, loss: 0.8614226961135865\n",
      "Epoch: 18, batch: 199, loss: 0.8687879478931427\n",
      "Epoch: 18, batch: 249, loss: 0.8500971764326095\n",
      "Epoch: 18, batch: 299, loss: 0.8421127665042877\n",
      "Epoch: 18, batch: 349, loss: 0.8425855427980423\n",
      "Starting Epoch  19 ...\n",
      "Epoch: 19, batch: 24, loss: 0.85729363322258\n",
      "Epoch: 19, batch: 74, loss: 0.854700118303299\n",
      "Epoch: 19, batch: 124, loss: 0.8336093497276306\n",
      "Epoch: 19, batch: 174, loss: 0.8348227286338806\n",
      "Epoch: 19, batch: 224, loss: 0.8408592253923416\n",
      "Epoch: 19, batch: 274, loss: 0.8639259856939315\n",
      "Epoch: 19, batch: 324, loss: 0.8620131731033325\n",
      "Epoch: 19, batch: 374, loss: 0.8382749843597412\n",
      "Starting Epoch  20 ...\n",
      "Epoch: 20, batch: 49, loss: 0.8340590882301331\n",
      "Epoch: 20, batch: 99, loss: 0.8415320062637329\n",
      "Epoch: 20, batch: 149, loss: 0.8398039168119431\n",
      "Epoch: 20, batch: 199, loss: 0.8293084931373597\n",
      "Epoch: 20, batch: 249, loss: 0.8290149062871933\n",
      "Epoch: 20, batch: 299, loss: 0.8330570548772812\n",
      "Epoch: 20, batch: 349, loss: 0.8462426877021789\n",
      "Starting Epoch  21 ...\n",
      "Epoch: 21, batch: 24, loss: 0.8394599628448486\n",
      "Epoch: 21, batch: 74, loss: 0.826725697517395\n",
      "Epoch: 21, batch: 124, loss: 0.8276210057735444\n",
      "Epoch: 21, batch: 174, loss: 0.8390458601713181\n",
      "Epoch: 21, batch: 224, loss: 0.8381706839799881\n",
      "Epoch: 21, batch: 274, loss: 0.8248049592971802\n",
      "Epoch: 21, batch: 324, loss: 0.8257238698005677\n",
      "Epoch: 21, batch: 374, loss: 0.830932754278183\n",
      "Starting Epoch  22 ...\n",
      "Epoch: 22, batch: 49, loss: 0.8331936508417129\n",
      "Epoch: 22, batch: 99, loss: 0.8312600362300873\n",
      "Epoch: 22, batch: 149, loss: 0.8320306921005249\n",
      "Epoch: 22, batch: 199, loss: 0.8251971364021301\n",
      "Epoch: 22, batch: 249, loss: 0.8200071334838868\n",
      "Epoch: 22, batch: 299, loss: 0.8209954744577408\n",
      "Epoch: 22, batch: 349, loss: 0.8225725930929184\n",
      "Starting Epoch  23 ...\n",
      "Epoch: 23, batch: 24, loss: 0.8215855443477631\n",
      "Epoch: 23, batch: 74, loss: 0.81939000248909\n",
      "Epoch: 23, batch: 124, loss: 0.8280899375677109\n",
      "Epoch: 23, batch: 174, loss: 0.8261831301450729\n",
      "Epoch: 23, batch: 224, loss: 0.8183288967609406\n",
      "Epoch: 23, batch: 274, loss: 0.819033818244934\n",
      "Epoch: 23, batch: 324, loss: 0.8153184169530868\n",
      "Epoch: 23, batch: 374, loss: 0.822859199643135\n",
      "Starting Epoch  24 ...\n",
      "Epoch: 24, batch: 49, loss: 0.8231767028570175\n",
      "Epoch: 24, batch: 99, loss: 0.8124267780780792\n",
      "Epoch: 24, batch: 149, loss: 0.8235572862625122\n",
      "Epoch: 24, batch: 199, loss: 0.8258134841918945\n",
      "Epoch: 24, batch: 249, loss: 0.8126457989215851\n",
      "Epoch: 24, batch: 299, loss: 0.8102984631061554\n",
      "Epoch: 24, batch: 349, loss: 0.8096450692415238\n",
      "Starting Epoch  25 ...\n",
      "Epoch: 25, batch: 24, loss: 0.8083040249347687\n",
      "Epoch: 25, batch: 74, loss: 0.8278240525722503\n",
      "Epoch: 25, batch: 124, loss: 0.8264925247430801\n",
      "Epoch: 25, batch: 174, loss: 0.8082344388961792\n",
      "Epoch: 25, batch: 224, loss: 0.808987221121788\n",
      "Epoch: 25, batch: 274, loss: 0.8059078109264374\n",
      "Epoch: 25, batch: 324, loss: 0.8048495906591415\n",
      "Epoch: 25, batch: 374, loss: 0.8047469085454941\n",
      "Starting Epoch  26 ...\n",
      "Epoch: 26, batch: 49, loss: 0.8264822763204575\n",
      "Epoch: 26, batch: 99, loss: 0.8271926617622376\n",
      "Epoch: 26, batch: 149, loss: 0.8055922120809555\n",
      "Epoch: 26, batch: 199, loss: 0.8038777059316635\n",
      "Epoch: 26, batch: 249, loss: 0.8030340921878815\n",
      "Epoch: 26, batch: 299, loss: 0.8028994357585907\n",
      "Epoch: 26, batch: 349, loss: 0.8008952796459198\n",
      "Starting Epoch  27 ...\n",
      "Epoch: 27, batch: 24, loss: 0.7998886203765869\n",
      "Epoch: 27, batch: 74, loss: 0.7990239155292511\n",
      "Epoch: 27, batch: 124, loss: 0.7995980197191238\n",
      "Epoch: 27, batch: 174, loss: 0.805340187549591\n",
      "Epoch: 27, batch: 224, loss: 0.8175539767742157\n",
      "Epoch: 27, batch: 274, loss: 0.8100559449195862\n",
      "Epoch: 27, batch: 324, loss: 0.7956161791086197\n",
      "Epoch: 27, batch: 374, loss: 0.8051739078760147\n",
      "Starting Epoch  28 ...\n",
      "Epoch: 28, batch: 49, loss: 0.8048414874076844\n",
      "Epoch: 28, batch: 99, loss: 0.7961499416828155\n",
      "Epoch: 28, batch: 149, loss: 0.7973342728614807\n",
      "Epoch: 28, batch: 199, loss: 0.7960882276296616\n",
      "Epoch: 28, batch: 249, loss: 0.7929847252368927\n",
      "Epoch: 28, batch: 299, loss: 0.8025828564167022\n",
      "Epoch: 28, batch: 349, loss: 0.8272154116630555\n",
      "Starting Epoch  29 ...\n",
      "Epoch: 29, batch: 24, loss: 0.8164410328865052\n",
      "Epoch: 29, batch: 74, loss: 0.7901500236988067\n",
      "Epoch: 29, batch: 124, loss: 0.7896754938364029\n",
      "Epoch: 29, batch: 174, loss: 0.7937139362096787\n",
      "Epoch: 29, batch: 224, loss: 0.8200064671039581\n",
      "Epoch: 29, batch: 274, loss: 0.8218695491552352\n",
      "Epoch: 29, batch: 324, loss: 0.7927470892667771\n",
      "Epoch: 29, batch: 374, loss: 0.7843501353263855\n",
      "Starting Epoch  30 ...\n",
      "Epoch: 30, batch: 49, loss: 0.78621457695961\n",
      "Epoch: 30, batch: 99, loss: 0.7882705861330033\n",
      "Epoch: 30, batch: 149, loss: 0.7872187852859497\n",
      "Epoch: 30, batch: 199, loss: 0.7870757395029068\n",
      "Epoch: 30, batch: 249, loss: 0.7891979473829269\n",
      "Epoch: 30, batch: 299, loss: 0.789943882226944\n",
      "Epoch: 30, batch: 349, loss: 0.787982104420662\n",
      "Starting Epoch  31 ...\n",
      "Epoch: 31, batch: 24, loss: 0.7846848261356354\n",
      "Epoch: 31, batch: 74, loss: 0.792810726761818\n",
      "Epoch: 31, batch: 124, loss: 0.7949053871631623\n",
      "Epoch: 31, batch: 174, loss: 0.7854915237426758\n",
      "Epoch: 31, batch: 224, loss: 0.7844171327352524\n",
      "Epoch: 31, batch: 274, loss: 0.7967107039690018\n",
      "Epoch: 31, batch: 324, loss: 0.7946671372652054\n",
      "Epoch: 31, batch: 374, loss: 0.7822992300987244\n",
      "Starting Epoch  32 ...\n",
      "Epoch: 32, batch: 49, loss: 0.7836825788021088\n",
      "Epoch: 32, batch: 99, loss: 0.7812827676534653\n",
      "Epoch: 32, batch: 149, loss: 0.7900516271591187\n",
      "Epoch: 32, batch: 199, loss: 0.7898275196552277\n",
      "Epoch: 32, batch: 249, loss: 0.782187482714653\n",
      "Epoch: 32, batch: 299, loss: 0.7913607621192932\n",
      "Epoch: 32, batch: 349, loss: 0.7878744637966156\n",
      "Starting Epoch  33 ...\n",
      "Epoch: 33, batch: 24, loss: 0.7790555346012116\n",
      "Epoch: 33, batch: 74, loss: 0.7788407576084136\n",
      "Epoch: 33, batch: 124, loss: 0.7836547780036927\n",
      "Epoch: 33, batch: 174, loss: 0.7880985176563263\n",
      "Epoch: 33, batch: 224, loss: 0.7816125005483627\n",
      "Epoch: 33, batch: 274, loss: 0.7780687856674194\n",
      "Epoch: 33, batch: 324, loss: 0.7784686481952667\n",
      "Epoch: 33, batch: 374, loss: 0.7775624406337738\n",
      "Starting Epoch  34 ...\n",
      "Epoch: 34, batch: 49, loss: 0.7772452437877655\n",
      "Epoch: 34, batch: 99, loss: 0.7840822929143906\n",
      "Epoch: 34, batch: 149, loss: 0.7835535943508148\n",
      "Epoch: 34, batch: 199, loss: 0.7758769202232361\n",
      "Epoch: 34, batch: 249, loss: 0.7760242038965225\n",
      "Epoch: 34, batch: 299, loss: 0.7753104597330094\n",
      "Epoch: 34, batch: 349, loss: 0.7740886515378952\n",
      "Starting Epoch  35 ...\n",
      "Epoch: 35, batch: 24, loss: 0.7745385354757309\n",
      "Epoch: 35, batch: 74, loss: 0.778408659696579\n",
      "Epoch: 35, batch: 124, loss: 0.7779323244094849\n",
      "Epoch: 35, batch: 174, loss: 0.7750994527339935\n",
      "Epoch: 35, batch: 224, loss: 0.7774943941831589\n",
      "Epoch: 35, batch: 274, loss: 0.7749601900577545\n",
      "Epoch: 35, batch: 324, loss: 0.7688126856088638\n",
      "Epoch: 35, batch: 374, loss: 0.7710565960407257\n",
      "Starting Epoch  36 ...\n",
      "Epoch: 36, batch: 49, loss: 0.7734251946210862\n",
      "Epoch: 36, batch: 99, loss: 0.7718640989065171\n",
      "Epoch: 36, batch: 149, loss: 0.7701999932527542\n",
      "Epoch: 36, batch: 199, loss: 0.7689957922697067\n",
      "Epoch: 36, batch: 249, loss: 0.7768934136629104\n",
      "Epoch: 36, batch: 299, loss: 0.7818957513570786\n",
      "Epoch: 36, batch: 349, loss: 0.7729823076725006\n",
      "Starting Epoch  37 ...\n",
      "Epoch: 37, batch: 24, loss: 0.7659443247318268\n",
      "Epoch: 37, batch: 74, loss: 0.7774376827478409\n",
      "Epoch: 37, batch: 124, loss: 0.7773952174186707\n",
      "Epoch: 37, batch: 174, loss: 0.7706774652004242\n",
      "Epoch: 37, batch: 224, loss: 0.7710981094837188\n",
      "Epoch: 37, batch: 274, loss: 0.76550841152668\n",
      "Epoch: 37, batch: 324, loss: 0.7666363447904587\n",
      "Epoch: 37, batch: 374, loss: 0.7686273825168609\n",
      "Starting Epoch  38 ...\n",
      "Epoch: 38, batch: 49, loss: 0.7649013769626617\n",
      "Epoch: 38, batch: 99, loss: 0.7691168755292892\n",
      "Epoch: 38, batch: 149, loss: 0.7707664805650711\n",
      "Epoch: 38, batch: 199, loss: 0.7644910514354706\n",
      "Epoch: 38, batch: 249, loss: 0.7675634431838989\n",
      "Epoch: 38, batch: 299, loss: 0.7669284051656723\n",
      "Epoch: 38, batch: 349, loss: 0.7694554167985916\n",
      "Starting Epoch  39 ...\n",
      "Epoch: 39, batch: 24, loss: 0.7705196958780288\n",
      "Epoch: 39, batch: 74, loss: 0.7622020322084427\n",
      "Epoch: 39, batch: 124, loss: 0.7605188989639282\n",
      "Epoch: 39, batch: 174, loss: 0.7628833043575287\n",
      "Epoch: 39, batch: 224, loss: 0.7673145318031311\n",
      "Epoch: 39, batch: 274, loss: 0.7652862411737442\n",
      "Epoch: 39, batch: 324, loss: 0.7608406972885132\n",
      "Epoch: 39, batch: 374, loss: 0.7620029735565186\n",
      "Starting Epoch  40 ...\n",
      "Epoch: 40, batch: 49, loss: 0.7607772833108902\n",
      "Epoch: 40, batch: 99, loss: 0.7598851239681244\n",
      "Epoch: 40, batch: 149, loss: 0.7584340119361878\n",
      "Epoch: 40, batch: 199, loss: 0.7869130051136017\n",
      "Epoch: 40, batch: 249, loss: 0.7874736487865448\n",
      "Epoch: 40, batch: 299, loss: 0.7557096147537231\n",
      "Epoch: 40, batch: 349, loss: 0.755033306479454\n",
      "Starting Epoch  41 ...\n",
      "Epoch: 41, batch: 24, loss: 0.7565975207090377\n",
      "Epoch: 41, batch: 74, loss: 0.7570348632335663\n",
      "Epoch: 41, batch: 124, loss: 0.7583028072118759\n",
      "Epoch: 41, batch: 174, loss: 0.7572885578870774\n",
      "Epoch: 41, batch: 224, loss: 0.763235655426979\n",
      "Epoch: 41, batch: 274, loss: 0.7618678134679794\n",
      "Epoch: 41, batch: 324, loss: 0.752315776348114\n",
      "Epoch: 41, batch: 374, loss: 0.7750587224960327\n",
      "Starting Epoch  42 ...\n",
      "Epoch: 42, batch: 49, loss: 0.783232473731041\n",
      "Epoch: 42, batch: 99, loss: 0.7593861579895019\n",
      "Epoch: 42, batch: 149, loss: 0.7522656589746475\n",
      "Epoch: 42, batch: 199, loss: 0.7528850656747818\n",
      "Epoch: 42, batch: 249, loss: 0.7510152006149292\n",
      "Epoch: 42, batch: 299, loss: 0.7549877864122391\n",
      "Epoch: 42, batch: 349, loss: 0.7617003649473191\n",
      "Starting Epoch  43 ...\n",
      "Epoch: 43, batch: 24, loss: 0.7566543352603913\n",
      "Epoch: 43, batch: 74, loss: 0.7659423911571502\n",
      "Epoch: 43, batch: 124, loss: 0.7762183058261871\n",
      "Epoch: 43, batch: 174, loss: 0.7591200196743011\n",
      "Epoch: 43, batch: 224, loss: 0.7664228874444962\n",
      "Epoch: 43, batch: 274, loss: 0.7696407443284988\n",
      "Epoch: 43, batch: 324, loss: 0.7524813616275787\n",
      "Epoch: 43, batch: 374, loss: 0.748018324971199\n",
      "Starting Epoch  44 ...\n",
      "Epoch: 44, batch: 49, loss: 0.746817370057106\n",
      "Epoch: 44, batch: 99, loss: 0.7486127871274948\n",
      "Epoch: 44, batch: 149, loss: 0.750116565823555\n",
      "Epoch: 44, batch: 199, loss: 0.749174132347107\n",
      "Epoch: 44, batch: 249, loss: 0.7473838222026825\n",
      "Epoch: 44, batch: 299, loss: 0.7474894005060196\n",
      "Epoch: 44, batch: 349, loss: 0.7506692242622376\n",
      "Starting Epoch  45 ...\n",
      "Epoch: 45, batch: 24, loss: 0.7550892889499664\n",
      "Epoch: 45, batch: 74, loss: 0.7520669066905975\n",
      "Epoch: 45, batch: 124, loss: 0.7466493415832519\n",
      "Epoch: 45, batch: 174, loss: 0.7479402512311936\n",
      "Epoch: 45, batch: 224, loss: 0.748253526687622\n",
      "Epoch: 45, batch: 274, loss: 0.7493862855434418\n",
      "Epoch: 45, batch: 324, loss: 0.7506540787220001\n",
      "Epoch: 45, batch: 374, loss: 0.7575722032785416\n",
      "Starting Epoch  46 ...\n",
      "Epoch: 46, batch: 49, loss: 0.7554390799999237\n",
      "Epoch: 46, batch: 99, loss: 0.7452469563484192\n",
      "Epoch: 46, batch: 149, loss: 0.7478929674625396\n",
      "Epoch: 46, batch: 199, loss: 0.7471986043453217\n",
      "Epoch: 46, batch: 249, loss: 0.752800641655922\n",
      "Epoch: 46, batch: 299, loss: 0.7520373910665512\n",
      "Epoch: 46, batch: 349, loss: 0.7471480321884155\n",
      "Starting Epoch  47 ...\n",
      "Epoch: 47, batch: 24, loss: 0.7469125807285308\n",
      "Epoch: 47, batch: 74, loss: 0.7423059552907944\n",
      "Epoch: 47, batch: 124, loss: 0.7462717992067337\n",
      "Epoch: 47, batch: 174, loss: 0.7525343996286392\n",
      "Epoch: 47, batch: 224, loss: 0.7467172813415527\n",
      "Epoch: 47, batch: 274, loss: 0.7400094002485276\n",
      "Epoch: 47, batch: 324, loss: 0.7476404374837875\n",
      "Epoch: 47, batch: 374, loss: 0.7484800910949707\n",
      "Starting Epoch  48 ...\n",
      "Epoch: 48, batch: 49, loss: 0.7414323204755783\n",
      "Epoch: 48, batch: 99, loss: 0.7415317791700363\n",
      "Epoch: 48, batch: 149, loss: 0.742048287987709\n",
      "Epoch: 48, batch: 199, loss: 0.7411456763744354\n",
      "Epoch: 48, batch: 249, loss: 0.7538633346557617\n",
      "Epoch: 48, batch: 299, loss: 0.7516093307733536\n",
      "Epoch: 48, batch: 349, loss: 0.737936737537384\n",
      "Starting Epoch  49 ...\n",
      "Epoch: 49, batch: 24, loss: 0.7388648438453674\n",
      "Epoch: 49, batch: 74, loss: 0.7384449064731597\n",
      "Epoch: 49, batch: 124, loss: 0.7381791633367538\n",
      "Epoch: 49, batch: 174, loss: 0.7376029509305954\n",
      "Epoch: 49, batch: 224, loss: 0.7367386204004288\n",
      "Epoch: 49, batch: 274, loss: 0.7464411079883575\n",
      "Epoch: 49, batch: 324, loss: 0.7461258029937744\n",
      "Epoch: 49, batch: 374, loss: 0.7379460978507996\n",
      "Starting Epoch  50 ...\n",
      "Epoch: 50, batch: 49, loss: 0.7405756109952927\n",
      "Epoch: 50, batch: 99, loss: 0.73863086104393\n",
      "Epoch: 50, batch: 149, loss: 0.7359547883272171\n",
      "Epoch: 50, batch: 199, loss: 0.734559343457222\n",
      "Epoch: 50, batch: 249, loss: 0.734983976483345\n",
      "Epoch: 50, batch: 299, loss: 0.7382639741897583\n",
      "Epoch: 50, batch: 349, loss: 0.7807811897993088\n",
      "Starting Epoch  51 ...\n",
      "Epoch: 51, batch: 24, loss: 0.7775605529546737\n",
      "Epoch: 51, batch: 74, loss: 0.7319110786914825\n",
      "Epoch: 51, batch: 124, loss: 0.7309390968084335\n",
      "Epoch: 51, batch: 174, loss: 0.7316063463687896\n",
      "Epoch: 51, batch: 224, loss: 0.7335622650384903\n",
      "Epoch: 51, batch: 274, loss: 0.7348391222953796\n",
      "Epoch: 51, batch: 324, loss: 0.7521270954608917\n",
      "Epoch: 51, batch: 374, loss: 0.7513942420482635\n",
      "Starting Epoch  52 ...\n",
      "Epoch: 52, batch: 49, loss: 0.7325517165660859\n",
      "Epoch: 52, batch: 99, loss: 0.735100280046463\n",
      "Epoch: 52, batch: 149, loss: 0.7335367351770401\n",
      "Epoch: 52, batch: 199, loss: 0.7301709109544754\n",
      "Epoch: 52, batch: 249, loss: 0.733846076130867\n",
      "Epoch: 52, batch: 299, loss: 0.733779883980751\n",
      "Epoch: 52, batch: 349, loss: 0.7308909898996353\n",
      "Starting Epoch  53 ...\n",
      "Epoch: 53, batch: 24, loss: 0.7394409537315368\n",
      "Epoch: 53, batch: 74, loss: 0.7387004274129868\n",
      "Epoch: 53, batch: 124, loss: 0.730432236790657\n",
      "Epoch: 53, batch: 174, loss: 0.7322964853048325\n",
      "Epoch: 53, batch: 224, loss: 0.7332669228315354\n",
      "Epoch: 53, batch: 274, loss: 0.7337292754650115\n",
      "Epoch: 53, batch: 324, loss: 0.7310799354314804\n",
      "Epoch: 53, batch: 374, loss: 0.7293892616033554\n",
      "Starting Epoch  54 ...\n",
      "Epoch: 54, batch: 49, loss: 0.7304212790727616\n",
      "Epoch: 54, batch: 99, loss: 0.7433617824316024\n",
      "Epoch: 54, batch: 149, loss: 0.7416191416978836\n",
      "Epoch: 54, batch: 199, loss: 0.7270652401447296\n",
      "Epoch: 54, batch: 249, loss: 0.7284596735239028\n",
      "Epoch: 54, batch: 299, loss: 0.7290439218282699\n",
      "Epoch: 54, batch: 349, loss: 0.7309153038263321\n",
      "Starting Epoch  55 ...\n",
      "Epoch: 55, batch: 24, loss: 0.7292967861890793\n",
      "Epoch: 55, batch: 74, loss: 0.731374437212944\n",
      "Epoch: 55, batch: 124, loss: 0.7383581537008286\n",
      "Epoch: 55, batch: 174, loss: 0.7329512071609497\n",
      "Epoch: 55, batch: 224, loss: 0.725345585346222\n",
      "Epoch: 55, batch: 274, loss: 0.7242526894807816\n",
      "Epoch: 55, batch: 324, loss: 0.7261351734399796\n",
      "Epoch: 55, batch: 374, loss: 0.7424370092153549\n",
      "Starting Epoch  56 ...\n",
      "Epoch: 56, batch: 49, loss: 0.7419833409786224\n",
      "Epoch: 56, batch: 99, loss: 0.72567691385746\n",
      "Epoch: 56, batch: 149, loss: 0.7257694101333618\n",
      "Epoch: 56, batch: 199, loss: 0.7295586413145065\n",
      "Epoch: 56, batch: 249, loss: 0.7277098387479782\n",
      "Epoch: 56, batch: 299, loss: 0.7236137193441391\n",
      "Epoch: 56, batch: 349, loss: 0.7304154747724533\n",
      "Starting Epoch  57 ...\n",
      "Epoch: 57, batch: 24, loss: 0.7305549216270447\n",
      "Epoch: 57, batch: 74, loss: 0.7238670045137405\n",
      "Epoch: 57, batch: 124, loss: 0.7504131215810775\n",
      "Epoch: 57, batch: 174, loss: 0.7513698571920395\n",
      "Epoch: 57, batch: 224, loss: 0.7238732886314392\n",
      "Epoch: 57, batch: 274, loss: 0.7209283512830734\n",
      "Epoch: 57, batch: 324, loss: 0.7205886447429657\n",
      "Epoch: 57, batch: 374, loss: 0.7212527471780777\n",
      "Starting Epoch  58 ...\n",
      "Epoch: 58, batch: 49, loss: 0.7282036423683167\n",
      "Epoch: 58, batch: 99, loss: 0.7295990085601807\n",
      "Epoch: 58, batch: 149, loss: 0.7351022225618362\n",
      "Epoch: 58, batch: 199, loss: 0.7321655505895615\n",
      "Epoch: 58, batch: 249, loss: 0.7192098224163055\n",
      "Epoch: 58, batch: 299, loss: 0.7194770276546478\n",
      "Epoch: 58, batch: 349, loss: 0.7205293816328049\n",
      "Starting Epoch  59 ...\n",
      "Epoch: 59, batch: 24, loss: 0.7304786664247512\n",
      "Epoch: 59, batch: 74, loss: 0.7298725605010986\n",
      "Epoch: 59, batch: 124, loss: 0.731972844004631\n",
      "Epoch: 59, batch: 174, loss: 0.7354204666614532\n",
      "Epoch: 59, batch: 224, loss: 0.7232678174972534\n",
      "Epoch: 59, batch: 274, loss: 0.7251465988159179\n",
      "Epoch: 59, batch: 324, loss: 0.7276579785346985\n",
      "Epoch: 59, batch: 374, loss: 0.7202294147014618\n",
      "Starting Epoch  60 ...\n",
      "Epoch: 60, batch: 49, loss: 0.7162364727258682\n",
      "Epoch: 60, batch: 99, loss: 0.7174608719348907\n",
      "Epoch: 60, batch: 149, loss: 0.7178658658266067\n",
      "Epoch: 60, batch: 199, loss: 0.718768202662468\n",
      "Epoch: 60, batch: 249, loss: 0.7203438711166382\n",
      "Epoch: 60, batch: 299, loss: 0.7199254387617111\n",
      "Epoch: 60, batch: 349, loss: 0.7181769317388534\n",
      "Starting Epoch  61 ...\n",
      "Epoch: 61, batch: 24, loss: 0.7254138600826263\n",
      "Epoch: 61, batch: 74, loss: 0.7271137261390686\n",
      "Epoch: 61, batch: 124, loss: 0.7173086243867874\n",
      "Epoch: 61, batch: 174, loss: 0.7154158651828766\n",
      "Epoch: 61, batch: 224, loss: 0.7170335608720779\n",
      "Epoch: 61, batch: 274, loss: 0.7182408511638642\n",
      "Epoch: 61, batch: 324, loss: 0.718628123998642\n",
      "Epoch: 61, batch: 374, loss: 0.7189481544494629\n",
      "Starting Epoch  62 ...\n",
      "Epoch: 62, batch: 49, loss: 0.7167483377456665\n",
      "Epoch: 62, batch: 99, loss: 0.7150344794988632\n",
      "Epoch: 62, batch: 149, loss: 0.7161484807729721\n",
      "Epoch: 62, batch: 199, loss: 0.7146234130859375\n",
      "Epoch: 62, batch: 249, loss: 0.714423708319664\n",
      "Epoch: 62, batch: 299, loss: 0.7477655267715454\n",
      "Epoch: 62, batch: 349, loss: 0.746944552063942\n",
      "Starting Epoch  63 ...\n",
      "Epoch: 63, batch: 24, loss: 0.7219826704263688\n",
      "Epoch: 63, batch: 74, loss: 0.7218018662929535\n",
      "Epoch: 63, batch: 124, loss: 0.7147545969486236\n",
      "Epoch: 63, batch: 174, loss: 0.7120843994617462\n",
      "Epoch: 63, batch: 224, loss: 0.7117373883724213\n",
      "Epoch: 63, batch: 274, loss: 0.7356818556785584\n",
      "Epoch: 63, batch: 324, loss: 0.7355513924360275\n",
      "Epoch: 63, batch: 374, loss: 0.7127626949548721\n",
      "Starting Epoch  64 ...\n",
      "Epoch: 64, batch: 49, loss: 0.709292962551117\n",
      "Epoch: 64, batch: 99, loss: 0.7111614459753036\n",
      "Epoch: 64, batch: 149, loss: 0.7160463309288025\n",
      "Epoch: 64, batch: 199, loss: 0.7308678960800171\n",
      "Epoch: 64, batch: 249, loss: 0.7263714051246644\n",
      "Epoch: 64, batch: 299, loss: 0.7107433867454529\n",
      "Epoch: 64, batch: 349, loss: 0.7131819188594818\n",
      "Starting Epoch  65 ...\n",
      "Epoch: 65, batch: 24, loss: 0.7142178523540497\n",
      "Epoch: 65, batch: 74, loss: 0.7209083044528961\n",
      "Epoch: 65, batch: 124, loss: 0.7172922205924988\n",
      "Epoch: 65, batch: 174, loss: 0.7089383351802826\n",
      "Epoch: 65, batch: 224, loss: 0.7310837697982788\n",
      "Epoch: 65, batch: 274, loss: 0.7330283707380295\n",
      "Epoch: 65, batch: 324, loss: 0.7112932008504868\n",
      "Epoch: 65, batch: 374, loss: 0.710163088440895\n",
      "Starting Epoch  66 ...\n",
      "Epoch: 66, batch: 49, loss: 0.7091139763593673\n",
      "Epoch: 66, batch: 99, loss: 0.7115304690599441\n",
      "Epoch: 66, batch: 149, loss: 0.7120843309164048\n",
      "Epoch: 66, batch: 199, loss: 0.7101608365774155\n",
      "Epoch: 66, batch: 249, loss: 0.709295843243599\n",
      "Epoch: 66, batch: 299, loss: 0.712651316523552\n",
      "Epoch: 66, batch: 349, loss: 0.7157912331819535\n",
      "Starting Epoch  67 ...\n",
      "Epoch: 67, batch: 24, loss: 0.7097578364610672\n",
      "Epoch: 67, batch: 74, loss: 0.7146629345417023\n",
      "Epoch: 67, batch: 124, loss: 0.7150105607509613\n",
      "Epoch: 67, batch: 174, loss: 0.7123887193202972\n",
      "Epoch: 67, batch: 224, loss: 0.7126971083879471\n",
      "Epoch: 67, batch: 274, loss: 0.7083333903551101\n",
      "Epoch: 67, batch: 324, loss: 0.7098706078529358\n",
      "Epoch: 67, batch: 374, loss: 0.7094369006156921\n",
      "Starting Epoch  68 ...\n",
      "Epoch: 68, batch: 49, loss: 0.7202639657258988\n",
      "Epoch: 68, batch: 99, loss: 0.7200193083286286\n",
      "Epoch: 68, batch: 149, loss: 0.7085758829116822\n",
      "Epoch: 68, batch: 199, loss: 0.7170725011825562\n",
      "Epoch: 68, batch: 249, loss: 0.7153874492645264\n",
      "Epoch: 68, batch: 299, loss: 0.7050967669486999\n",
      "Epoch: 68, batch: 349, loss: 0.705349697470665\n",
      "Starting Epoch  69 ...\n",
      "Epoch: 69, batch: 24, loss: 0.7141324543952942\n",
      "Epoch: 69, batch: 74, loss: 0.7127291625738144\n",
      "Epoch: 69, batch: 124, loss: 0.7037601906061173\n",
      "Epoch: 69, batch: 174, loss: 0.7035445261001587\n",
      "Epoch: 69, batch: 224, loss: 0.7038973933458328\n",
      "Epoch: 69, batch: 274, loss: 0.7044405752420425\n",
      "Epoch: 69, batch: 324, loss: 0.7042923325300217\n",
      "Epoch: 69, batch: 374, loss: 0.7031551033258439\n",
      "Starting Epoch  70 ...\n",
      "Epoch: 70, batch: 49, loss: 0.7109291350841522\n",
      "Epoch: 70, batch: 99, loss: 0.7119296813011169\n",
      "Epoch: 70, batch: 149, loss: 0.7061995834112167\n",
      "Epoch: 70, batch: 199, loss: 0.7076762068271637\n",
      "Epoch: 70, batch: 249, loss: 0.7055703985691071\n",
      "Epoch: 70, batch: 299, loss: 0.7048980963230133\n",
      "Epoch: 70, batch: 349, loss: 0.7043878561258317\n",
      "Starting Epoch  71 ...\n",
      "Epoch: 71, batch: 24, loss: 0.7021976923942566\n",
      "Epoch: 71, batch: 74, loss: 0.7028379225730896\n",
      "Epoch: 71, batch: 124, loss: 0.7050600326061249\n",
      "Epoch: 71, batch: 174, loss: 0.7377044051885605\n",
      "Epoch: 71, batch: 224, loss: 0.7341264629364014\n",
      "Epoch: 71, batch: 274, loss: 0.6996458393335342\n",
      "Epoch: 71, batch: 324, loss: 0.7144641327857971\n",
      "Epoch: 71, batch: 374, loss: 0.7170341169834137\n",
      "Starting Epoch  72 ...\n",
      "Epoch: 72, batch: 49, loss: 0.7032373243570328\n",
      "Epoch: 72, batch: 99, loss: 0.7010592103004456\n",
      "Epoch: 72, batch: 149, loss: 0.7009487682580948\n",
      "Epoch: 72, batch: 199, loss: 0.7002704584598541\n",
      "Epoch: 72, batch: 249, loss: 0.7003708332777023\n",
      "Epoch: 72, batch: 299, loss: 0.7066612619161606\n",
      "Epoch: 72, batch: 349, loss: 0.7050884532928466\n",
      "Starting Epoch  73 ...\n",
      "Epoch: 73, batch: 24, loss: 0.7002119690179824\n",
      "Epoch: 73, batch: 74, loss: 0.702564321756363\n",
      "Epoch: 73, batch: 124, loss: 0.7010139966011047\n",
      "Epoch: 73, batch: 174, loss: 0.698001936674118\n",
      "Epoch: 73, batch: 224, loss: 0.6982196146249771\n",
      "Epoch: 73, batch: 274, loss: 0.6990460795164108\n",
      "Epoch: 73, batch: 324, loss: 0.6994064778089524\n",
      "Epoch: 73, batch: 374, loss: 0.6989014625549317\n",
      "Starting Epoch  74 ...\n",
      "Epoch: 74, batch: 49, loss: 0.7057028210163117\n",
      "Epoch: 74, batch: 99, loss: 0.7067878043651581\n",
      "Epoch: 74, batch: 149, loss: 0.6981969785690307\n",
      "Epoch: 74, batch: 199, loss: 0.6967975586652756\n",
      "Epoch: 74, batch: 249, loss: 0.6997021943330765\n",
      "Epoch: 74, batch: 299, loss: 0.6997987759113312\n",
      "Epoch: 74, batch: 349, loss: 0.7015684479475022\n",
      "Starting Epoch  75 ...\n",
      "Epoch: 75, batch: 24, loss: 0.7031088554859162\n",
      "Epoch: 75, batch: 74, loss: 0.6999380910396575\n",
      "Epoch: 75, batch: 124, loss: 0.7096642059087753\n",
      "Epoch: 75, batch: 174, loss: 0.7074622189998627\n",
      "Epoch: 75, batch: 224, loss: 0.6970233947038651\n",
      "Epoch: 75, batch: 274, loss: 0.7033394742012024\n",
      "Epoch: 75, batch: 324, loss: 0.7029347068071365\n",
      "Epoch: 75, batch: 374, loss: 0.6961061084270477\n",
      "Starting Epoch  76 ...\n",
      "Epoch: 76, batch: 49, loss: 0.69471675157547\n",
      "Epoch: 76, batch: 99, loss: 0.6950054538249969\n",
      "Epoch: 76, batch: 149, loss: 0.695455761551857\n",
      "Epoch: 76, batch: 199, loss: 0.6964185577630997\n",
      "Epoch: 76, batch: 249, loss: 0.6975513309240341\n",
      "Epoch: 76, batch: 299, loss: 0.6975729894638062\n",
      "Epoch: 76, batch: 349, loss: 0.6958733677864075\n",
      "Starting Epoch  77 ...\n",
      "Epoch: 77, batch: 24, loss: 0.6999004656076431\n",
      "Epoch: 77, batch: 74, loss: 0.7015332108736039\n",
      "Epoch: 77, batch: 124, loss: 0.6939130836725235\n",
      "Epoch: 77, batch: 174, loss: 0.6914949840307236\n",
      "Epoch: 77, batch: 224, loss: 0.6932678121328354\n",
      "Epoch: 77, batch: 274, loss: 0.6950854873657226\n",
      "Epoch: 77, batch: 324, loss: 0.6956527817249298\n",
      "Epoch: 77, batch: 374, loss: 0.6931197863817214\n",
      "Starting Epoch  78 ...\n",
      "Epoch: 78, batch: 49, loss: 0.6946465712785721\n",
      "Epoch: 78, batch: 99, loss: 0.6948952543735504\n",
      "Epoch: 78, batch: 149, loss: 0.6998060697317123\n",
      "Epoch: 78, batch: 199, loss: 0.704532471895218\n",
      "Epoch: 78, batch: 249, loss: 0.6967691552639007\n",
      "Epoch: 78, batch: 299, loss: 0.6917499309778213\n",
      "Epoch: 78, batch: 349, loss: 0.6933793902397156\n",
      "Starting Epoch  79 ...\n",
      "Epoch: 79, batch: 24, loss: 0.6973545897006989\n",
      "Epoch: 79, batch: 74, loss: 0.7191468542814254\n",
      "Epoch: 79, batch: 124, loss: 0.7148441201448441\n",
      "Epoch: 79, batch: 174, loss: 0.6903384351730346\n",
      "Epoch: 79, batch: 224, loss: 0.69107293009758\n",
      "Epoch: 79, batch: 274, loss: 0.6917791765928268\n",
      "Epoch: 79, batch: 324, loss: 0.6915630120038986\n",
      "Epoch: 79, batch: 374, loss: 0.6950064271688461\n",
      "Starting Epoch  80 ...\n",
      "Epoch: 80, batch: 49, loss: 0.6965367966890335\n",
      "Epoch: 80, batch: 99, loss: 0.693451817035675\n",
      "Epoch: 80, batch: 149, loss: 0.6927350634336471\n",
      "Epoch: 80, batch: 199, loss: 0.6952179008722306\n",
      "Epoch: 80, batch: 249, loss: 0.758320934176445\n",
      "Epoch: 80, batch: 299, loss: 0.7570236116647721\n",
      "Epoch: 80, batch: 349, loss: 0.6902618306875229\n",
      "Starting Epoch  81 ...\n",
      "Epoch: 81, batch: 24, loss: 0.6872613680362701\n",
      "Epoch: 81, batch: 74, loss: 0.6881824713945389\n",
      "Epoch: 81, batch: 124, loss: 0.6906989032030105\n",
      "Epoch: 81, batch: 174, loss: 0.6950141501426697\n",
      "Epoch: 81, batch: 224, loss: 0.6927146476507187\n",
      "Epoch: 81, batch: 274, loss: 0.6883456414937973\n",
      "Epoch: 81, batch: 324, loss: 0.6890571373701095\n",
      "Epoch: 81, batch: 374, loss: 0.690036547780037\n",
      "Starting Epoch  82 ...\n",
      "Epoch: 82, batch: 49, loss: 0.6933988434076309\n",
      "Epoch: 82, batch: 99, loss: 0.7189828062057495\n",
      "Epoch: 82, batch: 149, loss: 0.72242815554142\n",
      "Epoch: 82, batch: 199, loss: 0.6948365724086761\n",
      "Epoch: 82, batch: 249, loss: 0.6865495103597641\n",
      "Epoch: 82, batch: 299, loss: 0.686570119857788\n",
      "Epoch: 82, batch: 349, loss: 0.6861154359579086\n",
      "Starting Epoch  83 ...\n",
      "Epoch: 83, batch: 24, loss: 0.6898633724451065\n",
      "Epoch: 83, batch: 74, loss: 0.691929636001587\n",
      "Epoch: 83, batch: 124, loss: 0.6896113389730454\n",
      "Epoch: 83, batch: 174, loss: 0.6913934409618377\n",
      "Epoch: 83, batch: 224, loss: 0.6934740406274795\n",
      "Epoch: 83, batch: 274, loss: 0.6903899985551835\n",
      "Epoch: 83, batch: 324, loss: 0.6864190030097962\n",
      "Epoch: 83, batch: 374, loss: 0.6869525820016861\n",
      "Starting Epoch  84 ...\n",
      "Epoch: 84, batch: 49, loss: 0.6874754703044892\n",
      "Epoch: 84, batch: 99, loss: 0.6893644243478775\n",
      "Epoch: 84, batch: 149, loss: 0.6890685695409775\n",
      "Epoch: 84, batch: 199, loss: 0.6855663907527924\n",
      "Epoch: 84, batch: 249, loss: 0.68631307721138\n",
      "Epoch: 84, batch: 299, loss: 0.6904758411645889\n",
      "Epoch: 84, batch: 349, loss: 0.6894389081001282\n",
      "Starting Epoch  85 ...\n",
      "Epoch: 85, batch: 24, loss: 0.7016583287715912\n",
      "Epoch: 85, batch: 74, loss: 0.7034267663955689\n",
      "Epoch: 85, batch: 124, loss: 0.6909110993146896\n",
      "Epoch: 85, batch: 174, loss: 0.6881125491857528\n",
      "Epoch: 85, batch: 224, loss: 0.6986765033006668\n",
      "Epoch: 85, batch: 274, loss: 0.7109783571958542\n",
      "Epoch: 85, batch: 324, loss: 0.6939472377300262\n",
      "Epoch: 85, batch: 374, loss: 0.6816718465089798\n",
      "Starting Epoch  86 ...\n",
      "Epoch: 86, batch: 49, loss: 0.6832865738868713\n",
      "Epoch: 86, batch: 99, loss: 0.6840093952417373\n",
      "Epoch: 86, batch: 149, loss: 0.6834575963020325\n",
      "Epoch: 86, batch: 199, loss: 0.6829806077480316\n",
      "Epoch: 86, batch: 249, loss: 0.6841079127788544\n",
      "Epoch: 86, batch: 299, loss: 0.6828112262487411\n",
      "Epoch: 86, batch: 349, loss: 0.6857669097185135\n",
      "Starting Epoch  87 ...\n",
      "Epoch: 87, batch: 24, loss: 0.7079264909029007\n",
      "Epoch: 87, batch: 74, loss: 0.7067311650514603\n",
      "Epoch: 87, batch: 124, loss: 0.6846842610836029\n",
      "Epoch: 87, batch: 174, loss: 0.6808745676279068\n",
      "Epoch: 87, batch: 224, loss: 0.6899160993099213\n",
      "Epoch: 87, batch: 274, loss: 0.6952190601825714\n",
      "Epoch: 87, batch: 324, loss: 0.6975476640462875\n",
      "Epoch: 87, batch: 374, loss: 0.6972612249851227\n",
      "Starting Epoch  88 ...\n",
      "Epoch: 88, batch: 49, loss: 0.6857009083032608\n",
      "Epoch: 88, batch: 99, loss: 0.6806145054101944\n",
      "Epoch: 88, batch: 149, loss: 0.6844932162761688\n",
      "Epoch: 88, batch: 199, loss: 0.6856864660978317\n",
      "Epoch: 88, batch: 249, loss: 0.6814344900846482\n",
      "Epoch: 88, batch: 299, loss: 0.6798942279815674\n",
      "Epoch: 88, batch: 349, loss: 0.681784730553627\n",
      "Starting Epoch  89 ...\n",
      "Epoch: 89, batch: 24, loss: 0.6943217974901199\n",
      "Epoch: 89, batch: 74, loss: 0.6942487043142319\n",
      "Epoch: 89, batch: 124, loss: 0.6835347813367844\n",
      "Epoch: 89, batch: 174, loss: 0.68016277551651\n",
      "Epoch: 89, batch: 224, loss: 0.7027083510160446\n",
      "Epoch: 89, batch: 274, loss: 0.7043899738788605\n",
      "Epoch: 89, batch: 324, loss: 0.6885717922449112\n",
      "Epoch: 89, batch: 374, loss: 0.7060771626234055\n",
      "Starting Epoch  90 ...\n",
      "Epoch: 90, batch: 49, loss: 0.6991581505537033\n",
      "Epoch: 90, batch: 99, loss: 0.6804616671800613\n",
      "Epoch: 90, batch: 149, loss: 0.6772526037693024\n",
      "Epoch: 90, batch: 199, loss: 0.6775191068649292\n",
      "Epoch: 90, batch: 249, loss: 0.6781624311208725\n",
      "Epoch: 90, batch: 299, loss: 0.67928278028965\n",
      "Epoch: 90, batch: 349, loss: 0.6849329751729966\n",
      "Starting Epoch  91 ...\n",
      "Epoch: 91, batch: 24, loss: 0.6832156926393509\n",
      "Epoch: 91, batch: 74, loss: 0.6777779698371887\n",
      "Epoch: 91, batch: 124, loss: 0.6838234299421311\n",
      "Epoch: 91, batch: 174, loss: 0.6897531008720398\n",
      "Epoch: 91, batch: 224, loss: 0.6832840800285339\n",
      "Epoch: 91, batch: 274, loss: 0.6778722131252288\n",
      "Epoch: 91, batch: 324, loss: 0.68008769094944\n",
      "Epoch: 91, batch: 374, loss: 0.6810001629590988\n",
      "Starting Epoch  92 ...\n",
      "Epoch: 92, batch: 49, loss: 0.6788428032398224\n",
      "Epoch: 92, batch: 99, loss: 0.6790049344301223\n",
      "Epoch: 92, batch: 149, loss: 0.6965720647573471\n",
      "Epoch: 92, batch: 199, loss: 0.7062698918581009\n",
      "Epoch: 92, batch: 249, loss: 0.688986309170723\n",
      "Epoch: 92, batch: 299, loss: 0.6782394790649414\n",
      "Epoch: 92, batch: 349, loss: 0.6997030436992645\n",
      "Starting Epoch  93 ...\n",
      "Epoch: 93, batch: 24, loss: 0.6971253681182862\n",
      "Epoch: 93, batch: 74, loss: 0.6800431621074676\n",
      "Epoch: 93, batch: 124, loss: 0.6819711619615555\n",
      "Epoch: 93, batch: 174, loss: 0.6759007573127747\n",
      "Epoch: 93, batch: 224, loss: 0.6750260788202286\n",
      "Epoch: 93, batch: 274, loss: 0.6997733247280121\n",
      "Epoch: 93, batch: 324, loss: 0.7013877367973328\n",
      "Epoch: 93, batch: 374, loss: 0.6842804336547852\n",
      "Starting Epoch  94 ...\n",
      "Epoch: 94, batch: 49, loss: 0.6887835133075714\n",
      "Epoch: 94, batch: 99, loss: 0.6818050813674926\n",
      "Epoch: 94, batch: 149, loss: 0.6745237410068512\n",
      "Epoch: 94, batch: 199, loss: 0.6834773242473602\n",
      "Epoch: 94, batch: 249, loss: 0.6948008495569229\n",
      "Epoch: 94, batch: 299, loss: 0.6856062513589859\n",
      "Epoch: 94, batch: 349, loss: 0.6739367306232452\n",
      "Starting Epoch  95 ...\n",
      "Epoch: 95, batch: 24, loss: 0.675477774143219\n",
      "Epoch: 95, batch: 74, loss: 0.6770339101552963\n",
      "Epoch: 95, batch: 124, loss: 0.6810807019472123\n",
      "Epoch: 95, batch: 174, loss: 0.6937544649839401\n",
      "Epoch: 95, batch: 224, loss: 0.6873524349927902\n",
      "Epoch: 95, batch: 274, loss: 0.6745196050405502\n",
      "Epoch: 95, batch: 324, loss: 0.6758654546737671\n",
      "Epoch: 95, batch: 374, loss: 0.6761533808708191\n",
      "Starting Epoch  96 ...\n",
      "Epoch: 96, batch: 49, loss: 0.67512730717659\n",
      "Epoch: 96, batch: 99, loss: 0.6749939107894898\n",
      "Epoch: 96, batch: 149, loss: 0.6770638847351074\n",
      "Epoch: 96, batch: 199, loss: 0.6761211043596268\n",
      "Epoch: 96, batch: 249, loss: 0.6739744728803635\n",
      "Epoch: 96, batch: 299, loss: 0.6739169889688492\n",
      "Epoch: 96, batch: 349, loss: 0.6740613979101181\n",
      "Starting Epoch  97 ...\n",
      "Epoch: 97, batch: 24, loss: 0.6746280854940414\n",
      "Epoch: 97, batch: 74, loss: 0.6753720873594284\n",
      "Epoch: 97, batch: 124, loss: 0.6749573886394501\n",
      "Epoch: 97, batch: 174, loss: 0.6817951738834381\n",
      "Epoch: 97, batch: 224, loss: 0.683649018406868\n",
      "Epoch: 97, batch: 274, loss: 0.6772224533557892\n",
      "Epoch: 97, batch: 324, loss: 0.6740079987049102\n",
      "Epoch: 97, batch: 374, loss: 0.6768869870901107\n",
      "Starting Epoch  98 ...\n",
      "Epoch: 98, batch: 49, loss: 0.6767007154226303\n",
      "Epoch: 98, batch: 99, loss: 0.6730853343009948\n",
      "Epoch: 98, batch: 149, loss: 0.6729863524436951\n",
      "Epoch: 98, batch: 199, loss: 0.6716459476947785\n",
      "Epoch: 98, batch: 249, loss: 0.675828508734703\n",
      "Epoch: 98, batch: 299, loss: 0.6768936908245087\n",
      "Epoch: 98, batch: 349, loss: 0.671954875588417\n",
      "Starting Epoch  99 ...\n",
      "Epoch: 99, batch: 24, loss: 0.6764997535943985\n",
      "Epoch: 99, batch: 74, loss: 0.6794151651859284\n",
      "Epoch: 99, batch: 124, loss: 0.6967641752958298\n",
      "Epoch: 99, batch: 174, loss: 0.6947233790159225\n",
      "Epoch: 99, batch: 224, loss: 0.6708080673217773\n",
      "Epoch: 99, batch: 274, loss: 0.6703888541460037\n",
      "Epoch: 99, batch: 324, loss: 0.6850407016277313\n",
      "Epoch: 99, batch: 374, loss: 0.684771403670311\n",
      "Starting Epoch  100 ...\n",
      "Epoch: 100, batch: 49, loss: 0.6751968395709992\n",
      "Epoch: 100, batch: 99, loss: 0.6815859681367874\n",
      "Epoch: 100, batch: 149, loss: 0.6776316642761231\n",
      "Epoch: 100, batch: 199, loss: 0.6809059721231461\n",
      "Epoch: 100, batch: 249, loss: 0.6817663371562958\n",
      "Epoch: 100, batch: 299, loss: 0.671047682762146\n",
      "Epoch: 100, batch: 349, loss: 0.6681288123130799\n",
      "Starting Epoch  101 ...\n",
      "Epoch: 101, batch: 24, loss: 0.6683358824253083\n",
      "Epoch: 101, batch: 74, loss: 0.6691532003879547\n",
      "Epoch: 101, batch: 124, loss: 0.670248926281929\n",
      "Epoch: 101, batch: 174, loss: 0.6782947212457657\n",
      "Epoch: 101, batch: 224, loss: 0.6783478701114655\n",
      "Epoch: 101, batch: 274, loss: 0.6692562735080719\n",
      "Epoch: 101, batch: 324, loss: 0.668416188955307\n",
      "Epoch: 101, batch: 374, loss: 0.6902721691131591\n",
      "Starting Epoch  102 ...\n",
      "Epoch: 102, batch: 49, loss: 0.6886013519763946\n",
      "Epoch: 102, batch: 99, loss: 0.668202878832817\n",
      "Epoch: 102, batch: 149, loss: 0.6701992017030716\n",
      "Epoch: 102, batch: 199, loss: 0.673107892870903\n",
      "Epoch: 102, batch: 249, loss: 0.6750267571210862\n",
      "Epoch: 102, batch: 299, loss: 0.6709036546945571\n",
      "Epoch: 102, batch: 349, loss: 0.6818963479995728\n",
      "Starting Epoch  103 ...\n",
      "Epoch: 103, batch: 24, loss: 0.6855353444814682\n",
      "Epoch: 103, batch: 74, loss: 0.6723262643814087\n",
      "Epoch: 103, batch: 124, loss: 0.6731834554672241\n",
      "Epoch: 103, batch: 174, loss: 0.6835198646783829\n",
      "Epoch: 103, batch: 224, loss: 0.6794962227344513\n",
      "Epoch: 103, batch: 274, loss: 0.6699971407651901\n",
      "Epoch: 103, batch: 324, loss: 0.6700770878791809\n",
      "Epoch: 103, batch: 374, loss: 0.6687839788198471\n",
      "Starting Epoch  104 ...\n",
      "Epoch: 104, batch: 49, loss: 0.6666668081283569\n",
      "Epoch: 104, batch: 99, loss: 0.6991392177343368\n",
      "Epoch: 104, batch: 149, loss: 0.7007469993829727\n",
      "Epoch: 104, batch: 199, loss: 0.6679415953159332\n",
      "Epoch: 104, batch: 249, loss: 0.6710458582639695\n",
      "Epoch: 104, batch: 299, loss: 0.6727527439594269\n",
      "Epoch: 104, batch: 349, loss: 0.6682577884197235\n",
      "Starting Epoch  105 ...\n",
      "Epoch: 105, batch: 24, loss: 0.6690724992752075\n",
      "Epoch: 105, batch: 74, loss: 0.6688889014720917\n",
      "Epoch: 105, batch: 124, loss: 0.6655092871189118\n",
      "Epoch: 105, batch: 174, loss: 0.6653083646297455\n",
      "Epoch: 105, batch: 224, loss: 0.6681998229026794\n",
      "Epoch: 105, batch: 274, loss: 0.6829169523715973\n",
      "Epoch: 105, batch: 324, loss: 0.6807635825872421\n",
      "Epoch: 105, batch: 374, loss: 0.6663296627998352\n",
      "Starting Epoch  106 ...\n",
      "Epoch: 106, batch: 49, loss: 0.6652308642864228\n",
      "Epoch: 106, batch: 99, loss: 0.6657954514026642\n",
      "Epoch: 106, batch: 149, loss: 0.680256854891777\n",
      "Epoch: 106, batch: 199, loss: 0.6840673726797104\n",
      "Epoch: 106, batch: 249, loss: 0.6682636106014251\n",
      "Epoch: 106, batch: 299, loss: 0.6660314124822616\n",
      "Epoch: 106, batch: 349, loss: 0.6675844967365265\n",
      "Starting Epoch  107 ...\n",
      "Epoch: 107, batch: 24, loss: 0.6652212727069855\n",
      "Epoch: 107, batch: 74, loss: 0.664962415099144\n",
      "Epoch: 107, batch: 124, loss: 0.6652647233009339\n",
      "Epoch: 107, batch: 174, loss: 0.6748018109798432\n",
      "Epoch: 107, batch: 224, loss: 0.6742538702487946\n",
      "Epoch: 107, batch: 274, loss: 0.6640722101926804\n",
      "Epoch: 107, batch: 324, loss: 0.6648231679201126\n",
      "Epoch: 107, batch: 374, loss: 0.6729104769229889\n",
      "Starting Epoch  108 ...\n",
      "Epoch: 108, batch: 49, loss: 0.6722973066568375\n",
      "Epoch: 108, batch: 99, loss: 0.6640378946065902\n",
      "Epoch: 108, batch: 149, loss: 0.664019450545311\n",
      "Epoch: 108, batch: 199, loss: 0.6771160036325454\n",
      "Epoch: 108, batch: 249, loss: 0.6775285631418229\n",
      "Epoch: 108, batch: 299, loss: 0.6646081751585007\n",
      "Epoch: 108, batch: 349, loss: 0.6641805672645569\n",
      "Starting Epoch  109 ...\n",
      "Epoch: 109, batch: 24, loss: 0.6805646574497223\n",
      "Epoch: 109, batch: 74, loss: 0.6821251058578491\n",
      "Epoch: 109, batch: 124, loss: 0.6637711763381958\n",
      "Epoch: 109, batch: 174, loss: 0.6611819911003113\n",
      "Epoch: 109, batch: 224, loss: 0.6652709370851517\n",
      "Epoch: 109, batch: 274, loss: 0.6669558513164521\n",
      "Epoch: 109, batch: 324, loss: 0.6653854113817215\n",
      "Epoch: 109, batch: 374, loss: 0.6843488270044327\n",
      "Starting Epoch  110 ...\n",
      "Epoch: 110, batch: 49, loss: 0.6826036822795868\n",
      "Epoch: 110, batch: 99, loss: 0.6615196859836578\n",
      "Epoch: 110, batch: 149, loss: 0.6626261895895005\n",
      "Epoch: 110, batch: 199, loss: 0.6627575951814652\n",
      "Epoch: 110, batch: 249, loss: 0.6651701617240906\n",
      "Epoch: 110, batch: 299, loss: 0.6661439681053162\n",
      "Epoch: 110, batch: 349, loss: 0.6642397207021713\n",
      "Starting Epoch  111 ...\n",
      "Epoch: 111, batch: 24, loss: 0.667069764137268\n",
      "Epoch: 111, batch: 74, loss: 0.6655379152297973\n",
      "Epoch: 111, batch: 124, loss: 0.6619173610210418\n",
      "Epoch: 111, batch: 174, loss: 0.6611505091190338\n",
      "Epoch: 111, batch: 224, loss: 0.661547217965126\n",
      "Epoch: 111, batch: 274, loss: 0.6620972400903702\n",
      "Epoch: 111, batch: 324, loss: 0.6631384819746018\n",
      "Epoch: 111, batch: 374, loss: 0.688020389676094\n",
      "Starting Epoch  112 ...\n",
      "Epoch: 112, batch: 49, loss: 0.6898314249515534\n",
      "Epoch: 112, batch: 99, loss: 0.6643742722272873\n",
      "Epoch: 112, batch: 149, loss: 0.660913633108139\n",
      "Epoch: 112, batch: 199, loss: 0.660588835477829\n",
      "Epoch: 112, batch: 249, loss: 0.6675577628612518\n",
      "Epoch: 112, batch: 299, loss: 0.6767873680591583\n",
      "Epoch: 112, batch: 349, loss: 0.6683856052160263\n",
      "Starting Epoch  113 ...\n",
      "Epoch: 113, batch: 24, loss: 0.6598564088344574\n",
      "Epoch: 113, batch: 74, loss: 0.6610486686229706\n",
      "Epoch: 113, batch: 124, loss: 0.6598930448293686\n",
      "Epoch: 113, batch: 174, loss: 0.6652958405017853\n",
      "Epoch: 113, batch: 224, loss: 0.6669562172889709\n",
      "Epoch: 113, batch: 274, loss: 0.6598576378822326\n",
      "Epoch: 113, batch: 324, loss: 0.6600764960050582\n",
      "Epoch: 113, batch: 374, loss: 0.6621555322408677\n",
      "Starting Epoch  114 ...\n",
      "Epoch: 114, batch: 49, loss: 0.6685199683904648\n",
      "Epoch: 114, batch: 99, loss: 0.6673095655441285\n",
      "Epoch: 114, batch: 149, loss: 0.6593243861198426\n",
      "Epoch: 114, batch: 199, loss: 0.6621822321414947\n",
      "Epoch: 114, batch: 249, loss: 0.6617059016227722\n",
      "Epoch: 114, batch: 299, loss: 0.6598106849193573\n",
      "Epoch: 114, batch: 349, loss: 0.6757517141103745\n",
      "Starting Epoch  115 ...\n",
      "Epoch: 115, batch: 24, loss: 0.6734669655561447\n",
      "Epoch: 115, batch: 74, loss: 0.656470645070076\n",
      "Epoch: 115, batch: 124, loss: 0.6598139780759812\n",
      "Epoch: 115, batch: 174, loss: 0.6648473173379899\n",
      "Epoch: 115, batch: 224, loss: 0.6624693524837494\n",
      "Epoch: 115, batch: 274, loss: 0.6673305583000183\n",
      "Epoch: 115, batch: 324, loss: 0.6683807623386383\n",
      "Epoch: 115, batch: 374, loss: 0.6623991984128952\n",
      "Starting Epoch  116 ...\n",
      "Epoch: 116, batch: 49, loss: 0.6631426519155502\n",
      "Epoch: 116, batch: 99, loss: 0.6605675345659257\n",
      "Epoch: 116, batch: 149, loss: 0.6611167085170746\n",
      "Epoch: 116, batch: 199, loss: 0.6696070796251297\n",
      "Epoch: 116, batch: 249, loss: 0.6646773803234101\n",
      "Epoch: 116, batch: 299, loss: 0.6555711835622787\n",
      "Epoch: 116, batch: 349, loss: 0.6565078574419022\n",
      "Starting Epoch  117 ...\n",
      "Epoch: 117, batch: 24, loss: 0.6553926879167556\n",
      "Epoch: 117, batch: 74, loss: 0.6569004756212234\n",
      "Epoch: 117, batch: 124, loss: 0.6637385165691376\n",
      "Epoch: 117, batch: 174, loss: 0.6633730518817902\n",
      "Epoch: 117, batch: 224, loss: 0.6568215441703796\n",
      "Epoch: 117, batch: 274, loss: 0.6684579771757125\n",
      "Epoch: 117, batch: 324, loss: 0.6719535464048385\n",
      "Epoch: 117, batch: 374, loss: 0.6588611334562302\n",
      "Starting Epoch  118 ...\n",
      "Epoch: 118, batch: 49, loss: 0.6639761829376221\n",
      "Epoch: 118, batch: 99, loss: 0.6662465691566467\n",
      "Epoch: 118, batch: 149, loss: 0.6566716533899307\n",
      "Epoch: 118, batch: 199, loss: 0.6588440245389938\n",
      "Epoch: 118, batch: 249, loss: 0.6590354073047638\n",
      "Epoch: 118, batch: 299, loss: 0.6558304041624069\n",
      "Epoch: 118, batch: 349, loss: 0.6602161914110184\n",
      "Starting Epoch  119 ...\n",
      "Epoch: 119, batch: 24, loss: 0.6777829068899155\n",
      "Epoch: 119, batch: 74, loss: 0.6752973508834839\n",
      "Epoch: 119, batch: 124, loss: 0.6572265768051148\n",
      "Epoch: 119, batch: 174, loss: 0.6566564917564393\n",
      "Epoch: 119, batch: 224, loss: 0.6557907599210739\n",
      "Epoch: 119, batch: 274, loss: 0.655695464015007\n",
      "Epoch: 119, batch: 324, loss: 0.672468119263649\n",
      "Epoch: 119, batch: 374, loss: 0.6757716059684753\n",
      "Starting Epoch  120 ...\n",
      "Epoch: 120, batch: 49, loss: 0.6654200732707978\n",
      "Epoch: 120, batch: 99, loss: 0.6614859563112259\n",
      "Epoch: 120, batch: 149, loss: 0.6536806517839432\n",
      "Epoch: 120, batch: 199, loss: 0.653426605463028\n",
      "Epoch: 120, batch: 249, loss: 0.6548004454374313\n",
      "Epoch: 120, batch: 299, loss: 0.6549513292312622\n",
      "Epoch: 120, batch: 349, loss: 0.6840094953775406\n",
      "Starting Epoch  121 ...\n",
      "Epoch: 121, batch: 24, loss: 0.6945999985933304\n",
      "Epoch: 121, batch: 74, loss: 0.6644316387176513\n",
      "Epoch: 121, batch: 124, loss: 0.6517164433002471\n",
      "Epoch: 121, batch: 174, loss: 0.6524711811542511\n",
      "Epoch: 121, batch: 224, loss: 0.653448611497879\n",
      "Epoch: 121, batch: 274, loss: 0.6540323066711425\n",
      "Epoch: 121, batch: 324, loss: 0.6557456648349762\n",
      "Epoch: 121, batch: 374, loss: 0.6542088598012924\n",
      "Starting Epoch  122 ...\n",
      "Epoch: 122, batch: 49, loss: 0.6539301592111587\n",
      "Epoch: 122, batch: 99, loss: 0.6557427662611007\n",
      "Epoch: 122, batch: 149, loss: 0.6587398731708527\n",
      "Epoch: 122, batch: 199, loss: 0.6595211124420166\n",
      "Epoch: 122, batch: 249, loss: 0.658194015622139\n",
      "Epoch: 122, batch: 299, loss: 0.6597591519355774\n",
      "Epoch: 122, batch: 349, loss: 0.6578837096691131\n",
      "Starting Epoch  123 ...\n",
      "Epoch: 123, batch: 24, loss: 0.6549844747781753\n",
      "Epoch: 123, batch: 74, loss: 0.6557743716239929\n",
      "Epoch: 123, batch: 124, loss: 0.6549790853261948\n",
      "Epoch: 123, batch: 174, loss: 0.6524349182844162\n",
      "Epoch: 123, batch: 224, loss: 0.6528404569625854\n",
      "Epoch: 123, batch: 274, loss: 0.6573660260438919\n",
      "Epoch: 123, batch: 324, loss: 0.6627536618709564\n",
      "Epoch: 123, batch: 374, loss: 0.6582337707281113\n",
      "Starting Epoch  124 ...\n",
      "Epoch: 124, batch: 49, loss: 0.6523889839649201\n",
      "Epoch: 124, batch: 99, loss: 0.6516102331876755\n",
      "Epoch: 124, batch: 149, loss: 0.6535019558668137\n",
      "Epoch: 124, batch: 199, loss: 0.66238290309906\n",
      "Epoch: 124, batch: 249, loss: 0.6616082215309143\n",
      "Epoch: 124, batch: 299, loss: 0.654547815322876\n",
      "Epoch: 124, batch: 349, loss: 0.6515760922431946\n",
      "Starting Epoch  125 ...\n",
      "Epoch: 125, batch: 24, loss: 0.6562858110666275\n",
      "Epoch: 125, batch: 74, loss: 0.6581249809265137\n",
      "Epoch: 125, batch: 124, loss: 0.6532896506786346\n",
      "Epoch: 125, batch: 174, loss: 0.6525342488288879\n",
      "Epoch: 125, batch: 224, loss: 0.6631160849332809\n",
      "Epoch: 125, batch: 274, loss: 0.6639213371276855\n",
      "Epoch: 125, batch: 324, loss: 0.6506541401147843\n",
      "Epoch: 125, batch: 374, loss: 0.6495328134298325\n",
      "Starting Epoch  126 ...\n",
      "Epoch: 126, batch: 49, loss: 0.6512832874059677\n",
      "Epoch: 126, batch: 99, loss: 0.6509162008762359\n",
      "Epoch: 126, batch: 149, loss: 0.6620681959390641\n",
      "Epoch: 126, batch: 199, loss: 0.6640633422136307\n",
      "Epoch: 126, batch: 249, loss: 0.651300904750824\n",
      "Epoch: 126, batch: 299, loss: 0.6498846101760865\n",
      "Epoch: 126, batch: 349, loss: 0.6510710775852203\n",
      "Starting Epoch  127 ...\n",
      "Epoch: 127, batch: 24, loss: 0.6676044261455536\n",
      "Epoch: 127, batch: 74, loss: 0.6927441090345383\n",
      "Epoch: 127, batch: 124, loss: 0.6746359997987748\n",
      "Epoch: 127, batch: 174, loss: 0.6475550872087479\n",
      "Epoch: 127, batch: 224, loss: 0.648402235507965\n",
      "Epoch: 127, batch: 274, loss: 0.6490774875879288\n",
      "Epoch: 127, batch: 324, loss: 0.6523730593919754\n",
      "Epoch: 127, batch: 374, loss: 0.6568686407804489\n",
      "Starting Epoch  128 ...\n",
      "Epoch: 128, batch: 49, loss: 0.6562369972467422\n",
      "Epoch: 128, batch: 99, loss: 0.6561787396669387\n",
      "Epoch: 128, batch: 149, loss: 0.6563516211509705\n",
      "Epoch: 128, batch: 199, loss: 0.6524260365962982\n",
      "Epoch: 128, batch: 249, loss: 0.6497626614570617\n",
      "Epoch: 128, batch: 299, loss: 0.6500221240520477\n",
      "Epoch: 128, batch: 349, loss: 0.649786376953125\n",
      "Starting Epoch  129 ...\n",
      "Epoch: 129, batch: 24, loss: 0.6482808113098144\n",
      "Epoch: 129, batch: 74, loss: 0.6474400168657303\n",
      "Epoch: 129, batch: 124, loss: 0.6479238039255142\n",
      "Epoch: 129, batch: 174, loss: 0.6547459876537323\n",
      "Epoch: 129, batch: 224, loss: 0.6550844466686249\n",
      "Epoch: 129, batch: 274, loss: 0.6518476819992065\n",
      "Epoch: 129, batch: 324, loss: 0.6615044414997101\n",
      "Epoch: 129, batch: 374, loss: 0.6586620616912842\n",
      "Starting Epoch  130 ...\n",
      "Epoch: 130, batch: 49, loss: 0.6545127928256989\n",
      "Epoch: 130, batch: 99, loss: 0.6532922595739364\n",
      "Epoch: 130, batch: 149, loss: 0.6468053603172302\n",
      "Epoch: 130, batch: 199, loss: 0.6463665473461151\n",
      "Epoch: 130, batch: 249, loss: 0.6483003431558609\n",
      "Epoch: 130, batch: 299, loss: 0.6526369845867157\n",
      "Epoch: 130, batch: 349, loss: 0.6522180551290512\n",
      "Starting Epoch  131 ...\n",
      "Epoch: 131, batch: 24, loss: 0.6484161746501923\n",
      "Epoch: 131, batch: 74, loss: 0.6469253033399582\n",
      "Epoch: 131, batch: 124, loss: 0.6490115875005722\n",
      "Epoch: 131, batch: 174, loss: 0.6508344656229019\n",
      "Epoch: 131, batch: 224, loss: 0.6529618793725968\n",
      "Epoch: 131, batch: 274, loss: 0.6510148864984512\n",
      "Epoch: 131, batch: 324, loss: 0.6475625610351563\n",
      "Epoch: 131, batch: 374, loss: 0.6469566059112549\n",
      "Starting Epoch  132 ...\n",
      "Epoch: 132, batch: 49, loss: 0.6461280179023743\n",
      "Epoch: 132, batch: 99, loss: 0.6557139450311661\n",
      "Epoch: 132, batch: 149, loss: 0.657063889503479\n",
      "Epoch: 132, batch: 199, loss: 0.6484267795085907\n",
      "Epoch: 132, batch: 249, loss: 0.6465886062383652\n",
      "Epoch: 132, batch: 299, loss: 0.6473576086759567\n",
      "Epoch: 132, batch: 349, loss: 0.6473681056499481\n",
      "Starting Epoch  133 ...\n",
      "Epoch: 133, batch: 24, loss: 0.646314679980278\n",
      "Epoch: 133, batch: 74, loss: 0.6495064479112626\n",
      "Epoch: 133, batch: 124, loss: 0.6601702719926834\n",
      "Epoch: 133, batch: 174, loss: 0.6553153955936432\n",
      "Epoch: 133, batch: 224, loss: 0.6505928379297257\n",
      "Epoch: 133, batch: 274, loss: 0.6624366933107376\n",
      "Epoch: 133, batch: 324, loss: 0.662409035563469\n",
      "Epoch: 133, batch: 374, loss: 0.6519256383180618\n",
      "Starting Epoch  134 ...\n",
      "Epoch: 134, batch: 49, loss: 0.6458846163749695\n",
      "Epoch: 134, batch: 99, loss: 0.6441339957714081\n",
      "Epoch: 134, batch: 149, loss: 0.6480440187454224\n",
      "Epoch: 134, batch: 199, loss: 0.6508290737867355\n",
      "Epoch: 134, batch: 249, loss: 0.6461559987068176\n",
      "Epoch: 134, batch: 299, loss: 0.6569579911231994\n",
      "Epoch: 134, batch: 349, loss: 0.6569334602355957\n",
      "Starting Epoch  135 ...\n",
      "Epoch: 135, batch: 24, loss: 0.6452850592136383\n",
      "Epoch: 135, batch: 74, loss: 0.6467174512147903\n",
      "Epoch: 135, batch: 124, loss: 0.6455934166908264\n",
      "Epoch: 135, batch: 174, loss: 0.6507601463794708\n",
      "Epoch: 135, batch: 224, loss: 0.651846382021904\n",
      "Epoch: 135, batch: 274, loss: 0.6472217667102814\n",
      "Epoch: 135, batch: 324, loss: 0.6467193675041198\n",
      "Epoch: 135, batch: 374, loss: 0.6641904205083847\n",
      "Starting Epoch  136 ...\n",
      "Epoch: 136, batch: 49, loss: 0.6668629986047745\n",
      "Epoch: 136, batch: 99, loss: 0.6457135516405106\n",
      "Epoch: 136, batch: 149, loss: 0.643202975988388\n",
      "Epoch: 136, batch: 199, loss: 0.6447644364833832\n",
      "Epoch: 136, batch: 249, loss: 0.6456048136949539\n",
      "Epoch: 136, batch: 299, loss: 0.6464439928531647\n",
      "Epoch: 136, batch: 349, loss: 0.6476840978860855\n",
      "Starting Epoch  137 ...\n",
      "Epoch: 137, batch: 24, loss: 0.647344046831131\n",
      "Epoch: 137, batch: 74, loss: 0.6434276753664017\n",
      "Epoch: 137, batch: 124, loss: 0.6418094444274902\n",
      "Epoch: 137, batch: 174, loss: 0.6519832187891006\n",
      "Epoch: 137, batch: 224, loss: 0.6538922894001007\n",
      "Epoch: 137, batch: 274, loss: 0.6462424141168595\n",
      "Epoch: 137, batch: 324, loss: 0.6485427874326706\n",
      "Epoch: 137, batch: 374, loss: 0.660053283572197\n",
      "Starting Epoch  138 ...\n",
      "Epoch: 138, batch: 49, loss: 0.6567138779163361\n",
      "Epoch: 138, batch: 99, loss: 0.6427629995346069\n",
      "Epoch: 138, batch: 149, loss: 0.6443116801977158\n",
      "Epoch: 138, batch: 199, loss: 0.6452903091907501\n",
      "Epoch: 138, batch: 249, loss: 0.6441379886865616\n",
      "Epoch: 138, batch: 299, loss: 0.6466960608959198\n",
      "Epoch: 138, batch: 349, loss: 0.6614292520284653\n",
      "Starting Epoch  139 ...\n",
      "Epoch: 139, batch: 24, loss: 0.6570851802825928\n",
      "Epoch: 139, batch: 74, loss: 0.6406477415561675\n",
      "Epoch: 139, batch: 124, loss: 0.6416773474216462\n",
      "Epoch: 139, batch: 174, loss: 0.6431297343969345\n",
      "Epoch: 139, batch: 224, loss: 0.6438889396190643\n",
      "Epoch: 139, batch: 274, loss: 0.6478799480199814\n",
      "Epoch: 139, batch: 324, loss: 0.6472286862134934\n",
      "Epoch: 139, batch: 374, loss: 0.6411973387002945\n",
      "Starting Epoch  140 ...\n",
      "Epoch: 140, batch: 49, loss: 0.6405553883314132\n",
      "Epoch: 140, batch: 99, loss: 0.6426395505666733\n",
      "Epoch: 140, batch: 149, loss: 0.6471642363071441\n",
      "Epoch: 140, batch: 199, loss: 0.6456814765930176\n",
      "Epoch: 140, batch: 249, loss: 0.6414857167005539\n",
      "Epoch: 140, batch: 299, loss: 0.6422529512643814\n",
      "Epoch: 140, batch: 349, loss: 0.6716519063711166\n",
      "Starting Epoch  141 ...\n",
      "Epoch: 141, batch: 24, loss: 0.671042475104332\n",
      "Epoch: 141, batch: 74, loss: 0.6422769069671631\n",
      "Epoch: 141, batch: 124, loss: 0.6497829085588456\n",
      "Epoch: 141, batch: 174, loss: 0.6494702804088592\n",
      "Epoch: 141, batch: 224, loss: 0.6422025913000107\n",
      "Epoch: 141, batch: 274, loss: 0.6445807111263275\n",
      "Epoch: 141, batch: 324, loss: 0.6449104624986649\n",
      "Epoch: 141, batch: 374, loss: 0.6430765616893769\n",
      "Starting Epoch  142 ...\n",
      "Epoch: 142, batch: 49, loss: 0.6427515363693237\n",
      "Epoch: 142, batch: 99, loss: 0.6430160200595856\n",
      "Epoch: 142, batch: 149, loss: 0.6422134852409362\n",
      "Epoch: 142, batch: 199, loss: 0.6430645328760147\n",
      "Epoch: 142, batch: 249, loss: 0.6431162333488465\n",
      "Epoch: 142, batch: 299, loss: 0.6410445064306259\n",
      "Epoch: 142, batch: 349, loss: 0.6403266561031341\n",
      "Starting Epoch  143 ...\n",
      "Epoch: 143, batch: 24, loss: 0.6421035814285279\n",
      "Epoch: 143, batch: 74, loss: 0.6441582411527633\n",
      "Epoch: 143, batch: 124, loss: 0.6401522922515869\n",
      "Epoch: 143, batch: 174, loss: 0.6389647203683854\n",
      "Epoch: 143, batch: 224, loss: 0.6465603011846542\n",
      "Epoch: 143, batch: 274, loss: 0.646197476387024\n",
      "Epoch: 143, batch: 324, loss: 0.6393372267484665\n",
      "Epoch: 143, batch: 374, loss: 0.6476007735729218\n",
      "Starting Epoch  144 ...\n",
      "Epoch: 144, batch: 49, loss: 0.6482654297351838\n",
      "Epoch: 144, batch: 99, loss: 0.6400466221570968\n",
      "Epoch: 144, batch: 149, loss: 0.6713839650154114\n",
      "Epoch: 144, batch: 199, loss: 0.6744343745708465\n",
      "Epoch: 144, batch: 249, loss: 0.6425967228412628\n",
      "Epoch: 144, batch: 299, loss: 0.640285826921463\n",
      "Epoch: 144, batch: 349, loss: 0.6401999938488007\n",
      "Starting Epoch  145 ...\n",
      "Epoch: 145, batch: 24, loss: 0.6383631783723831\n",
      "Epoch: 145, batch: 74, loss: 0.6400627732276917\n",
      "Epoch: 145, batch: 124, loss: 0.6393266528844833\n",
      "Epoch: 145, batch: 174, loss: 0.6397581213712692\n",
      "Epoch: 145, batch: 224, loss: 0.6514240843057633\n",
      "Epoch: 145, batch: 274, loss: 0.658815689086914\n",
      "Epoch: 145, batch: 324, loss: 0.6626504993438721\n",
      "Epoch: 145, batch: 374, loss: 0.6525922167301178\n",
      "Starting Epoch  146 ...\n",
      "Epoch: 146, batch: 49, loss: 0.6390635842084884\n",
      "Epoch: 146, batch: 99, loss: 0.647833622097969\n",
      "Epoch: 146, batch: 149, loss: 0.6467084234952927\n",
      "Epoch: 146, batch: 199, loss: 0.6424296069145202\n",
      "Epoch: 146, batch: 249, loss: 0.6420134419202804\n",
      "Epoch: 146, batch: 299, loss: 0.6367911475896836\n",
      "Epoch: 146, batch: 349, loss: 0.6380708742141724\n",
      "Starting Epoch  147 ...\n",
      "Epoch: 147, batch: 24, loss: 0.6391136872768403\n",
      "Epoch: 147, batch: 74, loss: 0.6438157540559769\n",
      "Epoch: 147, batch: 124, loss: 0.6704788541793824\n",
      "Epoch: 147, batch: 174, loss: 0.6666209417581558\n",
      "Epoch: 147, batch: 224, loss: 0.6382666194438934\n",
      "Epoch: 147, batch: 274, loss: 0.6358676379919053\n",
      "Epoch: 147, batch: 324, loss: 0.6372888231277466\n",
      "Epoch: 147, batch: 374, loss: 0.6377460724115371\n",
      "Starting Epoch  148 ...\n",
      "Epoch: 148, batch: 49, loss: 0.6399461245536804\n",
      "Epoch: 148, batch: 99, loss: 0.6457772475481033\n",
      "Epoch: 148, batch: 149, loss: 0.6430866700410843\n",
      "Epoch: 148, batch: 199, loss: 0.6362694406509399\n",
      "Epoch: 148, batch: 249, loss: 0.636226830482483\n",
      "Epoch: 148, batch: 299, loss: 0.6368796998262405\n",
      "Epoch: 148, batch: 349, loss: 0.6371205568313598\n",
      "Starting Epoch  149 ...\n",
      "Epoch: 149, batch: 24, loss: 0.6448865896463394\n",
      "Epoch: 149, batch: 74, loss: 0.6469616347551346\n",
      "Epoch: 149, batch: 124, loss: 0.6410162943601608\n",
      "Epoch: 149, batch: 174, loss: 0.6393642097711563\n",
      "Epoch: 149, batch: 224, loss: 0.6380148619413376\n",
      "Epoch: 149, batch: 274, loss: 0.6387609910964965\n",
      "Epoch: 149, batch: 324, loss: 0.6385771816968918\n",
      "Epoch: 149, batch: 374, loss: 0.6377577096223831\n",
      "Starting Epoch  150 ...\n",
      "Epoch: 150, batch: 49, loss: 0.6387521874904633\n",
      "Epoch: 150, batch: 99, loss: 0.6374038970470428\n",
      "Epoch: 150, batch: 149, loss: 0.6353426998853684\n",
      "Epoch: 150, batch: 199, loss: 0.6372645491361618\n",
      "Epoch: 150, batch: 249, loss: 0.6430224531888962\n",
      "Epoch: 150, batch: 299, loss: 0.6402481651306152\n",
      "Epoch: 150, batch: 349, loss: 0.6353134077787399\n",
      "Starting Epoch  151 ...\n",
      "Epoch: 151, batch: 24, loss: 0.6372457790374756\n",
      "Epoch: 151, batch: 74, loss: 0.6354548108577728\n",
      "Epoch: 151, batch: 124, loss: 0.6347264903783798\n",
      "Epoch: 151, batch: 174, loss: 0.6372522574663162\n",
      "Epoch: 151, batch: 224, loss: 0.6365209245681762\n",
      "Epoch: 151, batch: 274, loss: 0.6363154608011246\n",
      "Epoch: 151, batch: 324, loss: 0.6375203037261963\n",
      "Epoch: 151, batch: 374, loss: 0.6357321858406066\n",
      "Starting Epoch  152 ...\n",
      "Epoch: 152, batch: 49, loss: 0.6537440198659897\n",
      "Epoch: 152, batch: 99, loss: 0.6639825361967087\n",
      "Epoch: 152, batch: 149, loss: 0.6438216155767441\n",
      "Epoch: 152, batch: 199, loss: 0.6331107974052429\n",
      "Epoch: 152, batch: 249, loss: 0.6367913734912872\n",
      "Epoch: 152, batch: 299, loss: 0.6366364407539368\n",
      "Epoch: 152, batch: 349, loss: 0.6340277129411698\n",
      "Starting Epoch  153 ...\n",
      "Epoch: 153, batch: 24, loss: 0.6345059818029404\n",
      "Epoch: 153, batch: 74, loss: 0.6363262504339218\n",
      "Epoch: 153, batch: 124, loss: 0.6359837180376053\n",
      "Epoch: 153, batch: 174, loss: 0.6349746590852737\n",
      "Epoch: 153, batch: 224, loss: 0.6378136074542999\n",
      "Epoch: 153, batch: 274, loss: 0.6380792534351349\n",
      "Epoch: 153, batch: 324, loss: 0.6370102071762085\n",
      "Epoch: 153, batch: 374, loss: 0.6363604915142059\n",
      "Starting Epoch  154 ...\n",
      "Epoch: 154, batch: 49, loss: 0.6393134289979935\n",
      "Epoch: 154, batch: 99, loss: 0.6404902005195617\n",
      "Epoch: 154, batch: 149, loss: 0.6338946658372879\n",
      "Epoch: 154, batch: 199, loss: 0.6317482900619507\n",
      "Epoch: 154, batch: 249, loss: 0.6325153160095215\n",
      "Epoch: 154, batch: 299, loss: 0.6392811697721481\n",
      "Epoch: 154, batch: 349, loss: 0.6403889107704163\n",
      "Starting Epoch  155 ...\n",
      "Epoch: 155, batch: 24, loss: 0.6352187579870224\n",
      "Epoch: 155, batch: 74, loss: 0.6354250097274781\n",
      "Epoch: 155, batch: 124, loss: 0.6431461852788926\n",
      "Epoch: 155, batch: 174, loss: 0.6417212909460068\n",
      "Epoch: 155, batch: 224, loss: 0.6323221784830093\n",
      "Epoch: 155, batch: 274, loss: 0.6336372530460358\n",
      "Epoch: 155, batch: 324, loss: 0.6420354050397873\n",
      "Epoch: 155, batch: 374, loss: 0.6421456658840179\n",
      "Starting Epoch  156 ...\n",
      "Epoch: 156, batch: 49, loss: 0.6532101655006408\n",
      "Epoch: 156, batch: 99, loss: 0.6526576340198517\n",
      "Epoch: 156, batch: 149, loss: 0.6316554379463196\n",
      "Epoch: 156, batch: 199, loss: 0.6320605278015137\n",
      "Epoch: 156, batch: 249, loss: 0.635499295592308\n",
      "Epoch: 156, batch: 299, loss: 0.6354088503122329\n",
      "Epoch: 156, batch: 349, loss: 0.6331947368383407\n",
      "Starting Epoch  157 ...\n",
      "Epoch: 157, batch: 24, loss: 0.6334097748994827\n",
      "Epoch: 157, batch: 74, loss: 0.6334561562538147\n",
      "Epoch: 157, batch: 124, loss: 0.6313963425159455\n",
      "Epoch: 157, batch: 174, loss: 0.632159184217453\n",
      "Epoch: 157, batch: 224, loss: 0.633361229300499\n",
      "Epoch: 157, batch: 274, loss: 0.6399945259094239\n",
      "Epoch: 157, batch: 324, loss: 0.6389323896169663\n",
      "Epoch: 157, batch: 374, loss: 0.6517843973636627\n",
      "Starting Epoch  158 ...\n",
      "Epoch: 158, batch: 49, loss: 0.6556238824129105\n",
      "Epoch: 158, batch: 99, loss: 0.6338502246141434\n",
      "Epoch: 158, batch: 149, loss: 0.6310688066482544\n",
      "Epoch: 158, batch: 199, loss: 0.6349435061216354\n",
      "Epoch: 158, batch: 249, loss: 0.6347051298618317\n",
      "Epoch: 158, batch: 299, loss: 0.6324336302280426\n",
      "Epoch: 158, batch: 349, loss: 0.6316835927963257\n",
      "Starting Epoch  159 ...\n",
      "Epoch: 159, batch: 24, loss: 0.6303630882501602\n",
      "Epoch: 159, batch: 74, loss: 0.6323834925889968\n",
      "Epoch: 159, batch: 124, loss: 0.6344274735450744\n",
      "Epoch: 159, batch: 174, loss: 0.6328935408592224\n",
      "Epoch: 159, batch: 224, loss: 0.631268515586853\n",
      "Epoch: 159, batch: 274, loss: 0.6321451908349991\n",
      "Epoch: 159, batch: 324, loss: 0.631898382306099\n",
      "Epoch: 159, batch: 374, loss: 0.6391088598966599\n",
      "Starting Epoch  160 ...\n",
      "Epoch: 160, batch: 49, loss: 0.6420292574167251\n",
      "Epoch: 160, batch: 99, loss: 0.6334189200401306\n",
      "Epoch: 160, batch: 149, loss: 0.6324271816015243\n",
      "Epoch: 160, batch: 199, loss: 0.6365783476829528\n",
      "Epoch: 160, batch: 249, loss: 0.6413615703582763\n",
      "Epoch: 160, batch: 299, loss: 0.6390035730600357\n",
      "Epoch: 160, batch: 349, loss: 0.6324775123596191\n",
      "Starting Epoch  161 ...\n",
      "Epoch: 161, batch: 24, loss: 0.6301205098628998\n",
      "Epoch: 161, batch: 74, loss: 0.6417328768968582\n",
      "Epoch: 161, batch: 124, loss: 0.6417333674430847\n",
      "Epoch: 161, batch: 174, loss: 0.6299892288446426\n",
      "Epoch: 161, batch: 224, loss: 0.644420456290245\n",
      "Epoch: 161, batch: 274, loss: 0.6456520825624465\n",
      "Epoch: 161, batch: 324, loss: 0.6310451239347458\n",
      "Epoch: 161, batch: 374, loss: 0.6292119431495666\n",
      "Starting Epoch  162 ...\n",
      "Epoch: 162, batch: 49, loss: 0.6293954885005951\n",
      "Epoch: 162, batch: 99, loss: 0.6307228767871856\n",
      "Epoch: 162, batch: 149, loss: 0.6320614516735077\n",
      "Epoch: 162, batch: 199, loss: 0.6314267426729202\n",
      "Epoch: 162, batch: 249, loss: 0.6378927278518677\n",
      "Epoch: 162, batch: 299, loss: 0.6383844202756882\n",
      "Epoch: 162, batch: 349, loss: 0.6317937988042831\n",
      "Starting Epoch  163 ...\n",
      "Epoch: 163, batch: 24, loss: 0.6691867107152939\n",
      "Epoch: 163, batch: 74, loss: 0.6678101879358291\n",
      "Epoch: 163, batch: 124, loss: 0.6286890149116516\n",
      "Epoch: 163, batch: 174, loss: 0.6347260266542435\n",
      "Epoch: 163, batch: 224, loss: 0.6341343009471894\n",
      "Epoch: 163, batch: 274, loss: 0.6285415697097778\n",
      "Epoch: 163, batch: 324, loss: 0.6302536427974701\n",
      "Epoch: 163, batch: 374, loss: 0.6357868903875351\n",
      "Starting Epoch  164 ...\n",
      "Epoch: 164, batch: 49, loss: 0.6342176723480225\n",
      "Epoch: 164, batch: 99, loss: 0.6273666310310364\n",
      "Epoch: 164, batch: 149, loss: 0.627300700545311\n",
      "Epoch: 164, batch: 199, loss: 0.6273108875751495\n",
      "Epoch: 164, batch: 249, loss: 0.6290641731023788\n",
      "Epoch: 164, batch: 299, loss: 0.6299867510795594\n",
      "Epoch: 164, batch: 349, loss: 0.6299801743030549\n",
      "Starting Epoch  165 ...\n",
      "Epoch: 165, batch: 24, loss: 0.6304669219255448\n",
      "Epoch: 165, batch: 74, loss: 0.6296997731924057\n",
      "Epoch: 165, batch: 124, loss: 0.6351790571212769\n",
      "Epoch: 165, batch: 174, loss: 0.6352491444349289\n",
      "Epoch: 165, batch: 224, loss: 0.6310988682508468\n",
      "Epoch: 165, batch: 274, loss: 0.6310870945453644\n",
      "Epoch: 165, batch: 324, loss: 0.6300473207235336\n",
      "Epoch: 165, batch: 374, loss: 0.628967216014862\n",
      "Starting Epoch  166 ...\n",
      "Epoch: 166, batch: 49, loss: 0.6271964770555496\n",
      "Epoch: 166, batch: 99, loss: 0.6272883087396621\n",
      "Epoch: 166, batch: 149, loss: 0.629892709851265\n",
      "Epoch: 166, batch: 199, loss: 0.6300437051057816\n",
      "Epoch: 166, batch: 249, loss: 0.6275011330842972\n",
      "Epoch: 166, batch: 299, loss: 0.6345691984891891\n",
      "Epoch: 166, batch: 349, loss: 0.6345610421895981\n",
      "Starting Epoch  167 ...\n",
      "Epoch: 167, batch: 24, loss: 0.6279623711109161\n",
      "Epoch: 167, batch: 74, loss: 0.6263539355993271\n",
      "Epoch: 167, batch: 124, loss: 0.6274410253763198\n",
      "Epoch: 167, batch: 174, loss: 0.6309709173440933\n",
      "Epoch: 167, batch: 224, loss: 0.6295003759860992\n",
      "Epoch: 167, batch: 274, loss: 0.6271720153093338\n",
      "Epoch: 167, batch: 324, loss: 0.626635131239891\n",
      "Epoch: 167, batch: 374, loss: 0.6283976924419403\n",
      "Starting Epoch  168 ...\n",
      "Epoch: 168, batch: 49, loss: 0.6475732094049453\n",
      "Epoch: 168, batch: 99, loss: 0.6504843759536744\n",
      "Epoch: 168, batch: 149, loss: 0.631590068936348\n",
      "Epoch: 168, batch: 199, loss: 0.6270381444692612\n",
      "Epoch: 168, batch: 249, loss: 0.6322887414693832\n",
      "Epoch: 168, batch: 299, loss: 0.6319536882638931\n",
      "Epoch: 168, batch: 349, loss: 0.6254964011907578\n",
      "Starting Epoch  169 ...\n",
      "Epoch: 169, batch: 24, loss: 0.6287881481647491\n",
      "Epoch: 169, batch: 74, loss: 0.6337806183099747\n",
      "Epoch: 169, batch: 124, loss: 0.6357515352964401\n",
      "Epoch: 169, batch: 174, loss: 0.6330026841163635\n",
      "Epoch: 169, batch: 224, loss: 0.634481817483902\n",
      "Epoch: 169, batch: 274, loss: 0.63262610912323\n",
      "Epoch: 169, batch: 324, loss: 0.6252711707353592\n",
      "Epoch: 169, batch: 374, loss: 0.6256723421812057\n",
      "Starting Epoch  170 ...\n",
      "Epoch: 170, batch: 49, loss: 0.6270754474401474\n",
      "Epoch: 170, batch: 99, loss: 0.62578280210495\n",
      "Epoch: 170, batch: 149, loss: 0.6251749223470688\n",
      "Epoch: 170, batch: 199, loss: 0.62649986743927\n",
      "Epoch: 170, batch: 249, loss: 0.6269046306610108\n",
      "Epoch: 170, batch: 299, loss: 0.6596351617574692\n",
      "Epoch: 170, batch: 349, loss: 0.6810069674253464\n",
      "Starting Epoch  171 ...\n",
      "Epoch: 171, batch: 24, loss: 0.6481118094921112\n",
      "Epoch: 171, batch: 74, loss: 0.6245167487859726\n",
      "Epoch: 171, batch: 124, loss: 0.622971818447113\n",
      "Epoch: 171, batch: 174, loss: 0.6262983316183091\n",
      "Epoch: 171, batch: 224, loss: 0.6307254099845886\n",
      "Epoch: 171, batch: 274, loss: 0.6352181684970856\n",
      "Epoch: 171, batch: 324, loss: 0.6297238850593567\n",
      "Epoch: 171, batch: 374, loss: 0.6227546012401581\n",
      "Starting Epoch  172 ...\n",
      "Epoch: 172, batch: 49, loss: 0.6300979733467102\n",
      "Epoch: 172, batch: 99, loss: 0.6464896488189698\n",
      "Epoch: 172, batch: 149, loss: 0.6387706458568573\n",
      "Epoch: 172, batch: 199, loss: 0.6222131890058518\n",
      "Epoch: 172, batch: 249, loss: 0.6246016979217529\n",
      "Epoch: 172, batch: 299, loss: 0.6245730149745942\n",
      "Epoch: 172, batch: 349, loss: 0.6305261266231537\n",
      "Starting Epoch  173 ...\n",
      "Epoch: 173, batch: 24, loss: 0.6343504917621613\n",
      "Epoch: 173, batch: 74, loss: 0.6347189164161682\n",
      "Epoch: 173, batch: 124, loss: 0.6354842746257782\n",
      "Epoch: 173, batch: 174, loss: 0.6287669265270233\n",
      "Epoch: 173, batch: 224, loss: 0.624178900718689\n",
      "Epoch: 173, batch: 274, loss: 0.624776736497879\n",
      "Epoch: 173, batch: 324, loss: 0.6233076328039169\n",
      "Epoch: 173, batch: 374, loss: 0.623913300037384\n",
      "Starting Epoch  174 ...\n",
      "Epoch: 174, batch: 49, loss: 0.625241926908493\n",
      "Epoch: 174, batch: 99, loss: 0.6355513316392899\n",
      "Epoch: 174, batch: 149, loss: 0.6353960996866226\n",
      "Epoch: 174, batch: 199, loss: 0.6273114132881165\n",
      "Epoch: 174, batch: 249, loss: 0.6274637299776077\n",
      "Epoch: 174, batch: 299, loss: 0.6338028228282928\n",
      "Epoch: 174, batch: 349, loss: 0.6330470097064972\n",
      "Starting Epoch  175 ...\n",
      "Epoch: 175, batch: 24, loss: 0.6230693542957306\n",
      "Epoch: 175, batch: 74, loss: 0.6308036005496979\n",
      "Epoch: 175, batch: 124, loss: 0.6300151586532593\n",
      "Epoch: 175, batch: 174, loss: 0.6233881622552871\n",
      "Epoch: 175, batch: 224, loss: 0.6243125194311142\n",
      "Epoch: 175, batch: 274, loss: 0.6243549340963364\n",
      "Epoch: 175, batch: 324, loss: 0.640293356180191\n",
      "Epoch: 175, batch: 374, loss: 0.6395060199499131\n",
      "Starting Epoch  176 ...\n",
      "Epoch: 176, batch: 49, loss: 0.6231420648097992\n",
      "Epoch: 176, batch: 99, loss: 0.6221166378259659\n",
      "Epoch: 176, batch: 149, loss: 0.6216439443826676\n",
      "Epoch: 176, batch: 199, loss: 0.6221001905202865\n",
      "Epoch: 176, batch: 249, loss: 0.6341795039176941\n",
      "Epoch: 176, batch: 299, loss: 0.6368393981456757\n",
      "Epoch: 176, batch: 349, loss: 0.6345110362768174\n",
      "Starting Epoch  177 ...\n",
      "Epoch: 177, batch: 24, loss: 0.6370555490255356\n",
      "Epoch: 177, batch: 74, loss: 0.6278237670660018\n",
      "Epoch: 177, batch: 124, loss: 0.6224036693572998\n",
      "Epoch: 177, batch: 174, loss: 0.6397187519073486\n",
      "Epoch: 177, batch: 224, loss: 0.6424092501401901\n",
      "Epoch: 177, batch: 274, loss: 0.6256856870651245\n",
      "Epoch: 177, batch: 324, loss: 0.6236964684724807\n",
      "Epoch: 177, batch: 374, loss: 0.6278120648860931\n",
      "Starting Epoch  178 ...\n",
      "Epoch: 178, batch: 49, loss: 0.6272897225618362\n",
      "Epoch: 178, batch: 99, loss: 0.6218434965610504\n",
      "Epoch: 178, batch: 149, loss: 0.6230329328775406\n",
      "Epoch: 178, batch: 199, loss: 0.6237219268083573\n",
      "Epoch: 178, batch: 249, loss: 0.6231953299045563\n",
      "Epoch: 178, batch: 299, loss: 0.6227128291130066\n",
      "Epoch: 178, batch: 349, loss: 0.6223065423965454\n",
      "Starting Epoch  179 ...\n",
      "Epoch: 179, batch: 24, loss: 0.6239159965515136\n",
      "Epoch: 179, batch: 74, loss: 0.6246439921855926\n",
      "Epoch: 179, batch: 124, loss: 0.6219501847028732\n",
      "Epoch: 179, batch: 174, loss: 0.6214863389730454\n",
      "Epoch: 179, batch: 224, loss: 0.6230692803859711\n",
      "Epoch: 179, batch: 274, loss: 0.6462251454591751\n",
      "Epoch: 179, batch: 324, loss: 0.6444251012802124\n",
      "Epoch: 179, batch: 374, loss: 0.6373549753427505\n",
      "Starting Epoch  180 ...\n",
      "Epoch: 180, batch: 49, loss: 0.642247564792633\n",
      "Epoch: 180, batch: 99, loss: 0.6480277264118195\n",
      "Epoch: 180, batch: 149, loss: 0.6515152525901794\n",
      "Epoch: 180, batch: 199, loss: 0.6291039097309112\n",
      "Epoch: 180, batch: 249, loss: 0.6214535194635391\n",
      "Epoch: 180, batch: 299, loss: 0.6225125676393509\n",
      "Epoch: 180, batch: 349, loss: 0.6243079715967178\n",
      "Starting Epoch  181 ...\n",
      "Epoch: 181, batch: 24, loss: 0.6224535566568374\n",
      "Epoch: 181, batch: 74, loss: 0.6202612453699112\n",
      "Epoch: 181, batch: 124, loss: 0.620888671875\n",
      "Epoch: 181, batch: 174, loss: 0.6211508983373641\n",
      "Epoch: 181, batch: 224, loss: 0.6303010511398316\n",
      "Epoch: 181, batch: 274, loss: 0.6342531019449233\n",
      "Epoch: 181, batch: 324, loss: 0.6241215062141419\n",
      "Epoch: 181, batch: 374, loss: 0.6219909971952439\n",
      "Starting Epoch  182 ...\n",
      "Epoch: 182, batch: 49, loss: 0.6246143019199372\n",
      "Epoch: 182, batch: 99, loss: 0.6232882678508759\n",
      "Epoch: 182, batch: 149, loss: 0.6219681394100189\n",
      "Epoch: 182, batch: 199, loss: 0.6240409868955612\n",
      "Epoch: 182, batch: 249, loss: 0.6230340576171876\n",
      "Epoch: 182, batch: 299, loss: 0.6416099125146866\n",
      "Epoch: 182, batch: 349, loss: 0.6452219933271408\n",
      "Starting Epoch  183 ...\n",
      "Epoch: 183, batch: 24, loss: 0.6227914351224899\n",
      "Epoch: 183, batch: 74, loss: 0.62565065741539\n",
      "Epoch: 183, batch: 124, loss: 0.6270774096250534\n",
      "Epoch: 183, batch: 174, loss: 0.6201019638776779\n",
      "Epoch: 183, batch: 224, loss: 0.6199011981487275\n",
      "Epoch: 183, batch: 274, loss: 0.6216613525152206\n",
      "Epoch: 183, batch: 324, loss: 0.6209983938932419\n",
      "Epoch: 183, batch: 374, loss: 0.6235891175270081\n",
      "Starting Epoch  184 ...\n",
      "Epoch: 184, batch: 49, loss: 0.6237761926651001\n",
      "Epoch: 184, batch: 99, loss: 0.6196253031492234\n",
      "Epoch: 184, batch: 149, loss: 0.6204685646295548\n",
      "Epoch: 184, batch: 199, loss: 0.622878497838974\n",
      "Epoch: 184, batch: 249, loss: 0.6272614067792892\n",
      "Epoch: 184, batch: 299, loss: 0.6237180870771408\n",
      "Epoch: 184, batch: 349, loss: 0.617827742099762\n",
      "Starting Epoch  185 ...\n",
      "Epoch: 185, batch: 24, loss: 0.6189833116531372\n",
      "Epoch: 185, batch: 74, loss: 0.6196975845098496\n",
      "Epoch: 185, batch: 124, loss: 0.6182261747121811\n",
      "Epoch: 185, batch: 174, loss: 0.635203395485878\n",
      "Epoch: 185, batch: 224, loss: 0.6377881222963333\n",
      "Epoch: 185, batch: 274, loss: 0.6289822298288346\n",
      "Epoch: 185, batch: 324, loss: 0.6295003616809844\n",
      "Epoch: 185, batch: 374, loss: 0.6234767305850982\n",
      "Starting Epoch  186 ...\n",
      "Epoch: 186, batch: 49, loss: 0.6239561933279038\n",
      "Epoch: 186, batch: 99, loss: 0.6219236707687378\n",
      "Epoch: 186, batch: 149, loss: 0.6173870915174484\n",
      "Epoch: 186, batch: 199, loss: 0.621004610657692\n",
      "Epoch: 186, batch: 249, loss: 0.6243245440721512\n",
      "Epoch: 186, batch: 299, loss: 0.6215393608808517\n",
      "Epoch: 186, batch: 349, loss: 0.6221485596895218\n",
      "Starting Epoch  187 ...\n",
      "Epoch: 187, batch: 24, loss: 0.6198784250020981\n",
      "Epoch: 187, batch: 74, loss: 0.6174540168046951\n",
      "Epoch: 187, batch: 124, loss: 0.6195905917882919\n",
      "Epoch: 187, batch: 174, loss: 0.6208512568473816\n",
      "Epoch: 187, batch: 224, loss: 0.6213752454519272\n",
      "Epoch: 187, batch: 274, loss: 0.6415988630056382\n",
      "Epoch: 187, batch: 324, loss: 0.6392800277471542\n",
      "Epoch: 187, batch: 374, loss: 0.6229045909643173\n",
      "Starting Epoch  188 ...\n",
      "Epoch: 188, batch: 49, loss: 0.6231729173660279\n",
      "Epoch: 188, batch: 99, loss: 0.617761857509613\n",
      "Epoch: 188, batch: 149, loss: 0.6195318192243576\n",
      "Epoch: 188, batch: 199, loss: 0.6206472390890121\n",
      "Epoch: 188, batch: 249, loss: 0.6195889043807984\n",
      "Epoch: 188, batch: 299, loss: 0.620439550280571\n",
      "Epoch: 188, batch: 349, loss: 0.619007602930069\n",
      "Starting Epoch  189 ...\n",
      "Epoch: 189, batch: 24, loss: 0.6177863734960556\n",
      "Epoch: 189, batch: 74, loss: 0.6201922273635865\n",
      "Epoch: 189, batch: 124, loss: 0.6213961017131805\n",
      "Epoch: 189, batch: 174, loss: 0.6206357663869858\n",
      "Epoch: 189, batch: 224, loss: 0.6207258415222168\n",
      "Epoch: 189, batch: 274, loss: 0.6225137507915497\n",
      "Epoch: 189, batch: 324, loss: 0.6204993188381195\n",
      "Epoch: 189, batch: 374, loss: 0.6183817434310913\n",
      "Starting Epoch  190 ...\n",
      "Epoch: 190, batch: 49, loss: 0.6168835431337356\n",
      "Epoch: 190, batch: 99, loss: 0.6149318367242813\n",
      "Epoch: 190, batch: 149, loss: 0.6187521052360535\n",
      "Epoch: 190, batch: 199, loss: 0.6195392727851867\n",
      "Epoch: 190, batch: 249, loss: 0.6180914789438248\n",
      "Epoch: 190, batch: 299, loss: 0.6246740394830703\n",
      "Epoch: 190, batch: 349, loss: 0.6244710034132004\n",
      "Starting Epoch  191 ...\n",
      "Epoch: 191, batch: 24, loss: 0.6170860749483108\n",
      "Epoch: 191, batch: 74, loss: 0.6172597807645798\n",
      "Epoch: 191, batch: 124, loss: 0.6175807851552964\n",
      "Epoch: 191, batch: 174, loss: 0.6331611341238021\n",
      "Epoch: 191, batch: 224, loss: 0.6328441298007965\n",
      "Epoch: 191, batch: 274, loss: 0.6191281372308731\n",
      "Epoch: 191, batch: 324, loss: 0.6228990119695663\n",
      "Epoch: 191, batch: 374, loss: 0.6248580461740494\n",
      "Starting Epoch  192 ...\n",
      "Epoch: 192, batch: 49, loss: 0.6220376861095428\n",
      "Epoch: 192, batch: 99, loss: 0.6159588372707367\n",
      "Epoch: 192, batch: 149, loss: 0.6169586366415024\n",
      "Epoch: 192, batch: 199, loss: 0.623630411028862\n",
      "Epoch: 192, batch: 249, loss: 0.6273512411117553\n",
      "Epoch: 192, batch: 299, loss: 0.6322257912158966\n",
      "Epoch: 192, batch: 349, loss: 0.6262604314088821\n",
      "Starting Epoch  193 ...\n",
      "Epoch: 193, batch: 24, loss: 0.6241360229253768\n",
      "Epoch: 193, batch: 74, loss: 0.6257958048582077\n",
      "Epoch: 193, batch: 124, loss: 0.6171573239564896\n",
      "Epoch: 193, batch: 174, loss: 0.6173276293277741\n",
      "Epoch: 193, batch: 224, loss: 0.61860793530941\n",
      "Epoch: 193, batch: 274, loss: 0.6592575186491012\n",
      "Epoch: 193, batch: 324, loss: 0.6582182121276855\n",
      "Epoch: 193, batch: 374, loss: 0.6140629911422729\n",
      "Starting Epoch  194 ...\n",
      "Epoch: 194, batch: 49, loss: 0.6125908815860748\n",
      "Epoch: 194, batch: 99, loss: 0.6139455533027649\n",
      "Epoch: 194, batch: 149, loss: 0.6177133804559708\n",
      "Epoch: 194, batch: 199, loss: 0.62891899228096\n",
      "Epoch: 194, batch: 249, loss: 0.6257790368795395\n",
      "Epoch: 194, batch: 299, loss: 0.6145252525806427\n",
      "Epoch: 194, batch: 349, loss: 0.6140379202365875\n",
      "Starting Epoch  195 ...\n",
      "Epoch: 195, batch: 24, loss: 0.6274339145421982\n",
      "Epoch: 195, batch: 74, loss: 0.6294614213705063\n",
      "Epoch: 195, batch: 124, loss: 0.6166093504428863\n",
      "Epoch: 195, batch: 174, loss: 0.6154688239097595\n",
      "Epoch: 195, batch: 224, loss: 0.6330484193563461\n",
      "Epoch: 195, batch: 274, loss: 0.6313260924816132\n",
      "Epoch: 195, batch: 324, loss: 0.6140065622329712\n",
      "Epoch: 195, batch: 374, loss: 0.6153651756048203\n",
      "Starting Epoch  196 ...\n",
      "Epoch: 196, batch: 49, loss: 0.6159312200546264\n",
      "Epoch: 196, batch: 99, loss: 0.6155695855617523\n",
      "Epoch: 196, batch: 149, loss: 0.6142070364952087\n",
      "Epoch: 196, batch: 199, loss: 0.6159426474571228\n",
      "Epoch: 196, batch: 249, loss: 0.6182963019609451\n",
      "Epoch: 196, batch: 299, loss: 0.6167602688074112\n",
      "Epoch: 196, batch: 349, loss: 0.6230300033092498\n",
      "Starting Epoch  197 ...\n",
      "Epoch: 197, batch: 24, loss: 0.6219869238138199\n",
      "Epoch: 197, batch: 74, loss: 0.6157340294122696\n",
      "Epoch: 197, batch: 124, loss: 0.622537996172905\n",
      "Epoch: 197, batch: 174, loss: 0.63302525639534\n",
      "Epoch: 197, batch: 224, loss: 0.62772795855999\n",
      "Epoch: 197, batch: 274, loss: 0.6147662514448166\n",
      "Epoch: 197, batch: 324, loss: 0.6137841767072678\n",
      "Epoch: 197, batch: 374, loss: 0.6137437510490418\n",
      "Starting Epoch  198 ...\n",
      "Epoch: 198, batch: 49, loss: 0.6311093425750732\n",
      "Epoch: 198, batch: 99, loss: 0.6310296273231506\n",
      "Epoch: 198, batch: 149, loss: 0.6238767039775849\n",
      "Epoch: 198, batch: 199, loss: 0.6273198467493057\n",
      "Epoch: 198, batch: 249, loss: 0.6157865262031555\n",
      "Epoch: 198, batch: 299, loss: 0.6151831662654876\n",
      "Epoch: 198, batch: 349, loss: 0.6194376432895661\n",
      "Starting Epoch  199 ...\n",
      "Epoch: 199, batch: 24, loss: 0.6160211032629013\n",
      "Epoch: 199, batch: 74, loss: 0.6193769139051437\n",
      "Epoch: 199, batch: 124, loss: 0.622633786201477\n",
      "Epoch: 199, batch: 174, loss: 0.6247948569059372\n",
      "Epoch: 199, batch: 224, loss: 0.621501760482788\n",
      "Epoch: 199, batch: 274, loss: 0.6133903497457505\n",
      "Epoch: 199, batch: 324, loss: 0.6313989746570587\n",
      "Epoch: 199, batch: 374, loss: 0.6517752587795258\n",
      "Starting Epoch  200 ...\n",
      "Epoch: 200, batch: 49, loss: 0.632556345462799\n",
      "Epoch: 200, batch: 99, loss: 0.6104130530357361\n",
      "Epoch: 200, batch: 149, loss: 0.6125482994318009\n",
      "Epoch: 200, batch: 199, loss: 0.6139632910490036\n",
      "Epoch: 200, batch: 249, loss: 0.6135580730438233\n",
      "Epoch: 200, batch: 299, loss: 0.6118206870555878\n",
      "Epoch: 200, batch: 349, loss: 0.6132231074571609\n",
      "Starting Epoch  201 ...\n",
      "Epoch: 201, batch: 24, loss: 0.6152617698907852\n",
      "Epoch: 201, batch: 74, loss: 0.6149339371919632\n",
      "Epoch: 201, batch: 124, loss: 0.615658990740776\n",
      "Epoch: 201, batch: 174, loss: 0.6390062630176544\n",
      "Epoch: 201, batch: 224, loss: 0.6389159113168716\n",
      "Epoch: 201, batch: 274, loss: 0.615622296333313\n",
      "Epoch: 201, batch: 324, loss: 0.6153219038248062\n",
      "Epoch: 201, batch: 374, loss: 0.6128800719976425\n",
      "Starting Epoch  202 ...\n",
      "Epoch: 202, batch: 49, loss: 0.6124539101123809\n",
      "Epoch: 202, batch: 99, loss: 0.6170454323291779\n",
      "Epoch: 202, batch: 149, loss: 0.6183259677886963\n",
      "Epoch: 202, batch: 199, loss: 0.6158132255077362\n",
      "Epoch: 202, batch: 249, loss: 0.6263766074180603\n",
      "Epoch: 202, batch: 299, loss: 0.6236948227882385\n",
      "Epoch: 202, batch: 349, loss: 0.6120111864805221\n",
      "Starting Epoch  203 ...\n",
      "Epoch: 203, batch: 24, loss: 0.6133552896976471\n",
      "Epoch: 203, batch: 74, loss: 0.6122034668922425\n",
      "Epoch: 203, batch: 124, loss: 0.6124028885364532\n",
      "Epoch: 203, batch: 174, loss: 0.6216528612375259\n",
      "Epoch: 203, batch: 224, loss: 0.6232912921905518\n",
      "Epoch: 203, batch: 274, loss: 0.6142194175720215\n",
      "Epoch: 203, batch: 324, loss: 0.6130171179771423\n",
      "Epoch: 203, batch: 374, loss: 0.6152739655971527\n",
      "Starting Epoch  204 ...\n",
      "Epoch: 204, batch: 49, loss: 0.6171365082263947\n",
      "Epoch: 204, batch: 99, loss: 0.6144876170158386\n",
      "Epoch: 204, batch: 149, loss: 0.612512337565422\n",
      "Epoch: 204, batch: 199, loss: 0.6250099802017212\n",
      "Epoch: 204, batch: 249, loss: 0.6248829209804535\n",
      "Epoch: 204, batch: 299, loss: 0.6162978053092957\n",
      "Epoch: 204, batch: 349, loss: 0.61457135617733\n",
      "Starting Epoch  205 ...\n",
      "Epoch: 205, batch: 24, loss: 0.6126695019006729\n",
      "Epoch: 205, batch: 74, loss: 0.612871196269989\n",
      "Epoch: 205, batch: 124, loss: 0.6109850180149078\n",
      "Epoch: 205, batch: 174, loss: 0.6295628988742829\n",
      "Epoch: 205, batch: 224, loss: 0.6346780002117157\n",
      "Epoch: 205, batch: 274, loss: 0.6156658071279526\n",
      "Epoch: 205, batch: 324, loss: 0.6097873455286026\n",
      "Epoch: 205, batch: 374, loss: 0.611475732922554\n",
      "Starting Epoch  206 ...\n",
      "Epoch: 206, batch: 49, loss: 0.6129867678880692\n",
      "Epoch: 206, batch: 99, loss: 0.6118748968839646\n",
      "Epoch: 206, batch: 149, loss: 0.6134838652610779\n",
      "Epoch: 206, batch: 199, loss: 0.6173482781648636\n",
      "Epoch: 206, batch: 249, loss: 0.6149067431688309\n",
      "Epoch: 206, batch: 299, loss: 0.6111855775117874\n",
      "Epoch: 206, batch: 349, loss: 0.6129650032520294\n",
      "Starting Epoch  207 ...\n",
      "Epoch: 207, batch: 24, loss: 0.6128349053859711\n",
      "Epoch: 207, batch: 74, loss: 0.6108218449354171\n",
      "Epoch: 207, batch: 124, loss: 0.6110379791259766\n",
      "Epoch: 207, batch: 174, loss: 0.6111888086795807\n",
      "Epoch: 207, batch: 224, loss: 0.6119908791780472\n",
      "Epoch: 207, batch: 274, loss: 0.6107575738430023\n",
      "Epoch: 207, batch: 324, loss: 0.6116379934549332\n",
      "Epoch: 207, batch: 374, loss: 0.6137395542860031\n",
      "Starting Epoch  208 ...\n",
      "Epoch: 208, batch: 49, loss: 0.6204778683185578\n",
      "Epoch: 208, batch: 99, loss: 0.6197724843025207\n",
      "Epoch: 208, batch: 149, loss: 0.6179363310337067\n",
      "Epoch: 208, batch: 199, loss: 0.6215267038345337\n",
      "Epoch: 208, batch: 249, loss: 0.6138088822364807\n",
      "Epoch: 208, batch: 299, loss: 0.610786252617836\n",
      "Epoch: 208, batch: 349, loss: 0.6172636193037033\n",
      "Starting Epoch  209 ...\n",
      "Epoch: 209, batch: 24, loss: 0.6353712540864944\n",
      "Epoch: 209, batch: 74, loss: 0.6305904293060303\n",
      "Epoch: 209, batch: 124, loss: 0.6121558386087418\n",
      "Epoch: 209, batch: 174, loss: 0.6101456445455551\n",
      "Epoch: 209, batch: 224, loss: 0.6087706351280212\n",
      "Epoch: 209, batch: 274, loss: 0.6083755028247834\n",
      "Epoch: 209, batch: 324, loss: 0.6085771715641022\n",
      "Epoch: 209, batch: 374, loss: 0.6091771757602692\n",
      "Starting Epoch  210 ...\n",
      "Epoch: 210, batch: 49, loss: 0.6097232079505921\n",
      "Epoch: 210, batch: 99, loss: 0.612828523516655\n",
      "Epoch: 210, batch: 149, loss: 0.6128996980190277\n",
      "Epoch: 210, batch: 199, loss: 0.6125793474912643\n",
      "Epoch: 210, batch: 249, loss: 0.6132758194208145\n",
      "Epoch: 210, batch: 299, loss: 0.6106859427690506\n",
      "Epoch: 210, batch: 349, loss: 0.618806638121605\n",
      "Starting Epoch  211 ...\n",
      "Epoch: 211, batch: 24, loss: 0.6200929790735245\n",
      "Epoch: 211, batch: 74, loss: 0.6140193778276444\n",
      "Epoch: 211, batch: 124, loss: 0.6130374670028687\n",
      "Epoch: 211, batch: 174, loss: 0.6085073107481003\n",
      "Epoch: 211, batch: 224, loss: 0.6160235154628754\n",
      "Epoch: 211, batch: 274, loss: 0.6201561391353607\n",
      "Epoch: 211, batch: 324, loss: 0.6114796608686447\n",
      "Epoch: 211, batch: 374, loss: 0.6082889020442963\n",
      "Starting Epoch  212 ...\n",
      "Epoch: 212, batch: 49, loss: 0.6111094242334366\n",
      "Epoch: 212, batch: 99, loss: 0.6130054998397827\n",
      "Epoch: 212, batch: 149, loss: 0.6154373735189438\n",
      "Epoch: 212, batch: 199, loss: 0.6132684856653213\n",
      "Epoch: 212, batch: 249, loss: 0.6081321454048156\n",
      "Epoch: 212, batch: 299, loss: 0.6152488559484481\n",
      "Epoch: 212, batch: 349, loss: 0.615589548945427\n",
      "Starting Epoch  213 ...\n",
      "Epoch: 213, batch: 24, loss: 0.6087442207336425\n",
      "Epoch: 213, batch: 74, loss: 0.6109860730171204\n",
      "Epoch: 213, batch: 124, loss: 0.6114482742547989\n",
      "Epoch: 213, batch: 174, loss: 0.610805617570877\n",
      "Epoch: 213, batch: 224, loss: 0.6094683700799942\n",
      "Epoch: 213, batch: 274, loss: 0.6085546189546585\n",
      "Epoch: 213, batch: 324, loss: 0.608837702870369\n",
      "Epoch: 213, batch: 374, loss: 0.6080223613977432\n",
      "Starting Epoch  214 ...\n",
      "Epoch: 214, batch: 49, loss: 0.6083549267053604\n",
      "Epoch: 214, batch: 99, loss: 0.6238027364015579\n",
      "Epoch: 214, batch: 149, loss: 0.6245488411188126\n",
      "Epoch: 214, batch: 199, loss: 0.609662259221077\n",
      "Epoch: 214, batch: 249, loss: 0.6101521480083466\n",
      "Epoch: 214, batch: 299, loss: 0.6104722267389298\n",
      "Epoch: 214, batch: 349, loss: 0.6083199107646942\n",
      "Starting Epoch  215 ...\n",
      "Epoch: 215, batch: 24, loss: 0.6079858231544495\n",
      "Epoch: 215, batch: 74, loss: 0.608895355463028\n",
      "Epoch: 215, batch: 124, loss: 0.6089861112833023\n",
      "Epoch: 215, batch: 174, loss: 0.6090442335605621\n",
      "Epoch: 215, batch: 224, loss: 0.6159877377748489\n",
      "Epoch: 215, batch: 274, loss: 0.6151432174444199\n",
      "Epoch: 215, batch: 324, loss: 0.6091529715061188\n",
      "Epoch: 215, batch: 374, loss: 0.609038587808609\n",
      "Starting Epoch  216 ...\n",
      "Epoch: 216, batch: 49, loss: 0.6071382820606231\n",
      "Epoch: 216, batch: 99, loss: 0.6079492914676666\n",
      "Epoch: 216, batch: 149, loss: 0.6076753288507462\n",
      "Epoch: 216, batch: 199, loss: 0.6131488651037216\n",
      "Epoch: 216, batch: 249, loss: 0.6186935359239578\n",
      "Epoch: 216, batch: 299, loss: 0.6139012098312377\n",
      "Epoch: 216, batch: 349, loss: 0.6098041194677353\n",
      "Starting Epoch  217 ...\n",
      "Epoch: 217, batch: 24, loss: 0.6082076603174209\n",
      "Epoch: 217, batch: 74, loss: 0.6057846796512604\n",
      "Epoch: 217, batch: 124, loss: 0.6384844726324082\n",
      "Epoch: 217, batch: 174, loss: 0.6462257671356201\n",
      "Epoch: 217, batch: 224, loss: 0.6127010786533356\n",
      "Epoch: 217, batch: 274, loss: 0.6051112014055252\n",
      "Epoch: 217, batch: 324, loss: 0.6057743483781814\n",
      "Epoch: 217, batch: 374, loss: 0.6077589207887649\n",
      "Starting Epoch  218 ...\n",
      "Epoch: 218, batch: 49, loss: 0.6084847462177276\n",
      "Epoch: 218, batch: 99, loss: 0.6073757642507553\n",
      "Epoch: 218, batch: 149, loss: 0.6177049630880356\n",
      "Epoch: 218, batch: 199, loss: 0.6185484999418258\n",
      "Epoch: 218, batch: 249, loss: 0.6119391387701034\n",
      "Epoch: 218, batch: 299, loss: 0.6277840721607209\n",
      "Epoch: 218, batch: 349, loss: 0.6231223332881928\n",
      "Starting Epoch  219 ...\n",
      "Epoch: 219, batch: 24, loss: 0.6074871623516083\n",
      "Epoch: 219, batch: 74, loss: 0.6104219222068786\n",
      "Epoch: 219, batch: 124, loss: 0.6092702805995941\n",
      "Epoch: 219, batch: 174, loss: 0.6154234182834625\n",
      "Epoch: 219, batch: 224, loss: 0.6158961689472199\n",
      "Epoch: 219, batch: 274, loss: 0.6063425332307816\n",
      "Epoch: 219, batch: 324, loss: 0.606153039932251\n",
      "Epoch: 219, batch: 374, loss: 0.605781689286232\n",
      "Starting Epoch  220 ...\n",
      "Epoch: 220, batch: 49, loss: 0.6039173287153244\n",
      "Epoch: 220, batch: 99, loss: 0.6057859808206558\n",
      "Epoch: 220, batch: 149, loss: 0.6072922605276108\n",
      "Epoch: 220, batch: 199, loss: 0.6429954105615616\n",
      "Epoch: 220, batch: 249, loss: 0.6440423035621643\n",
      "Epoch: 220, batch: 299, loss: 0.6071497035026551\n",
      "Epoch: 220, batch: 349, loss: 0.6206653308868408\n",
      "Starting Epoch  221 ...\n",
      "Epoch: 221, batch: 24, loss: 0.6208671617507935\n",
      "Epoch: 221, batch: 74, loss: 0.6081150501966477\n",
      "Epoch: 221, batch: 124, loss: 0.6073328089714051\n",
      "Epoch: 221, batch: 174, loss: 0.609017259478569\n",
      "Epoch: 221, batch: 224, loss: 0.6396475601196289\n",
      "Epoch: 221, batch: 274, loss: 0.6379368925094604\n",
      "Epoch: 221, batch: 324, loss: 0.6095891618728637\n",
      "Epoch: 221, batch: 374, loss: 0.606127063035965\n",
      "Starting Epoch  222 ...\n",
      "Epoch: 222, batch: 49, loss: 0.6039514493942261\n",
      "Epoch: 222, batch: 99, loss: 0.6064315491914749\n",
      "Epoch: 222, batch: 149, loss: 0.6073413789272308\n",
      "Epoch: 222, batch: 199, loss: 0.6057421910762787\n",
      "Epoch: 222, batch: 249, loss: 0.605582132935524\n",
      "Epoch: 222, batch: 299, loss: 0.6089980363845825\n",
      "Epoch: 222, batch: 349, loss: 0.6089078634977341\n",
      "Starting Epoch  223 ...\n",
      "Epoch: 223, batch: 24, loss: 0.6109644132852554\n",
      "Epoch: 223, batch: 74, loss: 0.6114417719841003\n",
      "Epoch: 223, batch: 124, loss: 0.6111862117052078\n",
      "Epoch: 223, batch: 174, loss: 0.6104182362556457\n",
      "Epoch: 223, batch: 224, loss: 0.6471518403291703\n",
      "Epoch: 223, batch: 274, loss: 0.6502842807769775\n",
      "Epoch: 223, batch: 324, loss: 0.610164697766304\n",
      "Epoch: 223, batch: 374, loss: 0.6151713109016419\n",
      "Starting Epoch  224 ...\n",
      "Epoch: 224, batch: 49, loss: 0.6129590696096421\n",
      "Epoch: 224, batch: 99, loss: 0.6038350600004196\n",
      "Epoch: 224, batch: 149, loss: 0.6041808408498764\n",
      "Epoch: 224, batch: 199, loss: 0.6048382037878036\n",
      "Epoch: 224, batch: 249, loss: 0.6049302196502686\n",
      "Epoch: 224, batch: 299, loss: 0.604317171573639\n",
      "Epoch: 224, batch: 349, loss: 0.6075495040416717\n",
      "Starting Epoch  225 ...\n",
      "Epoch: 225, batch: 24, loss: 0.6123827612400055\n",
      "Epoch: 225, batch: 74, loss: 0.6095139557123184\n",
      "Epoch: 225, batch: 124, loss: 0.605210794210434\n",
      "Epoch: 225, batch: 174, loss: 0.6046341937780381\n",
      "Epoch: 225, batch: 224, loss: 0.6114478766918182\n",
      "Epoch: 225, batch: 274, loss: 0.6117906367778778\n",
      "Epoch: 225, batch: 324, loss: 0.6040685993432998\n",
      "Epoch: 225, batch: 374, loss: 0.6150745195150376\n",
      "Starting Epoch  226 ...\n",
      "Epoch: 226, batch: 49, loss: 0.6172359025478363\n",
      "Epoch: 226, batch: 99, loss: 0.610496141910553\n",
      "Epoch: 226, batch: 149, loss: 0.6092104011774063\n",
      "Epoch: 226, batch: 199, loss: 0.6154580235481262\n",
      "Epoch: 226, batch: 249, loss: 0.6137136298418046\n",
      "Epoch: 226, batch: 299, loss: 0.6083839809894562\n",
      "Epoch: 226, batch: 349, loss: 0.6097935217618943\n",
      "Starting Epoch  227 ...\n",
      "Epoch: 227, batch: 24, loss: 0.6071750622987747\n",
      "Epoch: 227, batch: 74, loss: 0.6075869697332382\n",
      "Epoch: 227, batch: 124, loss: 0.604657536149025\n",
      "Epoch: 227, batch: 174, loss: 0.6044555288553238\n",
      "Epoch: 227, batch: 224, loss: 0.6050497269630433\n",
      "Epoch: 227, batch: 274, loss: 0.6058083939552307\n",
      "Epoch: 227, batch: 324, loss: 0.6046441143751144\n",
      "Epoch: 227, batch: 374, loss: 0.6074706888198853\n",
      "Starting Epoch  228 ...\n",
      "Epoch: 228, batch: 49, loss: 0.6174472522735596\n",
      "Epoch: 228, batch: 99, loss: 0.6118751263618469\n",
      "Epoch: 228, batch: 149, loss: 0.6029683619737625\n",
      "Epoch: 228, batch: 199, loss: 0.6052539360523224\n",
      "Epoch: 228, batch: 249, loss: 0.6088733637332916\n",
      "Epoch: 228, batch: 299, loss: 0.6087171816825867\n",
      "Epoch: 228, batch: 349, loss: 0.6074363243579864\n",
      "Starting Epoch  229 ...\n",
      "Epoch: 229, batch: 24, loss: 0.6079172760248184\n",
      "Epoch: 229, batch: 74, loss: 0.6060993379354477\n",
      "Epoch: 229, batch: 124, loss: 0.6054739797115326\n",
      "Epoch: 229, batch: 174, loss: 0.6038561791181565\n",
      "Epoch: 229, batch: 224, loss: 0.6385224294662476\n",
      "Epoch: 229, batch: 274, loss: 0.6401174712181091\n",
      "Epoch: 229, batch: 324, loss: 0.6033823096752167\n",
      "Epoch: 229, batch: 374, loss: 0.6033405095338822\n",
      "Starting Epoch  230 ...\n",
      "Epoch: 230, batch: 49, loss: 0.6051076620817184\n",
      "Epoch: 230, batch: 99, loss: 0.6087023061513901\n",
      "Epoch: 230, batch: 149, loss: 0.6119105088710785\n",
      "Epoch: 230, batch: 199, loss: 0.6086515551805496\n",
      "Epoch: 230, batch: 249, loss: 0.6058959341049195\n",
      "Epoch: 230, batch: 299, loss: 0.6046699655055999\n",
      "Epoch: 230, batch: 349, loss: 0.6029152429103851\n",
      "Starting Epoch  231 ...\n",
      "Epoch: 231, batch: 24, loss: 0.6022782188653946\n",
      "Epoch: 231, batch: 74, loss: 0.6044911289215088\n",
      "Epoch: 231, batch: 124, loss: 0.6053568398952485\n",
      "Epoch: 231, batch: 174, loss: 0.6036658531427384\n",
      "Epoch: 231, batch: 224, loss: 0.6031671822071075\n",
      "Epoch: 231, batch: 274, loss: 0.6028353762626648\n",
      "Epoch: 231, batch: 324, loss: 0.632056006193161\n",
      "Epoch: 231, batch: 374, loss: 0.6328923267126083\n",
      "Starting Epoch  232 ...\n",
      "Epoch: 232, batch: 49, loss: 0.6017327040433884\n",
      "Epoch: 232, batch: 99, loss: 0.6013856905698777\n",
      "Epoch: 232, batch: 149, loss: 0.60192378282547\n",
      "Epoch: 232, batch: 199, loss: 0.6028945600986481\n",
      "Epoch: 232, batch: 249, loss: 0.6035027879476548\n",
      "Epoch: 232, batch: 299, loss: 0.6175531041622162\n",
      "Epoch: 232, batch: 349, loss: 0.6236103624105453\n",
      "Starting Epoch  233 ...\n",
      "Epoch: 233, batch: 24, loss: 0.6091655957698822\n",
      "Epoch: 233, batch: 74, loss: 0.6028267753124237\n",
      "Epoch: 233, batch: 124, loss: 0.6038356405496598\n",
      "Epoch: 233, batch: 174, loss: 0.6095366805791855\n",
      "Epoch: 233, batch: 224, loss: 0.6101534879207611\n",
      "Epoch: 233, batch: 274, loss: 0.6043990302085877\n",
      "Epoch: 233, batch: 324, loss: 0.6028311002254486\n",
      "Epoch: 233, batch: 374, loss: 0.6027143406867981\n",
      "Starting Epoch  234 ...\n",
      "Epoch: 234, batch: 49, loss: 0.6013457578420639\n",
      "Epoch: 234, batch: 99, loss: 0.6013069188594818\n",
      "Epoch: 234, batch: 149, loss: 0.6314348363876343\n",
      "Epoch: 234, batch: 199, loss: 0.6341556227207183\n",
      "Epoch: 234, batch: 249, loss: 0.6543835651874542\n",
      "Epoch: 234, batch: 299, loss: 0.6581193166971206\n",
      "Epoch: 234, batch: 349, loss: 0.6075133657455445\n",
      "Starting Epoch  235 ...\n",
      "Epoch: 235, batch: 24, loss: 0.610241419672966\n",
      "Epoch: 235, batch: 74, loss: 0.6110199236869812\n",
      "Epoch: 235, batch: 124, loss: 0.6015033882856369\n",
      "Epoch: 235, batch: 174, loss: 0.6012265282869339\n",
      "Epoch: 235, batch: 224, loss: 0.6042928558588028\n",
      "Epoch: 235, batch: 274, loss: 0.6044471925497055\n",
      "Epoch: 235, batch: 324, loss: 0.6016562128067017\n",
      "Epoch: 235, batch: 374, loss: 0.6060583251714706\n",
      "Starting Epoch  236 ...\n",
      "Epoch: 236, batch: 49, loss: 0.6352421319484711\n",
      "Epoch: 236, batch: 99, loss: 0.632646296620369\n",
      "Epoch: 236, batch: 149, loss: 0.6033679473400116\n",
      "Epoch: 236, batch: 199, loss: 0.6093505471944809\n",
      "Epoch: 236, batch: 249, loss: 0.6088587152957916\n",
      "Epoch: 236, batch: 299, loss: 0.6009563511610031\n",
      "Epoch: 236, batch: 349, loss: 0.6009246569871902\n",
      "Starting Epoch  237 ...\n",
      "Epoch: 237, batch: 24, loss: 0.6008101058006287\n",
      "Epoch: 237, batch: 74, loss: 0.6009383976459504\n",
      "Epoch: 237, batch: 124, loss: 0.6004685533046722\n",
      "Epoch: 237, batch: 174, loss: 0.6005465018749238\n",
      "Epoch: 237, batch: 224, loss: 0.6292112368345261\n",
      "Epoch: 237, batch: 274, loss: 0.629905972480774\n",
      "Epoch: 237, batch: 324, loss: 0.6021223998069763\n",
      "Epoch: 237, batch: 374, loss: 0.603066799044609\n",
      "Starting Epoch  238 ...\n",
      "Epoch: 238, batch: 49, loss: 0.6022917765378952\n",
      "Epoch: 238, batch: 99, loss: 0.6011753112077713\n",
      "Epoch: 238, batch: 149, loss: 0.601730432510376\n",
      "Epoch: 238, batch: 199, loss: 0.6026769685745239\n",
      "Epoch: 238, batch: 249, loss: 0.6018425416946411\n",
      "Epoch: 238, batch: 299, loss: 0.6006749182939529\n",
      "Epoch: 238, batch: 349, loss: 0.5995358526706696\n",
      "Starting Epoch  239 ...\n",
      "Epoch: 239, batch: 24, loss: 0.5997319740056991\n",
      "Epoch: 239, batch: 74, loss: 0.6021215397119523\n",
      "Epoch: 239, batch: 124, loss: 0.6176287287473679\n",
      "Epoch: 239, batch: 174, loss: 0.6165191423892975\n",
      "Epoch: 239, batch: 224, loss: 0.5998795169591904\n",
      "Epoch: 239, batch: 274, loss: 0.6011532598733902\n",
      "Epoch: 239, batch: 324, loss: 0.6099876374006271\n",
      "Epoch: 239, batch: 374, loss: 0.6081763744354248\n",
      "Starting Epoch  240 ...\n",
      "Epoch: 240, batch: 49, loss: 0.6027535063028335\n",
      "Epoch: 240, batch: 99, loss: 0.6030592978000641\n",
      "Epoch: 240, batch: 149, loss: 0.5993565207719803\n",
      "Epoch: 240, batch: 199, loss: 0.6058199059963226\n",
      "Epoch: 240, batch: 249, loss: 0.6083179074525833\n",
      "Epoch: 240, batch: 299, loss: 0.6010518223047256\n",
      "Epoch: 240, batch: 349, loss: 0.6350784957408905\n",
      "Starting Epoch  241 ...\n",
      "Epoch: 241, batch: 24, loss: 0.6392969757318496\n",
      "Epoch: 241, batch: 74, loss: 0.6032431012392044\n",
      "Epoch: 241, batch: 124, loss: 0.6003630322217941\n",
      "Epoch: 241, batch: 174, loss: 0.6015193039178848\n",
      "Epoch: 241, batch: 224, loss: 0.6055390626192093\n",
      "Epoch: 241, batch: 274, loss: 0.6046492409706116\n",
      "Epoch: 241, batch: 324, loss: 0.6089217460155487\n",
      "Epoch: 241, batch: 374, loss: 0.6078089010715485\n",
      "Starting Epoch  242 ...\n",
      "Epoch: 242, batch: 49, loss: 0.5998244720697403\n",
      "Epoch: 242, batch: 99, loss: 0.6002547782659531\n",
      "Epoch: 242, batch: 149, loss: 0.600613563656807\n",
      "Epoch: 242, batch: 199, loss: 0.6015701651573181\n",
      "Epoch: 242, batch: 249, loss: 0.5988387036323547\n",
      "Epoch: 242, batch: 299, loss: 0.6271281045675278\n",
      "Epoch: 242, batch: 349, loss: 0.6290556144714355\n",
      "Starting Epoch  243 ...\n",
      "Epoch: 243, batch: 24, loss: 0.6001617735624314\n",
      "Epoch: 243, batch: 74, loss: 0.6004817628860474\n",
      "Epoch: 243, batch: 124, loss: 0.5996278357505799\n",
      "Epoch: 243, batch: 174, loss: 0.5980469900369644\n",
      "Epoch: 243, batch: 224, loss: 0.5983835929632186\n",
      "Epoch: 243, batch: 274, loss: 0.5975431138277054\n",
      "Epoch: 243, batch: 324, loss: 0.601319095492363\n",
      "Epoch: 243, batch: 374, loss: 0.6102281701564789\n",
      "Starting Epoch  244 ...\n",
      "Epoch: 244, batch: 49, loss: 0.6067750895023346\n",
      "Epoch: 244, batch: 99, loss: 0.6018442511558533\n",
      "Epoch: 244, batch: 149, loss: 0.6024606025218964\n",
      "Epoch: 244, batch: 199, loss: 0.6000542747974396\n",
      "Epoch: 244, batch: 249, loss: 0.5998661649227143\n",
      "Epoch: 244, batch: 299, loss: 0.5991978037357331\n",
      "Epoch: 244, batch: 349, loss: 0.5994563561677932\n",
      "Starting Epoch  245 ...\n",
      "Epoch: 245, batch: 24, loss: 0.6082872384786606\n",
      "Epoch: 245, batch: 74, loss: 0.6091576534509658\n",
      "Epoch: 245, batch: 124, loss: 0.6017092293500901\n",
      "Epoch: 245, batch: 174, loss: 0.6009197968244553\n",
      "Epoch: 245, batch: 224, loss: 0.5989103728532791\n",
      "Epoch: 245, batch: 274, loss: 0.5977962249517441\n",
      "Epoch: 245, batch: 324, loss: 0.5989482194185257\n",
      "Epoch: 245, batch: 374, loss: 0.6002494752407074\n",
      "Starting Epoch  246 ...\n",
      "Epoch: 246, batch: 49, loss: 0.6074251246452331\n",
      "Epoch: 246, batch: 99, loss: 0.60551209628582\n",
      "Epoch: 246, batch: 149, loss: 0.5976054543256759\n",
      "Epoch: 246, batch: 199, loss: 0.5977849298715592\n",
      "Epoch: 246, batch: 249, loss: 0.5986001795530319\n",
      "Epoch: 246, batch: 299, loss: 0.5991506767272949\n",
      "Epoch: 246, batch: 349, loss: 0.6036452770233154\n",
      "Starting Epoch  247 ...\n",
      "Epoch: 247, batch: 24, loss: 0.6041616386175156\n",
      "Epoch: 247, batch: 74, loss: 0.6083152794837952\n",
      "Epoch: 247, batch: 124, loss: 0.6174024647474289\n",
      "Epoch: 247, batch: 174, loss: 0.6077756369113922\n",
      "Epoch: 247, batch: 224, loss: 0.6044035577774047\n",
      "Epoch: 247, batch: 274, loss: 0.604599984884262\n",
      "Epoch: 247, batch: 324, loss: 0.6139306557178498\n",
      "Epoch: 247, batch: 374, loss: 0.61453100502491\n",
      "Starting Epoch  248 ...\n",
      "Epoch: 248, batch: 49, loss: 0.598704708814621\n",
      "Epoch: 248, batch: 99, loss: 0.5976535391807556\n",
      "Epoch: 248, batch: 149, loss: 0.5977140551805497\n",
      "Epoch: 248, batch: 199, loss: 0.5996142637729645\n",
      "Epoch: 248, batch: 249, loss: 0.5996148943901062\n",
      "Epoch: 248, batch: 299, loss: 0.5989136081933976\n",
      "Epoch: 248, batch: 349, loss: 0.5993226319551468\n",
      "Starting Epoch  249 ...\n",
      "Epoch: 249, batch: 24, loss: 0.6134438610076904\n",
      "Epoch: 249, batch: 74, loss: 0.6150336271524429\n",
      "Epoch: 249, batch: 124, loss: 0.6004635500907898\n",
      "Epoch: 249, batch: 174, loss: 0.5990693217515946\n",
      "Epoch: 249, batch: 224, loss: 0.600233970284462\n",
      "Epoch: 249, batch: 274, loss: 0.5990853762626648\n",
      "Epoch: 249, batch: 324, loss: 0.5974845778942108\n",
      "Epoch: 249, batch: 374, loss: 0.6037656855583191\n",
      "Starting Epoch  250 ...\n",
      "Epoch: 250, batch: 49, loss: 0.6219817453622818\n",
      "Epoch: 250, batch: 99, loss: 0.6227979141473771\n",
      "Epoch: 250, batch: 149, loss: 0.6034774434566498\n",
      "Epoch: 250, batch: 199, loss: 0.5961123186349869\n",
      "Epoch: 250, batch: 249, loss: 0.5956969410181046\n",
      "Epoch: 250, batch: 299, loss: 0.5980741328001022\n",
      "Epoch: 250, batch: 349, loss: 0.5992566967010498\n",
      "Starting Epoch  251 ...\n",
      "Epoch: 251, batch: 24, loss: 0.6077253890037536\n",
      "Epoch: 251, batch: 74, loss: 0.6077542281150818\n",
      "Epoch: 251, batch: 124, loss: 0.5972763419151306\n",
      "Epoch: 251, batch: 174, loss: 0.59799606859684\n",
      "Epoch: 251, batch: 224, loss: 0.6049883854389191\n",
      "Epoch: 251, batch: 274, loss: 0.6032940715551376\n",
      "Epoch: 251, batch: 324, loss: 0.5965590947866439\n",
      "Epoch: 251, batch: 374, loss: 0.5968252819776535\n",
      "Starting Epoch  252 ...\n",
      "Epoch: 252, batch: 49, loss: 0.5961830687522888\n",
      "Epoch: 252, batch: 99, loss: 0.5974161148071289\n",
      "Epoch: 252, batch: 149, loss: 0.5973541498184204\n",
      "Epoch: 252, batch: 199, loss: 0.6359168636798859\n",
      "Epoch: 252, batch: 249, loss: 0.6361442905664444\n",
      "Epoch: 252, batch: 299, loss: 0.5972639387845993\n",
      "Epoch: 252, batch: 349, loss: 0.5966343295574188\n",
      "Starting Epoch  253 ...\n",
      "Epoch: 253, batch: 24, loss: 0.5945933020114899\n",
      "Epoch: 253, batch: 74, loss: 0.5951724523305892\n",
      "Epoch: 253, batch: 124, loss: 0.6014052283763885\n",
      "Epoch: 253, batch: 174, loss: 0.601769455075264\n",
      "Epoch: 253, batch: 224, loss: 0.5966565388441086\n",
      "Epoch: 253, batch: 274, loss: 0.5988539212942123\n",
      "Epoch: 253, batch: 324, loss: 0.606031329035759\n",
      "Epoch: 253, batch: 374, loss: 0.6056870281696319\n",
      "Starting Epoch  254 ...\n",
      "Epoch: 254, batch: 49, loss: 0.5983257776498795\n",
      "Epoch: 254, batch: 99, loss: 0.5957105559110641\n",
      "Epoch: 254, batch: 149, loss: 0.5961959785223008\n",
      "Epoch: 254, batch: 199, loss: 0.5970373487472534\n",
      "Epoch: 254, batch: 249, loss: 0.6048325055837631\n",
      "Epoch: 254, batch: 299, loss: 0.6030002158880233\n",
      "Epoch: 254, batch: 349, loss: 0.5951397860050202\n",
      "Starting Epoch  255 ...\n",
      "Epoch: 255, batch: 24, loss: 0.5964510369300843\n",
      "Epoch: 255, batch: 74, loss: 0.5994982326030731\n",
      "Epoch: 255, batch: 124, loss: 0.603129021525383\n",
      "Epoch: 255, batch: 174, loss: 0.598923745751381\n",
      "Epoch: 255, batch: 224, loss: 0.5958693832159042\n",
      "Epoch: 255, batch: 274, loss: 0.5973966574668884\n",
      "Epoch: 255, batch: 324, loss: 0.5963976180553436\n",
      "Epoch: 255, batch: 374, loss: 0.5968477106094361\n",
      "Starting Epoch  256 ...\n",
      "Epoch: 256, batch: 49, loss: 0.5993957418203354\n",
      "Epoch: 256, batch: 99, loss: 0.6041553491353988\n",
      "Epoch: 256, batch: 149, loss: 0.606354877948761\n",
      "Epoch: 256, batch: 199, loss: 0.603959037065506\n",
      "Epoch: 256, batch: 249, loss: 0.5995634728670121\n",
      "Epoch: 256, batch: 299, loss: 0.5960317158699036\n",
      "Epoch: 256, batch: 349, loss: 0.5953286689519882\n",
      "Starting Epoch  257 ...\n",
      "Epoch: 257, batch: 24, loss: 0.5945397943258286\n",
      "Epoch: 257, batch: 74, loss: 0.595333948135376\n",
      "Epoch: 257, batch: 124, loss: 0.5993233215808869\n",
      "Epoch: 257, batch: 174, loss: 0.6075274133682251\n",
      "Epoch: 257, batch: 224, loss: 0.6127713972330093\n",
      "Epoch: 257, batch: 274, loss: 0.6031307566165924\n",
      "Epoch: 257, batch: 324, loss: 0.5940774524211884\n",
      "Epoch: 257, batch: 374, loss: 0.594672964811325\n",
      "Starting Epoch  258 ...\n",
      "Epoch: 258, batch: 49, loss: 0.5956521731615066\n",
      "Epoch: 258, batch: 99, loss: 0.6551112157106399\n",
      "Epoch: 258, batch: 149, loss: 0.6562653791904449\n",
      "Epoch: 258, batch: 199, loss: 0.6013316172361374\n",
      "Epoch: 258, batch: 249, loss: 0.6012201631069183\n",
      "Epoch: 258, batch: 299, loss: 0.5966593897342682\n",
      "Epoch: 258, batch: 349, loss: 0.5976274609565735\n",
      "Starting Epoch  259 ...\n",
      "Epoch: 259, batch: 24, loss: 0.6010933071374893\n",
      "Epoch: 259, batch: 74, loss: 0.6036567759513854\n",
      "Epoch: 259, batch: 124, loss: 0.5995526492595673\n",
      "Epoch: 259, batch: 174, loss: 0.5939767527580261\n",
      "Epoch: 259, batch: 224, loss: 0.5997318387031555\n",
      "Epoch: 259, batch: 274, loss: 0.6093551504611969\n",
      "Epoch: 259, batch: 324, loss: 0.6035549187660217\n",
      "Epoch: 259, batch: 374, loss: 0.5941752254962921\n",
      "Starting Epoch  260 ...\n",
      "Epoch: 260, batch: 49, loss: 0.5945466047525406\n",
      "Epoch: 260, batch: 99, loss: 0.5958464688062668\n",
      "Epoch: 260, batch: 149, loss: 0.5950748002529145\n",
      "Epoch: 260, batch: 199, loss: 0.59776247382164\n",
      "Epoch: 260, batch: 249, loss: 0.6087221491336823\n",
      "Epoch: 260, batch: 299, loss: 0.6030272388458252\n",
      "Epoch: 260, batch: 349, loss: 0.5929283213615417\n",
      "Starting Epoch  261 ...\n",
      "Epoch: 261, batch: 24, loss: 0.5940545606613159\n",
      "Epoch: 261, batch: 74, loss: 0.5942238748073578\n",
      "Epoch: 261, batch: 124, loss: 0.5998901849985123\n",
      "Epoch: 261, batch: 174, loss: 0.6116019159555435\n",
      "Epoch: 261, batch: 224, loss: 0.6065699714422226\n",
      "Epoch: 261, batch: 274, loss: 0.5950821810960769\n",
      "Epoch: 261, batch: 324, loss: 0.594654587507248\n",
      "Epoch: 261, batch: 374, loss: 0.6016621202230453\n",
      "Starting Epoch  262 ...\n",
      "Epoch: 262, batch: 49, loss: 0.6014875519275665\n",
      "Epoch: 262, batch: 99, loss: 0.5927515286207199\n",
      "Epoch: 262, batch: 149, loss: 0.5946972680091858\n",
      "Epoch: 262, batch: 199, loss: 0.598720018863678\n",
      "Epoch: 262, batch: 249, loss: 0.597241250872612\n",
      "Epoch: 262, batch: 299, loss: 0.6002467530965805\n",
      "Epoch: 262, batch: 349, loss: 0.6003034126758575\n",
      "Starting Epoch  263 ...\n",
      "Epoch: 263, batch: 24, loss: 0.5948114889860153\n",
      "Epoch: 263, batch: 74, loss: 0.5978853726387023\n",
      "Epoch: 263, batch: 124, loss: 0.6060161972045899\n",
      "Epoch: 263, batch: 174, loss: 0.6013444030284881\n",
      "Epoch: 263, batch: 224, loss: 0.5921914792060852\n",
      "Epoch: 263, batch: 274, loss: 0.5940510147809982\n",
      "Epoch: 263, batch: 324, loss: 0.5949601191282272\n",
      "Epoch: 263, batch: 374, loss: 0.5938170248270035\n",
      "Starting Epoch  264 ...\n",
      "Epoch: 264, batch: 49, loss: 0.6005399411916733\n",
      "Epoch: 264, batch: 99, loss: 0.6014927971363068\n",
      "Epoch: 264, batch: 149, loss: 0.5941177248954773\n",
      "Epoch: 264, batch: 199, loss: 0.5934828335046768\n",
      "Epoch: 264, batch: 249, loss: 0.5935918247699737\n",
      "Epoch: 264, batch: 299, loss: 0.6077268278598785\n",
      "Epoch: 264, batch: 349, loss: 0.615122742652893\n",
      "Starting Epoch  265 ...\n",
      "Epoch: 265, batch: 24, loss: 0.6008696734905243\n",
      "Epoch: 265, batch: 74, loss: 0.5932382601499557\n",
      "Epoch: 265, batch: 124, loss: 0.5939298820495605\n",
      "Epoch: 265, batch: 174, loss: 0.5939322608709335\n",
      "Epoch: 265, batch: 224, loss: 0.5929122960567474\n",
      "Epoch: 265, batch: 274, loss: 0.5924750208854676\n",
      "Epoch: 265, batch: 324, loss: 0.5927261644601822\n",
      "Epoch: 265, batch: 374, loss: 0.5933884227275849\n",
      "Starting Epoch  266 ...\n",
      "Epoch: 266, batch: 49, loss: 0.5939215844869614\n",
      "Epoch: 266, batch: 99, loss: 0.6124407649040222\n",
      "Epoch: 266, batch: 149, loss: 0.6111597681045532\n",
      "Epoch: 266, batch: 199, loss: 0.5922364842891693\n",
      "Epoch: 266, batch: 249, loss: 0.5926988559961319\n",
      "Epoch: 266, batch: 299, loss: 0.5945113569498062\n",
      "Epoch: 266, batch: 349, loss: 0.5935573774576187\n",
      "Starting Epoch  267 ...\n",
      "Epoch: 267, batch: 24, loss: 0.59202712059021\n",
      "Epoch: 267, batch: 74, loss: 0.5958448904752731\n",
      "Epoch: 267, batch: 124, loss: 0.596114667057991\n",
      "Epoch: 267, batch: 174, loss: 0.5964285784959793\n",
      "Epoch: 267, batch: 224, loss: 0.5970712107419968\n",
      "Epoch: 267, batch: 274, loss: 0.592549386024475\n",
      "Epoch: 267, batch: 324, loss: 0.5916392654180527\n",
      "Epoch: 267, batch: 374, loss: 0.5922505897283554\n",
      "Starting Epoch  268 ...\n",
      "Epoch: 268, batch: 49, loss: 0.5961051738262176\n",
      "Epoch: 268, batch: 99, loss: 0.6019238638877868\n",
      "Epoch: 268, batch: 149, loss: 0.6079531162977219\n",
      "Epoch: 268, batch: 199, loss: 0.6031472271680832\n",
      "Epoch: 268, batch: 249, loss: 0.5919070988893509\n",
      "Epoch: 268, batch: 299, loss: 0.5910911428928375\n",
      "Epoch: 268, batch: 349, loss: 0.5940638661384583\n",
      "Starting Epoch  269 ...\n",
      "Epoch: 269, batch: 24, loss: 0.5929986947774887\n",
      "Epoch: 269, batch: 74, loss: 0.5914061456918717\n",
      "Epoch: 269, batch: 124, loss: 0.5947574895620346\n",
      "Epoch: 269, batch: 174, loss: 0.5939297389984131\n",
      "Epoch: 269, batch: 224, loss: 0.5928822654485703\n",
      "Epoch: 269, batch: 274, loss: 0.5924819821119308\n",
      "Epoch: 269, batch: 324, loss: 0.5948988157510757\n",
      "Epoch: 269, batch: 374, loss: 0.6187399095296859\n",
      "Starting Epoch  270 ...\n",
      "Epoch: 270, batch: 49, loss: 0.6154644364118576\n",
      "Epoch: 270, batch: 99, loss: 0.5908486342430115\n",
      "Epoch: 270, batch: 149, loss: 0.593607724905014\n",
      "Epoch: 270, batch: 199, loss: 0.5944103920459747\n",
      "Epoch: 270, batch: 249, loss: 0.5901245087385177\n",
      "Epoch: 270, batch: 299, loss: 0.5903914988040924\n",
      "Epoch: 270, batch: 349, loss: 0.60327044069767\n",
      "Starting Epoch  271 ...\n",
      "Epoch: 271, batch: 24, loss: 0.6110367202758789\n",
      "Epoch: 271, batch: 74, loss: 0.6001150393486023\n",
      "Epoch: 271, batch: 124, loss: 0.5910387343168259\n",
      "Epoch: 271, batch: 174, loss: 0.5903612542152404\n",
      "Epoch: 271, batch: 224, loss: 0.5902632874250412\n",
      "Epoch: 271, batch: 274, loss: 0.59168148458004\n",
      "Epoch: 271, batch: 324, loss: 0.5958438152074814\n",
      "Epoch: 271, batch: 374, loss: 0.6089485359191894\n",
      "Starting Epoch  272 ...\n",
      "Epoch: 272, batch: 49, loss: 0.6077295970916748\n",
      "Epoch: 272, batch: 99, loss: 0.5937781864404679\n",
      "Epoch: 272, batch: 149, loss: 0.5955398333072662\n",
      "Epoch: 272, batch: 199, loss: 0.5954451489448548\n",
      "Epoch: 272, batch: 249, loss: 0.5913236600160598\n",
      "Epoch: 272, batch: 299, loss: 0.5922267371416092\n",
      "Epoch: 272, batch: 349, loss: 0.5973783904314041\n",
      "Starting Epoch  273 ...\n",
      "Epoch: 273, batch: 24, loss: 0.6037879139184952\n",
      "Epoch: 273, batch: 74, loss: 0.5990056902170181\n",
      "Epoch: 273, batch: 124, loss: 0.591401441693306\n",
      "Epoch: 273, batch: 174, loss: 0.5924374860525131\n",
      "Epoch: 273, batch: 224, loss: 0.5921924382448196\n",
      "Epoch: 273, batch: 274, loss: 0.5910396325588226\n",
      "Epoch: 273, batch: 324, loss: 0.5917927348613738\n",
      "Epoch: 273, batch: 374, loss: 0.5930774068832397\n",
      "Starting Epoch  274 ...\n",
      "Epoch: 274, batch: 49, loss: 0.5916131019592286\n",
      "Epoch: 274, batch: 99, loss: 0.5901269215345383\n",
      "Epoch: 274, batch: 149, loss: 0.5904644107818604\n",
      "Epoch: 274, batch: 199, loss: 0.5909258675575256\n",
      "Epoch: 274, batch: 249, loss: 0.5921617859601974\n",
      "Epoch: 274, batch: 299, loss: 0.5932909071445465\n",
      "Epoch: 274, batch: 349, loss: 0.5933460921049118\n",
      "Starting Epoch  275 ...\n",
      "Epoch: 275, batch: 24, loss: 0.5941696733236312\n",
      "Epoch: 275, batch: 74, loss: 0.6110129368305206\n",
      "Epoch: 275, batch: 124, loss: 0.6090927785634994\n",
      "Epoch: 275, batch: 174, loss: 0.5907493424415589\n",
      "Epoch: 275, batch: 224, loss: 0.5928820192813873\n",
      "Epoch: 275, batch: 274, loss: 0.5945000523328781\n",
      "Epoch: 275, batch: 324, loss: 0.5947704416513443\n",
      "Epoch: 275, batch: 374, loss: 0.5928457057476044\n",
      "Starting Epoch  276 ...\n",
      "Epoch: 276, batch: 49, loss: 0.5896687227487564\n",
      "Epoch: 276, batch: 99, loss: 0.591162948012352\n",
      "Epoch: 276, batch: 149, loss: 0.6418713539838791\n",
      "Epoch: 276, batch: 199, loss: 0.6416492414474487\n",
      "Epoch: 276, batch: 249, loss: 0.5905213558673859\n",
      "Epoch: 276, batch: 299, loss: 0.5896152222156524\n",
      "Epoch: 276, batch: 349, loss: 0.5984298658370971\n",
      "Starting Epoch  277 ...\n",
      "Epoch: 277, batch: 24, loss: 0.5997246724367141\n",
      "Epoch: 277, batch: 74, loss: 0.5897219812870026\n",
      "Epoch: 277, batch: 124, loss: 0.5893315315246582\n",
      "Epoch: 277, batch: 174, loss: 0.5905021625757217\n",
      "Epoch: 277, batch: 224, loss: 0.5912484955787659\n",
      "Epoch: 277, batch: 274, loss: 0.5924326938390732\n",
      "Epoch: 277, batch: 324, loss: 0.5999874782562256\n",
      "Epoch: 277, batch: 374, loss: 0.5988843339681625\n",
      "Starting Epoch  278 ...\n",
      "Epoch: 278, batch: 49, loss: 0.5895775717496872\n",
      "Epoch: 278, batch: 99, loss: 0.6012699842453003\n",
      "Epoch: 278, batch: 149, loss: 0.6023334181308746\n",
      "Epoch: 278, batch: 199, loss: 0.5899241799116135\n",
      "Epoch: 278, batch: 249, loss: 0.588198174238205\n",
      "Epoch: 278, batch: 299, loss: 0.5970189613103867\n",
      "Epoch: 278, batch: 349, loss: 0.6028306138515472\n",
      "Starting Epoch  279 ...\n",
      "Epoch: 279, batch: 24, loss: 0.5948443228006363\n",
      "Epoch: 279, batch: 74, loss: 0.5895405268669128\n",
      "Epoch: 279, batch: 124, loss: 0.5898043316602707\n",
      "Epoch: 279, batch: 174, loss: 0.600756168961525\n",
      "Epoch: 279, batch: 224, loss: 0.6110902738571167\n",
      "Epoch: 279, batch: 274, loss: 0.5997456347942353\n",
      "Epoch: 279, batch: 324, loss: 0.5897567296028137\n",
      "Epoch: 279, batch: 374, loss: 0.5902918267250061\n",
      "Starting Epoch  280 ...\n",
      "Epoch: 280, batch: 49, loss: 0.5918232381343842\n",
      "Epoch: 280, batch: 99, loss: 0.6012486380338669\n",
      "Epoch: 280, batch: 149, loss: 0.5972439229488373\n",
      "Epoch: 280, batch: 199, loss: 0.5874207162857056\n",
      "Epoch: 280, batch: 249, loss: 0.5904177403450013\n",
      "Epoch: 280, batch: 299, loss: 0.5912500447034836\n",
      "Epoch: 280, batch: 349, loss: 0.5896758049726486\n",
      "Starting Epoch  281 ...\n",
      "Epoch: 281, batch: 24, loss: 0.5896612280607223\n",
      "Epoch: 281, batch: 74, loss: 0.6277821099758149\n",
      "Epoch: 281, batch: 124, loss: 0.6290404284000397\n",
      "Epoch: 281, batch: 174, loss: 0.5917657077312469\n",
      "Epoch: 281, batch: 224, loss: 0.5907816958427429\n",
      "Epoch: 281, batch: 274, loss: 0.6735013395547866\n",
      "Epoch: 281, batch: 324, loss: 0.6756021928787231\n",
      "Epoch: 281, batch: 374, loss: 0.5912805616855621\n",
      "Starting Epoch  282 ...\n",
      "Epoch: 282, batch: 49, loss: 0.5872445094585419\n",
      "Epoch: 282, batch: 99, loss: 0.5886637586355209\n",
      "Epoch: 282, batch: 149, loss: 0.5904571098089219\n",
      "Epoch: 282, batch: 199, loss: 0.5908413636684418\n",
      "Epoch: 282, batch: 249, loss: 0.589298951625824\n",
      "Epoch: 282, batch: 299, loss: 0.5896316611766815\n",
      "Epoch: 282, batch: 349, loss: 0.5889374977350235\n",
      "Starting Epoch  283 ...\n",
      "Epoch: 283, batch: 24, loss: 0.5881322759389878\n",
      "Epoch: 283, batch: 74, loss: 0.5926014029979706\n",
      "Epoch: 283, batch: 124, loss: 0.5940220361948013\n",
      "Epoch: 283, batch: 174, loss: 0.5902073645591736\n",
      "Epoch: 283, batch: 224, loss: 0.5888366866111755\n",
      "Epoch: 283, batch: 274, loss: 0.5889374685287475\n",
      "Epoch: 283, batch: 324, loss: 0.6010680824518204\n",
      "Epoch: 283, batch: 374, loss: 0.6016673856973648\n",
      "Starting Epoch  284 ...\n",
      "Epoch: 284, batch: 49, loss: 0.5895425665378571\n",
      "Epoch: 284, batch: 99, loss: 0.5899663245677949\n",
      "Epoch: 284, batch: 149, loss: 0.5912380403280258\n",
      "Epoch: 284, batch: 199, loss: 0.5987735515832902\n",
      "Epoch: 284, batch: 249, loss: 0.5959645199775696\n",
      "Epoch: 284, batch: 299, loss: 0.588092405796051\n",
      "Epoch: 284, batch: 349, loss: 0.5885503137111664\n",
      "Starting Epoch  285 ...\n",
      "Epoch: 285, batch: 24, loss: 0.5869823163747787\n",
      "Epoch: 285, batch: 74, loss: 0.5901744967699051\n",
      "Epoch: 285, batch: 124, loss: 0.5918429750204086\n",
      "Epoch: 285, batch: 174, loss: 0.589176949262619\n",
      "Epoch: 285, batch: 224, loss: 0.5918859869241715\n",
      "Epoch: 285, batch: 274, loss: 0.6139501070976258\n",
      "Epoch: 285, batch: 324, loss: 0.6095343768596649\n",
      "Epoch: 285, batch: 374, loss: 0.5862124383449554\n",
      "Starting Epoch  286 ...\n",
      "Epoch: 286, batch: 49, loss: 0.5874887180328369\n",
      "Epoch: 286, batch: 99, loss: 0.5907184338569641\n",
      "Epoch: 286, batch: 149, loss: 0.5900667536258698\n",
      "Epoch: 286, batch: 199, loss: 0.591498344540596\n",
      "Epoch: 286, batch: 249, loss: 0.5929150247573852\n",
      "Epoch: 286, batch: 299, loss: 0.5890966945886612\n",
      "Epoch: 286, batch: 349, loss: 0.5883898901939392\n",
      "Starting Epoch  287 ...\n",
      "Epoch: 287, batch: 24, loss: 0.5898272424936295\n",
      "Epoch: 287, batch: 74, loss: 0.5900072455406189\n",
      "Epoch: 287, batch: 124, loss: 0.5937198102474213\n",
      "Epoch: 287, batch: 174, loss: 0.5921536219120026\n",
      "Epoch: 287, batch: 224, loss: 0.5979511666297913\n",
      "Epoch: 287, batch: 274, loss: 0.5973662132024765\n",
      "Epoch: 287, batch: 324, loss: 0.5862224858999252\n",
      "Epoch: 287, batch: 374, loss: 0.6307381415367126\n",
      "Starting Epoch  288 ...\n",
      "Epoch: 288, batch: 49, loss: 0.630466434955597\n",
      "Epoch: 288, batch: 99, loss: 0.5875134462118149\n",
      "Epoch: 288, batch: 149, loss: 0.587629587650299\n",
      "Epoch: 288, batch: 199, loss: 0.5875375205278397\n",
      "Epoch: 288, batch: 249, loss: 0.6012713372707367\n",
      "Epoch: 288, batch: 299, loss: 0.6023064202070236\n",
      "Epoch: 288, batch: 349, loss: 0.5886367237567902\n",
      "Starting Epoch  289 ...\n",
      "Epoch: 289, batch: 24, loss: 0.5864310222864151\n",
      "Epoch: 289, batch: 74, loss: 0.587090767621994\n",
      "Epoch: 289, batch: 124, loss: 0.588711051940918\n",
      "Epoch: 289, batch: 174, loss: 0.5894144302606583\n",
      "Epoch: 289, batch: 224, loss: 0.5892182999849319\n",
      "Epoch: 289, batch: 274, loss: 0.5889840400218964\n",
      "Epoch: 289, batch: 324, loss: 0.5881942540407181\n",
      "Epoch: 289, batch: 374, loss: 0.587751391530037\n",
      "Starting Epoch  290 ...\n",
      "Epoch: 290, batch: 49, loss: 0.5882267111539841\n",
      "Epoch: 290, batch: 99, loss: 0.5883184456825257\n",
      "Epoch: 290, batch: 149, loss: 0.5871575903892517\n",
      "Epoch: 290, batch: 199, loss: 0.5882844907045365\n",
      "Epoch: 290, batch: 249, loss: 0.5882179313898086\n",
      "Epoch: 290, batch: 299, loss: 0.5874483072757721\n",
      "Epoch: 290, batch: 349, loss: 0.5925978183746338\n",
      "Starting Epoch  291 ...\n",
      "Epoch: 291, batch: 24, loss: 0.5895477139949798\n",
      "Epoch: 291, batch: 74, loss: 0.5870352309942245\n",
      "Epoch: 291, batch: 124, loss: 0.6089568722248078\n",
      "Epoch: 291, batch: 174, loss: 0.606666299700737\n",
      "Epoch: 291, batch: 224, loss: 0.5855038046836853\n",
      "Epoch: 291, batch: 274, loss: 0.5864891988039017\n",
      "Epoch: 291, batch: 324, loss: 0.5877134585380555\n",
      "Epoch: 291, batch: 374, loss: 0.5867259186506272\n",
      "Starting Epoch  292 ...\n",
      "Epoch: 292, batch: 49, loss: 0.5857371717691422\n",
      "Epoch: 292, batch: 99, loss: 0.6032466185092926\n",
      "Epoch: 292, batch: 149, loss: 0.6038577151298523\n",
      "Epoch: 292, batch: 199, loss: 0.5866523259878158\n",
      "Epoch: 292, batch: 249, loss: 0.5859178501367569\n",
      "Epoch: 292, batch: 299, loss: 0.5865192711353302\n",
      "Epoch: 292, batch: 349, loss: 0.6024095380306244\n",
      "Starting Epoch  293 ...\n",
      "Epoch: 293, batch: 24, loss: 0.609355880022049\n",
      "Epoch: 293, batch: 74, loss: 0.5927834713459015\n",
      "Epoch: 293, batch: 124, loss: 0.583697264790535\n",
      "Epoch: 293, batch: 174, loss: 0.590601024031639\n",
      "Epoch: 293, batch: 224, loss: 0.5942548757791519\n",
      "Epoch: 293, batch: 274, loss: 0.5883375757932663\n",
      "Epoch: 293, batch: 324, loss: 0.5873445844650269\n",
      "Epoch: 293, batch: 374, loss: 0.5886471128463745\n",
      "Starting Epoch  294 ...\n",
      "Epoch: 294, batch: 49, loss: 0.5867484104633331\n",
      "Epoch: 294, batch: 99, loss: 0.5867649376392364\n",
      "Epoch: 294, batch: 149, loss: 0.5991953819990158\n",
      "Epoch: 294, batch: 199, loss: 0.5989505732059479\n",
      "Epoch: 294, batch: 249, loss: 0.5867055773735046\n",
      "Epoch: 294, batch: 299, loss: 0.595880816578865\n",
      "Epoch: 294, batch: 349, loss: 0.6011063593626023\n",
      "Starting Epoch  295 ...\n",
      "Epoch: 295, batch: 24, loss: 0.5896209186315536\n",
      "Epoch: 295, batch: 74, loss: 0.5849099349975586\n",
      "Epoch: 295, batch: 124, loss: 0.5980380564928055\n",
      "Epoch: 295, batch: 174, loss: 0.598479255437851\n",
      "Epoch: 295, batch: 224, loss: 0.5856229913234711\n",
      "Epoch: 295, batch: 274, loss: 0.5834728521108627\n",
      "Epoch: 295, batch: 324, loss: 0.5851889431476593\n",
      "Epoch: 295, batch: 374, loss: 0.5868866735696793\n",
      "Starting Epoch  296 ...\n",
      "Epoch: 296, batch: 49, loss: 0.5872301745414734\n",
      "Epoch: 296, batch: 99, loss: 0.5870425206422806\n",
      "Epoch: 296, batch: 149, loss: 0.5864988285303115\n",
      "Epoch: 296, batch: 199, loss: 0.586522541642189\n",
      "Epoch: 296, batch: 249, loss: 0.5893648552894593\n",
      "Epoch: 296, batch: 299, loss: 0.5890724116563797\n",
      "Epoch: 296, batch: 349, loss: 0.5870276218652726\n",
      "Starting Epoch  297 ...\n",
      "Epoch: 297, batch: 24, loss: 0.5875048995018005\n",
      "Epoch: 297, batch: 74, loss: 0.5879061210155487\n",
      "Epoch: 297, batch: 124, loss: 0.5869165009260178\n",
      "Epoch: 297, batch: 174, loss: 0.5862449151277542\n",
      "Epoch: 297, batch: 224, loss: 0.5882835918664933\n",
      "Epoch: 297, batch: 274, loss: 0.5867504912614823\n",
      "Epoch: 297, batch: 324, loss: 0.5849367886781692\n",
      "Epoch: 297, batch: 374, loss: 0.585808122754097\n",
      "Starting Epoch  298 ...\n",
      "Epoch: 298, batch: 49, loss: 0.5885098248720169\n",
      "Epoch: 298, batch: 99, loss: 0.6100654709339142\n",
      "Epoch: 298, batch: 149, loss: 0.6065143352746963\n",
      "Epoch: 298, batch: 199, loss: 0.5854040426015854\n",
      "Epoch: 298, batch: 249, loss: 0.5851678401231766\n",
      "Epoch: 298, batch: 299, loss: 0.5829790931940079\n",
      "Epoch: 298, batch: 349, loss: 0.5833347088098526\n",
      "Starting Epoch  299 ...\n",
      "Epoch: 299, batch: 24, loss: 0.5930456382036209\n",
      "Epoch: 299, batch: 74, loss: 0.5933248203992844\n",
      "Epoch: 299, batch: 124, loss: 0.5841419965028762\n",
      "Epoch: 299, batch: 174, loss: 0.6069043278694153\n",
      "Epoch: 299, batch: 224, loss: 0.6061139386892319\n",
      "Epoch: 299, batch: 274, loss: 0.5840299570560455\n",
      "Epoch: 299, batch: 324, loss: 0.5857131910324097\n",
      "Epoch: 299, batch: 374, loss: 0.584269095659256\n",
      "Starting Epoch  300 ...\n",
      "Epoch: 300, batch: 49, loss: 0.5849714952707291\n",
      "Epoch: 300, batch: 99, loss: 0.5862495249509811\n",
      "Epoch: 300, batch: 149, loss: 0.5849541509151459\n",
      "Epoch: 300, batch: 199, loss: 0.5846792256832123\n",
      "Epoch: 300, batch: 249, loss: 0.5853180277347565\n",
      "Epoch: 300, batch: 299, loss: 0.5872867250442505\n",
      "Epoch: 300, batch: 349, loss: 0.5889091259241104\n",
      "Starting Epoch  301 ...\n",
      "Epoch: 301, batch: 24, loss: 0.5917652666568756\n",
      "Epoch: 301, batch: 74, loss: 0.5905474764108658\n",
      "Epoch: 301, batch: 124, loss: 0.5851068711280822\n",
      "Epoch: 301, batch: 174, loss: 0.5845626932382584\n",
      "Epoch: 301, batch: 224, loss: 0.5845911031961442\n",
      "Epoch: 301, batch: 274, loss: 0.5852948153018951\n",
      "Epoch: 301, batch: 324, loss: 0.5962923365831375\n",
      "Epoch: 301, batch: 374, loss: 0.5963121175765991\n",
      "Starting Epoch  302 ...\n",
      "Epoch: 302, batch: 49, loss: 0.5852744066715241\n",
      "Epoch: 302, batch: 99, loss: 0.5844174796342849\n",
      "Epoch: 302, batch: 149, loss: 0.5866361635923386\n",
      "Epoch: 302, batch: 199, loss: 0.602943884730339\n",
      "Epoch: 302, batch: 249, loss: 0.6117047441005706\n",
      "Epoch: 302, batch: 299, loss: 0.5978625345230103\n",
      "Epoch: 302, batch: 349, loss: 0.5867093485593796\n",
      "Starting Epoch  303 ...\n",
      "Epoch: 303, batch: 24, loss: 0.5928085625171662\n",
      "Epoch: 303, batch: 74, loss: 0.5915852797031402\n",
      "Epoch: 303, batch: 124, loss: 0.581770715713501\n",
      "Epoch: 303, batch: 174, loss: 0.589392340183258\n",
      "Epoch: 303, batch: 224, loss: 0.5893259525299073\n",
      "Epoch: 303, batch: 274, loss: 0.5844920682907104\n",
      "Epoch: 303, batch: 324, loss: 0.5858378791809082\n",
      "Epoch: 303, batch: 374, loss: 0.5912785881757736\n",
      "Starting Epoch  304 ...\n",
      "Epoch: 304, batch: 49, loss: 0.5931870746612549\n",
      "Epoch: 304, batch: 99, loss: 0.5861950576305389\n",
      "Epoch: 304, batch: 149, loss: 0.5834417229890824\n",
      "Epoch: 304, batch: 199, loss: 0.587605032324791\n",
      "Epoch: 304, batch: 249, loss: 0.5872631341218948\n",
      "Epoch: 304, batch: 299, loss: 0.585426499247551\n",
      "Epoch: 304, batch: 349, loss: 0.5856908369064331\n",
      "Starting Epoch  305 ...\n",
      "Epoch: 305, batch: 24, loss: 0.5835103595256805\n",
      "Epoch: 305, batch: 74, loss: 0.585034754872322\n",
      "Epoch: 305, batch: 124, loss: 0.5844487535953522\n",
      "Epoch: 305, batch: 174, loss: 0.5841482979059219\n",
      "Epoch: 305, batch: 224, loss: 0.591929263472557\n",
      "Epoch: 305, batch: 274, loss: 0.5906348413228989\n",
      "Epoch: 305, batch: 324, loss: 0.58289526283741\n",
      "Epoch: 305, batch: 374, loss: 0.6182530838251113\n",
      "Starting Epoch  306 ...\n",
      "Epoch: 306, batch: 49, loss: 0.6202493250370026\n",
      "Epoch: 306, batch: 99, loss: 0.5839163601398468\n",
      "Epoch: 306, batch: 149, loss: 0.582031974196434\n",
      "Epoch: 306, batch: 199, loss: 0.5834805840253829\n",
      "Epoch: 306, batch: 249, loss: 0.5837790203094483\n",
      "Epoch: 306, batch: 299, loss: 0.5891341179609298\n",
      "Epoch: 306, batch: 349, loss: 0.5897439140081405\n",
      "Starting Epoch  307 ...\n",
      "Epoch: 307, batch: 24, loss: 0.5860103172063827\n",
      "Epoch: 307, batch: 74, loss: 0.6088723868131638\n",
      "Epoch: 307, batch: 124, loss: 0.6062090408802032\n",
      "Epoch: 307, batch: 174, loss: 0.5812929135560989\n",
      "Epoch: 307, batch: 224, loss: 0.5832474541664123\n",
      "Epoch: 307, batch: 274, loss: 0.5843503773212433\n",
      "Epoch: 307, batch: 324, loss: 0.5819435852766037\n",
      "Epoch: 307, batch: 374, loss: 0.581497722864151\n",
      "Starting Epoch  308 ...\n",
      "Epoch: 308, batch: 49, loss: 0.6163763266801834\n",
      "Epoch: 308, batch: 99, loss: 0.6291125786304473\n",
      "Epoch: 308, batch: 149, loss: 0.5940789598226547\n",
      "Epoch: 308, batch: 199, loss: 0.5913799476623535\n",
      "Epoch: 308, batch: 249, loss: 0.59525734603405\n",
      "Epoch: 308, batch: 299, loss: 0.5850275957584381\n",
      "Epoch: 308, batch: 349, loss: 0.5812989407777787\n",
      "Starting Epoch  309 ...\n",
      "Epoch: 309, batch: 24, loss: 0.6220689368247986\n",
      "Epoch: 309, batch: 74, loss: 0.6237206566333771\n",
      "Epoch: 309, batch: 124, loss: 0.5875977712869644\n",
      "Epoch: 309, batch: 174, loss: 0.5883340924978256\n",
      "Epoch: 309, batch: 224, loss: 0.5849212354421616\n",
      "Epoch: 309, batch: 274, loss: 0.5839475560188293\n",
      "Epoch: 309, batch: 324, loss: 0.582975624203682\n",
      "Epoch: 309, batch: 374, loss: 0.588497006893158\n",
      "Starting Epoch  310 ...\n",
      "Epoch: 310, batch: 49, loss: 0.5902812641859054\n",
      "Epoch: 310, batch: 99, loss: 0.5974551403522491\n",
      "Epoch: 310, batch: 149, loss: 0.5960669136047363\n",
      "Epoch: 310, batch: 199, loss: 0.5822981214523315\n",
      "Epoch: 310, batch: 249, loss: 0.5813786894083023\n",
      "Epoch: 310, batch: 299, loss: 0.5828786128759385\n",
      "Epoch: 310, batch: 349, loss: 0.5831984943151474\n",
      "Starting Epoch  311 ...\n",
      "Epoch: 311, batch: 24, loss: 0.5832024466991425\n",
      "Epoch: 311, batch: 74, loss: 0.58418137550354\n",
      "Epoch: 311, batch: 124, loss: 0.583078116774559\n",
      "Epoch: 311, batch: 174, loss: 0.5825078248977661\n",
      "Epoch: 311, batch: 224, loss: 0.5825597304105758\n",
      "Epoch: 311, batch: 274, loss: 0.595548169016838\n",
      "Epoch: 311, batch: 324, loss: 0.5959933751821518\n",
      "Epoch: 311, batch: 374, loss: 0.582289964556694\n",
      "Starting Epoch  312 ...\n",
      "Epoch: 312, batch: 49, loss: 0.6027064949274064\n",
      "Epoch: 312, batch: 99, loss: 0.6094608616828918\n",
      "Epoch: 312, batch: 149, loss: 0.5870976424217225\n",
      "Epoch: 312, batch: 199, loss: 0.5822623270750046\n",
      "Epoch: 312, batch: 249, loss: 0.5834645235538483\n",
      "Epoch: 312, batch: 299, loss: 0.581830096244812\n",
      "Epoch: 312, batch: 349, loss: 0.5926253026723862\n",
      "Starting Epoch  313 ...\n",
      "Epoch: 313, batch: 24, loss: 0.5934859943389893\n",
      "Epoch: 313, batch: 74, loss: 0.5813258993625641\n",
      "Epoch: 313, batch: 124, loss: 0.5815161335468292\n",
      "Epoch: 313, batch: 174, loss: 0.6009154736995697\n",
      "Epoch: 313, batch: 224, loss: 0.6162568664550782\n",
      "Epoch: 313, batch: 274, loss: 0.5969371497631073\n",
      "Epoch: 313, batch: 324, loss: 0.5819627130031586\n",
      "Epoch: 313, batch: 374, loss: 0.5835460966825485\n",
      "Starting Epoch  314 ...\n",
      "Epoch: 314, batch: 49, loss: 0.5829261523485184\n",
      "Epoch: 314, batch: 99, loss: 0.5835294884443283\n",
      "Epoch: 314, batch: 149, loss: 0.5820770877599716\n",
      "Epoch: 314, batch: 199, loss: 0.5823229920864105\n",
      "Epoch: 314, batch: 249, loss: 0.5818708539009094\n",
      "Epoch: 314, batch: 299, loss: 0.5877796673774719\n",
      "Epoch: 314, batch: 349, loss: 0.5893691110610962\n",
      "Starting Epoch  315 ...\n",
      "Epoch: 315, batch: 24, loss: 0.5815130412578583\n",
      "Epoch: 315, batch: 74, loss: 0.5810211712121963\n",
      "Epoch: 315, batch: 124, loss: 0.5822910034656524\n",
      "Epoch: 315, batch: 174, loss: 0.6283755701780319\n",
      "Epoch: 315, batch: 224, loss: 0.6561745303869247\n",
      "Epoch: 315, batch: 274, loss: 0.6115335935354232\n",
      "Epoch: 315, batch: 324, loss: 0.5827041566371918\n",
      "Epoch: 315, batch: 374, loss: 0.5822537070512772\n",
      "Starting Epoch  316 ...\n",
      "Epoch: 316, batch: 49, loss: 0.582901554107666\n",
      "Epoch: 316, batch: 99, loss: 0.5847002112865448\n",
      "Epoch: 316, batch: 149, loss: 0.5842620658874512\n",
      "Epoch: 316, batch: 199, loss: 0.5805005317926407\n",
      "Epoch: 316, batch: 249, loss: 0.5810604512691497\n",
      "Epoch: 316, batch: 299, loss: 0.5819115751981735\n",
      "Epoch: 316, batch: 349, loss: 0.5845115542411804\n",
      "Starting Epoch  317 ...\n",
      "Epoch: 317, batch: 24, loss: 0.5856977427005767\n",
      "Epoch: 317, batch: 74, loss: 0.5822554314136505\n",
      "Epoch: 317, batch: 124, loss: 0.588462027311325\n",
      "Epoch: 317, batch: 174, loss: 0.5902517986297607\n",
      "Epoch: 317, batch: 224, loss: 0.5818811684846878\n",
      "Epoch: 317, batch: 274, loss: 0.5837092339992523\n",
      "Epoch: 317, batch: 324, loss: 0.5837239867448807\n",
      "Epoch: 317, batch: 374, loss: 0.5804512280225754\n",
      "Starting Epoch  318 ...\n",
      "Epoch: 318, batch: 49, loss: 0.6129780614376068\n",
      "Epoch: 318, batch: 99, loss: 0.6214571934938431\n",
      "Epoch: 318, batch: 149, loss: 0.5899038994312287\n",
      "Epoch: 318, batch: 199, loss: 0.5805150824785232\n",
      "Epoch: 318, batch: 249, loss: 0.6147610503435135\n",
      "Epoch: 318, batch: 299, loss: 0.6199451148509979\n",
      "Epoch: 318, batch: 349, loss: 0.584649413228035\n",
      "Starting Epoch  319 ...\n",
      "Epoch: 319, batch: 24, loss: 0.5790778863430023\n",
      "Epoch: 319, batch: 74, loss: 0.580085706114769\n",
      "Epoch: 319, batch: 124, loss: 0.5813159346580505\n",
      "Epoch: 319, batch: 174, loss: 0.5807323789596558\n",
      "Epoch: 319, batch: 224, loss: 0.5807031637430191\n",
      "Epoch: 319, batch: 274, loss: 0.5803274136781692\n",
      "Epoch: 319, batch: 324, loss: 0.5806218606233596\n",
      "Epoch: 319, batch: 374, loss: 0.5810580068826675\n",
      "Starting Epoch  320 ...\n",
      "Epoch: 320, batch: 49, loss: 0.6307456797361374\n",
      "Epoch: 320, batch: 99, loss: 0.638204175233841\n",
      "Epoch: 320, batch: 149, loss: 0.586765308380127\n",
      "Epoch: 320, batch: 199, loss: 0.5785044300556182\n",
      "Epoch: 320, batch: 249, loss: 0.5813200354576111\n",
      "Epoch: 320, batch: 299, loss: 0.5837995117902756\n",
      "Epoch: 320, batch: 349, loss: 0.5808013355731965\n",
      "Starting Epoch  321 ...\n",
      "Epoch: 321, batch: 24, loss: 0.5831940245628356\n",
      "Epoch: 321, batch: 74, loss: 0.5855551552772522\n",
      "Epoch: 321, batch: 124, loss: 0.581927683353424\n",
      "Epoch: 321, batch: 174, loss: 0.5800589472055435\n",
      "Epoch: 321, batch: 224, loss: 0.5834505945444107\n",
      "Epoch: 321, batch: 274, loss: 0.5847052282094956\n",
      "Epoch: 321, batch: 324, loss: 0.5813303101062774\n",
      "Epoch: 321, batch: 374, loss: 0.5818574875593185\n",
      "Starting Epoch  322 ...\n",
      "Epoch: 322, batch: 49, loss: 0.6107101649045944\n",
      "Epoch: 322, batch: 99, loss: 0.6095585483312607\n",
      "Epoch: 322, batch: 149, loss: 0.5792284244298935\n",
      "Epoch: 322, batch: 199, loss: 0.578916022181511\n",
      "Epoch: 322, batch: 249, loss: 0.5805835157632828\n",
      "Epoch: 322, batch: 299, loss: 0.5814806270599365\n",
      "Epoch: 322, batch: 349, loss: 0.5803142297267914\n",
      "Starting Epoch  323 ...\n",
      "Epoch: 323, batch: 24, loss: 0.580377629995346\n",
      "Epoch: 323, batch: 74, loss: 0.5806199622154236\n",
      "Epoch: 323, batch: 124, loss: 0.5790619248151779\n",
      "Epoch: 323, batch: 174, loss: 0.5915029549598694\n",
      "Epoch: 323, batch: 224, loss: 0.61934865295887\n",
      "Epoch: 323, batch: 274, loss: 0.6060343551635742\n",
      "Epoch: 323, batch: 324, loss: 0.5786643689870834\n",
      "Epoch: 323, batch: 374, loss: 0.5808683604001998\n",
      "Starting Epoch  324 ...\n",
      "Epoch: 324, batch: 49, loss: 0.5821784198284149\n",
      "Epoch: 324, batch: 99, loss: 0.5797363519668579\n",
      "Epoch: 324, batch: 149, loss: 0.5792787021398544\n",
      "Epoch: 324, batch: 199, loss: 0.5816918909549713\n",
      "Epoch: 324, batch: 249, loss: 0.6069663739204407\n",
      "Epoch: 324, batch: 299, loss: 0.6055160385370254\n",
      "Epoch: 324, batch: 349, loss: 0.5784242141246796\n",
      "Starting Epoch  325 ...\n",
      "Epoch: 325, batch: 24, loss: 0.5803826242685318\n",
      "Epoch: 325, batch: 74, loss: 0.5819087547063827\n",
      "Epoch: 325, batch: 124, loss: 0.5794671136140823\n",
      "Epoch: 325, batch: 174, loss: 0.5795268511772156\n",
      "Epoch: 325, batch: 224, loss: 0.6016821473836899\n",
      "Epoch: 325, batch: 274, loss: 0.6054865956306458\n",
      "Epoch: 325, batch: 324, loss: 0.5834590023756028\n",
      "Epoch: 325, batch: 374, loss: 0.5779422402381897\n",
      "Starting Epoch  326 ...\n",
      "Epoch: 326, batch: 49, loss: 0.5944284790754318\n",
      "Epoch: 326, batch: 99, loss: 0.5955576479434967\n",
      "Epoch: 326, batch: 149, loss: 0.5786731195449829\n",
      "Epoch: 326, batch: 199, loss: 0.5786018884181976\n",
      "Epoch: 326, batch: 249, loss: 0.5807155472040176\n",
      "Epoch: 326, batch: 299, loss: 0.5816226387023926\n",
      "Epoch: 326, batch: 349, loss: 0.600369639992714\n",
      "Starting Epoch  327 ...\n",
      "Epoch: 327, batch: 24, loss: 0.5980754524469376\n",
      "Epoch: 327, batch: 74, loss: 0.5775528919696807\n",
      "Epoch: 327, batch: 124, loss: 0.5784841734170914\n",
      "Epoch: 327, batch: 174, loss: 0.5796102339029312\n",
      "Epoch: 327, batch: 224, loss: 0.5830973398685455\n",
      "Epoch: 327, batch: 274, loss: 0.5812585806846619\n",
      "Epoch: 327, batch: 324, loss: 0.5801068621873856\n",
      "Epoch: 327, batch: 374, loss: 0.579408820271492\n",
      "Starting Epoch  328 ...\n",
      "Epoch: 328, batch: 49, loss: 0.5890939742326736\n",
      "Epoch: 328, batch: 99, loss: 0.6091207778453827\n",
      "Epoch: 328, batch: 149, loss: 0.6019326841831207\n",
      "Epoch: 328, batch: 199, loss: 0.5832990151643753\n",
      "Epoch: 328, batch: 249, loss: 0.5775475668907165\n",
      "Epoch: 328, batch: 299, loss: 0.5791111499071121\n",
      "Epoch: 328, batch: 349, loss: 0.5830452501773834\n",
      "Starting Epoch  329 ...\n",
      "Epoch: 329, batch: 24, loss: 0.5819437897205353\n",
      "Epoch: 329, batch: 74, loss: 0.5798853021860123\n",
      "Epoch: 329, batch: 124, loss: 0.5788116347789765\n",
      "Epoch: 329, batch: 174, loss: 0.5783105474710465\n",
      "Epoch: 329, batch: 224, loss: 0.5803350007534027\n",
      "Epoch: 329, batch: 274, loss: 0.5809225529432297\n",
      "Epoch: 329, batch: 324, loss: 0.5875033581256867\n",
      "Epoch: 329, batch: 374, loss: 0.5863589656352997\n",
      "Starting Epoch  330 ...\n",
      "Epoch: 330, batch: 49, loss: 0.5992019164562226\n",
      "Epoch: 330, batch: 99, loss: 0.6028552770614624\n",
      "Epoch: 330, batch: 149, loss: 0.5811771428585053\n",
      "Epoch: 330, batch: 199, loss: 0.5772849100828171\n",
      "Epoch: 330, batch: 249, loss: 0.5771680319309235\n",
      "Epoch: 330, batch: 299, loss: 0.5774065619707107\n",
      "Epoch: 330, batch: 349, loss: 0.5783830899000167\n",
      "Starting Epoch  331 ...\n",
      "Epoch: 331, batch: 24, loss: 0.5786469453573226\n",
      "Epoch: 331, batch: 74, loss: 0.5964750081300736\n",
      "Epoch: 331, batch: 124, loss: 0.5965132695436478\n",
      "Epoch: 331, batch: 174, loss: 0.5770562350749969\n",
      "Epoch: 331, batch: 224, loss: 0.5777135300636291\n",
      "Epoch: 331, batch: 274, loss: 0.5793003368377686\n",
      "Epoch: 331, batch: 324, loss: 0.5786042135953903\n",
      "Epoch: 331, batch: 374, loss: 0.5781880635023117\n",
      "Starting Epoch  332 ...\n",
      "Epoch: 332, batch: 49, loss: 0.5969280278682709\n",
      "Epoch: 332, batch: 99, loss: 0.5976100552082062\n",
      "Epoch: 332, batch: 149, loss: 0.5778047043085098\n",
      "Epoch: 332, batch: 199, loss: 0.5887717169523239\n",
      "Epoch: 332, batch: 249, loss: 0.5896112304925919\n",
      "Epoch: 332, batch: 299, loss: 0.5772936218976974\n",
      "Epoch: 332, batch: 349, loss: 0.5765995550155639\n",
      "Starting Epoch  333 ...\n",
      "Epoch: 333, batch: 24, loss: 0.5801663184165955\n",
      "Epoch: 333, batch: 74, loss: 0.5791526812314988\n",
      "Epoch: 333, batch: 124, loss: 0.577508134841919\n",
      "Epoch: 333, batch: 174, loss: 0.5988860833644867\n",
      "Epoch: 333, batch: 224, loss: 0.5977169567346573\n",
      "Epoch: 333, batch: 274, loss: 0.5811043381690979\n",
      "Epoch: 333, batch: 324, loss: 0.5809813416004181\n",
      "Epoch: 333, batch: 374, loss: 0.5779036200046539\n",
      "Starting Epoch  334 ...\n",
      "Epoch: 334, batch: 49, loss: 0.5783469331264496\n",
      "Epoch: 334, batch: 99, loss: 0.57823716878891\n",
      "Epoch: 334, batch: 149, loss: 0.5779363405704498\n",
      "Epoch: 334, batch: 199, loss: 0.5783458650112152\n",
      "Epoch: 334, batch: 249, loss: 0.5784593176841736\n",
      "Epoch: 334, batch: 299, loss: 0.5820424038171769\n",
      "Epoch: 334, batch: 349, loss: 0.5831331598758698\n",
      "Starting Epoch  335 ...\n",
      "Epoch: 335, batch: 24, loss: 0.5784426766633988\n",
      "Epoch: 335, batch: 74, loss: 0.5778491526842118\n",
      "Epoch: 335, batch: 124, loss: 0.5801438957452774\n",
      "Epoch: 335, batch: 174, loss: 0.5825498825311661\n",
      "Epoch: 335, batch: 224, loss: 0.5835174393653869\n",
      "Epoch: 335, batch: 274, loss: 0.595194336771965\n",
      "Epoch: 335, batch: 324, loss: 0.5915226358175277\n",
      "Epoch: 335, batch: 374, loss: 0.5865255391597748\n",
      "Starting Epoch  336 ...\n",
      "Epoch: 336, batch: 49, loss: 0.5934494072198868\n",
      "Epoch: 336, batch: 99, loss: 0.5833237242698669\n",
      "Epoch: 336, batch: 149, loss: 0.6038021743297577\n",
      "Epoch: 336, batch: 199, loss: 0.6298066979646683\n",
      "Epoch: 336, batch: 249, loss: 0.6023710280656814\n",
      "Epoch: 336, batch: 299, loss: 0.5741492348909378\n",
      "Epoch: 336, batch: 349, loss: 0.5774109584093093\n",
      "Starting Epoch  337 ...\n",
      "Epoch: 337, batch: 24, loss: 0.5839395254850388\n",
      "Epoch: 337, batch: 74, loss: 0.5815394240617752\n",
      "Epoch: 337, batch: 124, loss: 0.5774711972475052\n",
      "Epoch: 337, batch: 174, loss: 0.5781722223758697\n",
      "Epoch: 337, batch: 224, loss: 0.5778857654333115\n",
      "Epoch: 337, batch: 274, loss: 0.5764626461267471\n",
      "Epoch: 337, batch: 324, loss: 0.5759346914291382\n",
      "Epoch: 337, batch: 374, loss: 0.5936193215847015\n",
      "Starting Epoch  338 ...\n",
      "Epoch: 338, batch: 49, loss: 0.6068571102619171\n",
      "Epoch: 338, batch: 99, loss: 0.5881457006931305\n",
      "Epoch: 338, batch: 149, loss: 0.5756923621892929\n",
      "Epoch: 338, batch: 199, loss: 0.5764155280590058\n",
      "Epoch: 338, batch: 249, loss: 0.5760013592243195\n",
      "Epoch: 338, batch: 299, loss: 0.5767067909240723\n",
      "Epoch: 338, batch: 349, loss: 0.5782560169696808\n",
      "Starting Epoch  339 ...\n",
      "Epoch: 339, batch: 24, loss: 0.5777441787719727\n",
      "Epoch: 339, batch: 74, loss: 0.576295171380043\n",
      "Epoch: 339, batch: 124, loss: 0.5757974028587342\n",
      "Epoch: 339, batch: 174, loss: 0.5759600096940994\n",
      "Epoch: 339, batch: 224, loss: 0.5780451220273971\n",
      "Epoch: 339, batch: 274, loss: 0.579173538684845\n",
      "Epoch: 339, batch: 324, loss: 0.5789735800027848\n",
      "Epoch: 339, batch: 374, loss: 0.5792613923549652\n",
      "Starting Epoch  340 ...\n",
      "Epoch: 340, batch: 49, loss: 0.5770477372407913\n",
      "Epoch: 340, batch: 99, loss: 0.5791759192943573\n",
      "Epoch: 340, batch: 149, loss: 0.5808901745080948\n",
      "Epoch: 340, batch: 199, loss: 0.5793629026412964\n",
      "Epoch: 340, batch: 249, loss: 0.5798186069726944\n",
      "Epoch: 340, batch: 299, loss: 0.5789290916919708\n",
      "Epoch: 340, batch: 349, loss: 0.5765662890672684\n",
      "Starting Epoch  341 ...\n",
      "Epoch: 341, batch: 24, loss: 0.5801714390516282\n",
      "Epoch: 341, batch: 74, loss: 0.5819384545087815\n",
      "Epoch: 341, batch: 124, loss: 0.5833440655469895\n",
      "Epoch: 341, batch: 174, loss: 0.5836286497116089\n",
      "Epoch: 341, batch: 224, loss: 0.577130395770073\n",
      "Epoch: 341, batch: 274, loss: 0.5782536554336548\n",
      "Epoch: 341, batch: 324, loss: 0.5783286863565444\n",
      "Epoch: 341, batch: 374, loss: 0.5816479194164276\n",
      "Starting Epoch  342 ...\n",
      "Epoch: 342, batch: 49, loss: 0.5830988800525665\n",
      "Epoch: 342, batch: 99, loss: 0.5791485172510147\n",
      "Epoch: 342, batch: 149, loss: 0.5894475626945496\n",
      "Epoch: 342, batch: 199, loss: 0.5910818421840668\n",
      "Epoch: 342, batch: 249, loss: 0.5787773251533508\n",
      "Epoch: 342, batch: 299, loss: 0.5747807747125626\n",
      "Epoch: 342, batch: 349, loss: 0.5767499417066574\n",
      "Starting Epoch  343 ...\n",
      "Epoch: 343, batch: 24, loss: 0.6297927564382553\n",
      "Epoch: 343, batch: 74, loss: 0.6507171058654785\n",
      "Epoch: 343, batch: 124, loss: 0.5975845181941986\n",
      "Epoch: 343, batch: 174, loss: 0.5728028923273086\n",
      "Epoch: 343, batch: 224, loss: 0.5737503719329834\n",
      "Epoch: 343, batch: 274, loss: 0.5751534056663513\n",
      "Epoch: 343, batch: 324, loss: 0.5752265411615372\n",
      "Epoch: 343, batch: 374, loss: 0.5757255119085312\n",
      "Starting Epoch  344 ...\n",
      "Epoch: 344, batch: 49, loss: 0.5762513500452041\n",
      "Epoch: 344, batch: 99, loss: 0.5751698976755142\n",
      "Epoch: 344, batch: 149, loss: 0.5751503843069077\n",
      "Epoch: 344, batch: 199, loss: 0.5769776600599289\n",
      "Epoch: 344, batch: 249, loss: 0.5767297446727753\n",
      "Epoch: 344, batch: 299, loss: 0.5817906719446182\n",
      "Epoch: 344, batch: 349, loss: 0.5814190536737442\n",
      "Starting Epoch  345 ...\n",
      "Epoch: 345, batch: 24, loss: 0.5762796425819396\n",
      "Epoch: 345, batch: 74, loss: 0.5884164184331894\n",
      "Epoch: 345, batch: 124, loss: 0.5902958279848098\n",
      "Epoch: 345, batch: 174, loss: 0.5774391835927963\n",
      "Epoch: 345, batch: 224, loss: 0.5749376356601715\n",
      "Epoch: 345, batch: 274, loss: 0.5748581975698471\n",
      "Epoch: 345, batch: 324, loss: 0.57576680123806\n",
      "Epoch: 345, batch: 374, loss: 0.5771265172958374\n",
      "Starting Epoch  346 ...\n",
      "Epoch: 346, batch: 49, loss: 0.5859369492530823\n",
      "Epoch: 346, batch: 99, loss: 0.5852050584554672\n",
      "Epoch: 346, batch: 149, loss: 0.5756076890230178\n",
      "Epoch: 346, batch: 199, loss: 0.5754586327075958\n",
      "Epoch: 346, batch: 249, loss: 0.5761347568035126\n",
      "Epoch: 346, batch: 299, loss: 0.5798031240701675\n",
      "Epoch: 346, batch: 349, loss: 0.5833556348085404\n",
      "Starting Epoch  347 ...\n",
      "Epoch: 347, batch: 24, loss: 0.5969261902570725\n",
      "Epoch: 347, batch: 74, loss: 0.5919596111774444\n",
      "Epoch: 347, batch: 124, loss: 0.5734757900238037\n",
      "Epoch: 347, batch: 174, loss: 0.5740921717882156\n",
      "Epoch: 347, batch: 224, loss: 0.5756011909246445\n",
      "Epoch: 347, batch: 274, loss: 0.5888049721717834\n",
      "Epoch: 347, batch: 324, loss: 0.5896774518489838\n",
      "Epoch: 347, batch: 374, loss: 0.5759228253364563\n",
      "Starting Epoch  348 ...\n",
      "Epoch: 348, batch: 49, loss: 0.5753132623434066\n",
      "Epoch: 348, batch: 99, loss: 0.5764102023839951\n",
      "Epoch: 348, batch: 149, loss: 0.5764681071043014\n",
      "Epoch: 348, batch: 199, loss: 0.5761539250612259\n",
      "Epoch: 348, batch: 249, loss: 0.5749608302116394\n",
      "Epoch: 348, batch: 299, loss: 0.5849272352457047\n",
      "Epoch: 348, batch: 349, loss: 0.5940156871080399\n",
      "Starting Epoch  349 ...\n",
      "Epoch: 349, batch: 24, loss: 0.5817866712808609\n",
      "Epoch: 349, batch: 74, loss: 0.5764214235544205\n",
      "Epoch: 349, batch: 124, loss: 0.5766779839992523\n",
      "Epoch: 349, batch: 174, loss: 0.5750769394636154\n",
      "Epoch: 349, batch: 224, loss: 0.5765774834156037\n",
      "Epoch: 349, batch: 274, loss: 0.5747131389379502\n",
      "Epoch: 349, batch: 324, loss: 0.5763125813007355\n",
      "Epoch: 349, batch: 374, loss: 0.5761774116754532\n",
      "Starting Epoch  350 ...\n",
      "Epoch: 350, batch: 49, loss: 0.5798545104265213\n",
      "Epoch: 350, batch: 99, loss: 0.5805428397655487\n",
      "Epoch: 350, batch: 149, loss: 0.5753740000724793\n",
      "Epoch: 350, batch: 199, loss: 0.5749741595983505\n",
      "Epoch: 350, batch: 249, loss: 0.5825765877962112\n",
      "Epoch: 350, batch: 299, loss: 0.6006516706943512\n",
      "Epoch: 350, batch: 349, loss: 0.6049012839794159\n",
      "Starting Epoch  351 ...\n",
      "Epoch: 351, batch: 24, loss: 0.5866034811735154\n",
      "Epoch: 351, batch: 74, loss: 0.5731438946723938\n",
      "Epoch: 351, batch: 124, loss: 0.5731870633363724\n",
      "Epoch: 351, batch: 174, loss: 0.5728269517421722\n",
      "Epoch: 351, batch: 224, loss: 0.5725738304853439\n",
      "Epoch: 351, batch: 274, loss: 0.5734313488006592\n",
      "Epoch: 351, batch: 324, loss: 0.5969262653589249\n",
      "Epoch: 351, batch: 374, loss: 0.5991997081041336\n",
      "Starting Epoch  352 ...\n",
      "Epoch: 352, batch: 49, loss: 0.5744921272993088\n",
      "Epoch: 352, batch: 99, loss: 0.5734516805410386\n",
      "Epoch: 352, batch: 149, loss: 0.5743908172845841\n",
      "Epoch: 352, batch: 199, loss: 0.5768707829713822\n",
      "Epoch: 352, batch: 249, loss: 0.5775172817707062\n",
      "Epoch: 352, batch: 299, loss: 0.5749099689722061\n",
      "Epoch: 352, batch: 349, loss: 0.5763771790266037\n",
      "Starting Epoch  353 ...\n",
      "Epoch: 353, batch: 24, loss: 0.5800672364234924\n",
      "Epoch: 353, batch: 74, loss: 0.57853382229805\n",
      "Epoch: 353, batch: 124, loss: 0.5745359992980957\n",
      "Epoch: 353, batch: 174, loss: 0.6148783648014069\n",
      "Epoch: 353, batch: 224, loss: 0.6193570166826248\n",
      "Epoch: 353, batch: 274, loss: 0.57855593085289\n",
      "Epoch: 353, batch: 324, loss: 0.5731904083490371\n",
      "Epoch: 353, batch: 374, loss: 0.5891243255138398\n",
      "Starting Epoch  354 ...\n",
      "Epoch: 354, batch: 49, loss: 0.5949427825212479\n",
      "Epoch: 354, batch: 99, loss: 0.5775838273763657\n",
      "Epoch: 354, batch: 149, loss: 0.5713163274526596\n",
      "Epoch: 354, batch: 199, loss: 0.5734198921918869\n",
      "Epoch: 354, batch: 249, loss: 0.5731026673316956\n",
      "Epoch: 354, batch: 299, loss: 0.5722306162118912\n",
      "Epoch: 354, batch: 349, loss: 0.5733441656827927\n",
      "Starting Epoch  355 ...\n",
      "Epoch: 355, batch: 24, loss: 0.5874827444553375\n",
      "Epoch: 355, batch: 74, loss: 0.5912900549173356\n",
      "Epoch: 355, batch: 124, loss: 0.5767186665534973\n",
      "Epoch: 355, batch: 174, loss: 0.573766096830368\n",
      "Epoch: 355, batch: 224, loss: 0.5763322508335114\n",
      "Epoch: 355, batch: 274, loss: 0.5828939265012741\n",
      "Epoch: 355, batch: 324, loss: 0.5802314978837967\n",
      "Epoch: 355, batch: 374, loss: 0.5810024559497833\n",
      "Starting Epoch  356 ...\n",
      "Epoch: 356, batch: 49, loss: 0.581982274055481\n",
      "Epoch: 356, batch: 99, loss: 0.5744064372777938\n",
      "Epoch: 356, batch: 149, loss: 0.5741782653331756\n",
      "Epoch: 356, batch: 199, loss: 0.5731113296747208\n",
      "Epoch: 356, batch: 249, loss: 0.5729348903894425\n",
      "Epoch: 356, batch: 299, loss: 0.5745257812738419\n",
      "Epoch: 356, batch: 349, loss: 0.5759205371141434\n",
      "Starting Epoch  357 ...\n",
      "Epoch: 357, batch: 24, loss: 0.5751615512371063\n",
      "Epoch: 357, batch: 74, loss: 0.6035339057445526\n",
      "Epoch: 357, batch: 124, loss: 0.6016781663894654\n",
      "Epoch: 357, batch: 174, loss: 0.5710719752311707\n",
      "Epoch: 357, batch: 224, loss: 0.5722507590055466\n",
      "Epoch: 357, batch: 274, loss: 0.5847208160161972\n",
      "Epoch: 357, batch: 324, loss: 0.5857511508464813\n",
      "Epoch: 357, batch: 374, loss: 0.5732149374485016\n",
      "Starting Epoch  358 ...\n",
      "Epoch: 358, batch: 49, loss: 0.5731550657749176\n",
      "Epoch: 358, batch: 99, loss: 0.5743879228830338\n",
      "Epoch: 358, batch: 149, loss: 0.5732466465234757\n",
      "Epoch: 358, batch: 199, loss: 0.584432116150856\n",
      "Epoch: 358, batch: 249, loss: 0.5852980935573577\n",
      "Epoch: 358, batch: 299, loss: 0.5730370962619782\n",
      "Epoch: 358, batch: 349, loss: 0.5757940620183944\n",
      "Starting Epoch  359 ...\n",
      "Epoch: 359, batch: 24, loss: 0.5834183406829834\n",
      "Epoch: 359, batch: 74, loss: 0.5792831122875214\n",
      "Epoch: 359, batch: 124, loss: 0.5774390137195587\n",
      "Epoch: 359, batch: 174, loss: 0.5781064468622208\n",
      "Epoch: 359, batch: 224, loss: 0.5729698956012725\n",
      "Epoch: 359, batch: 274, loss: 0.5737549942731858\n",
      "Epoch: 359, batch: 324, loss: 0.5726890784502029\n",
      "Epoch: 359, batch: 374, loss: 0.573727160692215\n",
      "Starting Epoch  360 ...\n",
      "Epoch: 360, batch: 49, loss: 0.5748011004924775\n",
      "Epoch: 360, batch: 99, loss: 0.5937656581401825\n",
      "Epoch: 360, batch: 149, loss: 0.5964473330974579\n",
      "Epoch: 360, batch: 199, loss: 0.576164345741272\n",
      "Epoch: 360, batch: 249, loss: 0.5734743076562882\n",
      "Epoch: 360, batch: 299, loss: 0.5720939546823501\n",
      "Epoch: 360, batch: 349, loss: 0.5735611188411712\n",
      "Starting Epoch  361 ...\n",
      "Epoch: 361, batch: 24, loss: 0.5733496958017349\n",
      "Epoch: 361, batch: 74, loss: 0.5724735844135285\n",
      "Epoch: 361, batch: 124, loss: 0.5797633409500123\n",
      "Epoch: 361, batch: 174, loss: 0.5785277354717254\n",
      "Epoch: 361, batch: 224, loss: 0.5722558277845383\n",
      "Epoch: 361, batch: 274, loss: 0.5836632823944092\n",
      "Epoch: 361, batch: 324, loss: 0.5846182388067246\n",
      "Epoch: 361, batch: 374, loss: 0.5732836711406708\n",
      "Starting Epoch  362 ...\n",
      "Epoch: 362, batch: 49, loss: 0.5720139074325562\n",
      "Epoch: 362, batch: 99, loss: 0.571719360947609\n",
      "Epoch: 362, batch: 149, loss: 0.5772514915466309\n",
      "Epoch: 362, batch: 199, loss: 0.5791459345817566\n",
      "Epoch: 362, batch: 249, loss: 0.5724535316228867\n",
      "Epoch: 362, batch: 299, loss: 0.586945995092392\n",
      "Epoch: 362, batch: 349, loss: 0.5894427239894867\n",
      "Starting Epoch  363 ...\n",
      "Epoch: 363, batch: 24, loss: 0.5734745848178864\n",
      "Epoch: 363, batch: 74, loss: 0.5721821767091751\n",
      "Epoch: 363, batch: 124, loss: 0.571903720498085\n",
      "Epoch: 363, batch: 174, loss: 0.5975272452831268\n",
      "Epoch: 363, batch: 224, loss: 0.5989677238464356\n",
      "Epoch: 363, batch: 274, loss: 0.576122819185257\n",
      "Epoch: 363, batch: 324, loss: 0.5768825083971023\n",
      "Epoch: 363, batch: 374, loss: 0.5738222324848175\n",
      "Starting Epoch  364 ...\n",
      "Epoch: 364, batch: 49, loss: 0.5714143168926239\n",
      "Epoch: 364, batch: 99, loss: 0.5742432659864426\n",
      "Epoch: 364, batch: 149, loss: 0.57536467730999\n",
      "Epoch: 364, batch: 199, loss: 0.5878265273571014\n",
      "Epoch: 364, batch: 249, loss: 0.5874027818441391\n",
      "Epoch: 364, batch: 299, loss: 0.5722220396995544\n",
      "Epoch: 364, batch: 349, loss: 0.5714374804496765\n",
      "Starting Epoch  365 ...\n",
      "Epoch: 365, batch: 24, loss: 0.5714310383796692\n",
      "Epoch: 365, batch: 74, loss: 0.5721543270349503\n",
      "Epoch: 365, batch: 124, loss: 0.5811995095014573\n",
      "Epoch: 365, batch: 174, loss: 0.5823034656047821\n",
      "Epoch: 365, batch: 224, loss: 0.5737533521652222\n",
      "Epoch: 365, batch: 274, loss: 0.577431390285492\n",
      "Epoch: 365, batch: 324, loss: 0.5809827208518982\n",
      "Epoch: 365, batch: 374, loss: 0.5757752758264542\n",
      "Starting Epoch  366 ...\n",
      "Epoch: 366, batch: 49, loss: 0.5721198970079422\n",
      "Epoch: 366, batch: 99, loss: 0.5726766932010651\n",
      "Epoch: 366, batch: 149, loss: 0.5750395679473876\n",
      "Epoch: 366, batch: 199, loss: 0.5781295746564865\n",
      "Epoch: 366, batch: 249, loss: 0.5753416073322296\n",
      "Epoch: 366, batch: 299, loss: 0.5878151023387909\n",
      "Epoch: 366, batch: 349, loss: 0.5886369973421097\n",
      "Starting Epoch  367 ...\n",
      "Epoch: 367, batch: 24, loss: 0.5721436125040055\n",
      "Epoch: 367, batch: 74, loss: 0.5729445666074753\n",
      "Epoch: 367, batch: 124, loss: 0.5841808885335922\n",
      "Epoch: 367, batch: 174, loss: 0.5820941191911697\n",
      "Epoch: 367, batch: 224, loss: 0.5719194138050079\n",
      "Epoch: 367, batch: 274, loss: 0.5730466824769974\n",
      "Epoch: 367, batch: 324, loss: 0.5726621037721634\n",
      "Epoch: 367, batch: 374, loss: 0.5715145921707153\n",
      "Starting Epoch  368 ...\n",
      "Epoch: 368, batch: 49, loss: 0.570997177362442\n",
      "Epoch: 368, batch: 99, loss: 0.5729259955883026\n",
      "Epoch: 368, batch: 149, loss: 0.572347115278244\n",
      "Epoch: 368, batch: 199, loss: 0.5714611107110977\n",
      "Epoch: 368, batch: 249, loss: 0.598708782196045\n",
      "Epoch: 368, batch: 299, loss: 0.6167837017774582\n",
      "Epoch: 368, batch: 349, loss: 0.5897607845067978\n",
      "Starting Epoch  369 ...\n",
      "Epoch: 369, batch: 24, loss: 0.5708333599567413\n",
      "Epoch: 369, batch: 74, loss: 0.5717227989435196\n",
      "Epoch: 369, batch: 124, loss: 0.5763706976175308\n",
      "Epoch: 369, batch: 174, loss: 0.5767003637552262\n",
      "Epoch: 369, batch: 224, loss: 0.5719255608320236\n",
      "Epoch: 369, batch: 274, loss: 0.5717742794752121\n",
      "Epoch: 369, batch: 324, loss: 0.5707304406166077\n",
      "Epoch: 369, batch: 374, loss: 0.5704807758331298\n",
      "Starting Epoch  370 ...\n",
      "Epoch: 370, batch: 49, loss: 0.5729335355758667\n",
      "Epoch: 370, batch: 99, loss: 0.5725154566764832\n",
      "Epoch: 370, batch: 149, loss: 0.5712403625249862\n",
      "Epoch: 370, batch: 199, loss: 0.5794124007225037\n",
      "Epoch: 370, batch: 249, loss: 0.5797391772270203\n",
      "Epoch: 370, batch: 299, loss: 0.573813835978508\n",
      "Epoch: 370, batch: 349, loss: 0.5737005639076233\n",
      "Starting Epoch  371 ...\n",
      "Epoch: 371, batch: 24, loss: 0.580187337398529\n",
      "Epoch: 371, batch: 74, loss: 0.5796706587076187\n",
      "Epoch: 371, batch: 124, loss: 0.5700497549772262\n",
      "Epoch: 371, batch: 174, loss: 0.5711380213499069\n",
      "Epoch: 371, batch: 224, loss: 0.5878044831752777\n",
      "Epoch: 371, batch: 274, loss: 0.590126029253006\n",
      "Epoch: 371, batch: 324, loss: 0.5752859550714493\n",
      "Epoch: 371, batch: 374, loss: 0.5747044461965561\n",
      "Starting Epoch  372 ...\n",
      "Epoch: 372, batch: 49, loss: 0.5715096533298493\n",
      "Epoch: 372, batch: 99, loss: 0.5715425163507462\n",
      "Epoch: 372, batch: 149, loss: 0.5741015887260437\n",
      "Epoch: 372, batch: 199, loss: 0.5718771886825561\n",
      "Epoch: 372, batch: 249, loss: 0.572518230676651\n",
      "Epoch: 372, batch: 299, loss: 0.572058973312378\n",
      "Epoch: 372, batch: 349, loss: 0.5814098262786865\n",
      "Starting Epoch  373 ...\n",
      "Epoch: 373, batch: 24, loss: 0.5905946028232575\n",
      "Epoch: 373, batch: 74, loss: 0.5844885337352753\n",
      "Epoch: 373, batch: 124, loss: 0.5804028391838074\n",
      "Epoch: 373, batch: 174, loss: 0.5747731345891952\n",
      "Epoch: 373, batch: 224, loss: 0.5766055721044541\n",
      "Epoch: 373, batch: 274, loss: 0.5793910628557205\n",
      "Epoch: 373, batch: 324, loss: 0.5769555288553238\n",
      "Epoch: 373, batch: 374, loss: 0.5800151562690735\n",
      "Starting Epoch  374 ...\n",
      "Epoch: 374, batch: 49, loss: 0.5761598348617554\n",
      "Epoch: 374, batch: 99, loss: 0.5718992853164673\n",
      "Epoch: 374, batch: 149, loss: 0.5706728541851044\n",
      "Epoch: 374, batch: 199, loss: 0.5724913007020951\n",
      "Epoch: 374, batch: 249, loss: 0.5766660541296005\n",
      "Epoch: 374, batch: 299, loss: 0.5786368912458419\n",
      "Epoch: 374, batch: 349, loss: 0.5746691447496414\n",
      "Starting Epoch  375 ...\n",
      "Epoch: 375, batch: 24, loss: 0.5693528360128403\n",
      "Epoch: 375, batch: 74, loss: 0.5726494634151459\n",
      "Epoch: 375, batch: 124, loss: 0.5741977572441102\n",
      "Epoch: 375, batch: 174, loss: 0.5703286367654801\n",
      "Epoch: 375, batch: 224, loss: 0.572926681637764\n",
      "Epoch: 375, batch: 274, loss: 0.5743180257081986\n",
      "Epoch: 375, batch: 324, loss: 0.57172378718853\n",
      "Epoch: 375, batch: 374, loss: 0.5715880197286606\n",
      "Starting Epoch  376 ...\n",
      "Epoch: 376, batch: 49, loss: 0.5729327863454818\n",
      "Epoch: 376, batch: 99, loss: 0.5728595495223999\n",
      "Epoch: 376, batch: 149, loss: 0.5718502002954483\n",
      "Epoch: 376, batch: 199, loss: 0.5716856449842453\n",
      "Epoch: 376, batch: 249, loss: 0.5708228921890259\n",
      "Epoch: 376, batch: 299, loss: 0.5703425037860871\n",
      "Epoch: 376, batch: 349, loss: 0.5705823826789856\n",
      "Starting Epoch  377 ...\n",
      "Epoch: 377, batch: 24, loss: 0.5697638154029846\n",
      "Epoch: 377, batch: 74, loss: 0.5702753281593322\n",
      "Epoch: 377, batch: 124, loss: 0.5856029528379441\n",
      "Epoch: 377, batch: 174, loss: 0.5852213871479034\n",
      "Epoch: 377, batch: 224, loss: 0.5735611939430236\n",
      "Epoch: 377, batch: 274, loss: 0.5726673519611358\n",
      "Epoch: 377, batch: 324, loss: 0.5819026267528534\n",
      "Epoch: 377, batch: 374, loss: 0.5861320650577545\n",
      "Starting Epoch  378 ...\n",
      "Epoch: 378, batch: 49, loss: 0.5740674805641174\n",
      "Epoch: 378, batch: 99, loss: 0.5706337749958038\n",
      "Epoch: 378, batch: 149, loss: 0.5808178639411926\n",
      "Epoch: 378, batch: 199, loss: 0.5801962596178055\n",
      "Epoch: 378, batch: 249, loss: 0.569067907333374\n",
      "Epoch: 378, batch: 299, loss: 0.5692669469118118\n",
      "Epoch: 378, batch: 349, loss: 0.5697729671001435\n",
      "Starting Epoch  379 ...\n",
      "Epoch: 379, batch: 24, loss: 0.5727349603176117\n",
      "Epoch: 379, batch: 74, loss: 0.5748658937215805\n",
      "Epoch: 379, batch: 124, loss: 0.571915140748024\n",
      "Epoch: 379, batch: 174, loss: 0.5838705772161483\n",
      "Epoch: 379, batch: 224, loss: 0.5829988545179368\n",
      "Epoch: 379, batch: 274, loss: 0.5688437724113464\n",
      "Epoch: 379, batch: 324, loss: 0.5696036070585251\n",
      "Epoch: 379, batch: 374, loss: 0.5705543476343155\n",
      "Starting Epoch  380 ...\n",
      "Epoch: 380, batch: 49, loss: 0.582501916885376\n",
      "Epoch: 380, batch: 99, loss: 0.5813116765022278\n",
      "Epoch: 380, batch: 149, loss: 0.5682123225927352\n",
      "Epoch: 380, batch: 199, loss: 0.6149565798044204\n",
      "Epoch: 380, batch: 249, loss: 0.617028579711914\n",
      "Epoch: 380, batch: 299, loss: 0.5702689683437348\n",
      "Epoch: 380, batch: 349, loss: 0.5675582802295684\n",
      "Starting Epoch  381 ...\n",
      "Epoch: 381, batch: 24, loss: 0.5696884351968765\n",
      "Epoch: 381, batch: 74, loss: 0.5716613811254502\n",
      "Epoch: 381, batch: 124, loss: 0.5699474215507507\n",
      "Epoch: 381, batch: 174, loss: 0.5718807846307754\n",
      "Epoch: 381, batch: 224, loss: 0.5728839737176895\n",
      "Epoch: 381, batch: 274, loss: 0.5701232987642288\n",
      "Epoch: 381, batch: 324, loss: 0.567984527349472\n",
      "Epoch: 381, batch: 374, loss: 0.5689522409439087\n",
      "Starting Epoch  382 ...\n",
      "Epoch: 382, batch: 49, loss: 0.5727208858728409\n",
      "Epoch: 382, batch: 99, loss: 0.5714256983995437\n",
      "Epoch: 382, batch: 149, loss: 0.5691023713350296\n",
      "Epoch: 382, batch: 199, loss: 0.5741761726140976\n",
      "Epoch: 382, batch: 249, loss: 0.5803357589244843\n",
      "Epoch: 382, batch: 299, loss: 0.5749916696548462\n",
      "Epoch: 382, batch: 349, loss: 0.5758430606126785\n",
      "Starting Epoch  383 ...\n",
      "Epoch: 383, batch: 24, loss: 0.576327428817749\n",
      "Epoch: 383, batch: 74, loss: 0.5728144210577011\n",
      "Epoch: 383, batch: 124, loss: 0.5797857433557511\n",
      "Epoch: 383, batch: 174, loss: 0.5747586286067963\n",
      "Epoch: 383, batch: 224, loss: 0.5675393426418305\n",
      "Epoch: 383, batch: 274, loss: 0.5701065415143967\n",
      "Epoch: 383, batch: 324, loss: 0.5831380718946457\n",
      "Epoch: 383, batch: 374, loss: 0.5862676173448562\n",
      "Starting Epoch  384 ...\n",
      "Epoch: 384, batch: 49, loss: 0.5729792481660843\n",
      "Epoch: 384, batch: 99, loss: 0.5681691306829453\n",
      "Epoch: 384, batch: 149, loss: 0.5668293529748917\n",
      "Epoch: 384, batch: 199, loss: 0.5746405434608459\n",
      "Epoch: 384, batch: 249, loss: 0.5934959423542022\n",
      "Epoch: 384, batch: 299, loss: 0.5924834185838699\n",
      "Epoch: 384, batch: 349, loss: 0.5752115434408188\n",
      "Starting Epoch  385 ...\n",
      "Epoch: 385, batch: 24, loss: 0.5684891837835312\n",
      "Epoch: 385, batch: 74, loss: 0.5748916447162629\n",
      "Epoch: 385, batch: 124, loss: 0.5760071688890457\n",
      "Epoch: 385, batch: 174, loss: 0.5704794782400131\n",
      "Epoch: 385, batch: 224, loss: 0.5685931992530823\n",
      "Epoch: 385, batch: 274, loss: 0.5685470765829086\n",
      "Epoch: 385, batch: 324, loss: 0.5764389783143997\n",
      "Epoch: 385, batch: 374, loss: 0.5746125710010529\n",
      "Starting Epoch  386 ...\n",
      "Epoch: 386, batch: 49, loss: 0.5703524976968766\n",
      "Epoch: 386, batch: 99, loss: 0.6232758271694183\n",
      "Epoch: 386, batch: 149, loss: 0.6216923904418945\n",
      "Epoch: 386, batch: 199, loss: 0.5692149841785431\n",
      "Epoch: 386, batch: 249, loss: 0.5729510933160782\n",
      "Epoch: 386, batch: 299, loss: 0.5738472592830658\n",
      "Epoch: 386, batch: 349, loss: 0.5739700675010682\n",
      "Starting Epoch  387 ...\n",
      "Epoch: 387, batch: 24, loss: 0.5762823599576951\n",
      "Epoch: 387, batch: 74, loss: 0.569001414179802\n",
      "Epoch: 387, batch: 124, loss: 0.5669593894481659\n",
      "Epoch: 387, batch: 174, loss: 0.5693767029047012\n",
      "Epoch: 387, batch: 224, loss: 0.5697039198875428\n",
      "Epoch: 387, batch: 274, loss: 0.5686781698465347\n",
      "Epoch: 387, batch: 324, loss: 0.5691108685731888\n",
      "Epoch: 387, batch: 374, loss: 0.5703700035810471\n",
      "Starting Epoch  388 ...\n",
      "Epoch: 388, batch: 49, loss: 0.5715651655197144\n",
      "Epoch: 388, batch: 99, loss: 0.5729169082641602\n",
      "Epoch: 388, batch: 149, loss: 0.5702983975410462\n",
      "Epoch: 388, batch: 199, loss: 0.5678029304742813\n",
      "Epoch: 388, batch: 249, loss: 0.574029438495636\n",
      "Epoch: 388, batch: 299, loss: 0.5768488162755966\n",
      "Epoch: 388, batch: 349, loss: 0.570696217417717\n",
      "Starting Epoch  389 ...\n",
      "Epoch: 389, batch: 24, loss: 0.5675812667608261\n",
      "Epoch: 389, batch: 74, loss: 0.56843798995018\n",
      "Epoch: 389, batch: 124, loss: 0.5703510493040085\n",
      "Epoch: 389, batch: 174, loss: 0.5690106999874115\n",
      "Epoch: 389, batch: 224, loss: 0.5775139886140823\n",
      "Epoch: 389, batch: 274, loss: 0.5795121318101883\n",
      "Epoch: 389, batch: 324, loss: 0.5694513207674027\n",
      "Epoch: 389, batch: 374, loss: 0.5696033978462219\n",
      "Starting Epoch  390 ...\n",
      "Epoch: 390, batch: 49, loss: 0.5776054513454437\n",
      "Epoch: 390, batch: 99, loss: 0.574411867260933\n",
      "Epoch: 390, batch: 149, loss: 0.5696149051189423\n",
      "Epoch: 390, batch: 199, loss: 0.575586029291153\n",
      "Epoch: 390, batch: 249, loss: 0.5759718543291092\n",
      "Epoch: 390, batch: 299, loss: 0.5720500832796097\n",
      "Epoch: 390, batch: 349, loss: 0.5728643381595612\n",
      "Starting Epoch  391 ...\n",
      "Epoch: 391, batch: 24, loss: 0.5721196365356446\n",
      "Epoch: 391, batch: 74, loss: 0.56959044277668\n",
      "Epoch: 391, batch: 124, loss: 0.5692012363672256\n",
      "Epoch: 391, batch: 174, loss: 0.5677761143445968\n",
      "Epoch: 391, batch: 224, loss: 0.5679021000862121\n",
      "Epoch: 391, batch: 274, loss: 0.5800481182336807\n",
      "Epoch: 391, batch: 324, loss: 0.579329115152359\n",
      "Epoch: 391, batch: 374, loss: 0.5656432735919953\n",
      "Starting Epoch  392 ...\n",
      "Epoch: 392, batch: 49, loss: 0.5760954236984253\n",
      "Epoch: 392, batch: 99, loss: 0.5793283116817475\n",
      "Epoch: 392, batch: 149, loss: 0.5695598322153091\n",
      "Epoch: 392, batch: 199, loss: 0.5689312446117402\n",
      "Epoch: 392, batch: 249, loss: 0.5761153316497802\n",
      "Epoch: 392, batch: 299, loss: 0.5747889018058777\n",
      "Epoch: 392, batch: 349, loss: 0.5679184693098068\n",
      "Starting Epoch  393 ...\n",
      "Epoch: 393, batch: 24, loss: 0.5675246667861938\n",
      "Epoch: 393, batch: 74, loss: 0.5686518204212189\n",
      "Epoch: 393, batch: 124, loss: 0.5682356595993042\n",
      "Epoch: 393, batch: 174, loss: 0.5673200345039368\n",
      "Epoch: 393, batch: 224, loss: 0.5698133742809296\n",
      "Epoch: 393, batch: 274, loss: 0.5704659217596054\n",
      "Epoch: 393, batch: 324, loss: 0.5676210904121399\n",
      "Epoch: 393, batch: 374, loss: 0.5672057425975799\n",
      "Starting Epoch  394 ...\n",
      "Epoch: 394, batch: 49, loss: 0.5684899425506592\n",
      "Epoch: 394, batch: 99, loss: 0.5693991875648499\n",
      "Epoch: 394, batch: 149, loss: 0.5869021260738373\n",
      "Epoch: 394, batch: 199, loss: 0.5940745913982391\n",
      "Epoch: 394, batch: 249, loss: 0.5747532379627228\n",
      "Epoch: 394, batch: 299, loss: 0.5659822207689286\n",
      "Epoch: 394, batch: 349, loss: 0.5759066617488862\n",
      "Starting Epoch  395 ...\n",
      "Epoch: 395, batch: 24, loss: 0.5753782367706299\n",
      "Epoch: 395, batch: 74, loss: 0.5657854461669922\n",
      "Epoch: 395, batch: 124, loss: 0.5644316720962524\n",
      "Epoch: 395, batch: 174, loss: 0.5770399296283721\n",
      "Epoch: 395, batch: 224, loss: 0.580192551612854\n",
      "Epoch: 395, batch: 274, loss: 0.5700171285867691\n",
      "Epoch: 395, batch: 324, loss: 0.5769089841842652\n",
      "Epoch: 395, batch: 374, loss: 0.5753534525632858\n",
      "Starting Epoch  396 ...\n",
      "Epoch: 396, batch: 49, loss: 0.5666629332304001\n",
      "Epoch: 396, batch: 99, loss: 0.5718612617254257\n",
      "Epoch: 396, batch: 149, loss: 0.5720370638370514\n",
      "Epoch: 396, batch: 199, loss: 0.5835163736343384\n",
      "Epoch: 396, batch: 249, loss: 0.5835878700017929\n",
      "Epoch: 396, batch: 299, loss: 0.5679698246717453\n",
      "Epoch: 396, batch: 349, loss: 0.5680577403306961\n",
      "Starting Epoch  397 ...\n",
      "Epoch: 397, batch: 24, loss: 0.5761321949958801\n",
      "Epoch: 397, batch: 74, loss: 0.6268167537450791\n",
      "Epoch: 397, batch: 124, loss: 0.6175528407096863\n",
      "Epoch: 397, batch: 174, loss: 0.5657210659980774\n",
      "Epoch: 397, batch: 224, loss: 0.5651904487609863\n",
      "Epoch: 397, batch: 274, loss: 0.5651768910884857\n",
      "Epoch: 397, batch: 324, loss: 0.5673625618219376\n",
      "Epoch: 397, batch: 374, loss: 0.5681286180019378\n",
      "Starting Epoch  398 ...\n",
      "Epoch: 398, batch: 49, loss: 0.5650227707624436\n",
      "Epoch: 398, batch: 99, loss: 0.5652253311872483\n",
      "Epoch: 398, batch: 149, loss: 0.582535679936409\n",
      "Epoch: 398, batch: 199, loss: 0.5835599148273468\n",
      "Epoch: 398, batch: 249, loss: 0.567921599149704\n",
      "Epoch: 398, batch: 299, loss: 0.5669438552856445\n",
      "Epoch: 398, batch: 349, loss: 0.5672625106573105\n",
      "Starting Epoch  399 ...\n",
      "Epoch: 399, batch: 24, loss: 0.5866140413284302\n",
      "Epoch: 399, batch: 74, loss: 0.5956334286928177\n",
      "Epoch: 399, batch: 124, loss: 0.5760114026069642\n",
      "Epoch: 399, batch: 174, loss: 0.566208792924881\n",
      "Epoch: 399, batch: 224, loss: 0.5676039338111878\n",
      "Epoch: 399, batch: 274, loss: 0.568058003783226\n",
      "Epoch: 399, batch: 324, loss: 0.5673617768287659\n",
      "Epoch: 399, batch: 374, loss: 0.5664751398563385\n",
      "Starting Epoch  400 ...\n",
      "Epoch: 400, batch: 49, loss: 0.5789648884534836\n",
      "Epoch: 400, batch: 99, loss: 0.586946719288826\n",
      "Epoch: 400, batch: 149, loss: 0.5721880924701691\n",
      "Epoch: 400, batch: 199, loss: 0.5641844159364701\n",
      "Epoch: 400, batch: 249, loss: 0.5667620241641999\n",
      "Epoch: 400, batch: 299, loss: 0.5674552917480469\n",
      "Epoch: 400, batch: 349, loss: 0.5657343864440918\n",
      "Starting Epoch  401 ...\n",
      "Epoch: 401, batch: 24, loss: 0.5680550408363342\n",
      "Epoch: 401, batch: 74, loss: 0.5682779771089553\n",
      "Epoch: 401, batch: 124, loss: 0.5652392971515655\n",
      "Epoch: 401, batch: 174, loss: 0.5674961769580841\n",
      "Epoch: 401, batch: 224, loss: 0.570878301858902\n",
      "Epoch: 401, batch: 274, loss: 0.5860905379056931\n",
      "Epoch: 401, batch: 324, loss: 0.5828816080093384\n",
      "Epoch: 401, batch: 374, loss: 0.5655391347408295\n",
      "Starting Epoch  402 ...\n",
      "Epoch: 402, batch: 49, loss: 0.5689808630943298\n",
      "Epoch: 402, batch: 99, loss: 0.5721111232042313\n",
      "Epoch: 402, batch: 149, loss: 0.568317831158638\n",
      "Epoch: 402, batch: 199, loss: 0.5828606736660004\n",
      "Epoch: 402, batch: 249, loss: 0.5865136814117432\n",
      "Epoch: 402, batch: 299, loss: 0.5685399603843689\n",
      "Epoch: 402, batch: 349, loss: 0.567347109913826\n",
      "Starting Epoch  403 ...\n",
      "Epoch: 403, batch: 24, loss: 0.571417481303215\n",
      "Epoch: 403, batch: 74, loss: 0.5693756353855133\n",
      "Epoch: 403, batch: 124, loss: 0.5654120117425918\n",
      "Epoch: 403, batch: 174, loss: 0.5661756992340088\n",
      "Epoch: 403, batch: 224, loss: 0.5773239976167679\n",
      "Epoch: 403, batch: 274, loss: 0.5775729966163635\n",
      "Epoch: 403, batch: 324, loss: 0.5676183599233627\n",
      "Epoch: 403, batch: 374, loss: 0.5662781012058258\n",
      "Starting Epoch  404 ...\n",
      "Epoch: 404, batch: 49, loss: 0.5653294718265534\n",
      "Epoch: 404, batch: 99, loss: 0.5701199865341187\n",
      "Epoch: 404, batch: 149, loss: 0.5705479311943055\n",
      "Epoch: 404, batch: 199, loss: 0.5665776062011719\n",
      "Epoch: 404, batch: 249, loss: 0.5687224966287613\n",
      "Epoch: 404, batch: 299, loss: 0.5687686055898666\n",
      "Epoch: 404, batch: 349, loss: 0.5661046051979065\n",
      "Starting Epoch  405 ...\n",
      "Epoch: 405, batch: 24, loss: 0.5655438297986984\n",
      "Epoch: 405, batch: 74, loss: 0.5738312238454819\n",
      "Epoch: 405, batch: 124, loss: 0.5730844426155091\n",
      "Epoch: 405, batch: 174, loss: 0.5896065747737884\n",
      "Epoch: 405, batch: 224, loss: 0.5906172353029251\n",
      "Epoch: 405, batch: 274, loss: 0.5650616192817688\n",
      "Epoch: 405, batch: 324, loss: 0.5638034915924073\n",
      "Epoch: 405, batch: 374, loss: 0.5697345316410065\n",
      "Starting Epoch  406 ...\n",
      "Epoch: 406, batch: 49, loss: 0.5713849556446076\n",
      "Epoch: 406, batch: 99, loss: 0.5674602282047272\n",
      "Epoch: 406, batch: 149, loss: 0.5759959381818771\n",
      "Epoch: 406, batch: 199, loss: 0.5751650112867356\n",
      "Epoch: 406, batch: 249, loss: 0.5669159305095672\n",
      "Epoch: 406, batch: 299, loss: 0.5661448365449906\n",
      "Epoch: 406, batch: 349, loss: 0.5649454897642135\n",
      "Starting Epoch  407 ...\n",
      "Epoch: 407, batch: 24, loss: 0.5674528098106384\n",
      "Epoch: 407, batch: 74, loss: 0.5674432784318924\n",
      "Epoch: 407, batch: 124, loss: 0.5659045839309692\n",
      "Epoch: 407, batch: 174, loss: 0.5666215485334396\n",
      "Epoch: 407, batch: 224, loss: 0.5666975390911102\n",
      "Epoch: 407, batch: 274, loss: 0.5731345361471176\n",
      "Epoch: 407, batch: 324, loss: 0.5730434763431549\n",
      "Epoch: 407, batch: 374, loss: 0.5767913550138474\n",
      "Starting Epoch  408 ...\n",
      "Epoch: 408, batch: 49, loss: 0.5989825737476349\n",
      "Epoch: 408, batch: 99, loss: 0.5876495695114136\n",
      "Epoch: 408, batch: 149, loss: 0.5646717715263366\n",
      "Epoch: 408, batch: 199, loss: 0.5647751003503799\n",
      "Epoch: 408, batch: 249, loss: 0.5641708397865295\n",
      "Epoch: 408, batch: 299, loss: 0.5649758195877075\n",
      "Epoch: 408, batch: 349, loss: 0.5652971458435059\n",
      "Starting Epoch  409 ...\n",
      "Epoch: 409, batch: 24, loss: 0.5650447201728821\n",
      "Epoch: 409, batch: 74, loss: 0.5656403344869614\n",
      "Epoch: 409, batch: 124, loss: 0.566492133140564\n",
      "Epoch: 409, batch: 174, loss: 0.5669494330883026\n",
      "Epoch: 409, batch: 224, loss: 0.5661668473482132\n",
      "Epoch: 409, batch: 274, loss: 0.564639402627945\n",
      "Epoch: 409, batch: 324, loss: 0.5656033647060394\n",
      "Epoch: 409, batch: 374, loss: 0.5670019680261612\n",
      "Starting Epoch  410 ...\n",
      "Epoch: 410, batch: 49, loss: 0.5688773506879806\n",
      "Epoch: 410, batch: 99, loss: 0.5668970084190369\n",
      "Epoch: 410, batch: 149, loss: 0.5645065313577652\n",
      "Epoch: 410, batch: 199, loss: 0.5657335484027862\n",
      "Epoch: 410, batch: 249, loss: 0.5654762202501297\n",
      "Epoch: 410, batch: 299, loss: 0.5661263835430145\n",
      "Epoch: 410, batch: 349, loss: 0.566700029373169\n",
      "Starting Epoch  411 ...\n",
      "Epoch: 411, batch: 24, loss: 0.5656510728597641\n",
      "Epoch: 411, batch: 74, loss: 0.5961661511659622\n",
      "Epoch: 411, batch: 124, loss: 0.5974096727371215\n",
      "Epoch: 411, batch: 174, loss: 0.5642085951566697\n",
      "Epoch: 411, batch: 224, loss: 0.5667968374490738\n",
      "Epoch: 411, batch: 274, loss: 0.5678088599443436\n",
      "Epoch: 411, batch: 324, loss: 0.5655497270822525\n",
      "Epoch: 411, batch: 374, loss: 0.566146439909935\n",
      "Starting Epoch  412 ...\n",
      "Epoch: 412, batch: 49, loss: 0.5654517704248428\n",
      "Epoch: 412, batch: 99, loss: 0.5654766720533371\n",
      "Epoch: 412, batch: 149, loss: 0.5692834740877152\n",
      "Epoch: 412, batch: 199, loss: 0.5691585391759872\n",
      "Epoch: 412, batch: 249, loss: 0.5736522889137268\n",
      "Epoch: 412, batch: 299, loss: 0.574738312959671\n",
      "Epoch: 412, batch: 349, loss: 0.5645230764150619\n",
      "Starting Epoch  413 ...\n",
      "Epoch: 413, batch: 24, loss: 0.57057985663414\n",
      "Epoch: 413, batch: 74, loss: 0.5702384799718857\n",
      "Epoch: 413, batch: 124, loss: 0.5640602523088455\n",
      "Epoch: 413, batch: 174, loss: 0.5662177324295044\n",
      "Epoch: 413, batch: 224, loss: 0.5651214343309402\n",
      "Epoch: 413, batch: 274, loss: 0.5665033626556396\n",
      "Epoch: 413, batch: 324, loss: 0.5739618664979935\n",
      "Epoch: 413, batch: 374, loss: 0.5804642856121063\n",
      "Starting Epoch  414 ...\n",
      "Epoch: 414, batch: 49, loss: 0.5729612618684768\n",
      "Epoch: 414, batch: 99, loss: 0.5649681651592254\n",
      "Epoch: 414, batch: 149, loss: 0.5653547608852386\n",
      "Epoch: 414, batch: 199, loss: 0.5656277501583099\n",
      "Epoch: 414, batch: 249, loss: 0.5648552358150483\n",
      "Epoch: 414, batch: 299, loss: 0.566366838812828\n",
      "Epoch: 414, batch: 349, loss: 0.5669083905220031\n",
      "Starting Epoch  415 ...\n",
      "Epoch: 415, batch: 24, loss: 0.5689427191019059\n",
      "Epoch: 415, batch: 74, loss: 0.5678946071863175\n",
      "Epoch: 415, batch: 124, loss: 0.5813990473747254\n",
      "Epoch: 415, batch: 174, loss: 0.5831203019618988\n",
      "Epoch: 415, batch: 224, loss: 0.5665579420328141\n",
      "Epoch: 415, batch: 274, loss: 0.5695376747846603\n",
      "Epoch: 415, batch: 324, loss: 0.5679596203565598\n",
      "Epoch: 415, batch: 374, loss: 0.5646468716859817\n",
      "Starting Epoch  416 ...\n",
      "Epoch: 416, batch: 49, loss: 0.5663298660516739\n",
      "Epoch: 416, batch: 99, loss: 0.57026422560215\n",
      "Epoch: 416, batch: 149, loss: 0.5776226437091827\n",
      "Epoch: 416, batch: 199, loss: 0.5807314264774323\n",
      "Epoch: 416, batch: 249, loss: 0.5717703330516816\n",
      "Epoch: 416, batch: 299, loss: 0.5630343723297119\n",
      "Epoch: 416, batch: 349, loss: 0.5680543392896652\n",
      "Starting Epoch  417 ...\n",
      "Epoch: 417, batch: 24, loss: 0.5703496646881103\n",
      "Epoch: 417, batch: 74, loss: 0.5648376816511154\n",
      "Epoch: 417, batch: 124, loss: 0.5704255735874176\n",
      "Epoch: 417, batch: 174, loss: 0.571746420264244\n",
      "Epoch: 417, batch: 224, loss: 0.5662217545509338\n",
      "Epoch: 417, batch: 274, loss: 0.5658617162704468\n",
      "Epoch: 417, batch: 324, loss: 0.5633032190799713\n",
      "Epoch: 417, batch: 374, loss: 0.5628873842954636\n",
      "Starting Epoch  418 ...\n",
      "Epoch: 418, batch: 49, loss: 0.5654452639818192\n",
      "Epoch: 418, batch: 99, loss: 0.5641912150382996\n",
      "Epoch: 418, batch: 149, loss: 0.5716937464475632\n",
      "Epoch: 418, batch: 199, loss: 0.5727782934904099\n",
      "Epoch: 418, batch: 249, loss: 0.5770031136274337\n",
      "Epoch: 418, batch: 299, loss: 0.5792897009849548\n",
      "Epoch: 418, batch: 349, loss: 0.5648700046539307\n",
      "Starting Epoch  419 ...\n",
      "Epoch: 419, batch: 24, loss: 0.5629760497808456\n",
      "Epoch: 419, batch: 74, loss: 0.574936985373497\n",
      "Epoch: 419, batch: 124, loss: 0.5750334149599076\n",
      "Epoch: 419, batch: 174, loss: 0.5644589591026307\n",
      "Epoch: 419, batch: 224, loss: 0.5769625663757324\n",
      "Epoch: 419, batch: 274, loss: 0.5761219102144242\n",
      "Epoch: 419, batch: 324, loss: 0.5633889478445053\n",
      "Epoch: 419, batch: 374, loss: 0.5732845890522004\n",
      "Starting Epoch  420 ...\n",
      "Epoch: 420, batch: 49, loss: 0.5722003471851349\n",
      "Epoch: 420, batch: 99, loss: 0.5621342974901199\n",
      "Epoch: 420, batch: 149, loss: 0.5659962594509125\n",
      "Epoch: 420, batch: 199, loss: 0.5657288843393325\n",
      "Epoch: 420, batch: 249, loss: 0.5625188559293747\n",
      "Epoch: 420, batch: 299, loss: 0.5771415209770203\n",
      "Epoch: 420, batch: 349, loss: 0.5969240164756775\n",
      "Starting Epoch  421 ...\n",
      "Epoch: 421, batch: 24, loss: 0.5826149564981461\n",
      "Epoch: 421, batch: 74, loss: 0.563881801366806\n",
      "Epoch: 421, batch: 124, loss: 0.5644202572107315\n",
      "Epoch: 421, batch: 174, loss: 0.5645436412096023\n",
      "Epoch: 421, batch: 224, loss: 0.5638867676258087\n",
      "Epoch: 421, batch: 274, loss: 0.577949406504631\n",
      "Epoch: 421, batch: 324, loss: 0.5783521652221679\n",
      "Epoch: 421, batch: 374, loss: 0.5626542323827743\n",
      "Starting Epoch  422 ...\n",
      "Epoch: 422, batch: 49, loss: 0.5623702120780945\n",
      "Epoch: 422, batch: 99, loss: 0.5638053792715073\n",
      "Epoch: 422, batch: 149, loss: 0.5639573276042938\n",
      "Epoch: 422, batch: 199, loss: 0.5619811815023422\n",
      "Epoch: 422, batch: 249, loss: 0.5629561758041381\n",
      "Epoch: 422, batch: 299, loss: 0.5645477133989334\n",
      "Epoch: 422, batch: 349, loss: 0.5648788088560104\n",
      "Starting Epoch  423 ...\n",
      "Epoch: 423, batch: 24, loss: 0.5650934457778931\n",
      "Epoch: 423, batch: 74, loss: 0.5656171315908431\n",
      "Epoch: 423, batch: 124, loss: 0.5643284416198731\n",
      "Epoch: 423, batch: 174, loss: 0.5661115968227386\n",
      "Epoch: 423, batch: 224, loss: 0.5664031207561493\n",
      "Epoch: 423, batch: 274, loss: 0.5642741638422012\n",
      "Epoch: 423, batch: 324, loss: 0.5643179708719254\n",
      "Epoch: 423, batch: 374, loss: 0.5632985150814056\n",
      "Starting Epoch  424 ...\n",
      "Epoch: 424, batch: 49, loss: 0.5772915810346604\n",
      "Epoch: 424, batch: 99, loss: 0.5766343975067139\n",
      "Epoch: 424, batch: 149, loss: 0.5621938300132752\n",
      "Epoch: 424, batch: 199, loss: 0.5643353152275086\n",
      "Epoch: 424, batch: 249, loss: 0.56671355843544\n",
      "Epoch: 424, batch: 299, loss: 0.5687438803911209\n",
      "Epoch: 424, batch: 349, loss: 0.5727976357936859\n",
      "Starting Epoch  425 ...\n",
      "Epoch: 425, batch: 24, loss: 0.5683594954013824\n",
      "Epoch: 425, batch: 74, loss: 0.5634165036678315\n",
      "Epoch: 425, batch: 124, loss: 0.5648491168022156\n",
      "Epoch: 425, batch: 174, loss: 0.5639914590120315\n",
      "Epoch: 425, batch: 224, loss: 0.5642159026861191\n",
      "Epoch: 425, batch: 274, loss: 0.5680539804697037\n",
      "Epoch: 425, batch: 324, loss: 0.5718718945980072\n",
      "Epoch: 425, batch: 374, loss: 0.5682572275400162\n",
      "Starting Epoch  426 ...\n",
      "Epoch: 426, batch: 49, loss: 0.5638440281152726\n",
      "Epoch: 426, batch: 99, loss: 0.5689133870601654\n",
      "Epoch: 426, batch: 149, loss: 0.568067901134491\n",
      "Epoch: 426, batch: 199, loss: 0.5717531508207321\n",
      "Epoch: 426, batch: 249, loss: 0.5735965418815613\n",
      "Epoch: 426, batch: 299, loss: 0.5647191840410233\n",
      "Epoch: 426, batch: 349, loss: 0.5628536963462829\n",
      "Starting Epoch  427 ...\n",
      "Epoch: 427, batch: 24, loss: 0.5618579357862472\n",
      "Epoch: 427, batch: 74, loss: 0.5723155426979065\n",
      "Epoch: 427, batch: 124, loss: 0.5823963850736618\n",
      "Epoch: 427, batch: 174, loss: 0.5719855219125748\n",
      "Epoch: 427, batch: 224, loss: 0.5622555053234101\n",
      "Epoch: 427, batch: 274, loss: 0.5617084461450577\n",
      "Epoch: 427, batch: 324, loss: 0.5636723417043686\n",
      "Epoch: 427, batch: 374, loss: 0.5647835898399353\n",
      "Starting Epoch  428 ...\n",
      "Epoch: 428, batch: 49, loss: 0.5638505667448044\n",
      "Epoch: 428, batch: 99, loss: 0.5696528786420822\n",
      "Epoch: 428, batch: 149, loss: 0.572206791639328\n",
      "Epoch: 428, batch: 199, loss: 0.5656223803758621\n",
      "Epoch: 428, batch: 249, loss: 0.5628114420175553\n",
      "Epoch: 428, batch: 299, loss: 0.5624233794212341\n",
      "Epoch: 428, batch: 349, loss: 0.5616538381576538\n",
      "Starting Epoch  429 ...\n",
      "Epoch: 429, batch: 24, loss: 0.5657094764709473\n",
      "Epoch: 429, batch: 74, loss: 0.5645807415246964\n",
      "Epoch: 429, batch: 124, loss: 0.561241528391838\n",
      "Epoch: 429, batch: 174, loss: 0.5793446809053421\n",
      "Epoch: 429, batch: 224, loss: 0.5817569118738174\n",
      "Epoch: 429, batch: 274, loss: 0.5670264220237732\n",
      "Epoch: 429, batch: 324, loss: 0.5649056643247604\n",
      "Epoch: 429, batch: 374, loss: 0.5620840817689896\n",
      "Starting Epoch  430 ...\n",
      "Epoch: 430, batch: 49, loss: 0.5623342901468277\n",
      "Epoch: 430, batch: 99, loss: 0.5708992016315461\n",
      "Epoch: 430, batch: 149, loss: 0.5890283405780792\n",
      "Epoch: 430, batch: 199, loss: 0.5802566927671432\n",
      "Epoch: 430, batch: 249, loss: 0.562969817519188\n",
      "Epoch: 430, batch: 299, loss: 0.5622243577241898\n",
      "Epoch: 430, batch: 349, loss: 0.5606299149990082\n",
      "Starting Epoch  431 ...\n",
      "Epoch: 431, batch: 24, loss: 0.576170716881752\n",
      "Epoch: 431, batch: 74, loss: 0.5750612086057663\n",
      "Epoch: 431, batch: 124, loss: 0.5612905377149582\n",
      "Epoch: 431, batch: 174, loss: 0.5875836741924286\n",
      "Epoch: 431, batch: 224, loss: 0.5880305206775666\n",
      "Epoch: 431, batch: 274, loss: 0.5627908617258072\n",
      "Epoch: 431, batch: 324, loss: 0.5623863011598587\n",
      "Epoch: 431, batch: 374, loss: 0.5616198217868805\n",
      "Starting Epoch  432 ...\n",
      "Epoch: 432, batch: 49, loss: 0.560728702545166\n",
      "Epoch: 432, batch: 99, loss: 0.5751621794700622\n",
      "Epoch: 432, batch: 149, loss: 0.5761743533611298\n",
      "Epoch: 432, batch: 199, loss: 0.562053592801094\n",
      "Epoch: 432, batch: 249, loss: 0.5626134300231933\n",
      "Epoch: 432, batch: 299, loss: 0.5632994824647903\n",
      "Epoch: 432, batch: 349, loss: 0.5655902487039566\n",
      "Starting Epoch  433 ...\n",
      "Epoch: 433, batch: 24, loss: 0.5664306390285492\n",
      "Epoch: 433, batch: 74, loss: 0.5627796638011933\n",
      "Epoch: 433, batch: 124, loss: 0.5617087996006012\n",
      "Epoch: 433, batch: 174, loss: 0.5619845163822174\n",
      "Epoch: 433, batch: 224, loss: 0.5624299895763397\n",
      "Epoch: 433, batch: 274, loss: 0.5610285276174545\n",
      "Epoch: 433, batch: 324, loss: 0.561481357216835\n",
      "Epoch: 433, batch: 374, loss: 0.5640098261833191\n",
      "Starting Epoch  434 ...\n",
      "Epoch: 434, batch: 49, loss: 0.5620949280261993\n",
      "Epoch: 434, batch: 99, loss: 0.5608771246671677\n",
      "Epoch: 434, batch: 149, loss: 0.5625110626220703\n",
      "Epoch: 434, batch: 199, loss: 0.5631224042177201\n",
      "Epoch: 434, batch: 249, loss: 0.5633594685792923\n",
      "Epoch: 434, batch: 299, loss: 0.5637375098466874\n",
      "Epoch: 434, batch: 349, loss: 0.5684398794174195\n",
      "Starting Epoch  435 ...\n",
      "Epoch: 435, batch: 24, loss: 0.5673424661159515\n",
      "Epoch: 435, batch: 74, loss: 0.5754927319288253\n",
      "Epoch: 435, batch: 124, loss: 0.5784251946210861\n",
      "Epoch: 435, batch: 174, loss: 0.5651637285947799\n",
      "Epoch: 435, batch: 224, loss: 0.5669074428081512\n",
      "Epoch: 435, batch: 274, loss: 0.5660173958539962\n",
      "Epoch: 435, batch: 324, loss: 0.564180834889412\n",
      "Epoch: 435, batch: 374, loss: 0.5707192575931549\n",
      "Starting Epoch  436 ...\n",
      "Epoch: 436, batch: 49, loss: 0.5674830853939057\n",
      "Epoch: 436, batch: 99, loss: 0.5767042011022567\n",
      "Epoch: 436, batch: 149, loss: 0.5778247880935669\n",
      "Epoch: 436, batch: 199, loss: 0.586629502773285\n",
      "Epoch: 436, batch: 249, loss: 0.5848989760875702\n",
      "Epoch: 436, batch: 299, loss: 0.5691466426849365\n",
      "Epoch: 436, batch: 349, loss: 0.5809241545200348\n",
      "Starting Epoch  437 ...\n",
      "Epoch: 437, batch: 24, loss: 0.5711620014905929\n",
      "Epoch: 437, batch: 74, loss: 0.560282951593399\n",
      "Epoch: 437, batch: 124, loss: 0.5617721933126449\n",
      "Epoch: 437, batch: 174, loss: 0.5609612637758254\n",
      "Epoch: 437, batch: 224, loss: 0.5604454559087754\n",
      "Epoch: 437, batch: 274, loss: 0.5810421198606491\n",
      "Epoch: 437, batch: 324, loss: 0.6307468044757844\n",
      "Epoch: 437, batch: 374, loss: 0.6145473402738572\n",
      "Starting Epoch  438 ...\n",
      "Epoch: 438, batch: 49, loss: 0.5668125969171524\n",
      "Epoch: 438, batch: 99, loss: 0.5629274678230286\n",
      "Epoch: 438, batch: 149, loss: 0.5616746479272843\n",
      "Epoch: 438, batch: 199, loss: 0.5638114041090012\n",
      "Epoch: 438, batch: 249, loss: 0.6021925854682922\n",
      "Epoch: 438, batch: 299, loss: 0.6011278492212295\n",
      "Epoch: 438, batch: 349, loss: 0.5616913485527039\n",
      "Starting Epoch  439 ...\n",
      "Epoch: 439, batch: 24, loss: 0.5605918043851852\n",
      "Epoch: 439, batch: 74, loss: 0.5603599762916565\n",
      "Epoch: 439, batch: 124, loss: 0.5772350800037384\n",
      "Epoch: 439, batch: 174, loss: 0.5776499736309052\n",
      "Epoch: 439, batch: 224, loss: 0.5634555262327194\n",
      "Epoch: 439, batch: 274, loss: 0.565995666384697\n",
      "Epoch: 439, batch: 324, loss: 0.5678644508123398\n",
      "Epoch: 439, batch: 374, loss: 0.5680202502012253\n",
      "Starting Epoch  440 ...\n",
      "Epoch: 440, batch: 49, loss: 0.5625542426109313\n",
      "Epoch: 440, batch: 99, loss: 0.5599593925476074\n",
      "Epoch: 440, batch: 149, loss: 0.5620217317342758\n",
      "Epoch: 440, batch: 199, loss: 0.5629968076944352\n",
      "Epoch: 440, batch: 249, loss: 0.5783623874187469\n",
      "Epoch: 440, batch: 299, loss: 0.592454845905304\n",
      "Epoch: 440, batch: 349, loss: 0.5756467986106872\n",
      "Starting Epoch  441 ...\n",
      "Epoch: 441, batch: 24, loss: 0.570976338982582\n",
      "Epoch: 441, batch: 74, loss: 0.5854709339141846\n",
      "Epoch: 441, batch: 124, loss: 0.5736151230335236\n",
      "Epoch: 441, batch: 174, loss: 0.5602682119607926\n",
      "Epoch: 441, batch: 224, loss: 0.5615364134311676\n",
      "Epoch: 441, batch: 274, loss: 0.5635943222045898\n",
      "Epoch: 441, batch: 324, loss: 0.5633279055356979\n",
      "Epoch: 441, batch: 374, loss: 0.5592603749036789\n",
      "Starting Epoch  442 ...\n",
      "Epoch: 442, batch: 49, loss: 0.5589770692586898\n",
      "Epoch: 442, batch: 99, loss: 0.5608718729019165\n",
      "Epoch: 442, batch: 149, loss: 0.5701795524358749\n",
      "Epoch: 442, batch: 199, loss: 0.5721120858192443\n",
      "Epoch: 442, batch: 249, loss: 0.5677951318025589\n",
      "Epoch: 442, batch: 299, loss: 0.5681299161911011\n",
      "Epoch: 442, batch: 349, loss: 0.5656068927049637\n",
      "Starting Epoch  443 ...\n",
      "Epoch: 443, batch: 24, loss: 0.5615335875749587\n",
      "Epoch: 443, batch: 74, loss: 0.5599124658107758\n",
      "Epoch: 443, batch: 124, loss: 0.6217213904857636\n",
      "Epoch: 443, batch: 174, loss: 0.6383627790212631\n",
      "Epoch: 443, batch: 224, loss: 0.577886946797371\n",
      "Epoch: 443, batch: 274, loss: 0.5598785084486008\n",
      "Epoch: 443, batch: 324, loss: 0.5579182797670365\n",
      "Epoch: 443, batch: 374, loss: 0.5758762419223785\n",
      "Starting Epoch  444 ...\n",
      "Epoch: 444, batch: 49, loss: 0.5786648190021515\n",
      "Epoch: 444, batch: 99, loss: 0.5606899380683898\n",
      "Epoch: 444, batch: 149, loss: 0.559798891544342\n",
      "Epoch: 444, batch: 199, loss: 0.5616620707511902\n",
      "Epoch: 444, batch: 249, loss: 0.5730356913805008\n",
      "Epoch: 444, batch: 299, loss: 0.5711008787155152\n",
      "Epoch: 444, batch: 349, loss: 0.5590454596281051\n",
      "Starting Epoch  445 ...\n",
      "Epoch: 445, batch: 24, loss: 0.559954514503479\n",
      "Epoch: 445, batch: 74, loss: 0.577426398396492\n",
      "Epoch: 445, batch: 124, loss: 0.5775042462348938\n",
      "Epoch: 445, batch: 174, loss: 0.5611838662624359\n",
      "Epoch: 445, batch: 224, loss: 0.5661123543977737\n",
      "Epoch: 445, batch: 274, loss: 0.5654800778627396\n",
      "Epoch: 445, batch: 324, loss: 0.5620525652170181\n",
      "Epoch: 445, batch: 374, loss: 0.5615487909317016\n",
      "Starting Epoch  446 ...\n",
      "Epoch: 446, batch: 49, loss: 0.5599999207258225\n",
      "Epoch: 446, batch: 99, loss: 0.5609478098154068\n",
      "Epoch: 446, batch: 149, loss: 0.5605506670475006\n",
      "Epoch: 446, batch: 199, loss: 0.5606625992059707\n",
      "Epoch: 446, batch: 249, loss: 0.5622387492656707\n",
      "Epoch: 446, batch: 299, loss: 0.5634565407037735\n",
      "Epoch: 446, batch: 349, loss: 0.562919698357582\n",
      "Starting Epoch  447 ...\n",
      "Epoch: 447, batch: 24, loss: 0.5606659835577011\n",
      "Epoch: 447, batch: 74, loss: 0.5613390451669693\n",
      "Epoch: 447, batch: 124, loss: 0.5685723370313644\n",
      "Epoch: 447, batch: 174, loss: 0.5658483231067657\n",
      "Epoch: 447, batch: 224, loss: 0.57636767745018\n",
      "Epoch: 447, batch: 274, loss: 0.5818216645717621\n",
      "Epoch: 447, batch: 324, loss: 0.56822489798069\n",
      "Epoch: 447, batch: 374, loss: 0.629883941411972\n",
      "Starting Epoch  448 ...\n",
      "Epoch: 448, batch: 49, loss: 0.6302077358961106\n",
      "Epoch: 448, batch: 99, loss: 0.5632762598991394\n",
      "Epoch: 448, batch: 149, loss: 0.5583782505989074\n",
      "Epoch: 448, batch: 199, loss: 0.5597806638479232\n",
      "Epoch: 448, batch: 249, loss: 0.5596143364906311\n",
      "Epoch: 448, batch: 299, loss: 0.5603752243518829\n",
      "Epoch: 448, batch: 349, loss: 0.5702368915081024\n",
      "Starting Epoch  449 ...\n",
      "Epoch: 449, batch: 24, loss: 0.569056967496872\n",
      "Epoch: 449, batch: 74, loss: 0.5582555401325225\n",
      "Epoch: 449, batch: 124, loss: 0.5585365337133408\n",
      "Epoch: 449, batch: 174, loss: 0.5600280320644379\n",
      "Epoch: 449, batch: 224, loss: 0.5592579507827758\n",
      "Epoch: 449, batch: 274, loss: 0.5614050984382629\n",
      "Epoch: 449, batch: 324, loss: 0.5621982043981553\n",
      "Epoch: 449, batch: 374, loss: 0.5601051187515259\n",
      "Starting Epoch  450 ...\n",
      "Epoch: 450, batch: 49, loss: 0.5601049792766571\n",
      "Epoch: 450, batch: 99, loss: 0.5608156603574753\n",
      "Epoch: 450, batch: 149, loss: 0.5747968995571137\n",
      "Epoch: 450, batch: 199, loss: 0.5783011925220489\n",
      "Epoch: 450, batch: 249, loss: 0.5807075828313828\n",
      "Epoch: 450, batch: 299, loss: 0.5773367959260941\n",
      "Epoch: 450, batch: 349, loss: 0.5604130470752716\n",
      "Starting Epoch  451 ...\n",
      "Epoch: 451, batch: 24, loss: 0.5587958776950837\n",
      "Epoch: 451, batch: 74, loss: 0.5598711943626404\n",
      "Epoch: 451, batch: 124, loss: 0.5675519841909409\n",
      "Epoch: 451, batch: 174, loss: 0.5709896838665008\n",
      "Epoch: 451, batch: 224, loss: 0.5627354204654693\n",
      "Epoch: 451, batch: 274, loss: 0.5581248593330383\n",
      "Epoch: 451, batch: 324, loss: 0.5830557668209075\n",
      "Epoch: 451, batch: 374, loss: 0.6000567829608917\n",
      "Starting Epoch  452 ...\n",
      "Epoch: 452, batch: 49, loss: 0.5745347481966019\n",
      "Epoch: 452, batch: 99, loss: 0.5576566123962402\n",
      "Epoch: 452, batch: 149, loss: 0.559037812948227\n",
      "Epoch: 452, batch: 199, loss: 0.5582497131824493\n",
      "Epoch: 452, batch: 249, loss: 0.5601749247312546\n",
      "Epoch: 452, batch: 299, loss: 0.561956849694252\n",
      "Epoch: 452, batch: 349, loss: 0.5608869343996048\n",
      "Starting Epoch  453 ...\n",
      "Epoch: 453, batch: 24, loss: 0.561297322511673\n",
      "Epoch: 453, batch: 74, loss: 0.5605756843090057\n",
      "Epoch: 453, batch: 124, loss: 0.5622577178478241\n",
      "Epoch: 453, batch: 174, loss: 0.5622384518384933\n",
      "Epoch: 453, batch: 224, loss: 0.5597732794284821\n",
      "Epoch: 453, batch: 274, loss: 0.5723768836259842\n",
      "Epoch: 453, batch: 324, loss: 0.5726816427707672\n",
      "Epoch: 453, batch: 374, loss: 0.5587362831830979\n",
      "Starting Epoch  454 ...\n",
      "Epoch: 454, batch: 49, loss: 0.5571749079227447\n",
      "Epoch: 454, batch: 99, loss: 0.5596484231948853\n",
      "Epoch: 454, batch: 149, loss: 0.5598360443115235\n",
      "Epoch: 454, batch: 199, loss: 0.5597332376241684\n",
      "Epoch: 454, batch: 249, loss: 0.5630680513381958\n",
      "Epoch: 454, batch: 299, loss: 0.564213376045227\n",
      "Epoch: 454, batch: 349, loss: 0.562396103143692\n",
      "Starting Epoch  455 ...\n",
      "Epoch: 455, batch: 24, loss: 0.5605038291215897\n",
      "Epoch: 455, batch: 74, loss: 0.5796274590492249\n",
      "Epoch: 455, batch: 124, loss: 0.5780609387159348\n",
      "Epoch: 455, batch: 174, loss: 0.5578226542472839\n",
      "Epoch: 455, batch: 224, loss: 0.5596399861574173\n",
      "Epoch: 455, batch: 274, loss: 0.5592104172706605\n",
      "Epoch: 455, batch: 324, loss: 0.558187621831894\n",
      "Epoch: 455, batch: 374, loss: 0.5592380386590957\n",
      "Starting Epoch  456 ...\n",
      "Epoch: 456, batch: 49, loss: 0.5601521861553193\n",
      "Epoch: 456, batch: 99, loss: 0.5636791986227035\n",
      "Epoch: 456, batch: 149, loss: 0.5705559360980987\n",
      "Epoch: 456, batch: 199, loss: 0.5710201787948609\n",
      "Epoch: 456, batch: 249, loss: 0.5691827249526977\n",
      "Epoch: 456, batch: 299, loss: 0.5644043433666229\n",
      "Epoch: 456, batch: 349, loss: 0.5583780807256699\n",
      "Starting Epoch  457 ...\n",
      "Epoch: 457, batch: 24, loss: 0.5582406830787658\n",
      "Epoch: 457, batch: 74, loss: 0.5581608337163925\n",
      "Epoch: 457, batch: 124, loss: 0.5605664122104644\n",
      "Epoch: 457, batch: 174, loss: 0.5628561854362488\n",
      "Epoch: 457, batch: 224, loss: 0.5678758037090301\n",
      "Epoch: 457, batch: 274, loss: 0.6075500559806823\n",
      "Epoch: 457, batch: 324, loss: 0.6001069492101669\n",
      "Epoch: 457, batch: 374, loss: 0.5576171851158143\n",
      "Starting Epoch  458 ...\n",
      "Epoch: 458, batch: 49, loss: 0.5573325401544571\n",
      "Epoch: 458, batch: 99, loss: 0.5644837588071823\n",
      "Epoch: 458, batch: 149, loss: 0.5642801249027252\n",
      "Epoch: 458, batch: 199, loss: 0.5579659348726272\n",
      "Epoch: 458, batch: 249, loss: 0.5589441418647766\n",
      "Epoch: 458, batch: 299, loss: 0.5674236845970154\n",
      "Epoch: 458, batch: 349, loss: 0.578907425403595\n",
      "Starting Epoch  459 ...\n",
      "Epoch: 459, batch: 24, loss: 0.5695984053611756\n",
      "Epoch: 459, batch: 74, loss: 0.556760597229004\n",
      "Epoch: 459, batch: 124, loss: 0.5579042166471482\n",
      "Epoch: 459, batch: 174, loss: 0.5580681782960891\n",
      "Epoch: 459, batch: 224, loss: 0.559369502067566\n",
      "Epoch: 459, batch: 274, loss: 0.5606847828626633\n",
      "Epoch: 459, batch: 324, loss: 0.5747757089138031\n",
      "Epoch: 459, batch: 374, loss: 0.5737520521879196\n",
      "Starting Epoch  460 ...\n",
      "Epoch: 460, batch: 49, loss: 0.5590510869026184\n",
      "Epoch: 460, batch: 99, loss: 0.5713430148363113\n",
      "Epoch: 460, batch: 149, loss: 0.5698818522691727\n",
      "Epoch: 460, batch: 199, loss: 0.5588263827562332\n",
      "Epoch: 460, batch: 249, loss: 0.5598637884855271\n",
      "Epoch: 460, batch: 299, loss: 0.5591276520490647\n",
      "Epoch: 460, batch: 349, loss: 0.559450101852417\n",
      "Starting Epoch  461 ...\n",
      "Epoch: 461, batch: 24, loss: 0.5681090492010117\n",
      "Epoch: 461, batch: 74, loss: 0.5667598658800125\n",
      "Epoch: 461, batch: 124, loss: 0.5594145679473876\n",
      "Epoch: 461, batch: 174, loss: 0.5584968096017837\n",
      "Epoch: 461, batch: 224, loss: 0.5714980638027192\n",
      "Epoch: 461, batch: 274, loss: 0.5727852684259415\n",
      "Epoch: 461, batch: 324, loss: 0.5591939663887024\n",
      "Epoch: 461, batch: 374, loss: 0.5595514565706253\n",
      "Starting Epoch  462 ...\n",
      "Epoch: 462, batch: 49, loss: 0.5616282546520233\n",
      "Epoch: 462, batch: 99, loss: 0.5610845172405243\n",
      "Epoch: 462, batch: 149, loss: 0.5581886076927185\n",
      "Epoch: 462, batch: 199, loss: 0.5595175629854202\n",
      "Epoch: 462, batch: 249, loss: 0.5979758268594741\n",
      "Epoch: 462, batch: 299, loss: 0.6317204862833024\n",
      "Epoch: 462, batch: 349, loss: 0.5972764313220977\n",
      "Starting Epoch  463 ...\n",
      "Epoch: 463, batch: 24, loss: 0.5638268250226974\n",
      "Epoch: 463, batch: 74, loss: 0.561631755232811\n",
      "Epoch: 463, batch: 124, loss: 0.5619117116928101\n",
      "Epoch: 463, batch: 174, loss: 0.5610005050897598\n",
      "Epoch: 463, batch: 224, loss: 0.5595593947172165\n",
      "Epoch: 463, batch: 274, loss: 0.5641472655534744\n",
      "Epoch: 463, batch: 324, loss: 0.5648999029397964\n",
      "Epoch: 463, batch: 374, loss: 0.5592983913421631\n",
      "Starting Epoch  464 ...\n",
      "Epoch: 464, batch: 49, loss: 0.57261505484581\n",
      "Epoch: 464, batch: 99, loss: 0.5730121755599975\n",
      "Epoch: 464, batch: 149, loss: 0.5584129083156586\n",
      "Epoch: 464, batch: 199, loss: 0.5690419816970825\n",
      "Epoch: 464, batch: 249, loss: 0.598347716331482\n",
      "Epoch: 464, batch: 299, loss: 0.5862486284971237\n",
      "Epoch: 464, batch: 349, loss: 0.5568072140216828\n",
      "Starting Epoch  465 ...\n",
      "Epoch: 465, batch: 24, loss: 0.5570486921072006\n",
      "Epoch: 465, batch: 74, loss: 0.5578845131397248\n",
      "Epoch: 465, batch: 124, loss: 0.5587363082170487\n",
      "Epoch: 465, batch: 174, loss: 0.5591233718395233\n",
      "Epoch: 465, batch: 224, loss: 0.5585180765390396\n",
      "Epoch: 465, batch: 274, loss: 0.5569359874725341\n",
      "Epoch: 465, batch: 324, loss: 0.5633181852102279\n",
      "Epoch: 465, batch: 374, loss: 0.5649619543552399\n",
      "Starting Epoch  466 ...\n",
      "Epoch: 466, batch: 49, loss: 0.557346715927124\n",
      "Epoch: 466, batch: 99, loss: 0.5640504974126815\n",
      "Epoch: 466, batch: 149, loss: 0.5857533103227616\n",
      "Epoch: 466, batch: 199, loss: 0.5781625890731812\n",
      "Epoch: 466, batch: 249, loss: 0.5602087289094925\n",
      "Epoch: 466, batch: 299, loss: 0.5596224069595337\n",
      "Epoch: 466, batch: 349, loss: 0.5587817388772964\n",
      "Starting Epoch  467 ...\n",
      "Epoch: 467, batch: 24, loss: 0.558788126707077\n",
      "Epoch: 467, batch: 74, loss: 0.5712465196847916\n",
      "Epoch: 467, batch: 124, loss: 0.5720648789405822\n",
      "Epoch: 467, batch: 174, loss: 0.559154685139656\n",
      "Epoch: 467, batch: 224, loss: 0.5569512474536896\n",
      "Epoch: 467, batch: 274, loss: 0.5866600275039673\n",
      "Epoch: 467, batch: 324, loss: 0.6051358437538147\n",
      "Epoch: 467, batch: 374, loss: 0.5739994078874588\n",
      "Starting Epoch  468 ...\n",
      "Epoch: 468, batch: 49, loss: 0.556763020157814\n",
      "Epoch: 468, batch: 99, loss: 0.5564892947673797\n",
      "Epoch: 468, batch: 149, loss: 0.5561215764284134\n",
      "Epoch: 468, batch: 199, loss: 0.5703735470771789\n",
      "Epoch: 468, batch: 249, loss: 0.5734948718547821\n",
      "Epoch: 468, batch: 299, loss: 0.5597376853227616\n",
      "Epoch: 468, batch: 349, loss: 0.5571714103221893\n",
      "Starting Epoch  469 ...\n",
      "Epoch: 469, batch: 24, loss: 0.5584040123224259\n",
      "Epoch: 469, batch: 74, loss: 0.5585493433475495\n",
      "Epoch: 469, batch: 124, loss: 0.5576003879308701\n",
      "Epoch: 469, batch: 174, loss: 0.565718618631363\n",
      "Epoch: 469, batch: 224, loss: 0.5685068571567535\n",
      "Epoch: 469, batch: 274, loss: 0.5588172751665116\n",
      "Epoch: 469, batch: 324, loss: 0.555921597480774\n",
      "Epoch: 469, batch: 374, loss: 0.5686748391389846\n",
      "Starting Epoch  470 ...\n",
      "Epoch: 470, batch: 49, loss: 0.5935930222272873\n",
      "Epoch: 470, batch: 99, loss: 0.5818221265077591\n",
      "Epoch: 470, batch: 149, loss: 0.5565176141262055\n",
      "Epoch: 470, batch: 199, loss: 0.5580138975381851\n",
      "Epoch: 470, batch: 249, loss: 0.5584127128124237\n",
      "Epoch: 470, batch: 299, loss: 0.5587092643976211\n",
      "Epoch: 470, batch: 349, loss: 0.5672356671094895\n",
      "Starting Epoch  471 ...\n",
      "Epoch: 471, batch: 24, loss: 0.5694723576307297\n",
      "Epoch: 471, batch: 74, loss: 0.563838758468628\n",
      "Epoch: 471, batch: 124, loss: 0.5592748540639877\n",
      "Epoch: 471, batch: 174, loss: 0.5576412218809128\n",
      "Epoch: 471, batch: 224, loss: 0.5666446632146835\n",
      "Epoch: 471, batch: 274, loss: 0.5651573294401169\n",
      "Epoch: 471, batch: 324, loss: 0.556586075425148\n",
      "Epoch: 471, batch: 374, loss: 0.5568660098314285\n",
      "Starting Epoch  472 ...\n",
      "Epoch: 472, batch: 49, loss: 0.57555934548378\n",
      "Epoch: 472, batch: 99, loss: 0.575754389166832\n",
      "Epoch: 472, batch: 149, loss: 0.5570724987983704\n",
      "Epoch: 472, batch: 199, loss: 0.5631359881162643\n",
      "Epoch: 472, batch: 249, loss: 0.5631940865516663\n",
      "Epoch: 472, batch: 299, loss: 0.5681564402580261\n",
      "Epoch: 472, batch: 349, loss: 0.5681362825632096\n",
      "Starting Epoch  473 ...\n",
      "Epoch: 473, batch: 24, loss: 0.5558342665433884\n",
      "Epoch: 473, batch: 74, loss: 0.5564309102296829\n",
      "Epoch: 473, batch: 124, loss: 0.5576978617906571\n",
      "Epoch: 473, batch: 174, loss: 0.5683352082967759\n",
      "Epoch: 473, batch: 224, loss: 0.5687313294410705\n",
      "Epoch: 473, batch: 274, loss: 0.5580209624767304\n",
      "Epoch: 473, batch: 324, loss: 0.5563466936349869\n",
      "Epoch: 473, batch: 374, loss: 0.5669766277074814\n",
      "Starting Epoch  474 ...\n",
      "Epoch: 474, batch: 49, loss: 0.5694152182340622\n",
      "Epoch: 474, batch: 99, loss: 0.5575962573289871\n",
      "Epoch: 474, batch: 149, loss: 0.5571917200088501\n",
      "Epoch: 474, batch: 199, loss: 0.5590209788084031\n",
      "Epoch: 474, batch: 249, loss: 0.5584676861763\n",
      "Epoch: 474, batch: 299, loss: 0.5701551270484925\n",
      "Epoch: 474, batch: 349, loss: 0.5699065572023392\n",
      "Starting Epoch  475 ...\n",
      "Epoch: 475, batch: 24, loss: 0.5580104690790176\n",
      "Epoch: 475, batch: 74, loss: 0.5573073965311051\n",
      "Epoch: 475, batch: 124, loss: 0.5571579319238663\n",
      "Epoch: 475, batch: 174, loss: 0.5571701377630234\n",
      "Epoch: 475, batch: 224, loss: 0.5659505331516266\n",
      "Epoch: 475, batch: 274, loss: 0.5655041527748108\n",
      "Epoch: 475, batch: 324, loss: 0.5554449737071991\n",
      "Epoch: 475, batch: 374, loss: 0.5935527747869491\n",
      "Starting Epoch  476 ...\n",
      "Epoch: 476, batch: 49, loss: 0.6384136593341827\n",
      "Epoch: 476, batch: 99, loss: 0.6041274309158325\n",
      "Epoch: 476, batch: 149, loss: 0.5612925893068313\n",
      "Epoch: 476, batch: 199, loss: 0.557964664697647\n",
      "Epoch: 476, batch: 249, loss: 0.5572017115354538\n",
      "Epoch: 476, batch: 299, loss: 0.5601557689905167\n",
      "Epoch: 476, batch: 349, loss: 0.5686432522535324\n",
      "Starting Epoch  477 ...\n",
      "Epoch: 477, batch: 24, loss: 0.564842723608017\n",
      "Epoch: 477, batch: 74, loss: 0.5569765919446945\n",
      "Epoch: 477, batch: 124, loss: 0.5580648809671402\n",
      "Epoch: 477, batch: 174, loss: 0.5565848928689957\n",
      "Epoch: 477, batch: 224, loss: 0.5999102199077606\n",
      "Epoch: 477, batch: 274, loss: 0.6038221496343613\n",
      "Epoch: 477, batch: 324, loss: 0.5590423399209976\n",
      "Epoch: 477, batch: 374, loss: 0.5545570534467698\n",
      "Starting Epoch  478 ...\n",
      "Epoch: 478, batch: 49, loss: 0.5680753535032272\n",
      "Epoch: 478, batch: 99, loss: 0.5688082551956177\n",
      "Epoch: 478, batch: 149, loss: 0.5619598358869553\n",
      "Epoch: 478, batch: 199, loss: 0.5651486456394196\n",
      "Epoch: 478, batch: 249, loss: 0.5585121971368789\n",
      "Epoch: 478, batch: 299, loss: 0.5635101860761642\n",
      "Epoch: 478, batch: 349, loss: 0.5636898106336594\n",
      "Starting Epoch  479 ...\n",
      "Epoch: 479, batch: 24, loss: 0.5543568164110184\n",
      "Epoch: 479, batch: 74, loss: 0.5569808787107468\n",
      "Epoch: 479, batch: 124, loss: 0.562951831817627\n",
      "Epoch: 479, batch: 174, loss: 0.5944716513156891\n",
      "Epoch: 479, batch: 224, loss: 0.5909693205356598\n",
      "Epoch: 479, batch: 274, loss: 0.557243533730507\n",
      "Epoch: 479, batch: 324, loss: 0.5568525600433349\n",
      "Epoch: 479, batch: 374, loss: 0.5575295960903168\n",
      "Starting Epoch  480 ...\n",
      "Epoch: 480, batch: 49, loss: 0.5553710806369782\n",
      "Epoch: 480, batch: 99, loss: 0.5552027988433837\n",
      "Epoch: 480, batch: 149, loss: 0.5553039187192916\n",
      "Epoch: 480, batch: 199, loss: 0.5639644938707352\n",
      "Epoch: 480, batch: 249, loss: 0.5674199968576431\n",
      "Epoch: 480, batch: 299, loss: 0.5610029995441437\n",
      "Epoch: 480, batch: 349, loss: 0.5582298964262009\n",
      "Starting Epoch  481 ...\n",
      "Epoch: 481, batch: 24, loss: 0.5555906969308854\n",
      "Epoch: 481, batch: 74, loss: 0.5616207510232926\n",
      "Epoch: 481, batch: 124, loss: 0.5616180038452149\n",
      "Epoch: 481, batch: 174, loss: 0.5556528156995774\n",
      "Epoch: 481, batch: 224, loss: 0.5548489826917649\n",
      "Epoch: 481, batch: 274, loss: 0.5561277407407761\n",
      "Epoch: 481, batch: 324, loss: 0.557460178732872\n",
      "Epoch: 481, batch: 374, loss: 0.5568149530887604\n",
      "Starting Epoch  482 ...\n",
      "Epoch: 482, batch: 49, loss: 0.5650986546278\n",
      "Epoch: 482, batch: 99, loss: 0.5977487367391586\n",
      "Epoch: 482, batch: 149, loss: 0.5900002270936966\n",
      "Epoch: 482, batch: 199, loss: 0.5551246207952499\n",
      "Epoch: 482, batch: 249, loss: 0.5534910231828689\n",
      "Epoch: 482, batch: 299, loss: 0.5792079085111618\n",
      "Epoch: 482, batch: 349, loss: 0.5881654250621796\n",
      "Starting Epoch  483 ...\n",
      "Epoch: 483, batch: 24, loss: 0.5636994302272796\n",
      "Epoch: 483, batch: 74, loss: 0.5550708097219467\n",
      "Epoch: 483, batch: 124, loss: 0.5567761754989624\n",
      "Epoch: 483, batch: 174, loss: 0.5574336951971054\n",
      "Epoch: 483, batch: 224, loss: 0.5666078716516495\n",
      "Epoch: 483, batch: 274, loss: 0.564953526854515\n",
      "Epoch: 483, batch: 324, loss: 0.5555112272500992\n",
      "Epoch: 483, batch: 374, loss: 0.5559724420309067\n",
      "Starting Epoch  484 ...\n",
      "Epoch: 484, batch: 49, loss: 0.5623686838150025\n",
      "Epoch: 484, batch: 99, loss: 0.5779760527610779\n",
      "Epoch: 484, batch: 149, loss: 0.5695657473802567\n",
      "Epoch: 484, batch: 199, loss: 0.555041236281395\n",
      "Epoch: 484, batch: 249, loss: 0.5563295871019364\n",
      "Epoch: 484, batch: 299, loss: 0.5564664369821548\n",
      "Epoch: 484, batch: 349, loss: 0.5563276576995849\n",
      "Starting Epoch  485 ...\n",
      "Epoch: 485, batch: 24, loss: 0.5729738879203796\n",
      "Epoch: 485, batch: 74, loss: 0.5725325566530227\n",
      "Epoch: 485, batch: 124, loss: 0.5645844495296478\n",
      "Epoch: 485, batch: 174, loss: 0.5646006512641907\n",
      "Epoch: 485, batch: 224, loss: 0.5549935877323151\n",
      "Epoch: 485, batch: 274, loss: 0.5561206996440887\n",
      "Epoch: 485, batch: 324, loss: 0.5574032735824584\n",
      "Epoch: 485, batch: 374, loss: 0.5558234256505966\n",
      "Starting Epoch  486 ...\n",
      "Epoch: 486, batch: 49, loss: 0.5560874128341675\n",
      "Epoch: 486, batch: 99, loss: 0.5773286896944047\n",
      "Epoch: 486, batch: 149, loss: 0.5778909814357758\n",
      "Epoch: 486, batch: 199, loss: 0.5599197942018509\n",
      "Epoch: 486, batch: 249, loss: 0.5573642373085022\n",
      "Epoch: 486, batch: 299, loss: 0.5653969407081604\n",
      "Epoch: 486, batch: 349, loss: 0.565966232419014\n",
      "Starting Epoch  487 ...\n",
      "Epoch: 487, batch: 24, loss: 0.5589424681663513\n",
      "Epoch: 487, batch: 74, loss: 0.560822075009346\n",
      "Epoch: 487, batch: 124, loss: 0.556982411146164\n",
      "Epoch: 487, batch: 174, loss: 0.5533271491527557\n",
      "Epoch: 487, batch: 224, loss: 0.5670904809236527\n",
      "Epoch: 487, batch: 274, loss: 0.5688269692659378\n",
      "Epoch: 487, batch: 324, loss: 0.5594201076030731\n",
      "Epoch: 487, batch: 374, loss: 0.5640175318717957\n",
      "Starting Epoch  488 ...\n",
      "Epoch: 488, batch: 49, loss: 0.5600323647260665\n",
      "Epoch: 488, batch: 99, loss: 0.5558860784769059\n",
      "Epoch: 488, batch: 149, loss: 0.555583866238594\n",
      "Epoch: 488, batch: 199, loss: 0.5640102660655976\n",
      "Epoch: 488, batch: 249, loss: 0.5651879918575287\n",
      "Epoch: 488, batch: 299, loss: 0.5563555991649628\n",
      "Epoch: 488, batch: 349, loss: 0.55513228058815\n",
      "Starting Epoch  489 ...\n",
      "Epoch: 489, batch: 24, loss: 0.5625808352231979\n",
      "Epoch: 489, batch: 74, loss: 0.5631805092096329\n",
      "Epoch: 489, batch: 124, loss: 0.5566983187198639\n",
      "Epoch: 489, batch: 174, loss: 0.5555992358922959\n",
      "Epoch: 489, batch: 224, loss: 0.5565226292610168\n",
      "Epoch: 489, batch: 274, loss: 0.5567820262908936\n",
      "Epoch: 489, batch: 324, loss: 0.555755854845047\n",
      "Epoch: 489, batch: 374, loss: 0.5607932513952255\n",
      "Starting Epoch  490 ...\n",
      "Epoch: 490, batch: 49, loss: 0.5669069641828537\n",
      "Epoch: 490, batch: 99, loss: 0.5608758115768433\n",
      "Epoch: 490, batch: 149, loss: 0.5594118797779083\n",
      "Epoch: 490, batch: 199, loss: 0.5709021234512329\n",
      "Epoch: 490, batch: 249, loss: 0.5641687726974487\n",
      "Epoch: 490, batch: 299, loss: 0.554533924460411\n",
      "Epoch: 490, batch: 349, loss: 0.5553022557497025\n",
      "Starting Epoch  491 ...\n",
      "Epoch: 491, batch: 24, loss: 0.555188068151474\n",
      "Epoch: 491, batch: 74, loss: 0.5588625490665435\n",
      "Epoch: 491, batch: 124, loss: 0.5734745436906814\n",
      "Epoch: 491, batch: 174, loss: 0.5705970823764801\n",
      "Epoch: 491, batch: 224, loss: 0.5557159531116486\n",
      "Epoch: 491, batch: 274, loss: 0.556234113574028\n",
      "Epoch: 491, batch: 324, loss: 0.5555891919136048\n",
      "Epoch: 491, batch: 374, loss: 0.5772180789709092\n",
      "Starting Epoch  492 ...\n",
      "Epoch: 492, batch: 49, loss: 0.5820904511213303\n",
      "Epoch: 492, batch: 99, loss: 0.5593025016784668\n",
      "Epoch: 492, batch: 149, loss: 0.5590771627426148\n",
      "Epoch: 492, batch: 199, loss: 0.5631623697280884\n",
      "Epoch: 492, batch: 249, loss: 0.558417375087738\n",
      "Epoch: 492, batch: 299, loss: 0.5542558854818345\n",
      "Epoch: 492, batch: 349, loss: 0.5579987144470215\n",
      "Starting Epoch  493 ...\n",
      "Epoch: 493, batch: 24, loss: 0.5587682056427002\n",
      "Epoch: 493, batch: 74, loss: 0.5556950652599335\n",
      "Epoch: 493, batch: 124, loss: 0.5540895175933838\n",
      "Epoch: 493, batch: 174, loss: 0.553548778295517\n",
      "Epoch: 493, batch: 224, loss: 0.5548869985342025\n",
      "Epoch: 493, batch: 274, loss: 0.5559688073396682\n",
      "Epoch: 493, batch: 324, loss: 0.5604365533590316\n",
      "Epoch: 493, batch: 374, loss: 0.5662573885917663\n",
      "Starting Epoch  494 ...\n",
      "Epoch: 494, batch: 49, loss: 0.5659863168001175\n",
      "Epoch: 494, batch: 99, loss: 0.5586692357063293\n",
      "Epoch: 494, batch: 149, loss: 0.5543094074726105\n",
      "Epoch: 494, batch: 199, loss: 0.568341634273529\n",
      "Epoch: 494, batch: 249, loss: 0.5678708702325821\n",
      "Epoch: 494, batch: 299, loss: 0.5589100927114486\n",
      "Epoch: 494, batch: 349, loss: 0.5637305957078934\n",
      "Starting Epoch  495 ...\n",
      "Epoch: 495, batch: 24, loss: 0.5602239859104157\n",
      "Epoch: 495, batch: 74, loss: 0.5539497935771942\n",
      "Epoch: 495, batch: 124, loss: 0.5548692178726197\n",
      "Epoch: 495, batch: 174, loss: 0.5633078908920288\n",
      "Epoch: 495, batch: 224, loss: 0.563342833518982\n",
      "Epoch: 495, batch: 274, loss: 0.5555654454231262\n",
      "Epoch: 495, batch: 324, loss: 0.5542164748907089\n",
      "Epoch: 495, batch: 374, loss: 0.5564960533380509\n",
      "Starting Epoch  496 ...\n",
      "Epoch: 496, batch: 49, loss: 0.5666139137744903\n",
      "Epoch: 496, batch: 99, loss: 0.5639188617467881\n",
      "Epoch: 496, batch: 149, loss: 0.5539327836036683\n",
      "Epoch: 496, batch: 199, loss: 0.5549794346094131\n",
      "Epoch: 496, batch: 249, loss: 0.5547159695625306\n",
      "Epoch: 496, batch: 299, loss: 0.5652594369649887\n",
      "Epoch: 496, batch: 349, loss: 0.5791543006896973\n",
      "Starting Epoch  497 ...\n",
      "Epoch: 497, batch: 24, loss: 0.5682643741369248\n",
      "Epoch: 497, batch: 74, loss: 0.5597670084238052\n",
      "Epoch: 497, batch: 124, loss: 0.560583324432373\n",
      "Epoch: 497, batch: 174, loss: 0.553183440566063\n",
      "Epoch: 497, batch: 224, loss: 0.5538016271591186\n",
      "Epoch: 497, batch: 274, loss: 0.5614544016122818\n",
      "Epoch: 497, batch: 324, loss: 0.5792394369840622\n",
      "Epoch: 497, batch: 374, loss: 0.5721315485239029\n",
      "Starting Epoch  498 ...\n",
      "Epoch: 498, batch: 49, loss: 0.551863796710968\n",
      "Epoch: 498, batch: 99, loss: 0.5529485255479812\n",
      "Epoch: 498, batch: 149, loss: 0.5542657631635666\n",
      "Epoch: 498, batch: 199, loss: 0.5539922177791595\n",
      "Epoch: 498, batch: 249, loss: 0.5539805096387863\n",
      "Epoch: 498, batch: 299, loss: 0.5573529559373855\n",
      "Epoch: 498, batch: 349, loss: 0.5578252011537552\n",
      "Starting Epoch  499 ...\n",
      "Epoch: 499, batch: 24, loss: 0.5648834991455078\n",
      "Epoch: 499, batch: 74, loss: 0.5662029224634171\n",
      "Epoch: 499, batch: 124, loss: 0.5882247114181518\n",
      "Epoch: 499, batch: 174, loss: 0.5877280533313751\n",
      "Epoch: 499, batch: 224, loss: 0.5542369109392166\n",
      "Epoch: 499, batch: 274, loss: 0.5548040038347244\n",
      "Epoch: 499, batch: 324, loss: 0.5575458389520646\n",
      "Epoch: 499, batch: 374, loss: 0.5555640470981598\n"
     ]
    }
   ],
   "source": [
    "model, losses = train(\"pixel_cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbb184ee7f0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApIAAAHTCAYAAACUZPgyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHXklEQVR4nO3dd3xb1f3/8bdkO86ysyEJIQtiJzg7gSQmZDFbAm1aKG0ZTUPhy/i1pVBG+6XwTUohlFHKKAXK3pRZRoBQCAGyE2c7w1l2tme8l3R+fziWJc8r5cqKr17Px4NHZOle6fjDtfTWueec6zLGGAEAAABBcke6AQAAAGibCJIAAAAICUESAAAAISFIAgAAICQESQAAAISEIAkAAICQECQBAAAQEoIkAAAAQkKQBAAAQEhiI/Gi2dlFrfZabrdL3bt3Ul5eibxeLuLTHGplHbWyjlpZR62CQ72so1bWUas6vXoltLiN43sk3W6XXC6X3G5XpJty3KNW1lEr66iVddQqONTLOmplHbUKjuODJAAAAMKDIAkAAICQECQBAAAQEoIkAAAAQkKQBAAAQEgIkgAAAAgJQRIAAAAhIUgCAAAgJARJAAAAhIQgCQAAgJAQJAEAABASgiQAAABCQpAEAABASAiSAAAACAlBEgAAACFxfJAsKq2Ux2si3QwAAADHcXSQ3LH/iH7zyDe685/fRbopAAAAjuPoILlzX6E8XqONO3JlDL2SAAAAdnJ0kHS56m4TIwEAAOzl8CBZlyTpkQQAALCXo4Ok210XJL3eCDYEAADAgRwdJANObdMjCQAAYCtHB0l3wKntCDYEAADAgRwdJP17JL0kSQAAAFs5Okj690gSJAEAAOzl6CAZOEYycu0AAABwIkcHyYAeSS6TCAAAYCtHB0nWkQQAAAgfhwfJutvkSAAAAHs5Okgy2QYAACB8HB0kXQFBMoINAQAAcCBHB0m332/HGEkAAAB7OTpIupi1DQAAEDaODpJu/8k2kWsGAACAIzk8SLL8DwAAQLg4OkhyahsAACB8HB4k627TIQkAAGAvRwdJ1pEEAAAIH0cHSf8eSYIkAACAvRweJP0n20SwIQAAAA7k6CDpdjNrGwAAIFwcHSQDTm17I9cOAAAAJ3J0kGQdSQAAgPCJmiDJMpIAAAD2cnSQDFxHkiQJAABgJ0cHSdaRBAAACB9HB8nAyTYESQAAADs5OkgGJEkAAADYytFBkhgJAAAQPo4Okv4YIgkAAGAvRwfJgFnbkWsGAACAIzk6SAYiSgIAANjJ0UHSFXBlmwg2BAAAwIEcHSQBAAAQPo4OkszaBgAACB9HB0kFXCIxcs0AAABwIkcHSf8eScNkGwAAAFs5OkgCAAAgfJwdJFlIEgAAIGwcHSQDT20DAADATrHBbPzYY4/p8ccfD7hv0KBB+vTTT21tlF0CgiSzbQAAAGwVVJCUpCFDhuj555/3/RwTE2NrgwAAANA2BB0kY2Ji1KtXr3C0xX4sJAkAABA2QQfJPXv2aPLkyYqPj9fo0aN1yy23qG/fvkE9h9vtktsd/pQXG1vXW+pyuRQb6+ghoccsJsYd8C+aRq2so1bWUavgUC/rqJV11Co4LhPE4MGvv/5apaWlGjRokLKzs/XEE0/o0KFD+vDDD9W5c2fLL2qMCbgOdrhk55dpzj2fS5L+8IvTlToyuMALAACApgXVIzl16lTf7aFDh2rUqFGaPn26FixYoEsvvdTy8+TllbRKj2RhYbnvdmlppfLzS8L+mm1ZTIxbiYkdVFhYJo/HG+nmHNeolXXUyjpqFRzqZR21so5a1enWrVOL2wR9attfYmKiBg4cqMzMzKD283qNvN7wz6Kurq47ADxeb8DPaJrHQ62solbWUSvrqFVwqJd11Mo6amXNMQ0AKCkpUVZW1nE7+aY1Tp8DAABEq6B6JO+//35Nnz5dffv21eHDh/XYY4/J7XZr5syZ4WqffVhGEgAAwFZBBcmDBw/q5ptvVkFBgbp3765x48bprbfeUvfu3cPVvmPCFRIBAADCJ6gg+be//S1c7Qg7rmwDAABgL0cvksQISQAAgPBxdJAUk20AAADCxtFB0j9GcmYbAADAXo4Okv7IkQAAAPZydpCkSxIAACBsHB0kGSEJAAAQPs4Okn6TbeiPBAAAsJejg2QAkiQAAICtoiZIGpIkAACArRwdJAMukUiOBAAAsJWzg2SkGwAAAOBgjg6SREkAAIDwcXiQrMOpbQAAAHs5OkgGjJFksg0AAICtHB0kA5AjAQAAbOXoIOliiCQAAEDYODpI+qNDEgAAwF6ODpIuZm0DAACEjaODpD9mbQMAANjL2UGSDkkAAICwcXaQDECXJAAAgJ0cHSTpkAQAAAgfRwdJf4yRBAAAsJejgyTrSAIAAISPo4MkAAAAwsfhQZIuSQAAgHBxeJCswxBJAAAAezk6SDJGEgAAIHwcHST9GaZtAwAA2CpqgiQAAADsRZAEAABASBwdJBkjCQAAED6ODpL+GCIJAABgL0cHSRfrSAIAAISNo4OkP8NKkgAAALZydpCkQxIAACBsnB0k/dEhCQAAYCtHB0k6JAEAAMLH0UHSHx2SAAAA9nJ0kHSxkCQAAEDYODpI+mMdSQAAAHtFTZAEAACAvaIoSNIlCQAAYCfHB0lGSQIAAISH44NkbZJkjCQAAIC9nB8kAQAAEBaOD5IuTm4DAACEheODJAAAAMLD8UHSxRhJAACAsHB8kAQAAEB4RE2QNKwjCQAAYKuoCZIAAACwl+ODZO0YSTokAQAA7OX4IAkAAIDwcHyQrF1Hkg5JAAAAezk+SAIAACA8nB8kWUcSAAAgLJwfJAEAABAWjg+SdVfapksSAADATo4PkgAAAAgP5wdJxkgCAACEhfODJAAAAMLC8UHS5TdKEgAAAPZxfJCsZTi3DQAAYCvHB0kXHZIAAABh4fggWYv+SAAAAHtFTZAEAACAvaInSNIlCQAAYKtjCpJPP/20kpOT9Ze//MWu9tiOMZIAAADhEXKQXL9+vd544w0lJyfb2Z6woUMSAADAXiEFyZKSEt16662655571KVLF7vbZCvWkQQAAAiP2FB2mjdvnqZOnarU1FQ9+eSTQe/vdrvkdrduwHO5pNjY6BkSGoqYGHfAv2gatbKOWllHrYJDvayjVtZRq+AEHSQ//vhjbd68WW+//XbIL9q9eye5WmnwoutoYI2Pj1O3bp1a5TXbusTEDpFuQptBrayjVtZRq+BQL+uolXXUypqgguSBAwf0l7/8Rc8995zi4+NDftG8vJJW65GsvaJNeXmV8vNLWuU126qYGLcSEzuosLBMHo830s05rlEr66iVddQqONTLOmplHbWqY6UDLqgguWnTJuXm5upHP/qR7z6Px6OVK1fq1Vdf1YYNGxQTE9Pi83i9Rl5v60x/qY2rxhhVV0f3AWGVx+OlVhZRK+uolXXUKjjUyzpqZR21siaoIDlx4kR9+OGHAff94Q9/0ODBg3XNNddYCpGRwqW2AQAA7BVUkOzcubOSkpIC7uvYsaO6du3a4P7jBgtJAgAAhIXjpyT5Tm1HtBUAAADOE9LyP/5efvllO9oBAACANsb5PZJ1s20i2g4AAACncXyQBAAAQHhETZCkPxIAAMBeURMkAQAAYC/HB0nfpRjpkgQAALCV44MkAAAAwsPxQZJ1JAEAAMLD8UESAAAA4eH8IOkbIkmfJAAAgJ2cHyQBAAAQFo4PkrVjJOmQBAAAsJfjgyQAAADCw/FBsnYdSTokAQAA7OX4IAkAAIDwiJogaeiSBAAAsFXUBEkAAADYy/FB0jdrm1GSAAAAtnJ8kAQAAEB4OD9I1l7Zhg5JAAAAWzk/SAIAACAsHB8kXWIdSQAAgHBwfJAEAABAeDg+SLpqp20zSBIAAMBWjg+SAAAACI+oCZL0RwIAANgraoIkAAAA7OX4IOmqHSRJlyQAAICtHB8kAQAAEB6OD5K+SdsRbQUAAIDzOD5I+pIkAAAAbOX8IHmUYR1JAAAAWzk+SNIhCQAAEB6OD5IAAAAID+cHSRd9kgAAAOHg/CB5FEMkAQAA7OX4IMnyPwAAAOHh+CAJAACA8HB8kPQNkeTcNgAAgK0cHyQBAAAQHlETJOmPBAAAsFfUBEkAAADYy/FB0lU7SJIuSQAAAFs5PkgCAAAgPBwfJFlHEgAAIDwcHyQBAAAQHs4PkrVDJFlHEgAAwFbOD5IAAAAIC8cHSVfLmwAAACAEjg+SAAAACA/HB8nadSQZIgkAAGAvxwdJAAAAhEfUBEnDSpIAAAC2ipogCQAAAHs5Pki6uLQNAABAWDg+SAIAACA8oiZI0iEJAABgr6gJkgAAALCX44Mk60gCAACEh+ODJAAAAMLD8UGy7lrbdEkCAADYyfFBEgAAAOHh/CB5tEuSMZIAAAD2cnyQdPmd3AYAAIB9HB8kAQAAEB6OD5IuOiQBAADCwvFBshZjJAEAAOwVNUESAAAA9ooNZuPXXntNr7/+uvbt2ydJGjJkiG644QZNnTo1LI2zk2EdSQAAAFsFFSR79+6t3//+9xowYICMMXr//fd144036r333tOQIUPC1cZjwhhJAACA8AgqSM6YMSPg59/97nd6/fXXtXbt2uM2SPrQIQkAAGCroIKkP4/Ho08//VSlpaUaM2ZMUPu63S653a3TVeg62iXpcrsUG8uQ0ObExLgD/kXTqJV11Mo6ahUc6mUdtbKOWgUn6CC5detW/fSnP1VFRYU6duyoJ554QqeeempQz9G9eydfwAu32gMhNjZG3bp1apXXbOsSEztEugltBrWyjlpZR62CQ72so1bWUStrgg6SgwYN0vvvv6+ioiJ99tlnuv322/XKK68EFSbz8kparUfS6/FKkqqqPMrPL2mV12yrYmLcSkzsoMLCMnmO1g2No1bWUSvrqFVwqJd11Mo6alXHSgdc0EGyXbt2GjBggCRp+PDh2rBhg1566SXNmzfP8nN4vUZeb+sMWqx9Fa8xqq6O7gPCKo/HS60solbWUSvrqFVwqJd11Mo6amXNMQ8A8Hq9qqystKMtYcGkbQAAgPAIqkfyoYce0pQpU9SnTx+VlJToo48+0ooVK/Tss8+Gq3324dI2AAAAtgoqSObm5ur222/X4cOHlZCQoOTkZD377LM688wzw9U+AAAAHKeCCpL33ntvuNoRdvRHAgAA2MvxiyS11jJDAAAA0cbxQdKHLkkAAABbOT5I0h8JAAAQHo4PkrUMXZIAAAC2cn6QpEsSAAAgLJwfJI9iGUkAAAB7OT5I0iEJAAAQHo4PkgAAAAgPxwdJ1pEEAAAID8cHyVqMkQQAALBX9ARJlv8BAACwVdQESQAAANjL8UHSN0SSDkkAAABbOT5IAgAAIDyiIEjWdEnSIQkAAGAvxwdJVv8BAAAID8cHyVos/wMAAGAvxwdJOiQBAADCw/FBsg5dkgAAAHZyfpCkSxIAACAsnB8kj2KMJAAAgL0cHyQLSyolSbmF5RFuCQAAgLM4PkhmHiqWJO3LLolwSwAAAJzF8UESAAAA4eH4IDl+aC9JUnL/rpFtCAAAgMM4Pki6ai+RyGQbAAAAWzk/SB5d/seQJAEAAGzl+CBZmySJkQAAAPZyfJCs/QXpkAQAALCX44OkOLUNAAAQFo4Pkm4X10gEAAAIB8cHyVpeeiQBAABs5fgg6fJN245sOwAAAJwmCoJkzb/0SAIAANjL+UEy0g0AAABwKOcHSRdXtgEAAAiHKAiSNf+y/A8AAIC9oiBIcmUbAACAcIiCIFnzr9dLlAQAALBTFARJptsAAACEg+ODpJseSQAAgLCIgiDJrG0AAIBwcHyQZEFyAACA8HB8kHQfPbdNkAQAALCX44MkC5IDAACERxQEyZp/6ZEEAACwl+ODJJNtAAAAwsPxQbL21DbL/wAAANjL8UHSzbW2AQAAwiIKgiSztgEAAMLB+UHSzRhJAACAcHB8kHRxiUQAAICwcHyQZNY2AABAeDg+SLoYIwkAABAWURAka/4lSAIAANjL8UGSyTYAAADh4fggWdsjKdErCQAAYCfHB0m3X5Jk5jYAAIB9HB8kY2PqfkWPhyAJAABgF8cHyRh3XY+kx+uNYEsAAACcxfFB0r9HspoeSQAAANs4PkjGxPj3SBIkAQAA7OL4IFlR6fHdLimrimBLAAAAnMXxQXLxuv2+28s2H4pgSwAAAJzF8UEysWM73+2cI2URbAkAAICzOD5Inj2+n+92cv9uEWwJAACAszg+SPbs0t53u1vn+Ai2BAAAwFkcHyQDFiRnHUkAAADbxAaz8VNPPaXPP/9cO3fuVPv27TVmzBj9/ve/1+DBg8PVvmPmvyA560gCAADYJ6geyRUrVujyyy/XW2+9peeff17V1dW6+uqrVVpaGq72HbPABcnpkQQAALBLUD2Szz77bMDP8+fP16RJk7Rp0yadfvrptjbMLoGntumRBAAAsEtQQbK+oqIiSVKXLl2C2s/tdsntd8o5nGL8bhtJsbGOHxYaspijoTsmhhq1hFpZR62so1bBoV7WUSvrqFVwQg6SXq9X9957r8aOHaukpKSg9u3evZNcrtYJksbU9UK2i49Vt26dWuV127LExA6RbkKbQa2so1bWUavgUC/rqJV11MqakIPk3LlztX37dr322mtB75uXV9J6PZIxbsW4XfJ4jYqKKpSfX9Iqr9sWxcS4lZjYQYWFZfIwnrRZ1Mo6amUdtQoO9bKOWllHrepY6XwLKUjOmzdPixYt0iuvvKLevXsHvb/Xa+RtxfGKsbFueSo9qqzyqLo6ug8KKzweL3WyiFpZR62so1bBoV7WUSvrqJU1QQ0AMMZo3rx5WrhwoV588UWdfPLJ4WqXrWon3DDZBgAAwD5B9UjOnTtXH330kf7xj3+oU6dOys7OliQlJCSoffv2LewdOSVlVZK41jYAAICdguqRfP3111VUVKQrr7xSkydP9v33ySefhKt9tvpuw8FINwEAAMAxguqR3Lp1a7jaAQAAgDaGRZIAAAAQkqgIkrUrDZ3UkzUkAQAA7BIVQXJM8gmSpK4J8RFuCQAAgHNERZDcvCtPkrTp6L8AAAA4dlERJMsqqiPdBAAAAMeJiiAJAAAA+xEkAQAAEJKoCJIXnTU40k0AAABwnKgIkj271Fy+MTbGFeGWAAAAOEdUBMnYmJpfs9pjZIyJcGsAAACcITqCZGzdr+nxEiQBAADsEBVB8mBuqe92RZUngi0BAABwjqgIktsy8323D+SUNrMlAAAArIqKIHmx36ztnQcKI9gSAAAA54iKIFlUWum7vWDZngi2BAAAwDmiIkjGxcb4bldWeyPYEgAAAOeIiiA5/JQevtsDTuwcwZYAAAA4R1QEyZ5dOvhub8ksiFxDAAAAHCQqgqTbzRVtAAAA7BYVQdLfmCE9I90EAAAAR4i6IJldUB7pJgAAADhC1AXJvdnFkW4CAACAI0RdkAQAAIA9CJIAAAAICUESAAAAIYmaIDlrSs31tt0ul4wxEW4NAABA2xc1QbJ7QrwkyWuMyis9EW4NAABA2xc1QbJ9fKzvdkFxRVheI31Pvp54b4OyDjMzHAAAOF/UBMlqj9d3u6ra28yWoXvg9TSt3pqtP7+4MizPDwAAcDyJmiDZuUOc73a4r7dd7WEMJgAAcL6oCZKJndr5bm/fWxC5hgAAADhE1ATJgb0TfLdXb82OYEsAAACcIWqCpMvlinQTAAAAHCVqgiQAAADsRZAEAABASAiSAAAACElUBcluR69uI0m5R8oj2BIAAIC2L6qCZH5R3RVtHn9vQwRbAgAA0PZFVZD0t+dgUaSbAAAA0KZFVZCcmTog4GfWkwQAAAhdVAXJC87oH/DzE5zeBgAACFlUBcmO7eNa3ggAAACWRFWQBAAAgH0IkgAAAAhJ1AXJfr06Bfz81pcZEWoJAABA2xZ1QXJg78SAnz9dkSmvMaqo8kSoRQAAAG1T1AXJCyb0b3Dfx0t268aHF2vxuv0RaBEAAEDbFHVBsk+Pjg3ue++bXfIaoxcWbIlAiwAAANqmqAuSLpdLM1MHRroZAAAAbV7UBUlJio1xNfmY15hWbAkAAEDbFZVBcurok5p8rKikUjv2HyFQAgAAtCA20g2IhC6d2jX52LwXVym/qEI/mX5qoxNzAAAAUCMqeyQl6cdTBzd6f35RhSTpra8y6JUEAABoRtQGyQsnDWxxm5se/VZ7DhaFvzEAAABtUNQGSUm68vzkZh8vLqvS3BdW6rF31uudr3dozvwvtXprtqXnZoFzAADgdFEdJMcl9bK0Xdr2HH28dI8k6Yn3NljaJ+dIecjtAgAAaAuiOkgmdmqnLp2bnnhzLJpeYAgAAMAZojpIStKDN6Tql98bGvR+B3JLNPeFlVqwfE8YWgUAAHD8i/ogGeN266xRfTV9TNNrS9aXV1iuv76epj0Hi/Tvr3bI6zWq9ngDtlm2+aDdTQUAADiuROU6ko258vxk7TxQaGmW9u//sSTg55se+1am3lJBa7fn6EdTTrG1jQAAAMcTgqSfu2efLkmaM//LoPYrLqtqcN/e7BJb2gQAwLFiXWSES9Sf2m7Mc3fM0JO3TI10MwAAOGZvfZWhGx/6Wpt25ka6KXAggmQT4uNidM74furXq1PIz1F7lRwAACLl0+WZKimv1p3/XNLyxkCQOLXdjJ+fk+S7/erCbfrv6r1B7X/LE99JkoYP6q6fnTNEvbt31PL0Q+oYH6eRp/Swta0AADSn/qRQwA4ESYsuPzdJl5+bpIffXKuNu/KC2nfjrjz97zPLA+6bf90k9ezSXm6XSwXFFXr+ky3q1bW9ZqYOVJdO7eRysRIlAAA4vhEkg3TzZaMlSXOfX6k9h0K/DvefX1ipkvLqBvd/uWafUof31q9mnhbyc7cFaduylVNYrrPH9ZOb0Nzm7DpQqA+/263zTj9ZQwd0i3RzAMCSjH1H9Pwn6Tp7XD/NGNsv0s1xBMZIhujuX57um+UdisZCZK0lG2vWoDyQW6Jv1x/Qzv2FKiypbLDdnoNF2ptdHHIbIqWguEKPvbtBr3+xXcs2sd5mW/TnF1dpbUaO/vp6WqSbAhtUVXv0xn+3a/G6/ZFuChBW9768WgdyS/XK59si3RTHoEfyGAzonaCnb52mvKIKvb94p/qfmKALJvTXuowc/f3t9cf03Pe+vFoZ+44E3De0f1edfEKCRgzurh5d2mvuCyslSTFuly5KHaiLJw86ptdsLTkFddch37QrT6nD+0SwNdFhz8EibdtboCkj+yq+XUykm4PjzKfLM/X5yixJ0tikXurcIS7CLQLQVgQdJFeuXKlnn31WGzduVHZ2tp544gmdc8454WhbmxAb49YJXTvo2otTfPeNOrWn7r12ov749LKQn7d+iJSkLZkF2pJZoIWrsgLu93iN3v92V5sJkv7rmXFau3XUfuk4nFemy89LamFrRJttWQW+26XlVQRJAJYFfWq7tLRUycnJuvvuu8PRHsfo3b2jnr51mubOOUO//tGIVnnNqmqvvN66kLZhZ65uePhrbc3Mb5XXt8q/jW538EEyv6ii0UXgjzc5BWV6/N0NWpF+KNJN8fnvmuBWHkAU4ssdgCAE3SM5depUTZ3KYt1WxMa4dfIJnXXyCZ31yK8nq327GL346RYt3RSeYPE/Dy7y3Z6U0ltLj44/vP+1ND13x4ywvGYoPCb0IJlTUKbb/rlUcbFuPfqbs47r07SPvbtBWYeLtWZbts4YdmKkm3NcKS2v0ubd+UoZ1F0d4hlhE2n7c0t9t0vKqqSuHSLYGgBtSUTewd1uV0g9UaGIiXEH/Bsp3bu0lyRdP2uETujWUWu2Zat9uxht39vwFLYdltabxDL/1TW+01cP3JCqhI7tdKSkQn161Cy4vmzTQT31wSZ1bB+nG380QqcNbH4mrtdrQv5/6L+0Udr2HF090/r/mze/ypBU0/u6bV+BxgzpFVIbjpWV4yrrcN1EqNjY42dem91taen5GqvV399er+17j2jkKT30+5+NsaUdlVUetYs7fr9YWBGp9yv/iyfsPFCoISd3bdXXD9Xx8v7ellCrOk29d3FcBSciQbJ7906tvk5iYuLx8w37V7NGBvy8ISNHX6ft1WfL9oTtNf3HQN36j8CrG8wYf7K+PDrusqi0UvNfWa1rfjBcF085RVXVXsXV+2N74OVVWrx2n/r07KSfnD1E/12Vpet+NFIDeif6tmkuaHbqVBewCksq1a2b9asHrd6a7budX1wV1L61tuzJ07MfbNQPpp6iyaNOCnp/f+071Kz5Wb9G9TXWzqpqj7ym5ipKUt1iwbFhfvMKpWZ2PJ//32DtF6j1O3JtaU/a1sP683PLdfbp/XXjJaOO+fkiLZLvVwmd4m0/RsLteHp/t8IYE7G1gqlVnZaO87ZWq0iJSJDMyytp1R7JxMQOKiwsk+c4XdW/X48OuvycIbr8nCGSJI/XqwM5pXrwjTTlFYb/Motf1pu8I0nPfLBRz3ywsdn9DuSU6O9vrpUk3fboN3ry91O160CR/u+5FZKkB29M1QndOjbYr7CwLODn/PySkNpdXFIR0r63PvqNJGnLS6uUcmfXkF47JsatD5fs0RsLt0qS/jR7vIb0a/q56rezotKja/76lSTpqVunyeWS7nhyqWJj3Lr3uolqF9uwZ21bVoFKy6s1ekjPkNrcVFus8BqjsvJqdWpkEkZTz7dxZ64qqjw647Tezf4Nhvr/399dTy+VJH26dLd+Ov2UsL6/FBRXqGP72Eb/Hx2rYN6v9uWUaO/hYo0f2ksxbvu+fJSVV9ny/6Q1HOv7e0l5lTq1b72JRcYYPfTGWu3LLtHdc05X187xrfbatY7nz8L6tmcV6JF/r9O0MSfp0umn2v78TR3nbSE3tBYrXyojEiS9XhMw4aI1eDxeVVe3nQOid/eOevCGM+X1Gn20dLfe/2ZXpJvUrNKKav3iL/8NuO/WfyzR4zdN0a4DhUru31X7sktUVFalFxZsCdiuutqr4rIqbcsq0MDeCaqo8ujEbh3ldrv0zIebtHTTIf3xinE6tV+XgP38/58WllRqz6EinTawW1AfqsdyTNSGSEn68wurmh2HWl3tVc6RMnVPrLma0WsL69Ywe+yd9UoZ2F15R08vLt1wUGeO6KPisip1bB8rt8ul/KIK3fPiKknS7T8fo+T+1hYBL6+s1rJ6Y3KD/Z2rPV5d+8AiSdIfrhjbIDA39nzZBWX662s1a0z+8co4TRrdr8m/Qbv/LheuzNLZ48Kz0HDmoSLNe2GV+vToqLlXnxG2VQesvF/94Z814flnZw/RuaefbNtre9vYe6UU2vv7G//drs9XZul7E/vr0mn2h5TGHMwr1foduZKk1xdu1zUXtf6FJ5qqVUFxhb5df0Dnn3Gy4sLwJSkU819do6pqrz78brdmnTXY9udv6Zhpa7khUhjlfpxzu126+MxBuvjMQSqrqJbX1ITwQ3lliolx6aXPtmrPwdCvsBNOxkg3/m1xi9sVl1XpN3//JuC+CaedqHPG9fNNTLr3ldXq0yOwd/PLNft00Zk1Sx798ellKq2o1o+mDNbM1IGW21hc1vhSJ3afTvl2/QE990m6JqX01jUXnaYdfss77dpfqCEn1YVkrzHampmv+19L08hTeuimS0cFXEVp9dZsy0Hy1c+36buNTS/6vjUzX5+tyNLM1IEa3Dex0W2+Xlu3SPV9r6yxNHHL/5hcm5GjSaOtBztjjBYsz5Tb5dIFE/pb3q/WivRDYQuSry3cJq8x2pdToiPFleqW0Po9SvV9tjLT1iAZDY6UVPrWzVywLLPVgqTxm2h4vK08cfPj30mS3l2887iZnFlFiGsTgg6SJSUlyszM9P28d+9epaenq0uXLurbt6+tjUMg/9mtCR3bSZLu+sV47dxfqL+8vFqSdMflY7VuR44KiirUMT6uTSz3Uj9EStLyzYe0fHNgT9oBv5mlUs2Hwa3/WKLcwroFzt9dvFPvLt6phI5xumbmaRo+uIckaVHaPm3Ymasrz09u8NrP3TEjIDgWlVbq3pdXq3f3jvrNJSPlcrlkjNGSjQfVtXO8UgZ1D/p3fO6TdEk1k6Cuueg0VVR5fI+VlFervLLu54y9R/T8JzW9trW9F/LrwK+s9hzdr0o5BeXqf2LnJkNvcyFSqpnRL9WEvefumOG7WtLElBN9Pbv1/z9YsWl33fXoV285HNS+6Xvy9faiHZJqFv0fFqZLMBaXVWll+iGNOrWnuie2t7SP/ynz1j6r4s8/kNg9/CVSY/fs5DVGHy3Zra6d4zVlVMPPpdZYEm3z7jx98O0uXXzmIN97hn8Ptv96ukBbFnSQ3Lhxo6666irfz/fdd58kadasWZo/f759LYMlLpdLp5zURQ/ekKpOHeIUHxejJL8Zl5efl6SMfUd079Gg6TT+IdJfUWmVHn5rnS6Y0F+fLq/74pO2PafBtrc9uUQ5R8rlUkBe06H8Ml19f804xpSB3bRpd82Hz9/+35nq0cLyKKXNXAJTaniJzH05dWN1vll/oMH2OUfqxpUuXndAs783TH9+cZUO55fp1z8aoTFJxz573es1voXLSyuqde74ml6ussrmf5fGem/9Q/+h/LL6uzTLf98NO3ODDpJWg9BT/9mkTbvy9P63u/T335xlaZ+i0rpeJE8Eg0A4X/pYntpqT35OQZkefWe9hg/qoZ/MsL83cPnmQ77hQEP6dfGtTlGrNS6E8OAbayVJD7251tfD5/9F5HB+aWO7Hbfe/HK7tmUd0Y2zhlv+4mWniiqPb2Iiji9BB8kJEyZo69atLW+IVtXcH/apJ3XRc3fM0OH8UvXs2iHgTTTrcLHW78hRyqDuGnxSFz378RZ9s3ZfazS5VfiHyKbkHKkJo819gNaGSEn63dFTQI0xxvjCZ1MWrd3X4LSWp4XercLSwO29XqPDRwPaKwu32RIka3s6JembdQd8QbKlULxw1V6dV+/UaswxTHbxnwH/6fJMrd+Rq3t+NcHy/lZfedOuml7TolLrpxj9A39jg/BbClJLNh6QSy5NTDnxmHr+TCNHa2FppdZtz9HoIT19ZyxCsXzTQXXt3E4Ze49oZupAy+t8PvdJujbvztNtPxvT6CQ7fw++sVaHC8q0N7skLEFy5/5C3+30Pfm+IGki3Avo/96bXdD4l2C72fE7V3u8+mxFzVCAlz7bqpsuDVwZYef+QnXuENvi//dj8f43O3XZjCFhe/5IyS+q0INvpGlIvy6a/b1hkW5OSBgjGUUa+yOvXTBdqnmTu+3K8Tr/9H7K2HtE45N7qdprVFhSqXUZOaqo8uqskX10z0urgvrwjRZz5n+ppHoTghrz0qcNv4jVhprGfLYiUx8t2R1w34NvpPlu5xdVaOHKLC3ZeFCXn5vUYFJSfdUeb6NLDP3vM8t9t/2DoP8ag415b/HOBkGypeWQmhNXr237c4KbQWwln/kPLZCkQ3mlen7BFp0x7ATNGGttfOWeQ0W+gOI9Ohs3r6hCf7pqnDrWmwlcVFqpf36wSel7ar6QlFd5NH1M6EtPNZYNbnr0W0lS/BcxevKWuotGZOw7ou82HND3JvS39EG/be8Rbdu7QVLNGLWfn9vyJTU9Xq++PdqT/vi7GzXv6jP82mqUdbhYfXt28h13hwvKAh5vKlTnF1Xo85WZOmPYiRrUJ3AM75KNB7Qi/bD+30/GqH29jir/Y+iVz7dpxth+8ni9+stLq1VZ7dX3JwY/9jYYTQ17aK3VSvzZEZ39fx//9XElBZzxeuJ3U8J2gYHvNhxsM0HSa4zlXu9XPt+qA7mlOpBbqllnDVaXCMzkP1YESTTQ/8QE9fU7FZTYsZ369ers+7mx04Ber9H+nBJ9tHS3Uof3VvqefK3akq1hA7tpyqi+jj21Xt+2MCww/+aXGQ3u25JZEPDz6//dLqlmUtLM1IENgqe/9xbv1Nnj+unDetv4B8Y9h4r0yudb9dOzG75x1+/hqKjyqLLKo8LSSnWMj9Xe7JJmg3F1vZ68otLKgB60YwmhUs3M2Jb4j0mVaoJ5bmGFtmUVWA6SHf0+MLdlFvhC4t/eWqf/vWp8wLa/PRryar382VZ1S4jX6FObX8qpqfVYm+tkqqjy6ItVWdq8O1+/+N5Q39/e5t15uv+61GZfr771O3L183Nb3q6gqNJ3e292YNB488sM38SWxiZxeLxGsTGNf+j+/d/rlHm4WJ+tyGqw778+qhl3fO19X+ilO88JeCw2tuHzrdmWo91HJ4F9vDRwzV6P19viag+1Ex2trPPaWI9xxNjclPp//1+tqTuDtTe7uNll0I5FOEYjlFVU2x583128U1+u3qsbZw3XsIEtj6c/7Df050/PrtCjv7U2zOZ4QpCELdxul/qd0FnX/WC4JGnkKT0Dvj3+vx+N0OPvbtCUUX2VOry3uiXEKzbGre82HNC7i3dGqtmO1FyIlKQFyzO1wMIp/y/X7NOXaxoOc2js1P11D33d7HPlFJTpl/d80ehje7NLNGxAO+UXVWjllsONBkH/XiuvMUrblqPePTrKeI3e/npHwLYFxTWhpjbY7jlUpBi3S727d9R9r6xRtcerm38yOmCfXL8JK1ZChRQYRh94va6HeIffadXmPPr2ev31uknq2cR42+c/Sdeabdn6/U/HaEDvhHqPNp8OXvui5ouF/JbaCuVU6uGCMkvjHsubGUdbGyKlmtn8CR0De2s3787XyFN6NLpvZr3eL6tcjQxw+M93dUuo1Z+4l1dYoV7NjHv2GqN7XlylvKIKzbv6DCW2MHQgEmfQt2UVaOHKLF2YOkAD/S8OYaExLZ3+bu5R/y9+lWGcZd3cEfjNuv36ZNkeXXV+sqXwVquotPKYgqQxRpXV3oCxm7Xvvw+8sdbS7Hf/4TLH20x+qwiSaBVjk3o1+kc1M3Wgb7me+h9YxWVVio9z69sNB/XFqiwdyC1V8slddcGE/qqs9urJ9+sWTHe5pMF9Ei1/iKN1/fLPnzf5mH8Ia0pteJ2ZOkAfLWn5ClDfrN/vm/nemFufXNLkYys2H1Zi53Y6UlyhSSm9fQG3dgWAWv5jR0PNDftzS5oMkrWTrua+sLLB305FlbUP7LUZDSeXBesPTy3T4JMStftAkQ7mleov10xoMHnF6gT2uS+sbBAIHvn3OtuWmzHGqKzC02h42pfd9BCJlpq/c1+hrzfzP9/u0hXnJbewx7FraghKU+a/ukaStHpbdkA9rYTaFsOm38MNv1TUPbhzf6FSgghywShqImR5vF49f/QLk9XwVrfvsSX+x9/doE278nTHFWMDwnu0IUjiuFH/Dap2fcfpY05qdDzZwOsmqWvndg0WzzXGyOM1Kq/0KC7GrXZxbhkj/frv36isoumek9Gn9tToIT0bLJiO44eVECmp2RDZkmc+2uy7XXv6VGo4xOClz7bqpc+2atrohsvL/PnFVZo8ordGndqz2d7fR/69XmOG9NScC4epXaxbMUdP8VbWG8MpSRt35eqDb3bpxh+N0J/+tbzB41YcKalUl07BTcQ5XFAWMKbxf59Z3uDDOpilkMLZWff8gi1asqH5Ja8as3l3nk4Y3fA9Jq+wXCvSD6t7Yt24tYrKhv9vrLI68WX73gLd98oaDRvQTbeGcC360vIqvbd4l04b1E3DLSxX5m3he4n/qfojxZUBj/n3zL+3eKcuCmId36bb03BIR1OlS9sW+pelY13Cq3YVkCff3xj0sBEnIUiizWrqVJTL5VJsjEudO7j97qsZCO7/BnUgt0S5heVK6NBOHdrH6oSjz1d/3blqj1d3PrNcR0oq9YsLkvX0hzVB46fnJuuCM/rpqfc3aemmxj+8Zn9vKMHU4Rb5Ldhea9eBQu06UKiXP9/WyB6B0rbn6NePNFxL1d8LC9K1eF1ND+XNjawa4GkpCRx138urdWHqAH29dr/axbrVt2cny72J/h54PU0/O2eIqj1e9T8hodEJWcYY3zCDljz69npd94MUtWtmeZc587/UtRedpokpvZvc5ttGls6yoqmFrx94Y60O1Rtq8d3Gg7p6ZvNXpDmWU9ter9F9r9T0LtaOuw3Wi59u1coth/XfNXsDJl7VVxts6/dIbt9b0ORYx/rbrkxvuE5sRaVH73y9QwP7JCh1eJ+Axxat3aeXPt2qCycN0I+nntJg38feWa/te4/of68c12S7yyqqVVJWpZ5dOwSsNhGsY+2RrFV/zHW0IUgiqvh/y+3To1ODU3SNiY1x68+/mqCqaq86to/VxJTeio11q1u3TsrPL9E1F52may46TdkFZdqSma8zhp6o+HZ1H4hTRvXVf77dpYz9R3TZjCHKKyxXRaVHJ/XqpJLyat9kiAeuT1VeUbm27MnXe0fXwPvVzGH6eOke35iuU/qGdvq+V9f2rbbcCOxXGyKbcs1fF1l6nsMFZQG9tfUnbVmVvidfdz27osnHD+aV6v7X1jTovWrK2owcXffQ17rqgmRlHS7WhRMHqGP7hh9PT3+4WQN6JzT4uy2vrJbX03QoaClof74iy7fclb/6IbJWVbU3YGxgXmG5DuWVKnlAN7ldrgZj3YKZxbtxV67lfSuqPDpSXKHH390YcP9Kv4sANNULaozRA6+nKbewXLf9bGyD/f2DZFlF00GpsWf/4Ntd+mJ1zcUwxiWfEDCGsHbVio+X7mkQJEvLq3y9fLVf2Ovzeo3uenaFcgvLddfs8Y2Oh/UaI4/H2+KlHoMJks0NNYj2teUJkoAFcbHuFmcT9+raocle0osnD/LdPqln4Ifg07dOk1QTWHt0aa8h/brqwkkDZWQU43Y3+EZvjFF2QZl6de0grzGqrPLqq7R9GtQ7Qf/5brcmnHaiDuWX6rMVWZo75wzf8k4er1f7skv0zboD+u+avfr+xAH6ZFndqeKrzk/WS581XJropF6d9D8XpeiL1VktBhpAqrlkaShqQ8ZXjUzyquW/TFWta1sI0i+0MNQht7BcD72RprjYGJ0+9ATFxbqbXYj/fx5cpDOGnaCuneM1eWQfX6iemTpQs84apC31rpxTXuFRaXmV1tS7IEL9cLJj35EGy+tUV3t9PbVV1R5fOPpuwwE9+3G6WrJxZ+AKCrU9irsPFvm+SLz3TeCEx5x6XzqzC4K7qMCnK+qGcxzKK1X/E+tPFmucf8/wrgONf2HOL6rwXYhi3gurdE293mFjjH51dEx1c5PZpJrLqdZfVqoxL322VYvS9ik+Lkb/uHmK72pn/q/ZGLsvtXu8IkgCEdbYt9yantPG34BcLpdvPcAYl0sd4t36/sQBkhQwY7H+mmsxbrf6n5igy89L0OXn1awNeMm0wB6B8UNPUIzb5ZvJ6P9GeNUFQzU2qZe+XrtfVdVeXTChvw7ll+mdRTt03uknK2Vwd7VvF6v2cTHKL6pQjy7t1bVzOz3z4WYtq3eZxa6d22nWWYN9g+SbMv9/JuqOp0ILJUCtli4VKtVddMDqBKUVR0/p+s9K/2jJ7kZXTfh/jyxu9DmufWBRi69z9/Mrm+wZteIf79frrUw/rLFDegackl5Srz5rM3L0zbr9evvrHZoyqq8S642rffajzZo1ZXCjS1NtyyoI+PmZDzeryuNVVbVXV9W7RG1haWXADHgrPYRxcYHvl/V7f/2vDHbbP5c2O/nmsxVZLa5NWV5ZrUVpNV9sKqo82rw7XymDugf0xDbVI7kls0DDBnST1xhtzSzQgBMTGu1pb+tcJgJL/WdnF7Xaa/mfgqzmAvDNolbWUSvrgqmV1xgdKa7UwdwS9e+doE71FvY+mFeqVxdu0w/PGqSeR6/m1KVzvI6UVCpjb4G8pmbg+xnDTvB90EvSmCE9lbY9Ry5Jyf27aktmgS44o7+GDuimR/69TpLUIT6m2VN4AMLjivOSlFtYrgXLml+W7JHfTJYx0u8eq1uXtf5lcOurDZIVlR5VVHl002OBa7r+cPIgZR4uVtfO7TSgd4I6tItVj67tdWKvBB3KLtKfX1gVsP2A3gm64twkLVyV5XuPaRfn1u8uHaWBvRN1/cN1S6EN6pOgMUN6aemmg77hSc/ePl0ul0tvL9qh3MJyLa/3JfuamacpoVOchg9qfEms1tarV8u9yQRJ+FAr66iVdcdLraqqPYpxuxuZDWpUUeVR+3Y1PQUHcku0LiNXhaWVinG7tHFnns4a1UdnDu+jiiqPOneMkzFGD76+VluP9r4kdozTnVeNV1Z2sZ58f5OqPV6lDu8trzHasCNXc74/TH16dtKSjQeVsbeg0bGJJ3bveEw9TwCc42dnD9GMcSepqtorl1xatyNHHdvHtnrAJEjq+PkQawuolXXUyjon16p2qalg1vurnc2cXVCmnfsLNWPsSb4xcLW1yssrVubBIhWWVmnYgG4qKq3UguWZvuVoJKlT+1j94oKhGj/0BEnS6q3ZMsaouLxKL326VdPHnKSvjp6S+9+rxqm80qOH3lgrSZox9iR9uWaf3C6XRgzurnU7aiZ4TBtzkhal7dPoU3uqY/tYLdl4UMMHd28wzq4pl04/Rf/+akfLGwIIyV2zx7fqmpUESTn7Q8xu1Mo6amUdtbLO7loFu6h1S8oqqrU1q0DV1V4ldmqnwX0TFeN2BUwoqKzyaHn6IcW4Xdqyp0CXn5cUMGu3qtqjN77MkMfj1eSRfeXxePXF6r1avTVbkjQ+uZe6JbTX8vRDShnYXVNG9dFXafsChipYNfToMIamxMfFNLjuOnC8s2sBfysIkuJDLBjUyjpqZR21so5a1WluxqsxRnsOFemUk7qoe/fOys0rVk5+mUrKq3XyCZ1V7fH6Am7moSI9+s56XXzmIJ0x7ARlHirWA6+nafig7vrtpaN0ILdE//xgk7IOF2v44O7q1aWDjKRFaft082Wj1LdHJy3ddFAzxvZT+3YxevPLDH2Vtk8XpQ5s8fKud80er3n1xthJ0h2Xj/VdiaYpf/7VhJAXnoezESRFkDxeUSvrqJV11Mo6ahWcUOtVWl6l9vGxltd2bIkxRt9uOKCuneM1YnAPy+tG+gder9eosrpurK4kFZZU6h/vb9TQ/l2V0LGd1u3I0ewLhqr70YlmUs2SQbsPFmnq6L4qKK5Qzy4dVFperY7tY2WM0a4DRcrYW6AJKb116sAemv/CCn23oWZm86SU3hrUJ8F3bfY53x+mrp3b6eG3aiagTRvdV7Exbt+akE2pncyG8BvUJ0F/+sXprfZ6BEnxxhwMamUdtbKOWllHrYJDvaxrrlb5RRVK7BSnGHfjwyDyiyr0Vdo+nTu+nxI6Nn6JTa8xqqryBlyMobisqma5G1OzpFl+UYXW78hRnx6dlHRyV1VWeWSMfDOdJ6WcqG1ZBZpz4Wk6mFuirMPFOvf0k9WnRydl7D2i9u1i1DUhXmu356hbQrw+X5ml/TnFyi2s0NUXDtM36/Zr96EiVVZ5deX5yXr5s63q0qmdjpTULYw/M3WATh96oh5+c63v/qSTu/qWLYqLdat7QrwO5Qeunfl/vzxdK7cc1sdLAy/TOuf7w/TcJ02v53nKSYnasa/li0jc8MPhDZZqqq9DfKzuvXZi0Jc5PRYESfFGEwxqZR21so5aWUetgkO9rDuea1VYWqncI+Ua2DshpAW87Vj4u7CkUvFxMYpvF+Or1aHsQu3aVyi5pFP6dpEk/eWlVdqxv1A3XTpSI0/p6du/2uPVjn1H1LlDnOLjYtS9S3sVl1UpsWM7eY2RS9K+nBJ17hCnrp3jVVperRi3yxe8jTF67Yvt+u/qveoYH6ueXdvrzBF99N36A5o+9iSNPKWnuiXEN9b0sCJI6vj+4zneUCvrqJV11Mo6ahUc6mUdtbKuuVpVVXtVWFKpHl3aN7G3s1gJkvZN5wMAAHCwuFh31IRIqwiSAAAACAlBEgAAACEhSAIAACAkBEkAAACEhCAJAACAkBAkAQAAEBKCJAAAAEJCkAQAAEBICJIAAAAICUESAAAAISFIAgAAICQESQAAAISEIAkAAICQECQBAAAQEoIkAAAAQkKQBAAAQEhcxhgT6UYAAACg7aFHEgAAACEhSAIAACAkBEkAAACEhCAJAACAkBAkAQAAEBKCJAAAAEJCkAQAAEBICJIAAAAICUESAAAAISFIAgAAICSODpKvvvqqZsyYoREjRujSSy/V+vXrI92ksHrqqaf04x//WGPGjNGkSZN0ww03aOfOnQHbXHnllUpOTg7476677grYZv/+/br22ms1atQoTZo0Sffff7+qq6sDtlm+fLlmzZql4cOH69xzz9W7774b9t/Pbo899liDWlxwwQW+xysqKjR37lxNmDBBY8aM0a9//Wvl5OQEPEe01GrGjBkNapWcnKy5c+dKiu7jauXKlbruuus0efJkJScn64svvgh43Bijv//975o8ebJGjhyp2bNna/fu3QHbFBQU6JZbbtHYsWM1fvx4/fGPf1RJSUnANlu2bNHPf/5zjRgxQlOnTtUzzzzToC0LFizQBRdcoBEjRuiiiy7S119/bfvveyyaq1VVVZUeeOABXXTRRRo9erQmT56s2267TYcOHQp4jsaOxaeffjpgG6fXSpLuuOOOBnW4+uqrA7bhuKrR2HtXcnKy/vWvf/m2iZbjKiyMQ3388ccmJSXFvP3222b79u3mzjvvNOPHjzc5OTmRblrYzJkzx7zzzjtm27ZtJj093VxzzTVm2rRppqSkxLfNFVdcYe68805z+PBh339FRUW+x6urq83MmTPN7NmzzebNm82iRYvMhAkTzEMPPeTbJjMz04waNcrcd999JiMjw7z88stm2LBhZvHixa36+x6rRx991Fx44YUBtcjNzfU9ftddd5mpU6eaJUuWmA0bNpif/OQn5rLLLvM9Hk21ys3NDajTd999Z5KSksyyZcuMMdF9XC1atMg8/PDD5vPPPzdJSUlm4cKFAY8/9dRTZty4cWbhwoUmPT3dXHfddWbGjBmmvLzct83VV19tLr74YrN27VqzcuVKc+6555qbb77Z93hRUZFJTU01t9xyi9m2bZv56KOPzMiRI80bb7zh22b16tVm2LBh5plnnjEZGRnmb3/7m0lJSTFbt24NfxEsaq5WhYWFZvbs2ebjjz82O3bsMGlpaeaSSy4xs2bNCniO6dOnm8cffzzgWPN/j4uGWhljzO23326uvvrqgDoUFBQEbMNxVcO/RocPHzZvv/22SU5ONpmZmb5touW4CgfHBslLLrnEzJ071/ezx+MxkydPNk899VQEW9W6cnNzTVJSklmxYoXvviuuuMLcc889Te6zaNEiM3ToUJOdne2777XXXjNjx441FRUVxhhj/vrXv5oLL7wwYL+bbrrJzJkzx+bfILweffRRc/HFFzf6WGFhoUlJSTELFizw3ZeRkWGSkpJMWlqaMSa6alXfPffcY8455xzj9XqNMRxXtep/iHm9XnPmmWeaf/3rX777CgsLzfDhw81HH31kjKk7rtavX+/b5uuvvzbJycnm4MGDxhhjXn31VXP66af7amWMMQ888IA5//zzfT//9re/Nddee21Aey699FLzpz/9yd5f0iaNfeDXt27dOpOUlGT27dvnu2/69Onm+eefb3KfaKnV7bffbq6//vom9+G4atr1119vrrrqqoD7ovG4sosjT21XVlZq06ZNSk1N9d3ndruVmpqqtLS0CLasdRUVFUmSunTpEnD/hx9+qAkTJmjmzJl66KGHVFZW5nts7dq1SkpKUs+ePX33TZ48WcXFxcrIyPBtM2nSpIDnnDx5stauXRum3yR89uzZo8mTJ+vss8/WLbfcov3790uSNm7cqKqqqoBj6JRTTlHfvn19v2e01apWZWWl/vOf/+jHP/6xXC6X736Oq4b27t2r7OzsgOMoISFBo0aN8r0XpaWlKTExUSNGjPBtk5qaKrfb7RuOs3btWo0fP17t2rXzbTN58mTt2rVLR44c8W3jtPoVFxfL5XIpMTEx4P5nnnlGEyZM0A9/+EP961//ChgiEU21WrFihSZNmqTzzz9fd999t/Lz832PcVw1LicnR19//bUuueSSBo9xXIUmNtINCIf8/Hx5PB716NEj4P4ePXo0GDPoVF6vV/fee6/Gjh2rpKQk3/0zZ85U3759dcIJJ2jr1q168MEHtWvXLj3++OOSav7I/D/sJfl+zs7Obnab4uJilZeXq3379uH81WwzcuRI3XfffRo0aJCys7P1xBNP6PLLL9eHH36onJwcxcXFNfgA69GjR4t1kJxXK39ffPGFioqKNGvWLN99HFeNq/3dGnsvqh1vm5OTo+7duwc8Hhsbqy5dugTUpl+/fgHb1NYqJydHXbp0abR+/q/T1lRUVOjBBx/UhRdeqM6dO/vuv/LKK3XaaaepS5cuSktL08MPP6zs7Gz94Q9/kBQ9tTrrrLN07rnnql+/fsrKytLDDz+sa665Rm+++aZiYmI4rprw3nvvqVOnTjrvvPMC7ue4Cp0jgySkuXPnavv27XrttdcC7r/ssst8t5OTk9WrVy/Nnj1bmZmZ6t+/f2s3M6KmTp3quz106FCNGjVK06dP14IFC9pkaGkt77zzjqZMmaITTzzRdx/HFexUVVWl3/72tzLG+CZ01frlL3/puz106FDFxcXp7rvv1i233BLQW+R0F154oe927eSQc845x9dLica98847uuiiixQfHx9wP8dV6Bx5artbt26KiYlRbm5uwP25ubkNvi040bx587Ro0SK9+OKL6t27d7Pbjho1SlLNKV6p5htW/W9PtT/36tWr2W06d+7cpgNYYmKiBg4cqMzMTPXs2VNVVVUqLCwM2CY3N7fFOkjOrdW+ffu0ZMmSRk8L+eO4qlH7uzX3XtSzZ0/l5eUFPF5dXa0jR45YOtb8n6f+Nm3xPa+qqko33XST9u/fr+eeey6gN7Ixo0aNUnV1tfbu3Sspumrl7+STT1a3bt0C/uY4rgKtWrVKu3bt0qWXXtrithxX1jkySLZr104pKSlaunSp7z6v16ulS5dqzJgxEWxZeBljNG/ePC1cuFAvvviiTj755Bb3SU9Pl1T3gTd69Ght27Yt4INvyZIl6ty5s0499VTfNsuWLQt4niVLlmj06NE2/SaRUVJSoqysLPXq1UvDhw9XXFxcwDG0c+dO7d+/3/d7RmOt3n33XfXo0UPTpk1rdjuOqxr9+vVTr169Ao6j4uJirVu3zvdeNGbMGBUWFmrjxo2+bZYtWyav16uRI0dKqqnNqlWrVFVV5dtmyZIlGjRokG8MtBPqVxsi9+zZoxdeeEHdunVrcZ/09HS53W7f8IFoqVV9Bw8eVEFBge9vjuOqobffflspKSkaOnRoi9tyXAUh0rN9wuXjjz82w4cPN++++67JyMgwf/rTn8z48eMDZo06zd13323GjRtnli9fHrCEQVlZmTHGmD179pjHH3/cbNiwwWRlZZkvvvjCnH322ebyyy/3PUftMi1z5swx6enpZvHixWbixImNLtNy//33m4yMDPPKK6+0iWVa6ps/f75Zvny5ycrKMqtXrzazZ882EyZM8C0BdNddd5lp06aZpUuXmg0bNpjLLrus0eV/oqFWxtSsfDBt2jTzwAMPBNwf7cdVcXGx2bx5s9m8ebNJSkoyzz//vNm8ebNvpvFTTz1lxo8fb7744guzZcsWc/311ze6/M8Pf/hDs27dOrNq1Spz3nnnBSzTUlhYaFJTU82tt95qtm3bZj7++GMzatSoBkuPnHbaaebZZ581GRkZ5tFHHz3ulh5prlaVlZXmuuuuM1OmTDHp6ekB72G1M2XXrFljnn/+eZOenm4yMzPNBx98YCZOnGhuu+0232tEQ62Ki4vN/PnzTVpamsnKyjJLliwxs2bNMuedd17ArGKOq7rZ/kVFRWbUqFHmtddea7B/NB1X4eDYIGmMMS+//LKZNm2aSUlJMZdccolZu3ZtpJsUVklJSY3+98477xhjjNm/f7+5/PLLzRlnnGGGDx9uzj33XHP//fcHrPdnjDF79+41v/rVr8zIkSPNhAkTzPz5801VVVXANsuWLTM/+MEPTEpKijn77LN9r9GW3HTTTebMM880KSkp5qyzzjI33XST2bNnj+/x8vJy83//93/m9NNPN6NGjTI33nijOXz4cMBzREutjDHmm2++MUlJSWbnzp0B90f7cbVs2bJG/+5uv/12Y0zNEkCPPPKISU1NNcOHDze/+MUvGtQwPz/f3HzzzWb06NFm7Nix5o477jDFxcUB26Snp5uf/exnZvjw4eass85qdCmzTz75xJx33nkmJSXFXHjhhWbRokXh+8VD0FytsrKymnwPq12vdOPGjebSSy8148aNMyNGjDDf+973zD//+c+A8GSM82tVVlZm5syZYyZOnGhSUlLM9OnTzZ133tmgo4Tj6nbfNm+88YYZOXKkKSwsbLB/NB1X4eAyxphI94oCAACg7XHkGEkAAACEH0ESAAAAISFIAgAAICQESQAAAISEIAkAAICQECQBAAAQEoIkAAAAQkKQBAAAQEgIkgAAAAgJQRIAAAAhIUgCAAAgJARJAAAAhOT/AyKoI9exXnE8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
