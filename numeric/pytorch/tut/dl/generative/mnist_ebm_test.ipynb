{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env_dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import scipy.linalg as sl\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch import nn, distributions as dist, autograd\n",
    "from torch.func import jacfwd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomHorizontalFlip, RandomVerticalFlip, ToTensor, Normalize\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "# torch.set_default_device(\"cuda\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "from mnist import MNISTTrain, MNISTTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "batch_size = 512\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNISTTrain(transform=Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(0.1),\n",
    "    RandomVerticalFlip(0.1),\n",
    "    Normalize(127., 128.0)\n",
    "]))\n",
    "val_ds = MNISTTest(transform=Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(127., 128.0)\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    \n",
    "    def __init__(self, buffer_size, img_size):\n",
    "        self.random_sampler = dist.Uniform(-1., 1.)\n",
    "        self.buffer = deque(maxlen=buffer_size)\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer.extend(self.random_sampler.sample((self.buffer_size, 1, img_size, img_size)).unbind())\n",
    "        self.buffer_size = buffer_size\n",
    "        \n",
    "    def add(self, x):\n",
    "        self.buffer.append(x)\n",
    "        # self.buffer.append(torch.rand((1, img_size, img_size)))\n",
    "            \n",
    "    def clear(self):\n",
    "        self.buffer.clear()\n",
    "\n",
    "    def sample(self, size):\n",
    "        random_sample_probs = np.random.binomial(1, 0.05, (size,))\n",
    "        num_pos = max(1, sum(random_sample_probs))\n",
    "        for i in range(num_pos):\n",
    "            self.buffer[i] = self.random_sampler.sample((1, img_size, img_size)) \n",
    "        \n",
    "        idx = np.random.choice(size, size, replace=False)\n",
    "        \n",
    "        return [self.buffer[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_features=32, out_dim=1, **kwargs):\n",
    "        super().__init__()\n",
    "        # We increase the hidden dimension over layers. Here pre-calculated for simplicity.\n",
    "        c_hid1 = hidden_features//2\n",
    "        c_hid2 = hidden_features\n",
    "        c_hid3 = hidden_features*2\n",
    "\n",
    "        # Series of convolutions and Swish activation functions\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "                nn.Conv2d(1, c_hid1, kernel_size=5, stride=2, padding=4), # [16x16] - Larger padding to get 32x32 image\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid1, c_hid2, kernel_size=3, stride=2, padding=1), #  [8x8]\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid2, c_hid3, kernel_size=3, stride=2, padding=1), # [4x4]\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid3, c_hid3, kernel_size=3, stride=2, padding=1), # [2x2]\n",
    "                Swish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(c_hid3*4, c_hid3),\n",
    "                Swish(),\n",
    "                nn.Linear(c_hid3, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x).squeeze(dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = torch.load(\"/mnt/dl/generation/ebm/generation/model/ebm.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
       "    (1): Swish()\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): Swish()\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): Swish()\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): Swish()\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (10): Swish()\n",
       "    (11): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, train_loader, \n",
    "                 val_loader=None, epochs=0, \n",
    "                 savepath=None, K=1, batch_size=1,\n",
    "                 grad_step_scale=1., eval_epoch=1000000):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)    \n",
    "        self.savepath = savepath\n",
    "        if self.savepath is not None:\n",
    "            os.makedirs(self.savepath, exist_ok=True)\n",
    "        self.K = K\n",
    "        self.batch_size = batch_size\n",
    "        self.sampler = Sampler(buffer_size=batch_size, \n",
    "                                          img_size=img_size)\n",
    "        self.noise_process = dist.Normal(0., 0.003)\n",
    "        \n",
    "        self.lvn_grad_step_scale = grad_step_scale\n",
    "        self.eval_epoch = eval_epoch\n",
    "        self.batch_grad_fn = torch.func.vmap(torch.func.grad(self.grad_input_fn))\n",
    "        \n",
    "    \n",
    "    def sample_langevin(self, sample_size=-1, return_img_gen=False, steps=-1):\n",
    "        if sample_size == -1:\n",
    "            sample_size = self.batch_size\n",
    "        if steps == -1:\n",
    "            steps = self.K\n",
    "        \n",
    "        sampler_imgs = self.sampler.sample(sample_size)\n",
    "        x = torch.stack(sampler_imgs).cuda()\n",
    "        \n",
    "        self.model.eval()\n",
    "        gen_imgs = []\n",
    "        gen_imgs.append(x.clone().detach().cpu())\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            for k in range(steps - 1):\n",
    "                grad = self.batch_grad_fn(x)\n",
    "                grad = grad.clip(min=-0.03, max=0.03)\n",
    "                x = x - self.lvn_grad_step_scale * grad + self.noise_process.sample(x.size()).to(torch.device(\"cuda\"))\n",
    "                x = x.clip(min=-1, max=1.)\n",
    "                gen_imgs.append(x.clone().detach().cpu())\n",
    "\n",
    "\n",
    "        if return_img_gen:\n",
    "            gen_imgs = torch.stack(gen_imgs, 1).cpu()\n",
    "            return gen_imgs\n",
    "        \n",
    "        gen_imgs.clear()\n",
    "        self.sampler.clear()\n",
    "        for lx in x.unbind():\n",
    "            self.sampler.add(lx.detach().cpu())\n",
    "        \n",
    "        return x.clone().detach()\n",
    "    \n",
    "    \n",
    "    def grad_input_fn(self, x):\n",
    "        y = self.model(x.unsqueeze(0))\n",
    "        return y.sum()\n",
    "        \n",
    "    def fit(self, epoch, loader):\n",
    "        losses = []\n",
    "        for step, (img, label) in enumerate(loader):\n",
    "            img = img.cuda()\n",
    "            xgen = self.sample_langevin()\n",
    "            self.model.train()\n",
    "            Edata = self.model(img)\n",
    "            Etheta = self.model(xgen)\n",
    "            loss = Edata.mean() - Etheta.mean() +  (Edata.square() + Etheta.square()).mean()\n",
    "            \n",
    "            if torch.isnan(loss).item():\n",
    "                continue\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 10.)\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if step % 15 == 0:\n",
    "                print(f\"Epoch: {epoch}, step: {step}, loss: {np.mean(losses)}\")\n",
    "           \n",
    "            if step == 100:\n",
    "                break\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def train(self):\n",
    "        self.train_losses = []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            losses = self.fit(epoch, train_loader)\n",
    "            self.train_losses.extend(losses)\n",
    "            if epoch % self.eval_epoch == 0:\n",
    "                self.evaluate(epoch)\n",
    "        \n",
    "        self.generate_imgs(16)\n",
    "        return \n",
    "    \n",
    "    def evaluate(self, epoch=None):\n",
    "        if self.val_loader is None:\n",
    "            return\n",
    "        if epoch is None:\n",
    "            epoch = 0\n",
    "        self.model.eval()\n",
    "        re, fe = 0.0, 0.\n",
    "        with torch.no_grad():\n",
    "            k = 0\n",
    "            for (img, label) in self.val_loader:\n",
    "                real_img = img.cuda()\n",
    "                fake_img = torch.rand(real_img.size(0), 1, img_size, img_size).cuda()\n",
    "                \n",
    "                real_energy = self.model(real_img)\n",
    "                fake_energy = self.model(fake_img)\n",
    "                \n",
    "                re += real_energy.mean().item()\n",
    "                fe += fake_energy.mean().item()\n",
    "                # if k == 5:\n",
    "                #     break\n",
    "                # k += 1\n",
    "        print(f\"Evaluation epoch {epoch} loss: {re - fe}, real_energy {re}, fake_energy {fe}\")\n",
    "        self.model.train()\n",
    "    \n",
    "    def generate_imgs(self, nsample):\n",
    "        savepath = os.path.join(self.savepath, f\"samples\")\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        with torch.no_grad():\n",
    "            xgen = self.sample_langevin(sample_size=nsample, return_img_gen=True, steps=256)\n",
    "            imgs = xgen.permute((0, 1, 3, 4, 2))\n",
    "            imgs = imgs.squeeze(-1)\n",
    "            \n",
    "            imgs *= 128.\n",
    "            imgs += 127.\n",
    "            \n",
    "            imgs = imgs.unbind()\n",
    "            for n in range(nsample):\n",
    "                # img_path = os.path.join(savepath, f\"{n:03d}\")\n",
    "                # os.makedirs(img_path, exist_ok=True)\n",
    "                fname = os.path.join(savepath, f\"img{n}.jpeg\")\n",
    "                self.save_img(imgs[n], fname)\n",
    "    \n",
    "    def save_img(self, imgs, fname, timesteps=16):\n",
    "        length = imgs.shape[0]\n",
    "        npic = length // timesteps \n",
    "        \n",
    "        nrow = int(np.sqrt(npic))\n",
    "        ncol = int(np.sqrt(npic))\n",
    "        fig, axes = plt.subplots(nrows=nrow, ncols=ncol)\n",
    "        for i in range(nrow):\n",
    "            for j in range(ncol):\n",
    "                axes[i, j].imshow(imgs[(i * nrow + j) *npic])\n",
    "                # axes[i, j].set_xaxis_off()\n",
    "        fig.savefig(fname)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "mnist_trainer = Trainer(ebm, \n",
    "                        train_loader=train_loader, \n",
    "                        val_loader=val_loader,\n",
    "                        epochs=50, \n",
    "                        savepath=\"/mnt/dl/generation/ebm/generation\",\n",
    "                        batch_size=batch_size,\n",
    "                        grad_step_scale=10.,\n",
    "                        K=20,\n",
    "                        eval_epoch=10,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainer.generate_imgs(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
