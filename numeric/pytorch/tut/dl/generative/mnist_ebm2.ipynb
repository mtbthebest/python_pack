{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env_dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import scipy.linalg as sl\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "from torch import nn, distributions as dist, autograd\n",
    "from torch.func import jacfwd\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, RandomHorizontalFlip, RandomVerticalFlip, ToTensor, Normalize\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "# torch.set_default_device(\"cuda\")\n",
    "torch.set_default_dtype(torch.float32)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "from mnist import MNISTTrain, MNISTTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28\n",
    "batch_size = 128\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNISTTrain(transform=Compose([\n",
    "    ToTensor(),\n",
    "    RandomHorizontalFlip(0.1),\n",
    "    RandomVerticalFlip(0.1),\n",
    "    Normalize(127., 128.0)\n",
    "]))\n",
    "val_ds = MNISTTest(transform=Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(127., 128.0)\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_features=32, out_dim=1, **kwargs):\n",
    "        super().__init__()\n",
    "        c_hid1 = hidden_features//2\n",
    "        c_hid2 = hidden_features\n",
    "        c_hid3 = hidden_features*2\n",
    "\n",
    "        self.cnn_layers = nn.Sequential(\n",
    "                nn.Conv2d(1, c_hid1, kernel_size=5, stride=2, padding=4), # [16x16] - Larger padding to get 32x32 image\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid1, c_hid2, kernel_size=3, stride=2, padding=1), #  [8x8]\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid2, c_hid3, kernel_size=3, stride=2, padding=1), # [4x4]\n",
    "                Swish(),\n",
    "                nn.Conv2d(c_hid3, c_hid3, kernel_size=3, stride=2, padding=1), # [2x2]\n",
    "                Swish(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(c_hid3*4, c_hid3),\n",
    "                Swish(),\n",
    "                nn.Linear(c_hid3, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x).squeeze(dim=-1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (cnn_layers): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2), padding=(4, 4))\n",
       "    (1): Swish()\n",
       "    (2): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (3): Swish()\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (5): Swish()\n",
       "    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (7): Swish()\n",
       "    (8): Flatten(start_dim=1, end_dim=-1)\n",
       "    (9): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (10): Swish()\n",
       "    (11): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebm = CNNModel()\n",
    "# ebm(torch.randn((2, 1, 28, 28)))\n",
    "ebm.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "\n",
    "    def __init__(self, model, img_shape, sample_size, max_len=8192):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            model - Neural network to use for modeling E_theta\n",
    "            img_shape - Shape of the images to model\n",
    "            sample_size - Batch size of the samples\n",
    "            max_len - Maximum number of data points to keep in the buffer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.img_shape = img_shape\n",
    "        self.sample_size = sample_size\n",
    "        self.max_len = max_len\n",
    "        self.examples = [(torch.rand((1,)+img_shape)*2-1) for _ in range(self.sample_size)]\n",
    "\n",
    "    def sample_new_exmps(self, steps=60, step_size=10):\n",
    "        \"\"\"\n",
    "        Function for getting a new batch of \"fake\" images.\n",
    "        Inputs:\n",
    "            steps - Number of iterations in the MCMC algorithm\n",
    "            step_size - Learning rate nu in the algorithm above\n",
    "        \"\"\"\n",
    "        # Choose 95% of the batch from the buffer, 5% generate from scratch\n",
    "        n_new = np.random.binomial(self.sample_size, 0.05)\n",
    "        rand_imgs = torch.rand((n_new,) + self.img_shape) * 2 - 1\n",
    "        old_imgs = torch.cat(random.choices(self.examples, k=self.sample_size-n_new), dim=0)\n",
    "        inp_imgs = torch.cat([rand_imgs, old_imgs], dim=0).detach().to(torch.device(\"cuda\"))\n",
    "\n",
    "        # Perform MCMC sampling\n",
    "        inp_imgs = Sampler.generate_samples(self.model, inp_imgs, steps=steps, step_size=step_size)\n",
    "\n",
    "        # Add new images to the buffer and remove old ones if needed\n",
    "        self.examples = list(inp_imgs.to(torch.device(\"cpu\")).chunk(self.sample_size, dim=0)) + self.examples\n",
    "        self.examples = self.examples[:self.max_len]\n",
    "        return inp_imgs\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_samples(model, inp_imgs, steps=60, step_size=10, return_img_per_step=False):\n",
    "        \"\"\"\n",
    "        Function for sampling images for a given model.\n",
    "        Inputs:\n",
    "            model - Neural network to use for modeling E_theta\n",
    "            inp_imgs - Images to start from for sampling. If you want to generate new images, enter noise between -1 and 1.\n",
    "            steps - Number of iterations in the MCMC algorithm.\n",
    "            step_size - Learning rate nu in the algorithm above\n",
    "            return_img_per_step - If True, we return the sample at every iteration of the MCMC\n",
    "        \"\"\"\n",
    "        # Before MCMC: set model parameters to \"required_grad=False\"\n",
    "        # because we are only interested in the gradients of the input.\n",
    "        is_training = model.training\n",
    "        model.eval()\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        inp_imgs.requires_grad = True\n",
    "\n",
    "        # Enable gradient calculation if not already the case\n",
    "        had_gradients_enabled = torch.is_grad_enabled()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # We use a buffer tensor in which we generate noise each loop iteration.\n",
    "        # More efficient than creating a new tensor every iteration.\n",
    "        noise = torch.randn(inp_imgs.shape, device=inp_imgs.device)\n",
    "\n",
    "        # List for storing generations at each step (for later analysis)\n",
    "        imgs_per_step = []\n",
    "\n",
    "        # Loop over K (steps)\n",
    "        for _ in range(steps):\n",
    "            # Part 1: Add noise to the input.\n",
    "            noise.normal_(0, 0.005)\n",
    "            inp_imgs.data.add_(noise.data)\n",
    "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
    "\n",
    "            # Part 2: calculate gradients for the current input.\n",
    "            out_imgs = -model(inp_imgs)\n",
    "            out_imgs.sum().backward()\n",
    "            inp_imgs.grad.data.clamp_(-0.03, 0.03) # For stabilizing and preventing too high gradients\n",
    "\n",
    "            # Apply gradients to our current samples\n",
    "            inp_imgs.data.add_(-step_size * inp_imgs.grad.data)\n",
    "            inp_imgs.grad.detach_()\n",
    "            inp_imgs.grad.zero_()\n",
    "            inp_imgs.data.clamp_(min=-1.0, max=1.0)\n",
    "\n",
    "            if return_img_per_step:\n",
    "                imgs_per_step.append(inp_imgs.clone().detach())\n",
    "\n",
    "        # Reactivate gradients for parameters for training\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "        model.train(is_training)\n",
    "\n",
    "        # Reset gradient calculation to setting before this function\n",
    "        torch.set_grad_enabled(had_gradients_enabled)\n",
    "\n",
    "        if return_img_per_step:\n",
    "            return torch.stack(imgs_per_step, dim=0)\n",
    "        else:\n",
    "            return inp_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    \n",
    "    def __init__(self, model, train_loader, \n",
    "                 val_loader=None, epochs=0, \n",
    "                 savepath=None, K=1, batch_size=1,\n",
    "                 grad_step_scale=1., \n",
    "                 eval_epoch=1000000, \n",
    "                 img_shape=(1,28,28)):\n",
    "        self.cnn = model\n",
    "        self.optimizer = torch.optim.Adam(self.cnn.parameters(), lr=1e-5)    \n",
    "\n",
    "        self.epochs = epochs\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.batch_size = batch_size\n",
    "        self.sampler = Sampler(self.cnn, \n",
    "                               img_shape=img_shape, sample_size=batch_size)\n",
    "        \n",
    "    def fit(self, epoch, loader):\n",
    "        losses = []\n",
    "        for step, (img, label) in enumerate(loader):\n",
    "            real_imgs = img.cuda()\n",
    "            \n",
    "            # TODO comment for debug\n",
    "            small_noise = torch.randn_like(real_imgs) * 0.005\n",
    "            real_imgs.add_(small_noise).clamp_(min=-1.0, max=1.0)\n",
    "            fake_imgs = self.sampler.sample_new_exmps(steps=60, step_size=10)\n",
    "            self.cnn.train()\n",
    "            # Obtain samples\n",
    "\n",
    "            # Predict energy score for all images\n",
    "            inp_imgs = torch.cat([real_imgs, fake_imgs], dim=0)\n",
    "            real_out, fake_out = self.cnn(inp_imgs).chunk(2, dim=0)\n",
    "\n",
    "            # Calculate losses\n",
    "            reg_loss = 0.1 * (real_out ** 2 + fake_out ** 2).mean()\n",
    "            cdiv_loss = fake_out.mean() - real_out.mean()\n",
    "            loss = reg_loss + cdiv_loss\n",
    "            \n",
    "            if torch.isnan(loss).item():\n",
    "                continue\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.cnn.parameters(), 2.)\n",
    "            self.optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f\"Epoch: {epoch}, step: {step}, loss: {np.mean(losses)}\")\n",
    "           \n",
    "            if step == 200:\n",
    "                break\n",
    "        \n",
    "        return losses\n",
    "\n",
    "    def train(self):\n",
    "        self.train_losses = []\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            losses = self.fit(epoch, train_loader)\n",
    "            self.train_losses.extend(losses)\n",
    "        #     if epoch % self.eval_epoch == 0:\n",
    "        #         self.evaluate(epoch)\n",
    "        # self.generate_imgs(16)\n",
    "        return self.train_losses\n",
    "    \n",
    "    def evaluate(self, epoch=None):\n",
    "        if self.val_loader is None:\n",
    "            return\n",
    "        if epoch is None:\n",
    "            epoch = 0\n",
    "        savepath = os.path.join(self.savepath, \"evaluation\", f\"{epoch}\")\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        self.model.eval()\n",
    "        re, fe = 0.0, 0.\n",
    "        with torch.no_grad():\n",
    "            k = 0\n",
    "            for (img, label) in self.val_loader:\n",
    "                real_img = img.cuda()\n",
    "                fake_img = torch.rand(real_img.size(0), 1, img_size, img_size).cuda()\n",
    "                \n",
    "                real_energy = self.model(real_img)\n",
    "                fake_energy = self.model(fake_img)\n",
    "                \n",
    "                re += real_energy.mean().item()\n",
    "                fe += fake_energy.mean().item()\n",
    "        print(f\"Evaluation epoch {epoch} loss: {re - fe}, real_energy {re}, fake_energy {fe}\")\n",
    "        self.model.train()\n",
    "    \n",
    "    def generate_imgs(self, nsample):\n",
    "        savepath = os.path.join(self.savepath, f\"samples\")\n",
    "        os.makedirs(savepath, exist_ok=True)\n",
    "        with torch.no_grad():\n",
    "            xgen = self.sample_langevin(sample_size=nsample, return_img_gen=True, steps=256)\n",
    "\n",
    "            imgs = xgen.permute((0, 1, 3, 4, 2))\n",
    "            imgs = imgs.squeeze(-1)\n",
    "            \n",
    "            imgs *= 128.\n",
    "            imgs += 127.\n",
    "            \n",
    "            imgs = imgs.unbind()\n",
    "            for n in range(nsample):\n",
    "                # img_path = os.path.join(savepath, f\"{n:03d}\")\n",
    "                # os.makedirs(img_path, exist_ok=True)\n",
    "                fname = os.path.join(savepath, f\"img{n}.jpeg\")\n",
    "                self.save_img(imgs[n], fname)\n",
    "    \n",
    "    def save_img(self, imgs, fname, timesteps=16):\n",
    "        length = imgs.shape[0]\n",
    "        npic = length // timesteps \n",
    "        \n",
    "        nrow = int(np.sqrt(npic))\n",
    "        ncol = int(np.sqrt(npic))\n",
    "        fig, axes = plt.subplots(nrows=nrow, ncols=ncol)\n",
    "        for i in range(nrow):\n",
    "            for j in range(ncol):\n",
    "                axes[i, j].imshow(imgs[nrow * npic + npic * ncol])\n",
    "                # axes[i, j].set_xaxis_off()\n",
    "        fig.savefig(fname)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainer = Trainer(ebm, \n",
    "                        train_loader=train_loader, \n",
    "                        val_loader=val_loader,\n",
    "                        epochs=50, \n",
    "                        savepath=\"/mnt/dl/generation/ebm/generation\",\n",
    "                        batch_size=batch_size,\n",
    "                        # grad_step_scale=10.,\n",
    "                        K=50,\n",
    "                        eval_epoch=10,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, step: 0, loss: 0.0001292488886974752\n",
      "Epoch: 1, step: 10, loss: 0.00020195250611074945\n",
      "Epoch: 1, step: 20, loss: 3.2813809368582e-05\n",
      "Epoch: 1, step: 30, loss: -0.0001759304150548433\n",
      "Epoch: 1, step: 40, loss: -0.000428081394979594\n",
      "Epoch: 1, step: 50, loss: -0.00070470699004135\n",
      "Epoch: 1, step: 60, loss: -0.0010124365236136878\n",
      "Epoch: 1, step: 70, loss: -0.0013285907334648073\n",
      "Epoch: 1, step: 80, loss: -0.0016593246520956817\n",
      "Epoch: 1, step: 90, loss: -0.002022350258782383\n",
      "Epoch: 1, step: 100, loss: -0.0024156400174280574\n",
      "Epoch: 1, step: 110, loss: -0.002837564305901561\n",
      "Epoch: 1, step: 120, loss: -0.0032999134965987554\n",
      "Epoch: 1, step: 130, loss: -0.003799711201670544\n",
      "Epoch: 1, step: 140, loss: -0.004352109497231398\n",
      "Epoch: 1, step: 150, loss: -0.004960358763092031\n",
      "Epoch: 1, step: 160, loss: -0.0056140150976806925\n",
      "Epoch: 1, step: 170, loss: -0.006304464660032124\n",
      "Epoch: 1, step: 180, loss: -0.0070486138114906356\n",
      "Epoch: 1, step: 190, loss: -0.007861291660856534\n",
      "Epoch: 1, step: 200, loss: -0.008708770329246196\n",
      "Epoch: 2, step: 0, loss: -0.026145560666918755\n",
      "Epoch: 2, step: 10, loss: -0.02773976292122494\n",
      "Epoch: 2, step: 20, loss: -0.02903265514898868\n",
      "Epoch: 2, step: 30, loss: -0.030465644754229054\n",
      "Epoch: 2, step: 40, loss: -0.03186636022859957\n",
      "Epoch: 2, step: 50, loss: -0.03308585355533104\n",
      "Epoch: 2, step: 60, loss: -0.034209066879798154\n",
      "Epoch: 2, step: 70, loss: -0.03507827901819222\n",
      "Epoch: 2, step: 80, loss: -0.035909646570130634\n",
      "Epoch: 2, step: 90, loss: -0.03650840680923436\n",
      "Epoch: 2, step: 100, loss: -0.036904475605576345\n",
      "Epoch: 2, step: 110, loss: -0.037044510731960203\n",
      "Epoch: 2, step: 120, loss: -0.03698701006629743\n",
      "Epoch: 2, step: 130, loss: -0.036838850148647795\n",
      "Epoch: 2, step: 140, loss: -0.03646840896219649\n",
      "Epoch: 2, step: 150, loss: -0.03590611046463843\n",
      "Epoch: 2, step: 160, loss: -0.03530132003498744\n",
      "Epoch: 2, step: 170, loss: -0.03470548706357939\n",
      "Epoch: 2, step: 180, loss: -0.03383692910699225\n",
      "Epoch: 2, step: 190, loss: -0.03298624895552066\n",
      "Epoch: 2, step: 200, loss: -0.032152619449171554\n",
      "Epoch: 3, step: 0, loss: -0.010567745193839073\n",
      "Epoch: 3, step: 10, loss: -0.013449963901869276\n",
      "Epoch: 3, step: 20, loss: -0.013473110051736945\n",
      "Epoch: 3, step: 30, loss: -0.013017080018236753\n",
      "Epoch: 3, step: 40, loss: -0.013111033397385986\n",
      "Epoch: 3, step: 50, loss: -0.013145766960566534\n",
      "Epoch: 3, step: 60, loss: -0.012556552726653267\n",
      "Epoch: 3, step: 70, loss: -0.012257970102183836\n",
      "Epoch: 3, step: 80, loss: -0.01234031954412291\n",
      "Epoch: 3, step: 90, loss: -0.012179639947774646\n",
      "Epoch: 3, step: 100, loss: -0.012071300113555228\n",
      "Epoch: 3, step: 110, loss: -0.011914157677811009\n",
      "Epoch: 3, step: 120, loss: -0.011623363041372832\n",
      "Epoch: 3, step: 130, loss: -0.011411754784124498\n",
      "Epoch: 3, step: 140, loss: -0.01125618617598575\n",
      "Epoch: 3, step: 150, loss: -0.01107952847077653\n",
      "Epoch: 3, step: 160, loss: -0.010982643723233331\n",
      "Epoch: 3, step: 170, loss: -0.010918430104437802\n",
      "Epoch: 3, step: 180, loss: -0.010785990556732891\n",
      "Epoch: 3, step: 190, loss: -0.010632549661226297\n",
      "Epoch: 3, step: 200, loss: -0.010530134908558421\n",
      "Epoch: 4, step: 0, loss: -0.004852479789406061\n",
      "Epoch: 4, step: 10, loss: -0.006087838587435809\n",
      "Epoch: 4, step: 20, loss: -0.007027341318981988\n",
      "Epoch: 4, step: 30, loss: -0.007706991817441678\n",
      "Epoch: 4, step: 40, loss: -0.007750856656035999\n",
      "Epoch: 4, step: 50, loss: -0.007515603813397533\n",
      "Epoch: 4, step: 60, loss: -0.007595485740448119\n",
      "Epoch: 4, step: 70, loss: -0.007452787660901815\n",
      "Epoch: 4, step: 80, loss: -0.007488901393465054\n",
      "Epoch: 4, step: 90, loss: -0.007433561741241387\n",
      "Epoch: 4, step: 100, loss: -0.007370041245317991\n",
      "Epoch: 4, step: 110, loss: -0.007277722281680719\n",
      "Epoch: 4, step: 120, loss: -0.007312338472120772\n",
      "Epoch: 4, step: 130, loss: -0.007287595986267765\n",
      "Epoch: 4, step: 140, loss: -0.0071636549699126825\n",
      "Epoch: 4, step: 150, loss: -0.007134901856177098\n",
      "Epoch: 4, step: 160, loss: -0.007062586203726552\n",
      "Epoch: 4, step: 170, loss: -0.007272233453998614\n",
      "Epoch: 4, step: 180, loss: -0.007233624331117993\n",
      "Epoch: 4, step: 190, loss: -0.007055983495903421\n",
      "Epoch: 4, step: 200, loss: -0.007100330429401861\n",
      "Epoch: 5, step: 0, loss: -0.0088856415823102\n",
      "Epoch: 5, step: 10, loss: -0.010330286596647718\n",
      "Epoch: 5, step: 20, loss: -0.008767425659156981\n",
      "Epoch: 5, step: 30, loss: -0.008694604159362854\n",
      "Epoch: 5, step: 40, loss: -0.008702046169740399\n",
      "Epoch: 5, step: 50, loss: -0.008604951568093955\n",
      "Epoch: 5, step: 60, loss: -0.008402595739262025\n",
      "Epoch: 5, step: 70, loss: -0.008431480430119055\n",
      "Epoch: 5, step: 80, loss: -0.008266583527725788\n",
      "Epoch: 5, step: 90, loss: -0.008083775030592313\n",
      "Epoch: 5, step: 100, loss: -0.00824008591122704\n",
      "Epoch: 5, step: 110, loss: -0.008254449076212204\n",
      "Epoch: 5, step: 120, loss: -0.008239399934233713\n",
      "Epoch: 5, step: 130, loss: -0.008106057357953023\n",
      "Epoch: 5, step: 140, loss: -0.008121580192621084\n",
      "Epoch: 5, step: 150, loss: -0.008073406041112561\n",
      "Epoch: 5, step: 160, loss: -0.008091657859221193\n",
      "Epoch: 5, step: 170, loss: -0.008216763340067445\n",
      "Epoch: 5, step: 180, loss: -0.00840447972225056\n",
      "Epoch: 5, step: 190, loss: -0.00835125750730409\n",
      "Epoch: 5, step: 200, loss: -0.008443964063769105\n",
      "Epoch: 6, step: 0, loss: -0.013798782601952553\n",
      "Epoch: 6, step: 10, loss: -0.008517320394854654\n",
      "Epoch: 6, step: 20, loss: -0.00993536233103701\n",
      "Epoch: 6, step: 30, loss: -0.010142375730098255\n",
      "Epoch: 6, step: 40, loss: -0.009791463420431062\n",
      "Epoch: 6, step: 50, loss: -0.01023951783666716\n",
      "Epoch: 6, step: 60, loss: -0.010293192917206248\n",
      "Epoch: 6, step: 70, loss: -0.010152847689746971\n",
      "Epoch: 6, step: 80, loss: -0.01055269520499824\n",
      "Epoch: 6, step: 90, loss: -0.010716019669076898\n",
      "Epoch: 6, step: 100, loss: -0.010814000589607081\n",
      "Epoch: 6, step: 110, loss: -0.010829108104378253\n",
      "Epoch: 6, step: 120, loss: -0.011282570525418874\n",
      "Epoch: 6, step: 130, loss: -0.011381950559990325\n",
      "Epoch: 6, step: 140, loss: -0.011461408359678925\n",
      "Epoch: 6, step: 150, loss: -0.01156467499692511\n",
      "Epoch: 6, step: 160, loss: -0.011591877273474792\n",
      "Epoch: 6, step: 170, loss: -0.011681204310438613\n",
      "Epoch: 6, step: 180, loss: -0.011768603218894308\n",
      "Epoch: 6, step: 190, loss: -0.011846646620204468\n",
      "Epoch: 6, step: 200, loss: -0.011832254549571828\n",
      "Epoch: 7, step: 0, loss: -0.010449482128024101\n",
      "Epoch: 7, step: 10, loss: -0.01168903357095339\n",
      "Epoch: 7, step: 20, loss: -0.012151944606254498\n",
      "Epoch: 7, step: 30, loss: -0.011909090718554874\n",
      "Epoch: 7, step: 40, loss: -0.011900586314590239\n",
      "Epoch: 7, step: 50, loss: -0.011723630020723623\n",
      "Epoch: 7, step: 60, loss: -0.011895741710103437\n",
      "Epoch: 7, step: 70, loss: -0.012050747431972077\n",
      "Epoch: 7, step: 80, loss: -0.012208884558927866\n",
      "Epoch: 7, step: 90, loss: -0.011903119181374927\n",
      "Epoch: 7, step: 100, loss: -0.012242446575166271\n",
      "Epoch: 7, step: 110, loss: -0.012436919862421247\n",
      "Epoch: 7, step: 120, loss: -0.012783882885494015\n",
      "Epoch: 7, step: 130, loss: -0.012732083546637579\n",
      "Epoch: 7, step: 140, loss: -0.012602058341660609\n",
      "Epoch: 7, step: 150, loss: -0.012455257898603645\n",
      "Epoch: 7, step: 160, loss: -0.01238182049695842\n",
      "Epoch: 7, step: 170, loss: -0.012216165819755423\n",
      "Epoch: 7, step: 180, loss: -0.012222194040801314\n",
      "Epoch: 7, step: 190, loss: -0.012250556647094913\n",
      "Epoch: 7, step: 200, loss: -0.012139623652244755\n",
      "Epoch: 8, step: 0, loss: -0.008779969066381454\n",
      "Epoch: 8, step: 10, loss: -0.01172029950909994\n",
      "Epoch: 8, step: 20, loss: -0.011621205657277079\n",
      "Epoch: 8, step: 30, loss: -0.011408107685706308\n",
      "Epoch: 8, step: 40, loss: -0.011247926749425327\n",
      "Epoch: 8, step: 50, loss: -0.011372168224268392\n",
      "Epoch: 8, step: 60, loss: -0.011591768247212787\n",
      "Epoch: 8, step: 70, loss: -0.01153192299575558\n",
      "Epoch: 8, step: 80, loss: -0.011947201786240862\n",
      "Epoch: 8, step: 90, loss: -0.011998738412960218\n",
      "Epoch: 8, step: 100, loss: -0.011927091749385\n",
      "Epoch: 8, step: 110, loss: -0.01204171304817538\n",
      "Epoch: 8, step: 120, loss: -0.012188932894967681\n",
      "Epoch: 8, step: 130, loss: -0.01206579790735006\n",
      "Epoch: 8, step: 140, loss: -0.012010992101743712\n",
      "Epoch: 8, step: 150, loss: -0.01221639947928735\n",
      "Epoch: 8, step: 160, loss: -0.012283675862846444\n",
      "Epoch: 8, step: 170, loss: -0.012349055042457684\n",
      "Epoch: 8, step: 180, loss: -0.012494648892936703\n",
      "Epoch: 8, step: 190, loss: -0.012582818337555254\n",
      "Epoch: 8, step: 200, loss: -0.012848525513102537\n",
      "Epoch: 9, step: 0, loss: -0.014652352780103683\n",
      "Epoch: 9, step: 10, loss: -0.016166282648389988\n",
      "Epoch: 9, step: 20, loss: -0.015921380548250107\n",
      "Epoch: 9, step: 30, loss: -0.014901406649920729\n",
      "Epoch: 9, step: 40, loss: -0.014615141542446686\n",
      "Epoch: 9, step: 50, loss: -0.014037921367322697\n",
      "Epoch: 9, step: 60, loss: -0.013511149136380095\n",
      "Epoch: 9, step: 70, loss: -0.013587639473614768\n",
      "Epoch: 9, step: 80, loss: -0.013332438229778667\n",
      "Epoch: 9, step: 90, loss: -0.013174727551413926\n",
      "Epoch: 9, step: 100, loss: -0.013227313210597575\n",
      "Epoch: 9, step: 110, loss: -0.0131926525107308\n",
      "Epoch: 9, step: 120, loss: -0.012967886066464476\n",
      "Epoch: 9, step: 130, loss: -0.012767235188609885\n",
      "Epoch: 9, step: 140, loss: -0.012698118729312105\n",
      "Epoch: 9, step: 150, loss: -0.012737537289365188\n",
      "Epoch: 9, step: 160, loss: -0.012966468628721532\n",
      "Epoch: 9, step: 170, loss: -0.012768192973113155\n",
      "Epoch: 9, step: 180, loss: -0.012734642429200119\n",
      "Epoch: 9, step: 190, loss: -0.012965289455916518\n",
      "Epoch: 9, step: 200, loss: -0.012859953540164181\n",
      "Epoch: 10, step: 0, loss: -0.014875268563628197\n",
      "Epoch: 10, step: 10, loss: -0.015564122491262176\n",
      "Epoch: 10, step: 20, loss: -0.01690871592256285\n",
      "Epoch: 10, step: 30, loss: -0.01620897296966324\n",
      "Epoch: 10, step: 40, loss: -0.015538902640933307\n",
      "Epoch: 10, step: 50, loss: -0.0145723338686295\n",
      "Epoch: 10, step: 60, loss: -0.013782972550080692\n",
      "Epoch: 10, step: 70, loss: -0.013450349374464385\n",
      "Epoch: 10, step: 80, loss: -0.013102569979512028\n",
      "Epoch: 10, step: 90, loss: -0.013228533241979696\n",
      "Epoch: 10, step: 100, loss: -0.013414331241556913\n",
      "Epoch: 10, step: 110, loss: -0.013090830153643011\n",
      "Epoch: 10, step: 120, loss: -0.013104810933620968\n",
      "Epoch: 10, step: 130, loss: -0.013039058289412438\n",
      "Epoch: 10, step: 140, loss: -0.012945539365086625\n",
      "Epoch: 10, step: 150, loss: -0.012934485802716816\n",
      "Epoch: 10, step: 160, loss: -0.013003655757772395\n",
      "Epoch: 10, step: 170, loss: -0.012856109851388511\n",
      "Epoch: 10, step: 180, loss: -0.012898764263668731\n",
      "Epoch: 10, step: 190, loss: -0.01274279989692241\n",
      "Epoch: 10, step: 200, loss: -0.012701320026384954\n",
      "Epoch: 11, step: 0, loss: -0.011149482801556587\n",
      "Epoch: 11, step: 10, loss: -0.0070109163220463825\n",
      "Epoch: 11, step: 20, loss: -0.007410293051396452\n",
      "Epoch: 11, step: 30, loss: -0.00861449777373984\n",
      "Epoch: 11, step: 40, loss: -0.008988575637908426\n",
      "Epoch: 11, step: 50, loss: -0.008651794804095784\n",
      "Epoch: 11, step: 60, loss: -0.00928056611656593\n",
      "Epoch: 11, step: 70, loss: -0.008815330215467428\n",
      "Epoch: 11, step: 80, loss: -0.009035195117632363\n",
      "Epoch: 11, step: 90, loss: -0.009114068812578098\n",
      "Epoch: 11, step: 100, loss: -0.009265367552582728\n",
      "Epoch: 11, step: 110, loss: -0.009221194631856371\n",
      "Epoch: 11, step: 120, loss: -0.009140099690311149\n",
      "Epoch: 11, step: 130, loss: -0.009196813029009593\n",
      "Epoch: 11, step: 140, loss: -0.009219902153919511\n",
      "Epoch: 11, step: 150, loss: -0.009040678791942335\n",
      "Epoch: 11, step: 160, loss: -0.00916802627106793\n",
      "Epoch: 11, step: 170, loss: -0.009248652379368895\n",
      "Epoch: 11, step: 180, loss: -0.009261779004427506\n",
      "Epoch: 11, step: 190, loss: -0.0093069513622764\n",
      "Epoch: 11, step: 200, loss: -0.009358172244403919\n",
      "Epoch: 12, step: 0, loss: -0.008403556421399117\n",
      "Epoch: 12, step: 10, loss: -0.008502417222850701\n",
      "Epoch: 12, step: 20, loss: -0.008292844327765383\n",
      "Epoch: 12, step: 30, loss: -0.007364085404157278\n",
      "Epoch: 12, step: 40, loss: -0.007615766161484871\n",
      "Epoch: 12, step: 50, loss: -0.00823950581252575\n",
      "Epoch: 12, step: 60, loss: -0.008265614669892143\n",
      "Epoch: 12, step: 70, loss: -0.008408963286750754\n",
      "Epoch: 12, step: 80, loss: -0.008652899389868074\n",
      "Epoch: 12, step: 90, loss: -0.008453420692783585\n",
      "Epoch: 12, step: 100, loss: -0.008289893073638404\n",
      "Epoch: 12, step: 110, loss: -0.008395581320557441\n",
      "Epoch: 12, step: 120, loss: -0.008313988680828147\n",
      "Epoch: 12, step: 130, loss: -0.008214163726359207\n",
      "Epoch: 12, step: 140, loss: -0.008019484973393698\n",
      "Epoch: 12, step: 150, loss: -0.007965200038669963\n",
      "Epoch: 12, step: 160, loss: -0.007912508540668219\n",
      "Epoch: 12, step: 170, loss: -0.00789482883832619\n",
      "Epoch: 12, step: 180, loss: -0.00785913500382992\n",
      "Epoch: 12, step: 190, loss: -0.007634216154003955\n",
      "Epoch: 12, step: 200, loss: -0.007533959134201524\n",
      "Epoch: 13, step: 0, loss: -0.006332267075777054\n",
      "Epoch: 13, step: 10, loss: -0.002685196290258318\n",
      "Epoch: 13, step: 20, loss: -0.004087343831391384\n",
      "Epoch: 13, step: 30, loss: -0.0034034735909963566\n",
      "Epoch: 13, step: 40, loss: -0.003806603816905763\n",
      "Epoch: 13, step: 50, loss: -0.004060807706349913\n",
      "Epoch: 13, step: 60, loss: -0.004387031452440214\n",
      "Epoch: 13, step: 70, loss: -0.0034281956138495933\n",
      "Epoch: 13, step: 80, loss: -0.0034984728202143295\n",
      "Epoch: 13, step: 90, loss: -0.0038662799985843947\n",
      "Epoch: 13, step: 100, loss: -0.003708500973534503\n",
      "Epoch: 13, step: 110, loss: -0.0036612420184495816\n",
      "Epoch: 13, step: 120, loss: -0.0034342265850479505\n",
      "Epoch: 13, step: 130, loss: -0.003610072261564974\n",
      "Epoch: 13, step: 140, loss: -0.0037106628437255716\n",
      "Epoch: 13, step: 150, loss: -0.003922269004242902\n",
      "Epoch: 13, step: 160, loss: -0.0038212962609119943\n",
      "Epoch: 13, step: 170, loss: -0.0037504244801365057\n",
      "Epoch: 13, step: 180, loss: -0.0035424257383568636\n",
      "Epoch: 13, step: 190, loss: -0.0035134470337119285\n",
      "Epoch: 13, step: 200, loss: -0.003550347800260011\n",
      "Epoch: 14, step: 0, loss: -0.0036432205233722925\n",
      "Epoch: 14, step: 10, loss: -0.003595193308270113\n",
      "Epoch: 14, step: 20, loss: -0.004129514624808161\n",
      "Epoch: 14, step: 30, loss: -0.0033880378074583506\n",
      "Epoch: 14, step: 40, loss: -0.0025851391057097692\n",
      "Epoch: 14, step: 50, loss: -0.0029598939513294574\n",
      "Epoch: 14, step: 60, loss: -0.003225682260369363\n",
      "Epoch: 14, step: 70, loss: -0.003896340827824889\n",
      "Epoch: 14, step: 80, loss: -0.0035258611997612465\n",
      "Epoch: 14, step: 90, loss: -0.0030552000805203405\n",
      "Epoch: 14, step: 100, loss: -0.0031001081599134695\n",
      "Epoch: 14, step: 110, loss: -0.002904362926209295\n",
      "Epoch: 14, step: 120, loss: -0.002823868853016949\n",
      "Epoch: 14, step: 130, loss: -0.0026922589581182496\n",
      "Epoch: 14, step: 140, loss: -0.0026290079055301158\n",
      "Epoch: 14, step: 150, loss: -0.0023560228993474747\n",
      "Epoch: 14, step: 160, loss: -0.002131972211031301\n",
      "Epoch: 14, step: 170, loss: -0.0018385903537409564\n",
      "Epoch: 14, step: 180, loss: -0.0019134286481074124\n",
      "Epoch: 14, step: 190, loss: -0.0017726654881679732\n",
      "Epoch: 14, step: 200, loss: -0.0020054540995378695\n",
      "Epoch: 15, step: 0, loss: 0.0013736191904172301\n",
      "Epoch: 15, step: 10, loss: 0.00018343205606056884\n",
      "Epoch: 15, step: 20, loss: 0.0011520930953944724\n",
      "Epoch: 15, step: 30, loss: -0.0009348964480112397\n",
      "Epoch: 15, step: 40, loss: -0.0014199663334094534\n",
      "Epoch: 15, step: 50, loss: -0.002098571949674949\n",
      "Epoch: 15, step: 60, loss: -0.002227546283631723\n",
      "Epoch: 15, step: 70, loss: -0.0019228990857069657\n",
      "Epoch: 15, step: 80, loss: -0.002326128015547623\n",
      "Epoch: 15, step: 90, loss: -0.0023843867942220072\n",
      "Epoch: 15, step: 100, loss: -0.002093822342611038\n",
      "Epoch: 15, step: 110, loss: -0.0021097549464897595\n",
      "Epoch: 15, step: 120, loss: -0.001967631924554921\n",
      "Epoch: 15, step: 130, loss: -0.0020546986439748745\n",
      "Epoch: 15, step: 140, loss: -0.0019722212715312204\n",
      "Epoch: 15, step: 150, loss: -0.0020126547696784334\n",
      "Epoch: 15, step: 160, loss: -0.0019480045136463428\n",
      "Epoch: 15, step: 170, loss: -0.0019399186069341866\n",
      "Epoch: 15, step: 180, loss: -0.001908090779524379\n",
      "Epoch: 15, step: 190, loss: -0.002066858459924743\n",
      "Epoch: 15, step: 200, loss: -0.002057097598548923\n",
      "Epoch: 16, step: 0, loss: 0.005388735327869654\n",
      "Epoch: 16, step: 10, loss: -0.0043416630995290525\n",
      "Epoch: 16, step: 20, loss: -0.0025678005823422047\n",
      "Epoch: 16, step: 30, loss: -0.002406139101367444\n",
      "Epoch: 16, step: 40, loss: -0.0017786389103204739\n",
      "Epoch: 16, step: 50, loss: -0.0017639042070025906\n",
      "Epoch: 16, step: 60, loss: -0.001985990813528722\n",
      "Epoch: 16, step: 70, loss: -0.0015526318456977606\n",
      "Epoch: 16, step: 80, loss: -0.001704404616360495\n",
      "Epoch: 16, step: 90, loss: -0.0018833404570654199\n",
      "Epoch: 16, step: 100, loss: -0.0017509103532520926\n",
      "Epoch: 16, step: 110, loss: -0.0015084746425870705\n",
      "Epoch: 16, step: 120, loss: -0.0011867293443392254\n",
      "Epoch: 16, step: 130, loss: -0.0013763363173636715\n",
      "Epoch: 16, step: 140, loss: -0.001369778729450116\n",
      "Epoch: 16, step: 150, loss: -0.0014407049208441565\n",
      "Epoch: 16, step: 160, loss: -0.001467432777949765\n",
      "Epoch: 16, step: 170, loss: -0.0012854089543811586\n",
      "Epoch: 16, step: 180, loss: -0.0013325214482463115\n",
      "Epoch: 16, step: 190, loss: -0.001343843007231063\n",
      "Epoch: 16, step: 200, loss: -0.0012674948518553665\n",
      "Epoch: 17, step: 0, loss: -0.007198139559477568\n",
      "Epoch: 17, step: 10, loss: -0.00019977156559682706\n",
      "Epoch: 17, step: 20, loss: -0.0010594900869320902\n",
      "Epoch: 17, step: 30, loss: -0.000963071224114467\n",
      "Epoch: 17, step: 40, loss: -0.0015539306190387324\n",
      "Epoch: 17, step: 50, loss: -0.0021907502646083196\n",
      "Epoch: 17, step: 60, loss: -0.0023425478043538504\n",
      "Epoch: 17, step: 70, loss: -0.0019135259741156455\n",
      "Epoch: 17, step: 80, loss: -0.0016343976905638421\n",
      "Epoch: 17, step: 90, loss: -0.0017437641483291492\n",
      "Epoch: 17, step: 100, loss: -0.0018583448410107947\n",
      "Epoch: 17, step: 110, loss: -0.001817455167068286\n",
      "Epoch: 17, step: 120, loss: -0.0019839512038021543\n",
      "Epoch: 17, step: 130, loss: -0.002203904418896827\n",
      "Epoch: 17, step: 140, loss: -0.0017214064393027402\n",
      "Epoch: 17, step: 150, loss: -0.0018862568721674778\n",
      "Epoch: 17, step: 160, loss: -0.0019382494584923343\n",
      "Epoch: 17, step: 170, loss: -0.0019455917747364495\n",
      "Epoch: 17, step: 180, loss: -0.0018977917832430473\n",
      "Epoch: 17, step: 190, loss: -0.0019404349268989452\n",
      "Epoch: 17, step: 200, loss: -0.0017467706440484605\n",
      "Epoch: 18, step: 0, loss: -0.012488721869885921\n",
      "Epoch: 18, step: 10, loss: -0.0040509998375041914\n",
      "Epoch: 18, step: 20, loss: -0.003065758778358854\n",
      "Epoch: 18, step: 30, loss: -0.0017035440278930529\n",
      "Epoch: 18, step: 40, loss: -0.0010287470465366979\n",
      "Epoch: 18, step: 50, loss: -0.0014053636102699767\n",
      "Epoch: 18, step: 60, loss: -0.0012970159639466982\n",
      "Epoch: 18, step: 70, loss: -0.0017057994846254587\n",
      "Epoch: 18, step: 80, loss: -0.0015392121140281726\n",
      "Epoch: 18, step: 90, loss: -0.001696478603612427\n",
      "Epoch: 18, step: 100, loss: -0.0017893273339579159\n",
      "Epoch: 18, step: 110, loss: -0.0016690043025641694\n",
      "Epoch: 18, step: 120, loss: -0.001260329900917497\n",
      "Epoch: 18, step: 130, loss: -0.0012131182624396818\n",
      "Epoch: 18, step: 140, loss: -0.0013210584982529495\n",
      "Epoch: 18, step: 150, loss: -0.001236166611517354\n",
      "Epoch: 18, step: 160, loss: -0.001289605445037625\n",
      "Epoch: 18, step: 170, loss: -0.00093711848092968\n",
      "Epoch: 18, step: 180, loss: -0.0009793889881188863\n",
      "Epoch: 18, step: 190, loss: -0.0012451879749030693\n",
      "Epoch: 18, step: 200, loss: -0.0011042523020021247\n",
      "Epoch: 19, step: 0, loss: -0.014684372581541538\n",
      "Epoch: 19, step: 10, loss: 0.0005123729933984578\n",
      "Epoch: 19, step: 20, loss: 0.00043233232073751945\n",
      "Epoch: 19, step: 30, loss: -0.00019745309574289188\n",
      "Epoch: 19, step: 40, loss: -0.0007032128931136756\n",
      "Epoch: 19, step: 50, loss: -0.0003332445996028243\n",
      "Epoch: 19, step: 60, loss: -0.0009223399664748643\n",
      "Epoch: 19, step: 70, loss: -0.000774792539001718\n",
      "Epoch: 19, step: 80, loss: -0.0009904833550760407\n",
      "Epoch: 19, step: 90, loss: -0.001175106458294277\n",
      "Epoch: 19, step: 100, loss: -0.001021709358826796\n",
      "Epoch: 19, step: 110, loss: -0.0007967470373186443\n",
      "Epoch: 19, step: 120, loss: -0.0008251619403065791\n",
      "Epoch: 19, step: 130, loss: -0.0008359814866069164\n",
      "Epoch: 19, step: 140, loss: -0.0013557821223248087\n",
      "Epoch: 19, step: 150, loss: -0.0017578280280307183\n",
      "Epoch: 19, step: 160, loss: -0.0015489856028489722\n",
      "Epoch: 19, step: 170, loss: -0.0016479859212331735\n",
      "Epoch: 19, step: 180, loss: -0.001791751805566848\n",
      "Epoch: 19, step: 190, loss: -0.0017184812958956897\n",
      "Epoch: 19, step: 200, loss: -0.001778208681055581\n",
      "Epoch: 20, step: 0, loss: -0.01207922026515007\n",
      "Epoch: 20, step: 10, loss: -0.002904440810776908\n",
      "Epoch: 20, step: 20, loss: -0.0016691911982239357\n",
      "Epoch: 20, step: 30, loss: -0.0014056141052635448\n",
      "Epoch: 20, step: 40, loss: -0.0006130494052407945\n",
      "Epoch: 20, step: 50, loss: -0.00023658110248837985\n",
      "Epoch: 20, step: 60, loss: -0.0001670451067601804\n",
      "Epoch: 20, step: 70, loss: -0.0004104892223168322\n",
      "Epoch: 20, step: 80, loss: -0.0002211413840636795\n",
      "Epoch: 20, step: 90, loss: 0.00020950128468889538\n",
      "Epoch: 20, step: 100, loss: 9.942726326626863e-06\n",
      "Epoch: 20, step: 110, loss: 0.00021429418880903573\n",
      "Epoch: 20, step: 120, loss: 0.00017813758944807776\n",
      "Epoch: 20, step: 130, loss: 0.00021559770244799326\n",
      "Epoch: 20, step: 140, loss: 0.00016129674602148011\n",
      "Epoch: 20, step: 150, loss: -4.454048998832752e-05\n",
      "Epoch: 20, step: 160, loss: -0.00021274292046892577\n",
      "Epoch: 20, step: 170, loss: -0.0001397634429546694\n",
      "Epoch: 20, step: 180, loss: -0.0002043478159383145\n",
      "Epoch: 20, step: 190, loss: -0.0003012840779917558\n",
      "Epoch: 20, step: 200, loss: -0.0004959929559555887\n",
      "Epoch: 21, step: 0, loss: -0.004356917925179005\n",
      "Epoch: 21, step: 10, loss: -0.004774795231324705\n",
      "Epoch: 21, step: 20, loss: -0.0003696658365827586\n",
      "Epoch: 21, step: 30, loss: -0.0003900561066749956\n",
      "Epoch: 21, step: 40, loss: -0.0012390081445607015\n",
      "Epoch: 21, step: 50, loss: -0.0012172180286142975\n",
      "Epoch: 21, step: 60, loss: -0.0007037669062408329\n",
      "Epoch: 21, step: 70, loss: -0.0007091633935334344\n",
      "Epoch: 21, step: 80, loss: -0.0003662977326678595\n",
      "Epoch: 21, step: 90, loss: -0.00021110151818912518\n",
      "Epoch: 21, step: 100, loss: -0.0003365602619176048\n",
      "Epoch: 21, step: 110, loss: -0.0004352503521724495\n",
      "Epoch: 21, step: 120, loss: -0.0006238517651145832\n",
      "Epoch: 21, step: 130, loss: -0.000752131002093132\n",
      "Epoch: 21, step: 140, loss: -0.000704509117153427\n",
      "Epoch: 21, step: 150, loss: -0.0007536808988279879\n",
      "Epoch: 21, step: 160, loss: -0.0007838418691705403\n",
      "Epoch: 21, step: 170, loss: -0.0008580531613160557\n",
      "Epoch: 21, step: 180, loss: -0.0009745485168619298\n",
      "Epoch: 21, step: 190, loss: -0.001061079781063642\n",
      "Epoch: 21, step: 200, loss: -0.0012279364401451428\n",
      "Epoch: 22, step: 0, loss: -0.004195868503302336\n",
      "Epoch: 22, step: 10, loss: -0.002948402374220843\n",
      "Epoch: 22, step: 20, loss: -0.0023960331732052424\n",
      "Epoch: 22, step: 30, loss: -0.0015187835031669707\n",
      "Epoch: 22, step: 40, loss: -0.0014432119475336882\n",
      "Epoch: 22, step: 50, loss: -0.0020383186124758247\n",
      "Epoch: 22, step: 60, loss: -0.0016797244020157539\n",
      "Epoch: 22, step: 70, loss: -0.0010316125469767607\n",
      "Epoch: 22, step: 80, loss: -0.0011820910501374323\n",
      "Epoch: 22, step: 90, loss: -0.0009573672010286988\n",
      "Epoch: 22, step: 100, loss: -0.0011090477496284144\n",
      "Epoch: 22, step: 110, loss: -0.0013174057465155718\n",
      "Epoch: 22, step: 120, loss: -0.0013184144713892793\n",
      "Epoch: 22, step: 130, loss: -0.0014346327387393658\n",
      "Epoch: 22, step: 140, loss: -0.0013412968812886864\n",
      "Epoch: 22, step: 150, loss: -0.0014476337476281931\n",
      "Epoch: 22, step: 160, loss: -0.0014442405057854095\n",
      "Epoch: 22, step: 170, loss: -0.0013272813928098424\n",
      "Epoch: 22, step: 180, loss: -0.001164364944133671\n",
      "Epoch: 22, step: 190, loss: -0.0012469499672736232\n",
      "Epoch: 22, step: 200, loss: -0.0009984638313450087\n",
      "Epoch: 23, step: 0, loss: -0.002974320203065872\n",
      "Epoch: 23, step: 10, loss: 1.967884600162506e-05\n",
      "Epoch: 23, step: 20, loss: -0.0010401375447621657\n",
      "Epoch: 23, step: 30, loss: -0.0019340801593517103\n",
      "Epoch: 23, step: 40, loss: -0.001328358438047694\n",
      "Epoch: 23, step: 50, loss: -0.0012412384419482859\n",
      "Epoch: 23, step: 60, loss: -0.001551612792727461\n",
      "Epoch: 23, step: 70, loss: -0.0017036049246368274\n",
      "Epoch: 23, step: 80, loss: -0.0015505019878612164\n",
      "Epoch: 23, step: 90, loss: -0.0013163480223258855\n",
      "Epoch: 23, step: 100, loss: -0.0013009020787811295\n",
      "Epoch: 23, step: 110, loss: -0.001163900200317421\n",
      "Epoch: 23, step: 120, loss: -0.0010630616738772681\n",
      "Epoch: 23, step: 130, loss: -0.0009964136831117582\n",
      "Epoch: 23, step: 140, loss: -0.0008967812402183784\n",
      "Epoch: 23, step: 150, loss: -0.0009875502358329489\n",
      "Epoch: 23, step: 160, loss: -0.001016013830595054\n",
      "Epoch: 23, step: 170, loss: -0.0011340333538590141\n",
      "Epoch: 23, step: 180, loss: -0.0011420430295884568\n",
      "Epoch: 23, step: 190, loss: -0.001084952965056943\n",
      "Epoch: 23, step: 200, loss: -0.0011255626768842154\n",
      "Epoch: 24, step: 0, loss: 0.005257994402199984\n",
      "Epoch: 24, step: 10, loss: -0.0047353282253342595\n",
      "Epoch: 24, step: 20, loss: -0.0017182906546319525\n",
      "Epoch: 24, step: 30, loss: -0.0011043813090861564\n",
      "Epoch: 24, step: 40, loss: -0.00046560402090729374\n",
      "Epoch: 24, step: 50, loss: -0.0005731158536018841\n",
      "Epoch: 24, step: 60, loss: -0.0004468980239566843\n",
      "Epoch: 24, step: 70, loss: 5.4053415816513375e-05\n",
      "Epoch: 24, step: 80, loss: 0.00013512796772655421\n",
      "Epoch: 24, step: 90, loss: -9.198293664267512e-05\n",
      "Epoch: 24, step: 100, loss: -0.00040095760331415375\n",
      "Epoch: 24, step: 110, loss: -0.00015767837842078962\n",
      "Epoch: 24, step: 120, loss: -0.00012805327423848212\n",
      "Epoch: 24, step: 130, loss: -0.00019735181775256877\n",
      "Epoch: 24, step: 140, loss: -0.00021759903447286403\n",
      "Epoch: 24, step: 150, loss: -0.00015688431776893504\n",
      "Epoch: 24, step: 160, loss: 8.719024571636403e-05\n",
      "Epoch: 24, step: 170, loss: -1.0218980690812943e-05\n",
      "Epoch: 24, step: 180, loss: -0.0001339478634017422\n",
      "Epoch: 24, step: 190, loss: -0.0002090238291936005\n",
      "Epoch: 24, step: 200, loss: -0.00010539911135994084\n",
      "Epoch: 25, step: 0, loss: 0.0051148128695786\n",
      "Epoch: 25, step: 10, loss: -0.000756798248568719\n",
      "Epoch: 25, step: 20, loss: -0.0012653456180400792\n",
      "Epoch: 25, step: 30, loss: -0.0010861042631609785\n",
      "Epoch: 25, step: 40, loss: -0.001384846171897995\n",
      "Epoch: 25, step: 50, loss: -0.0014164977508377941\n",
      "Epoch: 25, step: 60, loss: -0.0021315381268695852\n",
      "Epoch: 25, step: 70, loss: -0.0024621842005191712\n",
      "Epoch: 25, step: 80, loss: -0.002645652979414013\n",
      "Epoch: 25, step: 90, loss: -0.0026525222871626552\n",
      "Epoch: 25, step: 100, loss: -0.002401774801604339\n",
      "Epoch: 25, step: 110, loss: -0.0025634978751563845\n",
      "Epoch: 25, step: 120, loss: -0.0023986891516742164\n",
      "Epoch: 25, step: 130, loss: -0.0022586175877750206\n",
      "Epoch: 25, step: 140, loss: -0.002100063853233339\n",
      "Epoch: 25, step: 150, loss: -0.0020089290919713676\n",
      "Epoch: 25, step: 160, loss: -0.0020892661327339985\n",
      "Epoch: 25, step: 170, loss: -0.0020463039560041974\n",
      "Epoch: 25, step: 180, loss: -0.0018955043733161127\n",
      "Epoch: 25, step: 190, loss: -0.0018352102439518998\n",
      "Epoch: 25, step: 200, loss: -0.0018051515480466372\n",
      "Epoch: 26, step: 0, loss: -0.0017645691987127066\n",
      "Epoch: 26, step: 10, loss: -0.0022029150171544065\n",
      "Epoch: 26, step: 20, loss: -0.0012884249167871616\n",
      "Epoch: 26, step: 30, loss: -0.0006562119721615266\n",
      "Epoch: 26, step: 40, loss: -0.0009851107123966625\n",
      "Epoch: 26, step: 50, loss: -0.0008656516506829683\n",
      "Epoch: 26, step: 60, loss: -0.0014152658519289288\n",
      "Epoch: 26, step: 70, loss: -0.0016684979442211892\n",
      "Epoch: 26, step: 80, loss: -0.001677461521467194\n",
      "Epoch: 26, step: 90, loss: -0.0018660641818404567\n",
      "Epoch: 26, step: 100, loss: -0.0014255885475679385\n",
      "Epoch: 26, step: 110, loss: -0.0014207478445379886\n",
      "Epoch: 26, step: 120, loss: -0.0014394299776104764\n",
      "Epoch: 26, step: 130, loss: -0.0013346436323743768\n",
      "Epoch: 26, step: 140, loss: -0.001171575951041548\n",
      "Epoch: 26, step: 150, loss: -0.0011451511893618778\n",
      "Epoch: 26, step: 160, loss: -0.0011421106661733541\n",
      "Epoch: 26, step: 170, loss: -0.0010339643864767157\n",
      "Epoch: 26, step: 180, loss: -0.0010670535594420455\n",
      "Epoch: 26, step: 190, loss: -0.0010537528778799365\n",
      "Epoch: 26, step: 200, loss: -0.0010793171804201376\n",
      "Epoch: 27, step: 0, loss: 0.0037345211021602154\n",
      "Epoch: 27, step: 10, loss: -0.002148823497753421\n",
      "Epoch: 27, step: 20, loss: -0.001343300865430917\n",
      "Epoch: 27, step: 30, loss: -0.001002232768505271\n",
      "Epoch: 27, step: 40, loss: -0.0014789798644814277\n",
      "Epoch: 27, step: 50, loss: -0.0017526044753407512\n",
      "Epoch: 27, step: 60, loss: -0.0017766674210462476\n",
      "Epoch: 27, step: 70, loss: -0.0017469156591687351\n",
      "Epoch: 27, step: 80, loss: -0.0016597892121084173\n",
      "Epoch: 27, step: 90, loss: -0.0017403371962795423\n",
      "Epoch: 27, step: 100, loss: -0.0018299624080640624\n",
      "Epoch: 27, step: 110, loss: -0.0019357959726229645\n",
      "Epoch: 27, step: 120, loss: -0.00171999201853952\n",
      "Epoch: 27, step: 130, loss: -0.0015442617026953922\n",
      "Epoch: 27, step: 140, loss: -0.0015992997437121069\n",
      "Epoch: 27, step: 150, loss: -0.0015481672830269086\n",
      "Epoch: 27, step: 160, loss: -0.0013400521019100563\n",
      "Epoch: 27, step: 170, loss: -0.0013143849068618112\n",
      "Epoch: 27, step: 180, loss: -0.001163415425394029\n",
      "Epoch: 27, step: 190, loss: -0.0011625532763315297\n",
      "Epoch: 27, step: 200, loss: -0.0011171885206889992\n",
      "Epoch: 28, step: 0, loss: 0.0004532083112280816\n",
      "Epoch: 28, step: 10, loss: 0.0008594754697035321\n",
      "Epoch: 28, step: 20, loss: -0.00041896494249591516\n",
      "Epoch: 28, step: 30, loss: -0.0002647914150128922\n",
      "Epoch: 28, step: 40, loss: -0.00016829361301483358\n",
      "Epoch: 28, step: 50, loss: -0.00012553519370746524\n",
      "Epoch: 28, step: 60, loss: -0.0002460023378724324\n",
      "Epoch: 28, step: 70, loss: -0.00026424811549589667\n",
      "Epoch: 28, step: 80, loss: -0.00029563287687689113\n",
      "Epoch: 28, step: 90, loss: -3.0142594618814904e-05\n",
      "Epoch: 28, step: 100, loss: -0.00011820952903069003\n",
      "Epoch: 28, step: 110, loss: -0.00023302748374041035\n",
      "Epoch: 28, step: 120, loss: -0.0005533072426636157\n",
      "Epoch: 28, step: 130, loss: -0.0007783875309458741\n",
      "Epoch: 28, step: 140, loss: -0.0007621141651964\n",
      "Epoch: 28, step: 150, loss: -0.0007404168287719236\n",
      "Epoch: 28, step: 160, loss: -0.0007763614124070378\n",
      "Epoch: 28, step: 170, loss: -0.0007846049719513258\n",
      "Epoch: 28, step: 180, loss: -0.0007826415362841198\n",
      "Epoch: 28, step: 190, loss: -0.0009334867897703122\n",
      "Epoch: 28, step: 200, loss: -0.0009290411715356364\n",
      "Epoch: 29, step: 0, loss: -0.005629609804600477\n",
      "Epoch: 29, step: 10, loss: -0.0012343131661923094\n",
      "Epoch: 29, step: 20, loss: -0.0019588219133549415\n",
      "Epoch: 29, step: 30, loss: -0.001485226764118359\n",
      "Epoch: 29, step: 40, loss: -0.0018378357784879372\n",
      "Epoch: 29, step: 50, loss: -0.0014729801435297465\n",
      "Epoch: 29, step: 60, loss: -0.0011789658682737653\n",
      "Epoch: 29, step: 70, loss: -0.0011585706369016766\n",
      "Epoch: 29, step: 80, loss: -0.0008201053357800974\n",
      "Epoch: 29, step: 90, loss: -0.0004404013054407007\n",
      "Epoch: 29, step: 100, loss: -0.00027837699102260875\n",
      "Epoch: 29, step: 110, loss: -0.00036124631210318386\n",
      "Epoch: 29, step: 120, loss: -0.0004484955830430258\n",
      "Epoch: 29, step: 130, loss: -0.000705618092715598\n",
      "Epoch: 29, step: 140, loss: -0.0007091916586496993\n",
      "Epoch: 29, step: 150, loss: -0.0007056583806915542\n",
      "Epoch: 29, step: 160, loss: -0.0007495795208845079\n",
      "Epoch: 29, step: 170, loss: -0.0006823813684328257\n",
      "Epoch: 29, step: 180, loss: -0.0007750485960692579\n",
      "Epoch: 29, step: 190, loss: -0.0007196787490444843\n",
      "Epoch: 29, step: 200, loss: -0.0006708528546631494\n",
      "Epoch: 30, step: 0, loss: -0.0001847977691795677\n",
      "Epoch: 30, step: 10, loss: 0.0019975021687886592\n",
      "Epoch: 30, step: 20, loss: 0.0010556136763798783\n",
      "Epoch: 30, step: 30, loss: 0.000967642848639028\n",
      "Epoch: 30, step: 40, loss: 0.0005139812593569797\n",
      "Epoch: 30, step: 50, loss: -3.3922924593949287e-05\n",
      "Epoch: 30, step: 60, loss: 0.00023831018283925035\n",
      "Epoch: 30, step: 70, loss: 0.00029940625204225924\n",
      "Epoch: 30, step: 80, loss: -8.335504300007021e-06\n",
      "Epoch: 30, step: 90, loss: -1.5867886659279874e-05\n",
      "Epoch: 30, step: 100, loss: -0.0002668070603141303\n",
      "Epoch: 30, step: 110, loss: -0.0003073964162303873\n",
      "Epoch: 30, step: 120, loss: -0.00016158338504350815\n",
      "Epoch: 30, step: 130, loss: 5.267844188830438e-06\n",
      "Epoch: 30, step: 140, loss: -1.7377244703247086e-05\n",
      "Epoch: 30, step: 150, loss: -0.00011690323443818122\n",
      "Epoch: 30, step: 160, loss: -0.00033501768737788433\n",
      "Epoch: 30, step: 170, loss: -0.0003011941951318312\n",
      "Epoch: 30, step: 180, loss: -0.00027432122285630893\n",
      "Epoch: 30, step: 190, loss: -0.0003724391099430635\n",
      "Epoch: 30, step: 200, loss: -0.00043970566984718963\n",
      "Epoch: 31, step: 0, loss: 0.003507261397317052\n",
      "Epoch: 31, step: 10, loss: -0.002224469562696124\n",
      "Epoch: 31, step: 20, loss: -0.0010269087894509237\n",
      "Epoch: 31, step: 30, loss: -0.001074250370654608\n",
      "Epoch: 31, step: 40, loss: -0.0009664671350747529\n",
      "Epoch: 31, step: 50, loss: -0.001008238844281318\n",
      "Epoch: 31, step: 60, loss: -0.0008388299210623028\n",
      "Epoch: 31, step: 70, loss: -0.0008992520005206092\n",
      "Epoch: 31, step: 80, loss: -0.0009663659104801438\n",
      "Epoch: 31, step: 90, loss: -0.0006302701166042915\n",
      "Epoch: 31, step: 100, loss: -0.0006756236840680353\n",
      "Epoch: 31, step: 110, loss: -0.0006644447555142531\n",
      "Epoch: 31, step: 120, loss: -0.0007977400932120437\n",
      "Epoch: 31, step: 130, loss: -0.000703805479050422\n",
      "Epoch: 31, step: 140, loss: -0.0006847372495301781\n",
      "Epoch: 31, step: 150, loss: -0.0007316199671369145\n",
      "Epoch: 31, step: 160, loss: -0.0008571818798147026\n",
      "Epoch: 31, step: 170, loss: -0.000957516742473991\n",
      "Epoch: 31, step: 180, loss: -0.0009926973843049176\n",
      "Epoch: 31, step: 190, loss: -0.0009703784725441066\n",
      "Epoch: 31, step: 200, loss: -0.0009872290684867057\n",
      "Epoch: 32, step: 0, loss: 0.0008570695063099265\n",
      "Epoch: 32, step: 10, loss: -0.0017111158575227653\n",
      "Epoch: 32, step: 20, loss: -0.0023212442548745976\n",
      "Epoch: 32, step: 30, loss: -0.0011912624848323063\n",
      "Epoch: 32, step: 40, loss: -0.0013489399631308938\n",
      "Epoch: 32, step: 50, loss: -0.0014705409015661251\n",
      "Epoch: 32, step: 60, loss: -0.0009892735342575299\n",
      "Epoch: 32, step: 70, loss: -0.0008635391898512263\n",
      "Epoch: 32, step: 80, loss: -0.0010310894558867325\n",
      "Epoch: 32, step: 90, loss: -0.0008844666964640575\n",
      "Epoch: 32, step: 100, loss: -0.000809190511855638\n",
      "Epoch: 32, step: 110, loss: -0.0008197470505455476\n",
      "Epoch: 32, step: 120, loss: -0.0007687156106208736\n",
      "Epoch: 32, step: 130, loss: -0.0007330833429707044\n",
      "Epoch: 32, step: 140, loss: -0.0007617053228425496\n",
      "Epoch: 32, step: 150, loss: -0.0006728133913137278\n",
      "Epoch: 32, step: 160, loss: -0.0007308561563483144\n",
      "Epoch: 32, step: 170, loss: -0.0006767831147411478\n",
      "Epoch: 32, step: 180, loss: -0.0005937377873676937\n",
      "Epoch: 32, step: 190, loss: -0.0005931737252172199\n",
      "Epoch: 32, step: 200, loss: -0.0006719178094300418\n",
      "Epoch: 33, step: 0, loss: -0.0020990034099668264\n",
      "Epoch: 33, step: 10, loss: -0.0010437561220235445\n",
      "Epoch: 33, step: 20, loss: -0.0002124488514493264\n",
      "Epoch: 33, step: 30, loss: -0.0009674658067524433\n",
      "Epoch: 33, step: 40, loss: -0.0012460576168761203\n",
      "Epoch: 33, step: 50, loss: -0.001667555172781588\n",
      "Epoch: 33, step: 60, loss: -0.0015125667483576375\n",
      "Epoch: 33, step: 70, loss: -0.0015007699913555154\n",
      "Epoch: 33, step: 80, loss: -0.0014283447955766647\n",
      "Epoch: 33, step: 90, loss: -0.001165866364237525\n",
      "Epoch: 33, step: 100, loss: -0.0012240097530953826\n",
      "Epoch: 33, step: 110, loss: -0.0012575220529027786\n",
      "Epoch: 33, step: 120, loss: -0.0012907020226678972\n",
      "Epoch: 33, step: 130, loss: -0.0012092245794887804\n",
      "Epoch: 33, step: 140, loss: -0.001237351823835931\n",
      "Epoch: 33, step: 150, loss: -0.001154768156174521\n",
      "Epoch: 33, step: 160, loss: -0.001099651548881315\n",
      "Epoch: 33, step: 170, loss: -0.0010461453407967453\n",
      "Epoch: 33, step: 180, loss: -0.0010605633086930107\n",
      "Epoch: 33, step: 190, loss: -0.0009226429208208616\n",
      "Epoch: 33, step: 200, loss: -0.0009114704475928079\n",
      "Epoch: 34, step: 0, loss: -0.0037009436637163162\n",
      "Epoch: 34, step: 10, loss: 0.00010141791161996397\n",
      "Epoch: 34, step: 20, loss: 0.0006212790446755077\n",
      "Epoch: 34, step: 30, loss: 0.0002615181053237569\n",
      "Epoch: 34, step: 40, loss: 0.00029063469619581065\n",
      "Epoch: 34, step: 50, loss: 0.00018464264119792657\n",
      "Epoch: 34, step: 60, loss: 3.551393313157815e-05\n",
      "Epoch: 34, step: 70, loss: -8.042062764731564e-05\n",
      "Epoch: 34, step: 80, loss: 3.577961337057023e-05\n",
      "Epoch: 34, step: 90, loss: -0.00010147918566452482\n",
      "Epoch: 34, step: 100, loss: -4.600796913082647e-07\n",
      "Epoch: 34, step: 110, loss: 0.0001224494882154505\n",
      "Epoch: 34, step: 120, loss: 7.469571303299143e-05\n",
      "Epoch: 34, step: 130, loss: -8.496823289630693e-05\n",
      "Epoch: 34, step: 140, loss: -0.00028910727965883275\n",
      "Epoch: 34, step: 150, loss: -0.0004794851262723743\n",
      "Epoch: 34, step: 160, loss: -0.00043825206534086686\n",
      "Epoch: 34, step: 170, loss: -0.000506621407792898\n",
      "Epoch: 34, step: 180, loss: -0.0004828828440024646\n",
      "Epoch: 34, step: 190, loss: -0.0005098970423157556\n",
      "Epoch: 34, step: 200, loss: -0.0005202448502037007\n",
      "Epoch: 35, step: 0, loss: 0.00010122793901246041\n",
      "Epoch: 35, step: 10, loss: -0.0015822242037922313\n",
      "Epoch: 35, step: 20, loss: -0.001566548076447188\n",
      "Epoch: 35, step: 30, loss: -0.0007919486064741748\n",
      "Epoch: 35, step: 40, loss: -0.00010646168368289293\n",
      "Epoch: 35, step: 50, loss: -0.000701428274338718\n",
      "Epoch: 35, step: 60, loss: -0.0011800608555232862\n",
      "Epoch: 35, step: 70, loss: -0.0013199541486166812\n",
      "Epoch: 35, step: 80, loss: -0.0013369871835212832\n",
      "Epoch: 35, step: 90, loss: -0.0013105697714938568\n",
      "Epoch: 35, step: 100, loss: -0.0011072349360000601\n",
      "Epoch: 35, step: 110, loss: -0.0010851462542599587\n",
      "Epoch: 35, step: 120, loss: -0.0008689077041392823\n",
      "Epoch: 35, step: 130, loss: -0.0007538964485577201\n",
      "Epoch: 35, step: 140, loss: -0.0006713762865748574\n",
      "Epoch: 35, step: 150, loss: -0.0006908355452296083\n",
      "Epoch: 35, step: 160, loss: -0.0008006792480085531\n",
      "Epoch: 35, step: 170, loss: -0.0008359305347501142\n",
      "Epoch: 35, step: 180, loss: -0.0008604036297106302\n",
      "Epoch: 35, step: 190, loss: -0.0007875082953113829\n",
      "Epoch: 35, step: 200, loss: -0.0007170379800091855\n",
      "Epoch: 36, step: 0, loss: 0.0034239361993968487\n",
      "Epoch: 36, step: 10, loss: 0.002286314842587506\n",
      "Epoch: 36, step: 20, loss: 0.0011215083927492656\n",
      "Epoch: 36, step: 30, loss: 0.0007223028486834899\n",
      "Epoch: 36, step: 40, loss: 0.0001955864774971837\n",
      "Epoch: 36, step: 50, loss: -1.0291824925362187e-06\n",
      "Epoch: 36, step: 60, loss: 0.00011782979637529457\n",
      "Epoch: 36, step: 70, loss: 0.00030804988862553114\n",
      "Epoch: 36, step: 80, loss: 0.00026907417136330707\n",
      "Epoch: 36, step: 90, loss: 0.00029391534101975324\n",
      "Epoch: 36, step: 100, loss: 7.07108302947853e-05\n",
      "Epoch: 36, step: 110, loss: 3.0125426689607536e-05\n",
      "Epoch: 36, step: 120, loss: -6.004119068692046e-05\n",
      "Epoch: 36, step: 130, loss: -0.00011941557350205897\n",
      "Epoch: 36, step: 140, loss: -0.00032104438596821213\n",
      "Epoch: 36, step: 150, loss: -0.00036672693916244914\n",
      "Epoch: 36, step: 160, loss: -0.00037432941458092554\n",
      "Epoch: 36, step: 170, loss: -0.00044479263876292483\n",
      "Epoch: 36, step: 180, loss: -0.0004011378102570525\n",
      "Epoch: 36, step: 190, loss: -0.000405072478067949\n",
      "Epoch: 36, step: 200, loss: -0.00040609425554093695\n",
      "Epoch: 37, step: 0, loss: -0.004205736331641674\n",
      "Epoch: 37, step: 10, loss: -0.0014440582685479471\n",
      "Epoch: 37, step: 20, loss: -0.001611327174205577\n",
      "Epoch: 37, step: 30, loss: -0.0009566394050301413\n",
      "Epoch: 37, step: 40, loss: -0.0008733799514607754\n",
      "Epoch: 37, step: 50, loss: -0.0009141478174783782\n",
      "Epoch: 37, step: 60, loss: -0.0007047895789404064\n",
      "Epoch: 37, step: 70, loss: -0.0009318478068322088\n",
      "Epoch: 37, step: 80, loss: -0.0007135806543958074\n",
      "Epoch: 37, step: 90, loss: -0.000842440818934727\n",
      "Epoch: 37, step: 100, loss: -0.0008934858809934127\n",
      "Epoch: 37, step: 110, loss: -0.0009863015501167382\n",
      "Epoch: 37, step: 120, loss: -0.000952698249879297\n",
      "Epoch: 37, step: 130, loss: -0.0010487362355298634\n",
      "Epoch: 37, step: 140, loss: -0.0009519950525834331\n",
      "Epoch: 37, step: 150, loss: -0.0009873649828688747\n",
      "Epoch: 37, step: 160, loss: -0.001065171402757944\n",
      "Epoch: 37, step: 170, loss: -0.0010355810816648243\n",
      "Epoch: 37, step: 180, loss: -0.0010121475642843516\n",
      "Epoch: 37, step: 190, loss: -0.0009821300771278184\n",
      "Epoch: 37, step: 200, loss: -0.0009737398156641974\n",
      "Epoch: 38, step: 0, loss: -0.004873883444815874\n",
      "Epoch: 38, step: 10, loss: -0.001541595731396228\n",
      "Epoch: 38, step: 20, loss: -0.000677266912091346\n",
      "Epoch: 38, step: 30, loss: -0.000519157383560894\n",
      "Epoch: 38, step: 40, loss: -0.0004994592848716577\n",
      "Epoch: 38, step: 50, loss: -0.0004341807470351056\n",
      "Epoch: 38, step: 60, loss: -0.0005512265705591312\n",
      "Epoch: 38, step: 70, loss: -0.0005720234047670678\n",
      "Epoch: 38, step: 80, loss: -0.0007961054255662739\n",
      "Epoch: 38, step: 90, loss: -0.0007517999476256811\n",
      "Epoch: 38, step: 100, loss: -0.0006755394052102065\n",
      "Epoch: 38, step: 110, loss: -0.0006010853738533459\n",
      "Epoch: 38, step: 120, loss: -0.000533272321639036\n",
      "Epoch: 38, step: 130, loss: -0.0004589895117727556\n",
      "Epoch: 38, step: 140, loss: -0.0005468588632222674\n",
      "Epoch: 38, step: 150, loss: -0.0004999634069860882\n",
      "Epoch: 38, step: 160, loss: -0.00040156575943334666\n",
      "Epoch: 38, step: 170, loss: -0.00033311307869718154\n",
      "Epoch: 38, step: 180, loss: -0.00025505624562456884\n",
      "Epoch: 38, step: 190, loss: -0.0003204329198891302\n",
      "Epoch: 38, step: 200, loss: -0.0003196049303315066\n",
      "Epoch: 39, step: 0, loss: -0.005640094634145498\n",
      "Epoch: 39, step: 10, loss: 1.9561918716962364e-05\n",
      "Epoch: 39, step: 20, loss: -0.000276219702625115\n",
      "Epoch: 39, step: 30, loss: -2.8588242956527297e-05\n",
      "Epoch: 39, step: 40, loss: 6.463634213659821e-07\n",
      "Epoch: 39, step: 50, loss: -1.5485297897647995e-05\n",
      "Epoch: 39, step: 60, loss: -0.00011633640011108373\n",
      "Epoch: 39, step: 70, loss: 3.3289571022155734e-05\n",
      "Epoch: 39, step: 80, loss: 0.0002580998728790516\n",
      "Epoch: 39, step: 90, loss: 0.00022328573238785163\n",
      "Epoch: 39, step: 100, loss: 0.0003047287505204181\n",
      "Epoch: 39, step: 110, loss: 0.0004263686400713391\n",
      "Epoch: 39, step: 120, loss: 0.00034346679579861045\n",
      "Epoch: 39, step: 130, loss: 0.00021948248734706587\n",
      "Epoch: 39, step: 140, loss: 0.0002686378340371422\n",
      "Epoch: 39, step: 150, loss: 0.0002142872372915851\n",
      "Epoch: 39, step: 160, loss: 0.0001404540283751518\n",
      "Epoch: 39, step: 170, loss: 7.709637374483724e-05\n",
      "Epoch: 39, step: 180, loss: 1.026550058638214e-05\n",
      "Epoch: 39, step: 190, loss: -1.3227676695422391e-05\n",
      "Epoch: 39, step: 200, loss: -0.00013172641792971715\n",
      "Epoch: 40, step: 0, loss: -0.0007961411029100418\n",
      "Epoch: 40, step: 10, loss: -0.00038051076064055616\n",
      "Epoch: 40, step: 20, loss: -0.0011755437340720423\n",
      "Epoch: 40, step: 30, loss: -0.0011302460803680361\n",
      "Epoch: 40, step: 40, loss: -0.0005413177941369302\n",
      "Epoch: 40, step: 50, loss: -0.0002502410139890808\n",
      "Epoch: 40, step: 60, loss: -0.0002646904624092057\n",
      "Epoch: 40, step: 70, loss: -0.00023668202496556775\n",
      "Epoch: 40, step: 80, loss: -0.0004912491340404319\n",
      "Epoch: 40, step: 90, loss: -0.00038753115806465066\n",
      "Epoch: 40, step: 100, loss: -0.0003197574945504427\n",
      "Epoch: 40, step: 110, loss: -0.00036487616143694886\n",
      "Epoch: 40, step: 120, loss: -0.0003197942159286785\n",
      "Epoch: 40, step: 130, loss: -0.0003805370706547663\n",
      "Epoch: 40, step: 140, loss: -0.000367167493921262\n",
      "Epoch: 40, step: 150, loss: -0.00036859227174203783\n",
      "Epoch: 40, step: 160, loss: -0.000438903707742289\n",
      "Epoch: 40, step: 170, loss: -0.0004136329007025928\n",
      "Epoch: 40, step: 180, loss: -0.000373685270440456\n",
      "Epoch: 40, step: 190, loss: -0.0004641851409888797\n",
      "Epoch: 40, step: 200, loss: -0.0004945536260203509\n",
      "Epoch: 41, step: 0, loss: 0.003265372011810541\n",
      "Epoch: 41, step: 10, loss: 0.0001259003646819937\n",
      "Epoch: 41, step: 20, loss: -8.860386289944429e-05\n",
      "Epoch: 41, step: 30, loss: -0.00028823506351815717\n",
      "Epoch: 41, step: 40, loss: -0.0003566216935102669\n",
      "Epoch: 41, step: 50, loss: -0.0004108545502223184\n",
      "Epoch: 41, step: 60, loss: -0.000550557018332107\n",
      "Epoch: 41, step: 70, loss: -0.00064484703352078\n",
      "Epoch: 41, step: 80, loss: -0.0005902032079361954\n",
      "Epoch: 41, step: 90, loss: -0.0006072684202361136\n",
      "Epoch: 41, step: 100, loss: -0.0005982241498641808\n",
      "Epoch: 41, step: 110, loss: -0.0005850371635788506\n",
      "Epoch: 41, step: 120, loss: -0.000486476135546965\n",
      "Epoch: 41, step: 130, loss: -0.0006242430400554773\n",
      "Epoch: 41, step: 140, loss: -0.0005724191726437202\n",
      "Epoch: 41, step: 150, loss: -0.0006058978628820512\n",
      "Epoch: 41, step: 160, loss: -0.0005416501382501761\n",
      "Epoch: 41, step: 170, loss: -0.0005274909658324142\n",
      "Epoch: 41, step: 180, loss: -0.00047186938739473064\n",
      "Epoch: 41, step: 190, loss: -0.0004903273399067794\n",
      "Epoch: 41, step: 200, loss: -0.0004705187695698039\n",
      "Epoch: 42, step: 0, loss: -0.0008104704320430756\n",
      "Epoch: 42, step: 10, loss: -0.0001909437547014518\n",
      "Epoch: 42, step: 20, loss: -3.0783797791671186e-05\n",
      "Epoch: 42, step: 30, loss: 0.00013394909347557734\n",
      "Epoch: 42, step: 40, loss: 0.00022839632157872362\n",
      "Epoch: 42, step: 50, loss: -7.299814195207813e-07\n",
      "Epoch: 42, step: 60, loss: -1.0022897603463565e-05\n",
      "Epoch: 42, step: 70, loss: 8.996424628388872e-05\n",
      "Epoch: 42, step: 80, loss: 0.00026644276326413\n",
      "Epoch: 42, step: 90, loss: 0.00017496804622958855\n",
      "Epoch: 42, step: 100, loss: 0.00020740602968265256\n",
      "Epoch: 42, step: 110, loss: 0.0001981978210031164\n",
      "Epoch: 42, step: 120, loss: 0.00023122762439556973\n",
      "Epoch: 42, step: 130, loss: 0.00019534318767868352\n",
      "Epoch: 42, step: 140, loss: 0.00019476579736294028\n",
      "Epoch: 42, step: 150, loss: 9.532585556600366e-05\n",
      "Epoch: 42, step: 160, loss: 9.443991064088222e-06\n",
      "Epoch: 42, step: 170, loss: -1.6261317136790057e-05\n",
      "Epoch: 42, step: 180, loss: -6.881138716325246e-05\n",
      "Epoch: 42, step: 190, loss: -2.7674483897222977e-05\n",
      "Epoch: 42, step: 200, loss: -4.180090007284165e-05\n",
      "Epoch: 43, step: 0, loss: -0.0010799539741128683\n",
      "Epoch: 43, step: 10, loss: -0.000666422168830071\n",
      "Epoch: 43, step: 20, loss: -0.001115723338443786\n",
      "Epoch: 43, step: 30, loss: -0.000893690487212171\n",
      "Epoch: 43, step: 40, loss: -0.00068407411376162\n",
      "Epoch: 43, step: 50, loss: -0.0007545268516896256\n",
      "Epoch: 43, step: 60, loss: -0.0008541274525713725\n",
      "Epoch: 43, step: 70, loss: -0.0008856991943772095\n",
      "Epoch: 43, step: 80, loss: -0.000797940487200883\n",
      "Epoch: 43, step: 90, loss: -0.0006491463796259927\n",
      "Epoch: 43, step: 100, loss: -0.0007532385876258181\n",
      "Epoch: 43, step: 110, loss: -0.0006144501846745141\n",
      "Epoch: 43, step: 120, loss: -0.0005802357218647761\n",
      "Epoch: 43, step: 130, loss: -0.0005167449776968343\n",
      "Epoch: 43, step: 140, loss: -0.0005241364978769041\n",
      "Epoch: 43, step: 150, loss: -0.000601996178122003\n",
      "Epoch: 43, step: 160, loss: -0.0005986275764992779\n",
      "Epoch: 43, step: 170, loss: -0.0005532606489624833\n",
      "Epoch: 43, step: 180, loss: -0.0005391601068935696\n",
      "Epoch: 43, step: 190, loss: -0.000531425378078117\n",
      "Epoch: 43, step: 200, loss: -0.0004761246280902209\n",
      "Epoch: 44, step: 0, loss: -0.00329597108066082\n",
      "Epoch: 44, step: 10, loss: 1.2738185680725358e-05\n",
      "Epoch: 44, step: 20, loss: 2.507586032152176e-05\n",
      "Epoch: 44, step: 30, loss: -0.0002877849640959363\n",
      "Epoch: 44, step: 40, loss: -0.0004338296529589925\n",
      "Epoch: 44, step: 50, loss: -0.00022019045775546235\n",
      "Epoch: 44, step: 60, loss: -0.00029020524439669107\n",
      "Epoch: 44, step: 70, loss: -0.0002779932560450004\n",
      "Epoch: 44, step: 80, loss: -0.0001381065154463961\n",
      "Epoch: 44, step: 90, loss: -0.0002430102177531008\n",
      "Epoch: 44, step: 100, loss: -0.00039451622015434677\n",
      "Epoch: 44, step: 110, loss: -0.0002953389229914719\n",
      "Epoch: 44, step: 120, loss: -0.00032868625891773986\n",
      "Epoch: 44, step: 130, loss: -0.0002550966827174869\n",
      "Epoch: 44, step: 140, loss: -0.00034110026471424146\n",
      "Epoch: 44, step: 150, loss: -0.00033430153272147073\n",
      "Epoch: 44, step: 160, loss: -0.0003517444324784519\n",
      "Epoch: 44, step: 170, loss: -0.0003942869578870095\n",
      "Epoch: 44, step: 180, loss: -0.0004295099220571149\n",
      "Epoch: 44, step: 190, loss: -0.0003789347186651086\n",
      "Epoch: 44, step: 200, loss: -0.00035542152004359307\n",
      "Epoch: 45, step: 0, loss: -0.002946332562714815\n",
      "Epoch: 45, step: 10, loss: -0.00031874344991096717\n",
      "Epoch: 45, step: 20, loss: -0.0008388674818672284\n",
      "Epoch: 45, step: 30, loss: -0.00032870653916278013\n",
      "Epoch: 45, step: 40, loss: -0.0001797304020572749\n",
      "Epoch: 45, step: 50, loss: -0.00017631308062346745\n",
      "Epoch: 45, step: 60, loss: -0.0002533677710982643\n",
      "Epoch: 45, step: 70, loss: -0.0002745796723310134\n",
      "Epoch: 45, step: 80, loss: -0.00041341464667412866\n",
      "Epoch: 45, step: 90, loss: -0.000411811551732551\n",
      "Epoch: 45, step: 100, loss: -0.00048732535856963816\n",
      "Epoch: 45, step: 110, loss: -0.000413331149936746\n",
      "Epoch: 45, step: 120, loss: -0.0003889152414092317\n",
      "Epoch: 45, step: 130, loss: -0.0003773745730117617\n",
      "Epoch: 45, step: 140, loss: -0.000386569551761916\n",
      "Epoch: 45, step: 150, loss: -0.0004046464520845784\n",
      "Epoch: 45, step: 160, loss: -0.00041440087811651157\n",
      "Epoch: 45, step: 170, loss: -0.00040933637667381974\n",
      "Epoch: 45, step: 180, loss: -0.00035555585295872673\n",
      "Epoch: 45, step: 190, loss: -0.0003737487476099653\n",
      "Epoch: 45, step: 200, loss: -0.00041076853646623406\n",
      "Epoch: 46, step: 0, loss: 0.00211574649438262\n",
      "Epoch: 46, step: 10, loss: -0.001359327378767458\n",
      "Epoch: 46, step: 20, loss: -0.0007960591714696161\n",
      "Epoch: 46, step: 30, loss: -0.0008116269375257675\n",
      "Epoch: 46, step: 40, loss: -0.000500632816976754\n",
      "Epoch: 46, step: 50, loss: -0.00028812961753311696\n",
      "Epoch: 46, step: 60, loss: -0.0002306377387330791\n",
      "Epoch: 46, step: 70, loss: -1.1506285452821724e-06\n",
      "Epoch: 46, step: 80, loss: -7.4915662458177974e-06\n",
      "Epoch: 46, step: 90, loss: -0.00011821987565061856\n",
      "Epoch: 46, step: 100, loss: -0.00022147592129174269\n",
      "Epoch: 46, step: 110, loss: -0.00010490044682687317\n",
      "Epoch: 46, step: 120, loss: -8.870080523029324e-05\n",
      "Epoch: 46, step: 130, loss: -0.0002145633200438558\n",
      "Epoch: 46, step: 140, loss: -0.0002853505768840439\n",
      "Epoch: 46, step: 150, loss: -0.00021496994367111412\n",
      "Epoch: 46, step: 160, loss: -0.00021524377651143854\n",
      "Epoch: 46, step: 170, loss: -0.00019028855395627247\n",
      "Epoch: 46, step: 180, loss: -0.00017573762789094635\n",
      "Epoch: 46, step: 190, loss: -0.00020443878031588107\n",
      "Epoch: 46, step: 200, loss: -0.00022120422044964692\n",
      "Epoch: 47, step: 0, loss: 0.003971703816205263\n",
      "Epoch: 47, step: 10, loss: 0.00022835901472717524\n",
      "Epoch: 47, step: 20, loss: -7.89399366892342e-05\n",
      "Epoch: 47, step: 30, loss: -0.0006743322014846208\n",
      "Epoch: 47, step: 40, loss: -0.00057877978720282\n",
      "Epoch: 47, step: 50, loss: -0.0008285658884286771\n",
      "Epoch: 47, step: 60, loss: -0.0007730106133480984\n",
      "Epoch: 47, step: 70, loss: -0.0008474869847676428\n",
      "Epoch: 47, step: 80, loss: -0.0009577376267658604\n",
      "Epoch: 47, step: 90, loss: -0.0009352131269374545\n",
      "Epoch: 47, step: 100, loss: -0.0009455895900702113\n",
      "Epoch: 47, step: 110, loss: -0.0008798042274377023\n",
      "Epoch: 47, step: 120, loss: -0.000882406449818518\n",
      "Epoch: 47, step: 130, loss: -0.0008814697285944362\n",
      "Epoch: 47, step: 140, loss: -0.0008127034329813376\n",
      "Epoch: 47, step: 150, loss: -0.0006900144580868073\n",
      "Epoch: 47, step: 160, loss: -0.0007170453916288628\n",
      "Epoch: 47, step: 170, loss: -0.0006347078800985007\n",
      "Epoch: 47, step: 180, loss: -0.0006149312880778434\n",
      "Epoch: 47, step: 190, loss: -0.0006167056366850937\n",
      "Epoch: 47, step: 200, loss: -0.0005572621817710701\n",
      "Epoch: 48, step: 0, loss: 0.0005998644046485424\n",
      "Epoch: 48, step: 10, loss: 0.0002475404329412744\n",
      "Epoch: 48, step: 20, loss: -0.0003216802196263979\n",
      "Epoch: 48, step: 30, loss: -0.0007045593026099771\n",
      "Epoch: 48, step: 40, loss: -0.0006570373998107332\n",
      "Epoch: 48, step: 50, loss: -0.0008789689616641422\n",
      "Epoch: 48, step: 60, loss: -0.0008676413894076565\n",
      "Epoch: 48, step: 70, loss: -0.0007448370802002257\n",
      "Epoch: 48, step: 80, loss: -0.0007779756953014941\n",
      "Epoch: 48, step: 90, loss: -0.0008801521703739687\n",
      "Epoch: 48, step: 100, loss: -0.0008310441942487862\n",
      "Epoch: 48, step: 110, loss: -0.000870951803425759\n",
      "Epoch: 48, step: 120, loss: -0.000888636844386135\n",
      "Epoch: 48, step: 130, loss: -0.0008352352132401358\n",
      "Epoch: 48, step: 140, loss: -0.0008495395538910682\n",
      "Epoch: 48, step: 150, loss: -0.0008513962630057609\n",
      "Epoch: 48, step: 160, loss: -0.000787121023507702\n",
      "Epoch: 48, step: 170, loss: -0.0006812105042286686\n",
      "Epoch: 48, step: 180, loss: -0.0006357043098307148\n",
      "Epoch: 48, step: 190, loss: -0.0006383482052296088\n",
      "Epoch: 48, step: 200, loss: -0.0006697227667906525\n",
      "Epoch: 49, step: 0, loss: 0.001367992372252047\n",
      "Epoch: 49, step: 10, loss: -8.61099794168364e-05\n",
      "Epoch: 49, step: 20, loss: -0.0003276868817573857\n",
      "Epoch: 49, step: 30, loss: -0.00015608645081820508\n",
      "Epoch: 49, step: 40, loss: -0.0004574245611410134\n",
      "Epoch: 49, step: 50, loss: -0.00033995787174824406\n",
      "Epoch: 49, step: 60, loss: -0.00044417067442364136\n",
      "Epoch: 49, step: 70, loss: -0.0003947453347074104\n",
      "Epoch: 49, step: 80, loss: -0.00037778890547974977\n",
      "Epoch: 49, step: 90, loss: -0.00038967524868804593\n",
      "Epoch: 49, step: 100, loss: -0.0004087164856857703\n",
      "Epoch: 49, step: 110, loss: -0.0004790106119413919\n",
      "Epoch: 49, step: 120, loss: -0.0005416739315914436\n",
      "Epoch: 49, step: 130, loss: -0.0005457428535482072\n",
      "Epoch: 49, step: 140, loss: -0.0005933833327094846\n",
      "Epoch: 49, step: 150, loss: -0.0006409849212520342\n",
      "Epoch: 49, step: 160, loss: -0.000633452570746271\n",
      "Epoch: 49, step: 170, loss: -0.0006800880677346548\n",
      "Epoch: 49, step: 180, loss: -0.0007365668908122398\n",
      "Epoch: 49, step: 190, loss: -0.000693642908589322\n",
      "Epoch: 49, step: 200, loss: -0.0006314596502673326\n",
      "Epoch: 50, step: 0, loss: -0.001885914825834334\n",
      "Epoch: 50, step: 10, loss: 2.991483250463551e-05\n",
      "Epoch: 50, step: 20, loss: -0.00024057004373476265\n",
      "Epoch: 50, step: 30, loss: -0.0005777426436731232\n",
      "Epoch: 50, step: 40, loss: -0.0007139181373243379\n",
      "Epoch: 50, step: 50, loss: -0.0005715344193638029\n",
      "Epoch: 50, step: 60, loss: -0.000576460446311222\n",
      "Epoch: 50, step: 70, loss: -0.0005662845575552381\n",
      "Epoch: 50, step: 80, loss: -0.0006758743396925705\n",
      "Epoch: 50, step: 90, loss: -0.0005973748578741164\n",
      "Epoch: 50, step: 100, loss: -0.0005283029375385751\n",
      "Epoch: 50, step: 110, loss: -0.0005249633562401344\n",
      "Epoch: 50, step: 120, loss: -0.0004873553351155186\n",
      "Epoch: 50, step: 130, loss: -0.0004918091988045712\n",
      "Epoch: 50, step: 140, loss: -0.0006544802460750541\n",
      "Epoch: 50, step: 150, loss: -0.0005802290748725014\n",
      "Epoch: 50, step: 160, loss: -0.0005280158189148859\n",
      "Epoch: 50, step: 170, loss: -0.0004833624901395354\n",
      "Epoch: 50, step: 180, loss: -0.0005091713233592017\n",
      "Epoch: 50, step: 190, loss: -0.000561753940042925\n",
      "Epoch: 50, step: 200, loss: -0.0005317403066052536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0001292488886974752,\n",
       " 0.0002907325397245586,\n",
       " 0.0001363924820907414,\n",
       " 0.00020030647283419967,\n",
       " 0.00014023605035617948,\n",
       " 0.00021829345496371388,\n",
       " 0.00016669597243890166,\n",
       " 0.00039306876715272665,\n",
       " 0.00020383292576298118,\n",
       " 0.0001607618178240955,\n",
       " 0.0001819081953726709,\n",
       " 1.9149098079651594e-05,\n",
       " 2.4871842470020056e-05,\n",
       " 2.1371175535023212e-05,\n",
       " 6.172480061650276e-05,\n",
       " -4.5621825847774744e-05,\n",
       " -0.00023650936782360077,\n",
       " -0.00022565218387171626,\n",
       " -0.00035081093665212393,\n",
       " -0.0003401594585739076,\n",
       " -0.0004607507144100964,\n",
       " -0.00023905921261757612,\n",
       " -0.0004413889837451279,\n",
       " -0.0004978015786036849,\n",
       " -0.00042434781789779663,\n",
       " -0.0006309150485321879,\n",
       " -0.0006479937583208084,\n",
       " -0.0007561392267234623,\n",
       " -0.0007727608899585903,\n",
       " -0.0008330378914251924,\n",
       " -0.0008994884556159377,\n",
       " -0.0009235524339601398,\n",
       " -0.000986519968137145,\n",
       " -0.000979479867964983,\n",
       " -0.001038221176713705,\n",
       " -0.0012471473310142756,\n",
       " -0.0011170250363647938,\n",
       " -0.001299145631492138,\n",
       " -0.0014932902995496988,\n",
       " -0.0014595044776797295,\n",
       " -0.0015536081045866013,\n",
       " -0.0015912214294075966,\n",
       " -0.0017015687189996243,\n",
       " -0.0015873778611421585,\n",
       " -0.0017903582192957401,\n",
       " -0.0017332440475001931,\n",
       " -0.0018161875195801258,\n",
       " -0.001943691517226398,\n",
       " -0.0019443247001618147,\n",
       " -0.0021040148567408323,\n",
       " -0.002176730427891016,\n",
       " -0.0022253538481891155,\n",
       " -0.0024212519638240337,\n",
       " -0.0024029456544667482,\n",
       " -0.0026058158837258816,\n",
       " -0.0025702661368995905,\n",
       " -0.0025695236399769783,\n",
       " -0.002696163719519973,\n",
       " -0.0027455841191112995,\n",
       " -0.002749756909906864,\n",
       " -0.0028319095727056265,\n",
       " -0.0028767918702214956,\n",
       " -0.002963991602882743,\n",
       " -0.0029880127403885126,\n",
       " -0.003200806677341461,\n",
       " -0.0031985952518880367,\n",
       " -0.003372778883203864,\n",
       " -0.00333230197429657,\n",
       " -0.003535553114488721,\n",
       " -0.003459593281149864,\n",
       " -0.0036428887397050858,\n",
       " -0.003648326499387622,\n",
       " -0.0037058477755635977,\n",
       " -0.003817336168140173,\n",
       " -0.003678577020764351,\n",
       " -0.003820380661636591,\n",
       " -0.003980197012424469,\n",
       " -0.004302936140447855,\n",
       " -0.004281241446733475,\n",
       " -0.004508757032454014,\n",
       " -0.004331754986196756,\n",
       " -0.004522149451076984,\n",
       " -0.0046894969418644905,\n",
       " -0.004521163180470467,\n",
       " -0.004797631874680519,\n",
       " -0.004896756261587143,\n",
       " -0.004988065920770168,\n",
       " -0.005149551201611757,\n",
       " -0.005304626189172268,\n",
       " -0.005234249867498875,\n",
       " -0.005524885840713978,\n",
       " -0.0054757134057581425,\n",
       " -0.005728862248361111,\n",
       " -0.005832565948367119,\n",
       " -0.005839078687131405,\n",
       " -0.00577370822429657,\n",
       " -0.005902406293898821,\n",
       " -0.0060817888006567955,\n",
       " -0.006267829332500696,\n",
       " -0.0065198070369660854,\n",
       " -0.006524008233100176,\n",
       " -0.0066251023672521114,\n",
       " -0.006900255102664232,\n",
       " -0.006727967411279678,\n",
       " -0.006771187297999859,\n",
       " -0.006992637645453215,\n",
       " -0.007083311676979065,\n",
       " -0.007276367396116257,\n",
       " -0.007520879153162241,\n",
       " -0.007557681296020746,\n",
       " -0.007534606847912073,\n",
       " -0.007967154495418072,\n",
       " -0.0078793466091156,\n",
       " -0.00819688756018877,\n",
       " -0.008332346566021442,\n",
       " -0.008490434847772121,\n",
       " -0.008423485793173313,\n",
       " -0.008528521284461021,\n",
       " -0.00879506953060627,\n",
       " -0.008752579800784588,\n",
       " -0.008954068645834923,\n",
       " -0.008912714198231697,\n",
       " -0.009380222298204899,\n",
       " -0.009339699521660805,\n",
       " -0.009542110376060009,\n",
       " -0.009776697494089603,\n",
       " -0.010064952075481415,\n",
       " -0.010173739865422249,\n",
       " -0.010250700637698174,\n",
       " -0.0102735860273242,\n",
       " -0.010758211836218834,\n",
       " -0.011005439795553684,\n",
       " -0.010942837223410606,\n",
       " -0.011234340257942677,\n",
       " -0.011204312555491924,\n",
       " -0.011243397369980812,\n",
       " -0.011534137651324272,\n",
       " -0.011721396818757057,\n",
       " -0.011928502470254898,\n",
       " -0.012302051298320293,\n",
       " -0.01276885624974966,\n",
       " -0.012537267059087753,\n",
       " -0.012915967963635921,\n",
       " -0.012892084196209908,\n",
       " -0.013229328207671642,\n",
       " -0.013650362379848957,\n",
       " -0.013356694020330906,\n",
       " -0.014032037928700447,\n",
       " -0.014011195860803127,\n",
       " -0.014408101327717304,\n",
       " -0.01433369517326355,\n",
       " -0.014478652738034725,\n",
       " -0.014665225520730019,\n",
       " -0.01539270207285881,\n",
       " -0.014959977939724922,\n",
       " -0.016029927879571915,\n",
       " -0.015396215952932835,\n",
       " -0.015406709164381027,\n",
       " -0.016314733773469925,\n",
       " -0.016126783564686775,\n",
       " -0.01607132889330387,\n",
       " -0.01671779155731201,\n",
       " -0.016154080629348755,\n",
       " -0.017145559191703796,\n",
       " -0.016947941854596138,\n",
       " -0.01764158345758915,\n",
       " -0.0172556284815073,\n",
       " -0.017734328284859657,\n",
       " -0.01802045851945877,\n",
       " -0.01808425597846508,\n",
       " -0.01850539818406105,\n",
       " -0.01866874285042286,\n",
       " -0.018430180847644806,\n",
       " -0.019346024841070175,\n",
       " -0.019650766626000404,\n",
       " -0.018856186419725418,\n",
       " -0.020305750891566277,\n",
       " -0.020313795655965805,\n",
       " -0.020700756460428238,\n",
       " -0.020828718319535255,\n",
       " -0.020634720101952553,\n",
       " -0.02118050493299961,\n",
       " -0.021566782146692276,\n",
       " -0.02201332151889801,\n",
       " -0.022450067102909088,\n",
       " -0.022693106904625893,\n",
       " -0.021885273978114128,\n",
       " -0.02336551807820797,\n",
       " -0.023086443543434143,\n",
       " -0.023493299260735512,\n",
       " -0.023973289877176285,\n",
       " -0.024066613987088203,\n",
       " -0.02414827048778534,\n",
       " -0.024054687470197678,\n",
       " -0.024948786944150925,\n",
       " -0.024787019938230515,\n",
       " -0.024688968434929848,\n",
       " -0.0247215423732996,\n",
       " -0.025515614077448845,\n",
       " -0.026027902960777283,\n",
       " -0.025996722280979156,\n",
       " -0.026145560666918755,\n",
       " -0.025713106617331505,\n",
       " -0.02697216346859932,\n",
       " -0.027209224179387093,\n",
       " -0.02653353288769722,\n",
       " -0.028838226571679115,\n",
       " -0.027565917000174522,\n",
       " -0.027441097423434258,\n",
       " -0.02882598154246807,\n",
       " -0.03016301617026329,\n",
       " -0.029729565605521202,\n",
       " -0.02877194434404373,\n",
       " -0.030121298506855965,\n",
       " -0.029663408175110817,\n",
       " -0.03016749769449234,\n",
       " -0.028909282758831978,\n",
       " -0.030478330329060555,\n",
       " -0.03141370415687561,\n",
       " -0.031207693740725517,\n",
       " -0.03158558905124664,\n",
       " -0.03222961723804474,\n",
       " -0.033194977790117264,\n",
       " -0.03181345388293266,\n",
       " -0.03375643119215965,\n",
       " -0.03419838845729828,\n",
       " -0.032140448689460754,\n",
       " -0.03308870643377304,\n",
       " -0.03402926027774811,\n",
       " -0.03338313102722168,\n",
       " -0.034496158361434937,\n",
       " -0.03464827314019203,\n",
       " -0.03528294712305069,\n",
       " -0.03487817198038101,\n",
       " -0.03572217375040054,\n",
       " -0.03562028706073761,\n",
       " -0.034555837512016296,\n",
       " -0.036135800182819366,\n",
       " -0.034847915172576904,\n",
       " -0.03750705346465111,\n",
       " -0.03897973895072937,\n",
       " -0.03855585679411888,\n",
       " -0.03591283783316612,\n",
       " -0.03640402853488922,\n",
       " -0.039431896060705185,\n",
       " -0.03715379163622856,\n",
       " -0.03893594071269035,\n",
       " -0.037956010550260544,\n",
       " -0.039489638060331345,\n",
       " -0.039502061903476715,\n",
       " -0.03801773861050606,\n",
       " -0.03805381804704666,\n",
       " -0.03996643051505089,\n",
       " -0.04054852947592735,\n",
       " -0.04028767719864845,\n",
       " -0.040179990231990814,\n",
       " -0.038244906812906265,\n",
       " -0.04164232313632965,\n",
       " -0.040746480226516724,\n",
       " -0.03934119641780853,\n",
       " -0.04077552258968353,\n",
       " -0.037641491740942,\n",
       " -0.036679018288850784,\n",
       " -0.04322652891278267,\n",
       " -0.041536830365657806,\n",
       " -0.04116281121969223,\n",
       " -0.04020262509584427,\n",
       " -0.039488062262535095,\n",
       " -0.040591027587652206,\n",
       " -0.0408506877720356,\n",
       " -0.037830207496881485,\n",
       " -0.04223693162202835,\n",
       " -0.041667889803647995,\n",
       " -0.04187997058033943,\n",
       " -0.04142342507839203,\n",
       " -0.04396070912480354,\n",
       " -0.0416070781648159,\n",
       " -0.04358368366956711,\n",
       " -0.04056442901492119,\n",
       " -0.041631076484918594,\n",
       " -0.04020698368549347,\n",
       " -0.04159831628203392,\n",
       " -0.03995034098625183,\n",
       " -0.04249542951583862,\n",
       " -0.03585438057780266,\n",
       " -0.039223190397024155,\n",
       " -0.047210339456796646,\n",
       " -0.03958721086382866,\n",
       " -0.04178769513964653,\n",
       " -0.04119620472192764,\n",
       " -0.044884487986564636,\n",
       " -0.041394367814064026,\n",
       " -0.04080827161669731,\n",
       " -0.03918292373418808,\n",
       " -0.04013017192482948,\n",
       " -0.04067303612828255,\n",
       " -0.03811342641711235,\n",
       " -0.04567806422710419,\n",
       " -0.044008851051330566,\n",
       " -0.04054572805762291,\n",
       " -0.04056935757398605,\n",
       " -0.03537718579173088,\n",
       " -0.03777220845222473,\n",
       " -0.037920378148555756,\n",
       " -0.04146028682589531,\n",
       " -0.037375565618276596,\n",
       " -0.039512984454631805,\n",
       " -0.0394335612654686,\n",
       " -0.03626261651515961,\n",
       " -0.037892088294029236,\n",
       " -0.035797785967588425,\n",
       " -0.041161179542541504,\n",
       " -0.037326838821172714,\n",
       " -0.034250784665346146,\n",
       " -0.037509676069021225,\n",
       " -0.040178075432777405,\n",
       " -0.03607046604156494,\n",
       " -0.03608442470431328,\n",
       " -0.03856867924332619,\n",
       " -0.03306814655661583,\n",
       " -0.03272243216633797,\n",
       " -0.03770800307393074,\n",
       " -0.03707464411854744,\n",
       " -0.03323816508054733,\n",
       " -0.03392835333943367,\n",
       " -0.0390082411468029,\n",
       " -0.03605493903160095,\n",
       " -0.03645051270723343,\n",
       " -0.03139635920524597,\n",
       " -0.037985168397426605,\n",
       " -0.03727378323674202,\n",
       " -0.0280509851872921,\n",
       " -0.030762244015932083,\n",
       " -0.03237810730934143,\n",
       " -0.03125770390033722,\n",
       " -0.032989997416734695,\n",
       " -0.03515935316681862,\n",
       " -0.030439376831054688,\n",
       " -0.0328296422958374,\n",
       " -0.03189706429839134,\n",
       " -0.02599293366074562,\n",
       " -0.032449871301651,\n",
       " -0.031666744500398636,\n",
       " -0.029091471806168556,\n",
       " -0.03167562931776047,\n",
       " -0.02707028016448021,\n",
       " -0.026821346953511238,\n",
       " -0.022558744996786118,\n",
       " -0.028695780783891678,\n",
       " -0.028196057304739952,\n",
       " -0.029324382543563843,\n",
       " -0.024676578119397163,\n",
       " -0.031845707446336746,\n",
       " -0.03014124557375908,\n",
       " -0.023844409734010696,\n",
       " -0.02622675523161888,\n",
       " -0.02311016246676445,\n",
       " -0.02557174488902092,\n",
       " -0.024422332644462585,\n",
       " -0.02819318138062954,\n",
       " -0.02300211228430271,\n",
       " -0.025332193821668625,\n",
       " -0.029413070529699326,\n",
       " -0.026083771139383316,\n",
       " -0.02841934934258461,\n",
       " -0.024018023163080215,\n",
       " -0.022825853899121284,\n",
       " -0.01775594986975193,\n",
       " -0.026313679292798042,\n",
       " -0.024026736617088318,\n",
       " -0.031096145510673523,\n",
       " -0.021173182874917984,\n",
       " -0.017710823565721512,\n",
       " -0.02327786386013031,\n",
       " -0.019230736419558525,\n",
       " -0.017108311876654625,\n",
       " -0.015830203890800476,\n",
       " -0.021550659090280533,\n",
       " -0.015011388808488846,\n",
       " -0.02288811095058918,\n",
       " -0.019207999110221863,\n",
       " -0.01802978292107582,\n",
       " -0.023966673761606216,\n",
       " -0.01622246950864792,\n",
       " -0.017662834376096725,\n",
       " -0.023953495547175407,\n",
       " -0.01999879814684391,\n",
       " -0.012056930921971798,\n",
       " -0.021777138113975525,\n",
       " -0.01657886430621147,\n",
       " -0.010081070475280285,\n",
       " -0.013591106981039047,\n",
       " -0.018270017579197884,\n",
       " -0.020086556673049927,\n",
       " -0.017140090465545654,\n",
       " -0.017688388004899025,\n",
       " -0.014144710265100002,\n",
       " -0.01373848132789135,\n",
       " -0.0077943354845047,\n",
       " -0.017623193562030792,\n",
       " -0.014532377943396568,\n",
       " -0.021284807473421097,\n",
       " -0.010567745193839073,\n",
       " -0.019217584282159805,\n",
       " -0.02006269432604313,\n",
       " -0.01438458263874054,\n",
       " -0.013435730710625648,\n",
       " -0.01280977576971054,\n",
       " -0.011593165807425976,\n",
       " -0.006508433725684881,\n",
       " -0.013479913584887981,\n",
       " -0.01567426323890686,\n",
       " -0.010215713642537594,\n",
       " -0.012656595557928085,\n",
       " -0.014115087687969208,\n",
       " -0.011372819542884827,\n",
       " -0.009274819865822792,\n",
       " -0.006370891351252794,\n",
       " -0.011160070076584816,\n",
       " -0.010525107383728027,\n",
       " -0.019461486488580704,\n",
       " -0.023444898426532745,\n",
       " -0.016603931784629822,\n",
       " -0.0046510277315974236,\n",
       " -0.011388006620109081,\n",
       " -0.00742608355358243,\n",
       " -0.021541083231568336,\n",
       " -0.008594535291194916,\n",
       " -0.012065958231687546,\n",
       " -0.009249753318727016,\n",
       " -0.01778021641075611,\n",
       " -0.015246119350194931,\n",
       " -0.012651385739445686,\n",
       " -0.013528190553188324,\n",
       " -0.013606740161776543,\n",
       " -0.019292429089546204,\n",
       " -0.011664038524031639,\n",
       " -0.011294124647974968,\n",
       " -0.013568396680057049,\n",
       " -0.013269633054733276,\n",
       " -0.012257454916834831,\n",
       " -0.013031646609306335,\n",
       " -0.012510234490036964,\n",
       " -0.012749171815812588,\n",
       " -0.011396219953894615,\n",
       " -0.011541459709405899,\n",
       " -0.012765064835548401,\n",
       " -0.019368521869182587,\n",
       " -0.015448728576302528,\n",
       " -0.014668488875031471,\n",
       " -0.006555235479027033,\n",
       " -0.020803581923246384,\n",
       " -0.007585272658616304,\n",
       " -0.005668979603797197,\n",
       " -0.016396034508943558,\n",
       " -0.008550111204385757,\n",
       " -0.011869361624121666,\n",
       " -0.005719449371099472,\n",
       " -0.007758574094623327,\n",
       " -0.012772220186889172,\n",
       " -0.008045832626521587,\n",
       " -0.007990146055817604,\n",
       " -0.010744892060756683,\n",
       " -0.00987219624221325,\n",
       " -0.01058371365070343,\n",
       " -0.008179765194654465,\n",
       " -0.01167258433997631,\n",
       " -0.0069435895420610905,\n",
       " -0.016329854726791382,\n",
       " -0.008675399236381054,\n",
       " -0.007568577770143747,\n",
       " -0.012794490903615952,\n",
       " -0.011745989322662354,\n",
       " -0.01636812835931778,\n",
       " -0.015690669417381287,\n",
       " -0.015757029876112938,\n",
       " -0.011371556669473648,\n",
       " -0.016500093042850494,\n",
       " -0.014478368684649467,\n",
       " -0.007520404644310474,\n",
       " -0.012274594977498055,\n",
       " -0.009572701528668404,\n",
       " -0.0097164586186409,\n",
       " -0.009410558268427849,\n",
       " -0.008036242797970772,\n",
       " -0.006800161208957434,\n",
       " -0.00960196927189827,\n",
       " -0.013001393526792526,\n",
       " -0.01263502612709999,\n",
       " -0.013588976114988327,\n",
       " -0.012393271550536156,\n",
       " -0.011959398165345192,\n",
       " -0.0113543551415205,\n",
       " -0.008953442797064781,\n",
       " -0.013575442135334015,\n",
       " -0.01144205592572689,\n",
       " -0.008375642821192741,\n",
       " -0.012304656207561493,\n",
       " -0.0073671420104801655,\n",
       " -0.01241911668330431,\n",
       " -0.011856308206915855,\n",
       " -0.00696928845718503,\n",
       " -0.017590980976819992,\n",
       " -0.010439000092446804,\n",
       " -0.010258322581648827,\n",
       " -0.015289762988686562,\n",
       " -0.017053844407200813,\n",
       " -0.003517325036227703,\n",
       " -0.013656411319971085,\n",
       " -0.011545579880475998,\n",
       " -0.0022088857367634773,\n",
       " -0.00813840888440609,\n",
       " -0.0111626498401165,\n",
       " -0.014921875670552254,\n",
       " -0.006845921277999878,\n",
       " -0.012122243642807007,\n",
       " -0.007586965337395668,\n",
       " -0.005576133728027344,\n",
       " -0.005558500532060862,\n",
       " -0.00972680002450943,\n",
       " -0.009425526484847069,\n",
       " -0.00586890010163188,\n",
       " -0.006322558969259262,\n",
       " -0.010789651423692703,\n",
       " -0.007503862492740154,\n",
       " -0.011380504816770554,\n",
       " -0.006680506281554699,\n",
       " -0.01126193255186081,\n",
       " -0.00865313969552517,\n",
       " -0.009146053344011307,\n",
       " -0.005481906235218048,\n",
       " -0.008481485769152641,\n",
       " -0.009133906103670597,\n",
       " -0.005043473094701767,\n",
       " -0.00659705325961113,\n",
       " -0.008340353146195412,\n",
       " -0.008352044969797134,\n",
       " -0.010301034897565842,\n",
       " -0.008524462580680847,\n",
       " -0.014964388683438301,\n",
       " -0.005486114416271448,\n",
       " -0.012351516634225845,\n",
       " -0.012221932411193848,\n",
       " -0.014004213735461235,\n",
       " -0.013514135032892227,\n",
       " -0.00023374706506729126,\n",
       " -0.009682477451860905,\n",
       " -0.008989205583930016,\n",
       " -0.009019490331411362,\n",
       " -0.007734735030680895,\n",
       " -0.009868230670690536,\n",
       " -0.004215007182210684,\n",
       " -0.008625306189060211,\n",
       " -0.007711602840572596,\n",
       " -0.009213084354996681,\n",
       " -0.008530211634933949,\n",
       " -0.008192870765924454,\n",
       " -0.014892000705003738,\n",
       " -0.008424803614616394,\n",
       " -0.010964060202240944,\n",
       " -0.007227207068353891,\n",
       " -0.0068012988194823265,\n",
       " -0.013239700347185135,\n",
       " -0.015002202242612839,\n",
       " -0.008564619347453117,\n",
       " -0.010601050220429897,\n",
       " -0.01288256049156189,\n",
       " -0.00941060297191143,\n",
       " -0.005591636523604393,\n",
       " -0.010713430121541023,\n",
       " -0.014974618330597878,\n",
       " -0.002981307916343212,\n",
       " -0.008123880252242088,\n",
       " -0.007454389240592718,\n",
       " -0.01074914075434208,\n",
       " -0.0102141834795475,\n",
       " -0.007158493157476187,\n",
       " -0.011711729690432549,\n",
       " -0.006155448965728283,\n",
       " -0.010706976056098938,\n",
       " -0.004039417020976543,\n",
       " -0.011647115461528301,\n",
       " -0.005375849083065987,\n",
       " -0.003850709181278944,\n",
       " -0.012430480681359768,\n",
       " -0.005350229796022177,\n",
       " -0.0024848119355738163,\n",
       " -0.0069266133941709995,\n",
       " -0.003585885278880596,\n",
       " -0.014601415023207664,\n",
       " -0.007509093265980482,\n",
       " -0.010114351287484169,\n",
       " -0.011699104681611061,\n",
       " -0.005367233417928219,\n",
       " -0.010749753564596176,\n",
       " -0.010313833132386208,\n",
       " -0.005120428744703531,\n",
       " -0.012782374396920204,\n",
       " -0.007502518128603697,\n",
       " -0.010095946490764618,\n",
       " -0.005529989022761583,\n",
       " -0.007384414318948984,\n",
       " -0.010893640108406544,\n",
       " -0.004852479789406061,\n",
       " -0.006676806602627039,\n",
       " -0.013905610889196396,\n",
       " -0.006212885491549969,\n",
       " -0.00483321025967598,\n",
       " -0.004061513114720583,\n",
       " -0.001358706969767809,\n",
       " -0.004199777264147997,\n",
       " -0.004701023455709219,\n",
       " -0.011770384386181831,\n",
       " -0.004393826238811016,\n",
       " -0.005468797869980335,\n",
       " -0.0009279069490730762,\n",
       " -0.007740501314401627,\n",
       " -0.009164974093437195,\n",
       " -0.010139143094420433,\n",
       " -0.007447290234267712,\n",
       " -0.014781724661588669,\n",
       " -0.005109739024192095,\n",
       " -0.005762486718595028,\n",
       " -0.014065379276871681,\n",
       " -0.011856721714138985,\n",
       " -0.013625634834170341,\n",
       " -0.007853235118091106,\n",
       " -0.01587667316198349,\n",
       " -0.005109752062708139,\n",
       " -0.012291636317968369,\n",
       " -0.001803555991500616,\n",
       " -0.013310182839632034,\n",
       " -0.00081659946590662,\n",
       " -0.008798587135970592,\n",
       " -0.008445149287581444,\n",
       " -0.0070254066959023476,\n",
       " -0.0024596890434622765,\n",
       " -0.0035146051086485386,\n",
       " -0.011059913784265518,\n",
       " -0.007766794413328171,\n",
       " -0.010832147672772408,\n",
       " -0.010358582250773907,\n",
       " -0.011888193897902966,\n",
       " -0.005517894402146339,\n",
       " -0.002756281290203333,\n",
       " -0.0036164638586342335,\n",
       " -0.0004603075794875622,\n",
       " -0.01196165569126606,\n",
       " -0.008714530616998672,\n",
       " -0.006900842767208815,\n",
       " -0.005213397089391947,\n",
       " -0.006571681704372168,\n",
       " -0.011701472103595734,\n",
       " -0.00761403888463974,\n",
       " -0.0036195479333400726,\n",
       " -0.009211051277816296,\n",
       " -0.007963307201862335,\n",
       " -0.00756197702139616,\n",
       " -0.00858457200229168,\n",
       " -0.011950723826885223,\n",
       " -0.004553916398435831,\n",
       " -0.013784730806946754,\n",
       " -0.009477877989411354,\n",
       " -0.0033211312256753445,\n",
       " -0.006402263883501291,\n",
       " -0.0028285421431064606,\n",
       " -0.008590379729866982,\n",
       " -0.005414672661572695,\n",
       " -0.009349512867629528,\n",
       " -0.006990022491663694,\n",
       " -0.004739989992231131,\n",
       " -0.008090335875749588,\n",
       " -0.01236022636294365,\n",
       " -0.0010573477484285831,\n",
       " -0.010124893859028816,\n",
       " -0.006123043596744537,\n",
       " -0.008412260562181473,\n",
       " -0.009090883657336235,\n",
       " -0.00469829561188817,\n",
       " -0.0015464858151972294,\n",
       " -0.013868914917111397,\n",
       " -0.008535824716091156,\n",
       " -0.004543628543615341,\n",
       " -0.010508857667446136,\n",
       " -0.0025084707885980606,\n",
       " -0.012588701210916042,\n",
       " -0.0076391142792999744,\n",
       " -0.006990240421146154,\n",
       " -0.013183279894292355,\n",
       " -0.0019935169257223606,\n",
       " -0.008552394807338715,\n",
       " 8.440157398581505e-05,\n",
       " -0.007520461454987526,\n",
       " -0.008961327373981476,\n",
       " -0.003565942868590355,\n",
       " -0.011697409674525261,\n",
       " -0.008398700505495071,\n",
       " -0.0028596362099051476,\n",
       " -0.005370249040424824,\n",
       " -0.011856857687234879,\n",
       " -0.0035597258247435093,\n",
       " -0.004082622472196817,\n",
       " -0.01025787740945816,\n",
       " -0.0062710256315767765,\n",
       " -0.006128374487161636,\n",
       " -0.014942623674869537,\n",
       " -0.004706048406660557,\n",
       " -0.0008746199309825897,\n",
       " -0.0006802533753216267,\n",
       " -0.005251571536064148,\n",
       " -0.005188337527215481,\n",
       " -0.0036140321753919125,\n",
       " -0.013073137030005455,\n",
       " -0.008994009345769882,\n",
       " -0.006840798072516918,\n",
       " -0.007703292649239302,\n",
       " -0.008361206389963627,\n",
       " -0.005047076381742954,\n",
       " -0.004800723399966955,\n",
       " -0.005247755441814661,\n",
       " -0.01416340097784996,\n",
       " -0.010522781871259212,\n",
       " -0.005559264216572046,\n",
       " -0.008719482459127903,\n",
       " -0.007166873663663864,\n",
       " -0.008850578218698502,\n",
       " -0.004033082630485296,\n",
       " -0.011623745784163475,\n",
       " -0.013655755668878555,\n",
       " -0.0026344982907176018,\n",
       " -0.004105460364371538,\n",
       " -0.005105209536850452,\n",
       " -0.008212586864829063,\n",
       " -0.004494328051805496,\n",
       " -0.004191155545413494,\n",
       " -0.008279945701360703,\n",
       " -0.00482225464656949,\n",
       " -0.006804187316447496,\n",
       " -0.008243944495916367,\n",
       " -0.00824759528040886,\n",
       " 0.0003757001832127571,\n",
       " -0.015164116397500038,\n",
       " 0.0020774374715983868,\n",
       " -0.0021002148278057575,\n",
       " -0.01154695451259613,\n",
       " -0.0018642437644302845,\n",
       " -0.005451819859445095,\n",
       " -0.00939984992146492,\n",
       " -0.010470704175531864,\n",
       " -0.009162144735455513,\n",
       " -0.0007760664448142052,\n",
       " -0.0063193924725055695,\n",
       " -0.008236515335738659,\n",
       " -0.0040671383030712605,\n",
       " -0.001991418655961752,\n",
       " -0.014527851715683937,\n",
       " -0.009455829858779907,\n",
       " 0.0002376660704612732,\n",
       " -0.006782385520637035,\n",
       " -0.001695562619715929,\n",
       " -0.006491759326308966,\n",
       " -0.004172844346612692,\n",
       " -0.009417364373803139,\n",
       " -0.00540884817019105,\n",
       " -0.013606386259198189,\n",
       " -0.009252544492483139,\n",
       " -0.017095142975449562,\n",
       " -0.009259521029889584,\n",
       " -0.015260259620845318,\n",
       " -0.012607807293534279,\n",
       " -0.012226543389260769,\n",
       " -0.0045154825784265995,\n",
       " -0.005657421890646219,\n",
       " -0.006994432304054499,\n",
       " -0.002198179718106985,\n",
       " -0.008981361985206604,\n",
       " -0.002786724828183651,\n",
       " -0.0037944852374494076,\n",
       " -0.012281759642064571,\n",
       " -0.007052923087030649,\n",
       " -0.00600316422060132,\n",
       " -0.005514800548553467,\n",
       " -0.010499421507120132,\n",
       " -0.006621262524276972,\n",
       " -0.005256980657577515,\n",
       " -0.004175709560513496,\n",
       " 0.0012194379232823849,\n",
       " -0.0014726687222719193,\n",
       " -0.005857088137418032,\n",
       " 0.002562673296779394,\n",
       " -0.0025138286873698235,\n",
       " -0.006120223551988602,\n",
       " -0.012344262562692165,\n",
       " -0.004448193125426769,\n",
       " -0.015871776267886162,\n",
       " -0.010968632996082306,\n",
       " -0.00748003413900733,\n",
       " -0.00962599366903305,\n",
       " -0.007822146639227867,\n",
       " -0.0024264156818389893,\n",
       " -0.011692902073264122,\n",
       " -0.006211543921381235,\n",
       " -0.0007133735343813896,\n",
       " -0.0066607496701180935,\n",
       " -0.0088856415823102,\n",
       " -0.014284240081906319,\n",
       " -0.011071096174418926,\n",
       " -0.010367784649133682,\n",
       " -0.012431256473064423,\n",
       " -0.00817481055855751,\n",
       " -0.012570456601679325,\n",
       " -0.011323915794491768,\n",
       " -0.009600039571523666,\n",
       " -0.008127408102154732,\n",
       " -0.006796502973884344,\n",
       " -0.0025356425903737545,\n",
       " -0.00507649639621377,\n",
       " -0.011391855776309967,\n",
       " -0.009295916184782982,\n",
       " -0.009031889960169792,\n",
       " -0.011927168816328049,\n",
       " -0.0022644237615168095,\n",
       " -0.005654996261000633,\n",
       " -0.010193969123065472,\n",
       " -0.0031104274094104767,\n",
       " -0.012832501903176308,\n",
       " -0.007682461757212877,\n",
       " -0.008965572342276573,\n",
       " -0.008144411258399487,\n",
       " -0.002107032109051943,\n",
       " -0.01246732473373413,\n",
       " -0.0026924917474389076,\n",
       " -0.00801510363817215,\n",
       " -0.005688785575330257,\n",
       " -0.016821105033159256,\n",
       " -0.006752289831638336,\n",
       " -0.011620291508734226,\n",
       " -0.006599664222449064,\n",
       " -0.009042697958648205,\n",
       " -0.013589151203632355,\n",
       " -0.009603960439562798,\n",
       " -0.009045815095305443,\n",
       " -0.005006866529583931,\n",
       " -0.010634634643793106,\n",
       " -0.005355792585760355,\n",
       " -0.011222198605537415,\n",
       " -0.01189362071454525,\n",
       " -0.011560019105672836,\n",
       " -0.00942397303879261,\n",
       " -0.006616386119276285,\n",
       " -0.008374063298106194,\n",
       " -0.011170865967869759,\n",
       " 0.004820587113499641,\n",
       " -0.009459041059017181,\n",
       " -0.0071690562181174755,\n",
       " -0.013165838085114956,\n",
       " -0.004178355447947979,\n",
       " -0.004170488100498915,\n",
       " -0.002790187019854784,\n",
       " -0.007898267358541489,\n",
       " -0.011515455320477486,\n",
       " -0.012740667909383774,\n",
       " -0.0029820408672094345,\n",
       " -0.0095803402364254,\n",
       " -0.00468416977673769,\n",
       " -0.01539292000234127,\n",
       " -0.0008822069503366947,\n",
       " -0.0075782486237585545,\n",
       " -0.010337766259908676,\n",
       " -0.011879129335284233,\n",
       " -0.002706302795559168,\n",
       " -0.008115958422422409,\n",
       " -0.01154464390128851,\n",
       " -0.0087242741137743,\n",
       " -0.008915320038795471,\n",
       " -0.0071854302659630775,\n",
       " -0.010942278429865837,\n",
       " -0.001977821346372366,\n",
       " -0.008525209501385689,\n",
       " -0.006656119134277105,\n",
       " -0.00464758463203907,\n",
       " -0.01145193725824356,\n",
       " -0.0007580509409308434,\n",
       " -0.011047753505408764,\n",
       " -0.007765970192849636,\n",
       " -0.002996465191245079,\n",
       " -0.01033971831202507,\n",
       " -0.004960682243108749,\n",
       " -0.0004231859929859638,\n",
       " -0.0047018867917358875,\n",
       " -0.015299815684556961,\n",
       " -0.0028557805344462395,\n",
       " -0.00579066900536418,\n",
       " -0.011276915669441223,\n",
       " -0.0073851426132023335,\n",
       " -0.007235297933220863,\n",
       " -0.015676889568567276,\n",
       " -0.008644076995551586,\n",
       " -0.00896453857421875,\n",
       " -0.005687136668711901,\n",
       " -0.012123731896281242,\n",
       " -0.014102717861533165,\n",
       " -0.008762836456298828,\n",
       " -0.006374786142259836,\n",
       " -0.00905313715338707,\n",
       " -0.007625861559063196,\n",
       " -0.010085655376315117,\n",
       " -0.015302065759897232,\n",
       " -0.008375364355742931,\n",
       " -0.005739158485084772,\n",
       " -0.008511903695762157,\n",
       " -0.007269266061484814,\n",
       " -0.011577433906495571,\n",
       " -0.004339355044066906,\n",
       " -0.0051691061817109585,\n",
       " -0.005591908935457468,\n",
       " -0.00580340763553977,\n",
       " -0.00700622471049428,\n",
       " -0.011730900034308434,\n",
       " -0.005845964886248112,\n",
       " -0.005036431364715099,\n",
       " -0.00905352272093296,\n",
       " -0.006746658589690924,\n",
       " -0.011803343892097473,\n",
       " -0.012105181813240051,\n",
       " -0.00915422011166811,\n",
       " -0.013805966824293137,\n",
       " -0.0015988019295036793,\n",
       " -0.006258531007915735,\n",
       " -0.006484024226665497,\n",
       " -0.011575448326766491,\n",
       " 0.001267461571842432,\n",
       " -0.008451761677861214,\n",
       " -0.003537145908921957,\n",
       " -0.005327683407813311,\n",
       " -0.015060275793075562,\n",
       " -0.006360631436109543,\n",
       " -0.005148185417056084,\n",
       " -0.013981914147734642,\n",
       " -0.01633988320827484,\n",
       " -0.0069316960871219635,\n",
       " -0.003705196548253298,\n",
       " -0.002757580950856209,\n",
       " -0.009421173483133316,\n",
       " -0.0035427561961114407,\n",
       " -0.010548608377575874,\n",
       " -0.01574086770415306,\n",
       " -0.008743567392230034,\n",
       " -0.005091517232358456,\n",
       " -0.00724929990246892,\n",
       " -0.0037733688950538635,\n",
       " -0.010659860447049141,\n",
       " -0.002716135699301958,\n",
       " -0.004300217144191265,\n",
       " -0.005118062254041433,\n",
       " -0.008340129628777504,\n",
       " -0.004433239344507456,\n",
       " -0.009746463969349861,\n",
       " -0.016265869140625,\n",
       " -0.012327535077929497,\n",
       " -0.004313328769057989,\n",
       " -0.009363662451505661,\n",
       " -0.008791412226855755,\n",
       " -0.006827907171100378,\n",
       " -0.003263055346906185,\n",
       " -0.006655598059296608,\n",
       " -0.010912441648542881,\n",
       " -0.009993634186685085,\n",
       " 0.0022021266631782055,\n",
       " -0.011653641238808632,\n",
       " -0.017447199672460556,\n",
       " -0.00519862025976181,\n",
       " -0.010583391413092613,\n",
       " -0.008483353070914745,\n",
       " -0.02358386293053627,\n",
       " -0.010694039054214954,\n",
       " -0.007953079417347908,\n",
       " -0.008692455478012562,\n",
       " -0.012618419714272022,\n",
       " -0.006563231348991394,\n",
       " -0.016112985089421272,\n",
       " -0.012650886550545692,\n",
       " -0.010640246793627739,\n",
       " -0.010776154696941376,\n",
       " -0.01944280043244362,\n",
       " -0.007840472273528576,\n",
       " -0.01071406900882721,\n",
       " -0.006706554908305407,\n",
       " -0.009197069332003593,\n",
       " -0.0069270445965230465,\n",
       " -0.003830558620393276,\n",
       " -0.005478463135659695,\n",
       " -0.010065828450024128,\n",
       " -0.005167724099010229,\n",
       " -0.007951569743454456,\n",
       " -0.0065687065944075584,\n",
       " -0.006996552925556898,\n",
       " -0.014207374304533005,\n",
       " -0.010492484085261822,\n",
       " -0.007887359708547592,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f90795b5690>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(mnist_trainer.train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
