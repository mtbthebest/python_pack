{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from functools import partial\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, autograd, func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "N = 4\n",
    "din = 3\n",
    "dout = 2\n",
    "x = torch.randn(N, din)\n",
    "w_hat = torch.rand(din, dout)\n",
    "y =  x @ w_hat + torch.tensor([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetLinear(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, bias=True):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"in_feat\", torch.tensor(in_feat).long())\n",
    "        self.register_buffer(\"out_feat\", torch.tensor(out_feat).long())\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_feat, self.in_feat))\n",
    "        self.scale = nn.Parameter(torch.ones(self.out_feat))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(self.out_feat))\n",
    "        else:\n",
    "            self.register_buffer(\"bias\", None)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.weight.data.copy_(torch.ones_like(self.weight.data))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"Netlinear forward...\")\n",
    "        out = x @ self.weight.transpose(0, 1)  + self.bias \n",
    "        return out \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netlinear forward...\n",
      "Forward scale: 1x...\n",
      "tensor(-6.2835, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def forward_hook(module, args, output, scale=1.0):\n",
    "    print(f\"Forward scale: {int(scale)}x...\")\n",
    "    \n",
    "    return scale * output\n",
    "\n",
    "def criterion(inp, target):\n",
    "    return inp.sum()\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net_lin = NetLinear(din, dout)\n",
    "net_lin.zero_grad()\n",
    "handle = net_lin.register_forward_hook(partial(forward_hook, scale=1.))\n",
    "yp = net_lin(x)\n",
    "loss = criterion(yp, y)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f1ec8464730>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netlinear forward...\n",
      "tensor(-6.2835, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yp = net_lin(x)\n",
    "loss = criterion(yp, y)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netlinear forward...\n",
      "Forward scale: 1x...\n",
      "tensor(-6.2835, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net_lin = NetLinear(din, dout)\n",
    "net_lin.zero_grad()\n",
    "handle = net_lin.register_forward_hook(partial(forward_hook, scale=1.))\n",
    "yp = net_lin(x)\n",
    "loss = criterion(yp, y)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.1094, -1.1366, -4.1146],\n",
       "         [ 2.1094, -1.1366, -4.1146]]),\n",
       " tensor([4., 4.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_lin.weight.grad, net_lin.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netlinear forward...\n",
      "Forward scale: 2x...\n",
      "tensor(-12.5669, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net_lin = NetLinear(din, dout)\n",
    "net_lin.zero_grad()\n",
    "handle = net_lin.register_forward_hook(partial(forward_hook, scale=2.))\n",
    "yp = net_lin(x)\n",
    "loss = criterion(yp, y)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.2189, -2.2731, -8.2292],\n",
       "         [ 4.2189, -2.2731, -8.2292]]),\n",
       " tensor([8., 8.]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_lin.weight.grad, net_lin.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetLinear(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, bias=True):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"in_feat\", torch.tensor(in_feat).long())\n",
    "        self.register_buffer(\"out_feat\", torch.tensor(out_feat).long())\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_feat, self.in_feat))\n",
    "        self.scale = nn.Parameter(torch.ones(self.out_feat))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(self.out_feat))\n",
    "        else:\n",
    "            self.register_buffer(\"bias\", None)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.weight.data.copy_(torch.ones_like(self.weight.data))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"Netlinear forward...\", x)\n",
    "        out = x @ self.weight.transpose(0, 1)  + self.bias \n",
    "        return out \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before x  tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193],\n",
      "        [-0.4033, -0.5966,  0.1820]])\n",
      "After x  tensor([[2.3747, 0.0861, 4.7471],\n",
      "        [0.3231, 1.1762, 1.9561],\n",
      "        [0.1627, 0.7023, 0.5173],\n",
      "        [0.1627, 0.3560, 0.0331]])\n",
      "Netlinear forward... tensor([[2.3747, 0.0861, 4.7471],\n",
      "        [0.3231, 1.1762, 1.9561],\n",
      "        [0.1627, 0.7023, 0.5173],\n",
      "        [0.1627, 0.3560, 0.0331]])\n",
      "tensor(25.1947, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def forward_hook_prep(module, args):\n",
    "    x, = args\n",
    "    print(\"before x \", x)\n",
    "    x *= x\n",
    "    print(\"After x \", x)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net_lin = NetLinear(din, dout)\n",
    "net_lin.zero_grad()\n",
    "handle = net_lin.register_forward_pre_hook(forward_hook_prep)\n",
    "yp = net_lin(torch.clone(x))\n",
    "loss = criterion(yp, y)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetLinear(nn.Module):\n",
    "    def __init__(self, in_feat, out_feat, bias=True):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"in_feat\", torch.tensor(in_feat).long())\n",
    "        self.register_buffer(\"out_feat\", torch.tensor(out_feat).long())\n",
    "        self.weight = nn.Parameter(torch.Tensor(self.out_feat, self.in_feat))\n",
    "        self.scale = nn.Parameter(torch.ones(self.out_feat))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(self.out_feat))\n",
    "        else:\n",
    "            self.register_buffer(\"bias\", None)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self.weight.data.copy_(torch.ones_like(self.weight.data))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(\"Netlinear forward...\", x)\n",
    "        out = x @ self.weight.transpose(0, 1)  + self.bias \n",
    "        return out \n",
    "\n",
    "class ModelLinear(nn.Module):\n",
    "    def __init__(self, net1: NetLinear, net2: NetLinear):\n",
    "        super().__init__()\n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        with torch.no_grad():\n",
    "            self.net1.weight.data.copy_(torch.ones_like(self.net1.weight))\n",
    "            self.net2.weight.data.copy_(torch.ones_like(self.net2.weight))\n",
    "        if self.net1.bias is not None:\n",
    "            nn.init.constant_(self.net1.bias, 0.)\n",
    "            nn.init.constant_(self.net2.bias, 0.)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        print(\"Start forwarding model\")\n",
    "        print(\"--- Forwarding NET1 ---\")\n",
    "        print()\n",
    "        \n",
    "        out1= self.net1(x)\n",
    "        print(\"--- Forwarding NET2 ---\")\n",
    "        print()\n",
    "        out = self.net2(out1)\n",
    "        print(\"Done forwarding model\")\n",
    "        return out \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start forwarding model\n",
      "--- Forwarding NET1 ---\n",
      "\n",
      "Netlinear forward... tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193],\n",
      "        [-0.4033, -0.5966,  0.1820]])\n",
      "************ Forward hook net 1****************** torch.Size([4, 3])\n",
      "--- Forwarding NET2 ---\n",
      "\n",
      "Netlinear forward... tensor([[-0.9312, -0.9312, -0.9312, -0.9312, -0.9312],\n",
      "        [-1.9147, -1.9147, -1.9147, -1.9147, -1.9147],\n",
      "        [ 0.5221,  0.5221,  0.5221,  0.5221,  0.5221],\n",
      "        [-0.8179, -0.8179, -0.8179, -0.8179, -0.8179]], grad_fn=<AddBackward0>)\n",
      "************ Forward hook net 2****************** torch.Size([4, 5])\n",
      "Done forwarding model\n",
      "************ Forward hook model****************** torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "def forward_hook_net1(module, args, output,):\n",
    "    print(f\"************ Forward hook net 1******************\", args[0].size())\n",
    "\n",
    "def forward_hook_net2(module, args, output,):\n",
    "    print(f\"************ Forward hook net 2******************\", args[0].size())\n",
    "\n",
    "def forward_hook_model(module, args, output,):\n",
    "    print(f\"************ Forward hook model******************\", args[0].size())\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net1 = NetLinear(din, 5, bias=True)\n",
    "net2 = NetLinear(5, dout , bias=True)\n",
    "net_lin = ModelLinear(net1, net2)\n",
    "\n",
    "net1.register_forward_hook(forward_hook_net1)\n",
    "net2.register_forward_hook(forward_hook_net2)\n",
    "net_lin.register_forward_hook(forward_hook_model)\n",
    "\n",
    "net_lin.zero_grad()\n",
    "\n",
    "yp = net_lin(torch.clone(x))\n",
    "loss = criterion(yp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start forwarding model\n",
      "--- Forwarding NET1 ---\n",
      "\n",
      "Netlinear forward... tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193],\n",
      "        [-0.4033, -0.5966,  0.1820]])\n",
      "************ Forward hook net 1****************** torch.Size([4, 3])\n",
      "--- Forwarding NET2 ---\n",
      "\n",
      "Netlinear forward... tensor([[-0.9312, -0.9312, -0.9312, -0.9312, -0.9312],\n",
      "        [-1.9147, -1.9147, -1.9147, -1.9147, -1.9147],\n",
      "        [ 0.5221,  0.5221,  0.5221,  0.5221,  0.5221],\n",
      "        [-0.8179, -0.8179, -0.8179, -0.8179, -0.8179]], grad_fn=<AddBackward0>)\n",
      "************ Forward hook net 2****************** torch.Size([4, 5])\n",
      "Done forwarding model\n",
      "************ Forward hook model 1 ****************** torch.Size([4, 3])\n",
      "************ Forward hook model 2 ****************** torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "def forward_hook_net1(module, args, output,):\n",
    "    print(f\"************ Forward hook net 1******************\", args[0].size())\n",
    "\n",
    "def forward_hook_net2(module, args, output,):\n",
    "    print(f\"************ Forward hook net 2******************\", args[0].size())\n",
    "\n",
    "def forward_hook_model(module, args, output,):\n",
    "    print(f\"************ Forward hook model 1 ******************\", args[0].size())\n",
    "def forward_hook_model2(module, args, output,):\n",
    "    print(f\"************ Forward hook model 2 ******************\", args[0].size())\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net1 = NetLinear(din, 5, bias=True)\n",
    "net2 = NetLinear(5, dout , bias=True)\n",
    "net_lin = ModelLinear(net1, net2)\n",
    "\n",
    "net1.register_forward_hook(forward_hook_net1)\n",
    "net2.register_forward_hook(forward_hook_net2)\n",
    "net_lin.register_forward_hook(forward_hook_model,)\n",
    "net_lin.register_forward_hook(forward_hook_model2)\n",
    "\n",
    "net_lin.zero_grad()\n",
    "\n",
    "yp = net_lin(torch.clone(x))\n",
    "loss = criterion(yp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start forwarding model\n",
      "--- Forwarding NET1 ---\n",
      "\n",
      "Netlinear forward... tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193],\n",
      "        [-0.4033, -0.5966,  0.1820]])\n",
      "************ Forward hook net 1****************** torch.Size([4, 3])\n",
      "--- Forwarding NET2 ---\n",
      "\n",
      "Netlinear forward... tensor([[-0.9312, -0.9312, -0.9312, -0.9312, -0.9312],\n",
      "        [-1.9147, -1.9147, -1.9147, -1.9147, -1.9147],\n",
      "        [ 0.5221,  0.5221,  0.5221,  0.5221,  0.5221],\n",
      "        [-0.8179, -0.8179, -0.8179, -0.8179, -0.8179]], grad_fn=<AddBackward0>)\n",
      "************ Forward hook net 2****************** torch.Size([4, 5])\n",
      "Done forwarding model\n",
      "************ Forward hook model 2 ****************** torch.Size([4, 3])\n",
      "************ Forward hook model 1 ****************** torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "def forward_hook_net1(module, args, output,):\n",
    "    print(f\"************ Forward hook net 1******************\", args[0].size())\n",
    "\n",
    "def forward_hook_net2(module, args, output,):\n",
    "    print(f\"************ Forward hook net 2******************\", args[0].size())\n",
    "\n",
    "def forward_hook_model(module, args, output,):\n",
    "    print(f\"************ Forward hook model 1 ******************\", args[0].size())\n",
    "def forward_hook_model2(module, args, kwargs, output,):\n",
    "    print(f\"************ Forward hook model 2 ******************\", args[0].size())\n",
    "\n",
    "torch.manual_seed(0)\n",
    "net1 = NetLinear(din, 5, bias=True)\n",
    "net2 = NetLinear(5, dout , bias=True)\n",
    "net_lin = ModelLinear(net1, net2)\n",
    "\n",
    "net1.register_forward_hook(forward_hook_net1)\n",
    "net2.register_forward_hook(forward_hook_net2)\n",
    "net_lin.register_forward_hook(forward_hook_model)\n",
    "net_lin.register_forward_hook(forward_hook_model2, with_kwargs=True, prepend=True)\n",
    "\n",
    "net_lin.zero_grad()\n",
    "\n",
    "yp = net_lin(torch.clone(x))\n",
    "loss = criterion(yp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
