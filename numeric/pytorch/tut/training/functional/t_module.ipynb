{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, m1, m2):\n",
    "        super().__init__()\n",
    "        self.m1 = m1\n",
    "        self.m2 = m2\n",
    "        self.linear = nn.Linear(3, 1)\n",
    "        self.register_buffer(\"slope\", torch.randn(1))\n",
    "        self.slope = torch.tensor(1.0)\n",
    "        self.apply(self.reset_parameters)\n",
    "    \n",
    "    def reset_parameters(self, m):\n",
    "        print(\"model: \", type(m), id(m))\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = x.clone()\n",
    "        x = self.m1(x)\n",
    "        x = self.m2(x)\n",
    "        x = self.linear(x)\n",
    "        x = F.sigmoid(x1.sum() + x) \n",
    "        return x\n",
    "\n",
    "\n",
    "class M1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(10, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return  self.net(x)\n",
    "        \n",
    "class M2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.p = nn.Parameter(torch.Tensor(5, 3))\n",
    "        self.apply(self.reset_parameters)\n",
    "        \n",
    "    def reset_parameters(self, m):\n",
    "        print(\"m2: \", type(m))\n",
    "        m.p.data.fill_(1.0)\n",
    "        print()\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        return x @ self.p\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"M2(p_size={self.p.size()})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m2:  <class '__main__.M2'>\n",
      "\n",
      "model:  <class 'torch.nn.modules.linear.Linear'> 140130153656912\n",
      "model:  <class '__main__.M1'> 140134722709872\n",
      "model:  <class '__main__.M2'> 140134722771120\n",
      "model:  <class 'torch.nn.modules.linear.Linear'> 140130153656864\n",
      "model:  <class '__main__.Model'> 140134721473936\n"
     ]
    }
   ],
   "source": [
    "m1 = M1()\n",
    "m2 = M2()\n",
    "model = Model(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140130153656912,\n",
       " 140134722709872,\n",
       " 140134722771120,\n",
       " 140130153656864,\n",
       " 140134721473936)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(m1.net), id(m1), id(m2), id(model.linear), id(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1(\n",
      "  (net): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n",
      "M2(p_size=torch.Size([5, 3]))\n",
      "Linear(in_features=3, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for ch in model.children():\n",
    "    print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('m1', M1(\n",
      "  (net): Linear(in_features=10, out_features=5, bias=True)\n",
      "))\n",
      "('m2', M2(p_size=torch.Size([5, 3])))\n",
      "('linear', Linear(in_features=3, out_features=1, bias=True))\n"
     ]
    }
   ],
   "source": [
    "for ch in model.named_children():\n",
    "    print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Model'>\n",
      "Model(\n",
      "  (m1): M1(\n",
      "    (net): Linear(in_features=10, out_features=5, bias=True)\n",
      "  )\n",
      "  (m2): M2(p_size=torch.Size([5, 3]))\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "<class '__main__.M1'>\n",
      "M1(\n",
      "  (net): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "Linear(in_features=10, out_features=5, bias=True)\n",
      "\n",
      "<class '__main__.M2'>\n",
      "M2(p_size=torch.Size([5, 3]))\n",
      "\n",
      "<class 'torch.nn.modules.linear.Linear'>\n",
      "Linear(in_features=3, out_features=1, bias=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ch in model.modules():\n",
    "    print(type(ch))\n",
    "    print(ch)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.extra_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_buffer(\"slope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2175, -0.2462,  0.1401,  0.0677,  0.1236,  0.0503, -0.0525,  0.2588,\n",
       "          0.0390, -0.0355],\n",
       "        [-0.0897,  0.0304, -0.0405, -0.1622, -0.0644,  0.0040,  0.2439,  0.1909,\n",
       "          0.2963, -0.2859],\n",
       "        [-0.2546,  0.2203,  0.1783, -0.0237,  0.2078, -0.1258,  0.1093,  0.2051,\n",
       "          0.1070,  0.1059],\n",
       "        [-0.1937, -0.2630, -0.1800,  0.1465, -0.0797,  0.0929,  0.1548, -0.2313,\n",
       "         -0.2101,  0.2310],\n",
       "        [-0.2429, -0.1604, -0.0051, -0.0184,  0.0735,  0.2035,  0.0530, -0.0518,\n",
       "          0.1792, -0.1293]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.m1.net.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2175, -0.2462,  0.1401,  0.0677,  0.1236,  0.0503, -0.0525,  0.2588,\n",
       "          0.0390, -0.0355],\n",
       "        [-0.0897,  0.0304, -0.0405, -0.1622, -0.0644,  0.0040,  0.2439,  0.1909,\n",
       "          0.2963, -0.2859],\n",
       "        [-0.2546,  0.2203,  0.1783, -0.0237,  0.2078, -0.1258,  0.1093,  0.2051,\n",
       "          0.1070,  0.1059],\n",
       "        [-0.1937, -0.2630, -0.1800,  0.1465, -0.0797,  0.0929,  0.1548, -0.2313,\n",
       "         -0.2101,  0.2310],\n",
       "        [-0.2429, -0.1604, -0.0051, -0.0184,  0.0735,  0.2035,  0.0530, -0.0518,\n",
       "          0.1792, -0.1293]], requires_grad=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_parameter(\"m1.net.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2(p_size=torch.Size([5, 3]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_submodule(\"m2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_submodule(\"m1.net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for buff in model.buffers():\n",
    "    print(buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('slope', tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "for buff in model.named_buffers():\n",
    "    print(buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('m1.net.weight', Parameter containing:\n",
      "tensor([[-0.2175, -0.2462,  0.1401,  0.0677,  0.1236,  0.0503, -0.0525,  0.2588,\n",
      "          0.0390, -0.0355],\n",
      "        [-0.0897,  0.0304, -0.0405, -0.1622, -0.0644,  0.0040,  0.2439,  0.1909,\n",
      "          0.2963, -0.2859],\n",
      "        [-0.2546,  0.2203,  0.1783, -0.0237,  0.2078, -0.1258,  0.1093,  0.2051,\n",
      "          0.1070,  0.1059],\n",
      "        [-0.1937, -0.2630, -0.1800,  0.1465, -0.0797,  0.0929,  0.1548, -0.2313,\n",
      "         -0.2101,  0.2310],\n",
      "        [-0.2429, -0.1604, -0.0051, -0.0184,  0.0735,  0.2035,  0.0530, -0.0518,\n",
      "          0.1792, -0.1293]], requires_grad=True))\n",
      "('m1.net.bias', Parameter containing:\n",
      "tensor([-0.2522, -0.0312, -0.2755, -0.2277, -0.1391], requires_grad=True))\n",
      "('m2.p', Parameter containing:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True))\n",
      "('linear.weight', Parameter containing:\n",
      "tensor([[ 0.3180,  0.1390, -0.5150]], requires_grad=True))\n",
      "('linear.bias', Parameter containing:\n",
      "tensor([0.3672], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for p in model.named_parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.m1._get_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7893],\n",
       "        [0.7694],\n",
       "        [0.7625],\n",
       "        [0.7560],\n",
       "        [0.7539],\n",
       "        [0.7758],\n",
       "        [0.7542],\n",
       "        [0.7660],\n",
       "        [0.7843],\n",
       "        [0.7587]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 10)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (m1): M1(\n",
       "    (net): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (m2): M2(p_size=torch.Size([5, 3]))\n",
       "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module(\"linear2\", nn.Linear(model.linear.out_features, model.linear.out_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M1(\n",
      "  (net): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n",
      "M2(p_size=torch.Size([5, 3]))\n",
      "Linear(in_features=3, out_features=1, bias=True)\n",
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for ch in model.children():\n",
    "    print(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (m1): M1(\n",
      "    (net): Linear(in_features=10, out_features=5, bias=True)\n",
      "  )\n",
      "  (m2): M2(p_size=torch.Size([5, 3]))\n",
      "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
      "  (linear2): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n",
      "M1(\n",
      "  (net): Linear(in_features=10, out_features=5, bias=True)\n",
      ")\n",
      "Linear(in_features=10, out_features=5, bias=True)\n",
      "M2(p_size=torch.Size([5, 3]))\n",
      "Linear(in_features=3, out_features=1, bias=True)\n",
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for m in model.modules():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.register_module(\"linear2\", nn.Linear(model.linear.out_features, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (m1): M1(\n",
       "    (net): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (m2): M2(p_size=torch.Size([5, 3]))\n",
       "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (linear2): Linear(in_features=1, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.register_parameter(\"p\", nn.Parameter(torch.zeros(4, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_copy.register_parameter(\"p\", nn.Parameter(torch.zeros(6, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3180,  0.1390, -0.5150]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.3672], requires_grad=True)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_copy.linear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=3, out_features=1, bias=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze\n",
    "model_copy.linear.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3180,  0.1390, -0.5150]]),\n",
       " Parameter containing:\n",
       " tensor([0.3672])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_copy.linear.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (m1): M1(\n",
       "    (net): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (m2): M2(p_size=torch.Size([5, 3]))\n",
       "  (linear): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (linear2): Linear(in_features=1, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "N = 4\n",
    "din = 10\n",
    "dout = 4\n",
    "x = torch.randn(N, din)\n",
    "w_hat = torch.rand(din, dout)\n",
    "y =  x @ w_hat + torch.tensor([1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
       "          0.3223, -1.2633],\n",
       "        [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473, -1.3527, -1.6959,\n",
       "          0.5667,  0.7935],\n",
       "        [ 0.5988, -1.5551, -0.3414,  1.8530, -0.2159, -0.7425,  0.5627,  0.2596,\n",
       "         -0.1740, -0.6787],\n",
       "        [ 0.9383,  0.4889,  1.2032,  0.0845, -1.2001, -0.0048, -0.5181, -0.3067,\n",
       "         -1.5810,  1.7066]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1714, -1.6280,  0.6360,  0.0610],\n",
       "        [ 3.1769,  2.2039,  0.7222,  2.8604],\n",
       "        [ 0.3377,  1.5358,  0.6844, -0.0122],\n",
       "        [ 2.2432,  1.1925, -0.9026,  0.2081]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {name: deepcopy(p) for name, p in model_copy.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['p',\n",
       " 'm1.net.weight',\n",
       " 'm1.net.bias',\n",
       " 'm2.p',\n",
       " 'linear.weight',\n",
       " 'linear.bias',\n",
       " 'linear2.weight',\n",
       " 'linear2.bias']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parameters.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtb/env/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([4, 4])) that is different to the input size (torch.Size([4, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "train_model = deepcopy(model_copy)\n",
    "adam = optim.Adam(train_model.parameters(), lr=1)\n",
    "criterion = nn.MSELoss()\n",
    "train_model.train()\n",
    "train_model.zero_grad()\n",
    "yp = train_model(x)\n",
    "loss = criterion(yp, y)\n",
    "loss.backward()\n",
    "adam.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]], requires_grad=True)\n",
      "m1.net.weight Parameter containing:\n",
      "tensor([[-0.2175, -0.2462,  0.1401,  0.0677,  0.1236,  0.0503, -0.0525,  0.2588,\n",
      "          0.0390, -0.0355],\n",
      "        [-0.0897,  0.0304, -0.0405, -0.1622, -0.0644,  0.0040,  0.2439,  0.1909,\n",
      "          0.2963, -0.2859],\n",
      "        [-0.2546,  0.2203,  0.1783, -0.0237,  0.2078, -0.1258,  0.1093,  0.2051,\n",
      "          0.1070,  0.1059],\n",
      "        [-0.1937, -0.2630, -0.1800,  0.1465, -0.0797,  0.0929,  0.1548, -0.2313,\n",
      "         -0.2101,  0.2310],\n",
      "        [-0.2429, -0.1604, -0.0051, -0.0184,  0.0735,  0.2035,  0.0530, -0.0518,\n",
      "          0.1792, -0.1293]], requires_grad=True) Parameter containing:\n",
      "tensor([[-1.2175, -1.2462, -0.8599, -0.9323, -0.8764,  1.0503,  0.9475,  1.2588,\n",
      "          1.0389, -1.0355],\n",
      "        [-1.0897, -0.9696, -1.0405, -1.1622, -1.0644,  1.0040,  1.2439,  1.1909,\n",
      "          1.2962, -1.2859],\n",
      "        [-1.2546, -0.7797, -0.8217, -1.0237, -0.7922,  0.8742,  1.1093,  1.2051,\n",
      "          1.1070, -0.8941],\n",
      "        [-1.1937, -1.2630, -1.1800, -0.8535, -1.0797,  1.0929,  1.1548,  0.7687,\n",
      "          0.7899, -0.7690],\n",
      "        [-1.2429, -1.1604, -1.0051, -1.0184, -0.9265,  1.2035,  1.0530,  0.9482,\n",
      "          1.1792, -1.1293]], requires_grad=True)\n",
      "m1.net.bias Parameter containing:\n",
      "tensor([-0.2522, -0.0312, -0.2755, -0.2277, -0.1391], requires_grad=True) Parameter containing:\n",
      "tensor([-1.2522, -1.0312, -1.2755, -1.2277, -1.1391], requires_grad=True)\n",
      "m2.p Parameter containing:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], requires_grad=True) Parameter containing:\n",
      "tensor([[7.1526e-07, 1.6093e-06, 2.0000e+00],\n",
      "        [3.5763e-07, 8.3447e-07, 2.0000e+00],\n",
      "        [1.0133e-06, 2.3246e-06, 2.0000e+00],\n",
      "        [4.2915e-06, 9.8348e-06, 2.0000e+00],\n",
      "        [5.9605e-07, 1.4305e-06, 2.0000e+00]], requires_grad=True)\n",
      "linear.weight Parameter containing:\n",
      "tensor([[ 0.3180,  0.1390, -0.5150]]) Parameter containing:\n",
      "tensor([[ 0.3180,  0.1390, -0.5150]])\n",
      "linear.bias Parameter containing:\n",
      "tensor([0.3672]) Parameter containing:\n",
      "tensor([0.3672])\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[ 0.5376],\n",
      "        [ 0.6335],\n",
      "        [-0.9274],\n",
      "        [ 0.7520]], requires_grad=True) Parameter containing:\n",
      "tensor([[ 0.5376],\n",
      "        [ 0.6335],\n",
      "        [-0.9274],\n",
      "        [ 0.7520]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([-0.9049,  0.3369,  0.4901,  0.3203], requires_grad=True) Parameter containing:\n",
      "tensor([-0.9049,  0.3369,  0.4901,  0.3203], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, old_p in parameters.items():\n",
    "    print(name, old_p, train_model.get_parameter(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slope', tensor(1.))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_model.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model.k = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1701673864.723633"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-12-04 16:11:43.263043'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('p',\n",
       "              tensor([[0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0.],\n",
       "                      [0., 0., 0., 0., 0.]])),\n",
       "             ('slope', tensor(1.)),\n",
       "             ('m1.net.weight',\n",
       "              tensor([[-1.2175, -1.2462, -0.8599, -0.9323, -0.8764,  1.0503,  0.9475,  1.2588,\n",
       "                        1.0389, -1.0355],\n",
       "                      [-1.0897, -0.9696, -1.0405, -1.1622, -1.0644,  1.0040,  1.2439,  1.1909,\n",
       "                        1.2962, -1.2859],\n",
       "                      [-1.2546, -0.7797, -0.8217, -1.0237, -0.7922,  0.8742,  1.1093,  1.2051,\n",
       "                        1.1070, -0.8941],\n",
       "                      [-1.1937, -1.2630, -1.1800, -0.8535, -1.0797,  1.0929,  1.1548,  0.7687,\n",
       "                        0.7899, -0.7690],\n",
       "                      [-1.2429, -1.1604, -1.0051, -1.0184, -0.9265,  1.2035,  1.0530,  0.9482,\n",
       "                        1.1792, -1.1293]])),\n",
       "             ('m1.net.bias',\n",
       "              tensor([-1.2522, -1.0312, -1.2755, -1.2277, -1.1391])),\n",
       "             ('m2.p',\n",
       "              tensor([[7.1526e-07, 1.6093e-06, 2.0000e+00],\n",
       "                      [3.5763e-07, 8.3447e-07, 2.0000e+00],\n",
       "                      [1.0133e-06, 2.3246e-06, 2.0000e+00],\n",
       "                      [4.2915e-06, 9.8348e-06, 2.0000e+00],\n",
       "                      [5.9605e-07, 1.4305e-06, 2.0000e+00]])),\n",
       "             ('linear.weight', tensor([[ 0.3180,  0.1390, -0.5150]])),\n",
       "             ('linear.bias', tensor([0.3672])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[ 0.5376],\n",
       "                      [ 0.6335],\n",
       "                      [-0.9274],\n",
       "                      [ 0.7520]])),\n",
       "             ('linear2.bias', tensor([-0.9049,  0.3369,  0.4901,  0.3203]))])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_extra_state(module):\n",
    "    return {\"time_saved\":datetime.now().timestamp() }\n",
    "\n",
    "def set_extra_state(module, state):\n",
    "    print(\"exta state \",)\n",
    "    return \n",
    "train_model.set_extra_state = set_extra_state\n",
    "train_model.get_extra_state = get_extra_state\n",
    "train_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_model.state_dict(), \"/mnt/dl/models/test_state/t_module.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10, 5), nn.Linear(5, 3), nn.ReLU(), nn.Dropout(), nn.Linear(3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (1): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (1): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Dropout(p=0.5, inplace=False)\n",
       "  (5): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.insert(3, nn.Dropout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (1): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Dropout(p=0.5, inplace=False)\n",
       "  (4): Dropout(p=0.5, inplace=False)\n",
       "  (5): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict({\n",
    "    \"net1\": nn.Linear(10, 5), \n",
    "    \"net2\": nn.Linear(5, 3), \n",
    "    \"net3\":nn.ReLU(), \n",
    "    \"net4\": nn.Dropout(), \n",
    "    \"net4\": nn.Linear(3, 1)\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net3): ReLU()\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net3): ReLU()\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (4): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.append(nn.Softmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net3): ReLU()\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (4): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = nn.ModuleList([])\n",
    "for name, m in {\n",
    "    \"net1\": nn.Linear(10, 5), \n",
    "    \"net2\": nn.Linear(5, 3), \n",
    "    \"net3\":nn.ReLU(), \n",
    "    \"net4\": nn.Dropout(), \n",
    "    \"net4\": nn.Linear(3, 1)\n",
    "}.items():\n",
    "    model_list.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (1): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.ModuleDict({\n",
    "    \"net1\": nn.Linear(10, 5), \n",
    "    \"net2\": nn.Linear(5, 3), \n",
    "    \"net3\":nn.ReLU(), \n",
    "    \"net4\": nn.Dropout(), \n",
    "    \"net4\": nn.Linear(3, 1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net3): ReLU()\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=5, bias=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['net1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model[\"net5\"] = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net3): ReLU()\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (net5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pop(\"net3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (net5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update({\"net6\": nn.Linear(1, 5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (net1): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (net2): Linear(in_features=5, out_features=3, bias=True)\n",
       "  (net4): Linear(in_features=3, out_features=1, bias=True)\n",
       "  (net5): Sigmoid()\n",
       "  (net6): Linear(in_features=1, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=5, bias=True)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"net6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nn.ParameterList([nn.Parameter(torch.randn(10, 10)) for i in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParameterList(\n",
       "    (0): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (1): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (2): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (3): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (4): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (5): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (6): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (7): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (8): Parameter containing: [torch.float32 of size 10x10]\n",
       "    (9): Parameter containing: [torch.float32 of size 10x10]\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  nn.ParameterDict({\n",
    "                'left': nn.Parameter(torch.randn(5, 10)),\n",
    "                'right': nn.Parameter(torch.randn(8, 10))\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6051,  1.6760,  1.1294,  0.7079, -0.1035, -1.1614, -1.3402, -1.8728,\n",
       "         -1.4816, -1.1734],\n",
       "        [ 0.7895, -0.5011,  0.8083,  1.2982, -0.0252,  1.2517,  1.2164,  0.3123,\n",
       "         -0.6479, -0.9943],\n",
       "        [-0.1160,  1.1690,  0.0049,  1.2685, -0.5895, -2.3923,  0.1723, -1.0662,\n",
       "          0.4395, -0.6011],\n",
       "        [-2.2042,  1.4215,  0.1101, -0.9445,  1.7215, -0.3624,  0.0371,  0.2175,\n",
       "         -0.4151, -1.1725],\n",
       "        [-0.1545, -0.8629, -0.2447, -0.6704,  1.3111,  0.6664,  0.8190,  1.7625,\n",
       "         -0.7507,  0.7245]], requires_grad=True)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[\"left\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1d\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 4, 128) #bz, feat, timestep\n",
    "conv_1d = nn.Conv1d(4, 32, 3)\n",
    "y = conv_1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 126])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2549, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 4, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d.weight.shape, conv_1d.bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :, :3].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2549, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[0, :, :3] * conv_1d.weight[0]).sum() + conv_1d.bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = F.conv1d(x, conv_1d.weight, conv_1d.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.eq(y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 32, 126]), torch.Size([2, 32, 126]))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 128])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1258, -1.1524, -0.2506,  ...,  1.1648,  0.9234,  1.3873],\n",
       "         [-0.8834, -0.4189, -0.8048,  ...,  0.1447,  1.9029,  0.3904],\n",
       "         [-0.0394, -0.8015, -0.4955,  ...,  0.5541, -0.1817, -0.2345],\n",
       "         [ 0.2942,  0.7973,  1.2642,  ..., -1.6989,  1.3094, -1.6613]],\n",
       "\n",
       "        [[-0.5461, -0.6302, -0.6347,  ...,  0.2290,  1.2833, -1.3792],\n",
       "         [ 0.5408, -0.9478,  0.2021,  ...,  1.6553,  0.5204, -0.2326],\n",
       "         [ 0.4974,  0.2685,  1.4769,  ..., -1.3728,  1.6909, -0.4622],\n",
       "         [ 0.2036, -1.0328,  1.1305,  ...,  0.5374,  1.0826, -1.7105]]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.9234,  1.3873,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  1.9029,  0.3904,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ..., -0.1817, -0.2345,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  1.3094, -1.6613,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  1.2833, -1.3792,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.5204, -0.2326,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  1.6909, -0.4622,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0826, -1.7105,  0.0000]]])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(x, (3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 132])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(x, (3, 1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  0.9234,  1.3873,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  1.9029,  0.3904,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ..., -0.1817, -0.2345,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  1.3094, -1.6613,  1.0000]],\n",
       "\n",
       "        [[ 1.0000,  1.0000,  1.0000,  ...,  1.2833, -1.3792,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  0.5204, -0.2326,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  1.6909, -0.4622,  1.0000],\n",
       "         [ 1.0000,  1.0000,  1.0000,  ...,  1.0826, -1.7105,  1.0000]]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(x, (3, 1), value=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  0.9234,  1.3873,  1.0000],\n",
       "          ...,\n",
       "          [ 1.0000,  1.0000,  1.0000,  ..., -0.1817, -0.2345,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.3094, -1.6613,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
       " \n",
       "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.2833, -1.3792,  1.0000],\n",
       "          ...,\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.6909, -0.4622,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0826, -1.7105,  1.0000],\n",
       "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]]),\n",
       " torch.Size([2, 4, 128]),\n",
       " torch.Size([2, 7, 132]))"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(x, (3, 1, 2, 1), value=1.0), x.size(), F.pad(x, (3, 1, 2, 1), value=1.0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 7, 132])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(x, (3, 1, 2, 1, 5, 2), value=1.0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.,  4.,  5.],\n",
       "         [ 6.,  7.,  8.,  9., 10.],\n",
       "         [11., 12., 13., 14., 15.]],\n",
       "\n",
       "        [[16., 17., 18., 19., 20.],\n",
       "         [21., 22., 23., 24., 25.],\n",
       "         [26., 27., 28., 29., 30.]],\n",
       "\n",
       "        [[31., 32., 33., 34., 35.],\n",
       "         [36., 37., 38., 39., 40.],\n",
       "         [41., 42., 43., 44., 45.]],\n",
       "\n",
       "        [[46., 47., 48., 49., 50.],\n",
       "         [51., 52., 53., 54., 55.],\n",
       "         [56., 57., 58., 59., 60.]]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.arange(4*3*5).view((4, 3, 5)).float() + 1\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.,  0.,  1.,  2.,  3.,  4.,  5.,  0.,  0.,  0.],\n",
       "         [ 0.,  0.,  6.,  7.,  8.,  9., 10.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 11., 12., 13., 14., 15.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0., 16., 17., 18., 19., 20.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 21., 22., 23., 24., 25.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 26., 27., 28., 29., 30.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0., 31., 32., 33., 34., 35.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 36., 37., 38., 39., 40.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 41., 42., 43., 44., 45.,  0.,  0.,  0.]],\n",
       "\n",
       "        [[ 0.,  0., 46., 47., 48., 49., 50.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 51., 52., 53., 54., 55.,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 56., 57., 58., 59., 60.,  0.,  0.,  0.]]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(z, (2, 3), mode=\"constant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.,  2.,  1.,  2.,  3.,  4.,  5.,  4.,  3.,  2.],\n",
       "         [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.,  7.],\n",
       "         [13., 12., 11., 12., 13., 14., 15., 14., 13., 12.]],\n",
       "\n",
       "        [[18., 17., 16., 17., 18., 19., 20., 19., 18., 17.],\n",
       "         [23., 22., 21., 22., 23., 24., 25., 24., 23., 22.],\n",
       "         [28., 27., 26., 27., 28., 29., 30., 29., 28., 27.]],\n",
       "\n",
       "        [[33., 32., 31., 32., 33., 34., 35., 34., 33., 32.],\n",
       "         [38., 37., 36., 37., 38., 39., 40., 39., 38., 37.],\n",
       "         [43., 42., 41., 42., 43., 44., 45., 44., 43., 42.]],\n",
       "\n",
       "        [[48., 47., 46., 47., 48., 49., 50., 49., 48., 47.],\n",
       "         [53., 52., 51., 52., 53., 54., 55., 54., 53., 52.],\n",
       "         [58., 57., 56., 57., 58., 59., 60., 59., 58., 57.]]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(z, (2, 3), mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[13., 12., 11., 12., 13., 14., 15., 14., 13., 12.],\n",
       "         [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.,  7.],\n",
       "         [ 3.,  2.,  1.,  2.,  3.,  4.,  5.,  4.,  3.,  2.],\n",
       "         [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.,  7.],\n",
       "         [13., 12., 11., 12., 13., 14., 15., 14., 13., 12.],\n",
       "         [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.,  7.],\n",
       "         [ 3.,  2.,  1.,  2.,  3.,  4.,  5.,  4.,  3.,  2.]],\n",
       "\n",
       "        [[28., 27., 26., 27., 28., 29., 30., 29., 28., 27.],\n",
       "         [23., 22., 21., 22., 23., 24., 25., 24., 23., 22.],\n",
       "         [18., 17., 16., 17., 18., 19., 20., 19., 18., 17.],\n",
       "         [23., 22., 21., 22., 23., 24., 25., 24., 23., 22.],\n",
       "         [28., 27., 26., 27., 28., 29., 30., 29., 28., 27.],\n",
       "         [23., 22., 21., 22., 23., 24., 25., 24., 23., 22.],\n",
       "         [18., 17., 16., 17., 18., 19., 20., 19., 18., 17.]],\n",
       "\n",
       "        [[43., 42., 41., 42., 43., 44., 45., 44., 43., 42.],\n",
       "         [38., 37., 36., 37., 38., 39., 40., 39., 38., 37.],\n",
       "         [33., 32., 31., 32., 33., 34., 35., 34., 33., 32.],\n",
       "         [38., 37., 36., 37., 38., 39., 40., 39., 38., 37.],\n",
       "         [43., 42., 41., 42., 43., 44., 45., 44., 43., 42.],\n",
       "         [38., 37., 36., 37., 38., 39., 40., 39., 38., 37.],\n",
       "         [33., 32., 31., 32., 33., 34., 35., 34., 33., 32.]],\n",
       "\n",
       "        [[58., 57., 56., 57., 58., 59., 60., 59., 58., 57.],\n",
       "         [53., 52., 51., 52., 53., 54., 55., 54., 53., 52.],\n",
       "         [48., 47., 46., 47., 48., 49., 50., 49., 48., 47.],\n",
       "         [53., 52., 51., 52., 53., 54., 55., 54., 53., 52.],\n",
       "         [58., 57., 56., 57., 58., 59., 60., 59., 58., 57.],\n",
       "         [53., 52., 51., 52., 53., 54., 55., 54., 53., 52.],\n",
       "         [48., 47., 46., 47., 48., 49., 50., 49., 48., 47.]]])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(z, (2, 3, 2, 2), mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  2.,  3.,  4.,  5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  7.,  8.,  9., 10., 10., 10., 10.],\n",
       "         [11., 11., 11., 12., 13., 14., 15., 15., 15., 15.]],\n",
       "\n",
       "        [[16., 16., 16., 17., 18., 19., 20., 20., 20., 20.],\n",
       "         [21., 21., 21., 22., 23., 24., 25., 25., 25., 25.],\n",
       "         [26., 26., 26., 27., 28., 29., 30., 30., 30., 30.]],\n",
       "\n",
       "        [[31., 31., 31., 32., 33., 34., 35., 35., 35., 35.],\n",
       "         [36., 36., 36., 37., 38., 39., 40., 40., 40., 40.],\n",
       "         [41., 41., 41., 42., 43., 44., 45., 45., 45., 45.]],\n",
       "\n",
       "        [[46., 46., 46., 47., 48., 49., 50., 50., 50., 50.],\n",
       "         [51., 51., 51., 52., 53., 54., 55., 55., 55., 55.],\n",
       "         [56., 56., 56., 57., 58., 59., 60., 60., 60., 60.]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(z, (2, 3), mode=\"replicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  1.,  1.,  2.,  3.,  4.,  5.,  5.,  5.,  5.],\n",
       "         [ 1.,  1.,  1.,  2.,  3.,  4.,  5.,  5.,  5.,  5.],\n",
       "         [ 6.,  6.,  6.,  7.,  8.,  9., 10., 10., 10., 10.],\n",
       "         [11., 11., 11., 12., 13., 14., 15., 15., 15., 15.],\n",
       "         [11., 11., 11., 12., 13., 14., 15., 15., 15., 15.],\n",
       "         [11., 11., 11., 12., 13., 14., 15., 15., 15., 15.]],\n",
       "\n",
       "        [[16., 16., 16., 17., 18., 19., 20., 20., 20., 20.],\n",
       "         [16., 16., 16., 17., 18., 19., 20., 20., 20., 20.],\n",
       "         [21., 21., 21., 22., 23., 24., 25., 25., 25., 25.],\n",
       "         [26., 26., 26., 27., 28., 29., 30., 30., 30., 30.],\n",
       "         [26., 26., 26., 27., 28., 29., 30., 30., 30., 30.],\n",
       "         [26., 26., 26., 27., 28., 29., 30., 30., 30., 30.]],\n",
       "\n",
       "        [[31., 31., 31., 32., 33., 34., 35., 35., 35., 35.],\n",
       "         [31., 31., 31., 32., 33., 34., 35., 35., 35., 35.],\n",
       "         [36., 36., 36., 37., 38., 39., 40., 40., 40., 40.],\n",
       "         [41., 41., 41., 42., 43., 44., 45., 45., 45., 45.],\n",
       "         [41., 41., 41., 42., 43., 44., 45., 45., 45., 45.],\n",
       "         [41., 41., 41., 42., 43., 44., 45., 45., 45., 45.]],\n",
       "\n",
       "        [[46., 46., 46., 47., 48., 49., 50., 50., 50., 50.],\n",
       "         [46., 46., 46., 47., 48., 49., 50., 50., 50., 50.],\n",
       "         [51., 51., 51., 52., 53., 54., 55., 55., 55., 55.],\n",
       "         [56., 56., 56., 57., 58., 59., 60., 60., 60., 60.],\n",
       "         [56., 56., 56., 57., 58., 59., 60., 60., 60., 60.],\n",
       "         [56., 56., 56., 57., 58., 59., 60., 60., 60., 60.]]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(z, (2, 3, 1, 2), mode=\"replicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 4.,  5.,  1.,  2.,  3.,  4.,  5.,  1.,  2.,  3.,  4.,  5.],\n",
       "         [ 9., 10.,  6.,  7.,  8.,  9., 10.,  6.,  7.,  8.,  9., 10.],\n",
       "         [14., 15., 11., 12., 13., 14., 15., 11., 12., 13., 14., 15.]],\n",
       "\n",
       "        [[19., 20., 16., 17., 18., 19., 20., 16., 17., 18., 19., 20.],\n",
       "         [24., 25., 21., 22., 23., 24., 25., 21., 22., 23., 24., 25.],\n",
       "         [29., 30., 26., 27., 28., 29., 30., 26., 27., 28., 29., 30.]],\n",
       "\n",
       "        [[34., 35., 31., 32., 33., 34., 35., 31., 32., 33., 34., 35.],\n",
       "         [39., 40., 36., 37., 38., 39., 40., 36., 37., 38., 39., 40.],\n",
       "         [44., 45., 41., 42., 43., 44., 45., 41., 42., 43., 44., 45.]],\n",
       "\n",
       "        [[49., 50., 46., 47., 48., 49., 50., 46., 47., 48., 49., 50.],\n",
       "         [54., 55., 51., 52., 53., 54., 55., 51., 52., 53., 54., 55.],\n",
       "         [59., 60., 56., 57., 58., 59., 60., 56., 57., 58., 59., 60.]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(z, (2, 5), mode=\"circular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# F.pad(z, (2, 3, 1, 3), mode=\"circular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1d with dilation\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 4, 128) #bz, feat, timestep\n",
    "conv_1d = nn.Conv1d(4, 32, 3, dilation=2)\n",
    "y = conv_1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 124])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 3])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :, 0:6:2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0894, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[0, :, 0:6:2] * conv_1d.weight[0]).sum() + conv_1d.bias[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0894, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv1d with group\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 4, 128) #bz, feat, timestep\n",
    "conv_1d = nn.Conv1d(4, 32, 3, groups=2)\n",
    "y = conv_1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 126])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2, 3])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3963, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3963, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[0, 0:2, 0:3] * conv_1d.weight[0, ]).sum() + conv_1d.bias[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d\n",
    "x = torch.randn(4, 3, 64, 64)\n",
    "conv_2d = nn.Conv2d(3, 32, 3)\n",
    "y = conv_2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 62, 62])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d padding mode\n",
    "x = torch.randn(4, 3, 64, 64)\n",
    "conv_2d = nn.Conv2d(3, 32, 3, padding=\"same\")\n",
    "y = conv_2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 64, 64])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d padding mode\n",
    "x = torch.randn(4, 3, 64, 64)\n",
    "conv_2d = nn.Conv2d(3, 32, 3, padding=\"valid\")\n",
    "y = conv_2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 62, 62])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv3d padding mode\n",
    "x = torch.randn(4, 16, 3, 64, 64)\n",
    "conv_3d = nn.Conv3d(16, 32, 3)\n",
    "y = conv_3d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 32, 1, 62, 62])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 66])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 64)\n",
    "conv_1d_t = nn.ConvTranspose1d(32, 16, kernel_size=3)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16, 3])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_t.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 58])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 64)\n",
    "conv_1d_t = nn.ConvTranspose1d(32, 16, kernel_size=3, padding=4)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 64)\n",
    "conv_1d_t = nn.ConvTranspose1d(32, 16, kernel_size=3, padding=1)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 68])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 64)\n",
    "conv_1d_t = nn.ConvTranspose1d(32, 16, kernel_size=5, padding=0)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d \n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 68)\n",
    "conv_1d_t = nn.Conv1d(32, 16, kernel_size=5, padding=0)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 58])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 64)\n",
    "conv_1d_t = nn.ConvTranspose1d(32, 16, kernel_size=5, padding=5)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv1d \n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 58)\n",
    "conv_1d_t = nn.Conv1d(32, 16, kernel_size=5, padding=5)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 66, 66])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv2d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 32, 64, 64)\n",
    "conv_1d_t = nn.ConvTranspose2d(32, 16, kernel_size=3)\n",
    "y = conv_1d_t(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv2d transpose\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 3, 32, 32)\n",
    "weight = torch.randn(10, 3, 3, 3)\n",
    "unfold = nn.Unfold(3, ) # Flatten the image patch to convolve and build blocks\n",
    "y = unfold(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unfold(kernel_size=3, dilation=1, padding=0, stride=1)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 27, 900])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506,  ..., -0.2407, -0.6251,  0.8161],\n",
       "        [-1.1524, -0.2506, -0.4339,  ..., -0.6251,  0.8161, -0.5711],\n",
       "        [-0.2506, -0.4339,  0.8487,  ...,  0.8161, -0.5711, -0.1195],\n",
       "        ...,\n",
       "        [-1.1870, -0.8221,  0.6051,  ...,  1.3223, -2.0006, -0.6380],\n",
       "        [-0.8221,  0.6051, -0.9905,  ..., -2.0006, -0.6380, -1.1714],\n",
       "        [ 0.6051, -0.9905, -0.2534,  ..., -0.6380, -1.1714, -0.8415]])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 27])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.view(10, -1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.matmul(weight.view(10, -1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 900])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2d = nn.Conv2d(3, 10, 3, bias=False)\n",
    "conv2d.weight.data = weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 30, 30])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.7220e-06, grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conv2d(x).view(4, 10, -1) - out).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 32, 32])"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nn.Fold((32, 32), 3)(y) ).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 9])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pooling\n",
    "x = torch.randn(4, 8, 27)\n",
    "pool = nn.MaxPool1d(3)\n",
    "y = pool(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 25])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pooling\n",
    "x = torch.randn(4, 8, 27)\n",
    "pool = nn.MaxPool1d(3, stride=1)\n",
    "y = pool(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 9])"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pooling\n",
    "x = torch.randn(4, 8, 27)\n",
    "pool = nn.AvgPool1d(3,)\n",
    "y = pool(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 6, 6])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pooling\n",
    "x = torch.arange(100).view(1, 1, 10, 10).float()\n",
    "pool = nn.AdaptiveMaxPool2d(output_size=6)\n",
    "y = pool(x)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[11., 13., 14., 16., 18., 19.],\n",
       "          [31., 33., 34., 36., 38., 39.],\n",
       "          [41., 43., 44., 46., 48., 49.],\n",
       "          [61., 63., 64., 66., 68., 69.],\n",
       "          [81., 83., 84., 86., 88., 89.],\n",
       "          [91., 93., 94., 96., 98., 99.]]]])"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[13., 12., 11., 12., 13., 14., 15., 14., 13.],\n",
       "           [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.],\n",
       "           [ 3.,  2.,  1.,  2.,  3.,  4.,  5.,  4.,  3.],\n",
       "           [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.],\n",
       "           [13., 12., 11., 12., 13., 14., 15., 14., 13.],\n",
       "           [18., 17., 16., 17., 18., 19., 20., 19., 18.],\n",
       "           [13., 12., 11., 12., 13., 14., 15., 14., 13.],\n",
       "           [ 8.,  7.,  6.,  7.,  8.,  9., 10.,  9.,  8.]],\n",
       " \n",
       "          [[33., 32., 31., 32., 33., 34., 35., 34., 33.],\n",
       "           [28., 27., 26., 27., 28., 29., 30., 29., 28.],\n",
       "           [23., 22., 21., 22., 23., 24., 25., 24., 23.],\n",
       "           [28., 27., 26., 27., 28., 29., 30., 29., 28.],\n",
       "           [33., 32., 31., 32., 33., 34., 35., 34., 33.],\n",
       "           [38., 37., 36., 37., 38., 39., 40., 39., 38.],\n",
       "           [33., 32., 31., 32., 33., 34., 35., 34., 33.],\n",
       "           [28., 27., 26., 27., 28., 29., 30., 29., 28.]],\n",
       " \n",
       "          [[53., 52., 51., 52., 53., 54., 55., 54., 53.],\n",
       "           [48., 47., 46., 47., 48., 49., 50., 49., 48.],\n",
       "           [43., 42., 41., 42., 43., 44., 45., 44., 43.],\n",
       "           [48., 47., 46., 47., 48., 49., 50., 49., 48.],\n",
       "           [53., 52., 51., 52., 53., 54., 55., 54., 53.],\n",
       "           [58., 57., 56., 57., 58., 59., 60., 59., 58.],\n",
       "           [53., 52., 51., 52., 53., 54., 55., 54., 53.],\n",
       "           [48., 47., 46., 47., 48., 49., 50., 49., 48.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 8, 9]))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ReflectionPad2d(2)\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[ 1.,  2.,  3.,  4.,  5.,  4.,  3.],\n",
       "           [ 6.,  7.,  8.,  9., 10.,  9.,  8.],\n",
       "           [11., 12., 13., 14., 15., 14., 13.],\n",
       "           [16., 17., 18., 19., 20., 19., 18.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25., 24., 23.],\n",
       "           [26., 27., 28., 29., 30., 29., 28.],\n",
       "           [31., 32., 33., 34., 35., 34., 33.],\n",
       "           [36., 37., 38., 39., 40., 39., 38.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45., 44., 43.],\n",
       "           [46., 47., 48., 49., 50., 49., 48.],\n",
       "           [51., 52., 53., 54., 55., 54., 53.],\n",
       "           [56., 57., 58., 59., 60., 59., 58.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 4, 7]))"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ReflectionPad2d((0, 2, 0, 0))\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[ 2.,  1.,  2.,  3.,  4.,  5.,  4.,  3.],\n",
       "           [ 7.,  6.,  7.,  8.,  9., 10.,  9.,  8.],\n",
       "           [12., 11., 12., 13., 14., 15., 14., 13.],\n",
       "           [17., 16., 17., 18., 19., 20., 19., 18.]],\n",
       " \n",
       "          [[22., 21., 22., 23., 24., 25., 24., 23.],\n",
       "           [27., 26., 27., 28., 29., 30., 29., 28.],\n",
       "           [32., 31., 32., 33., 34., 35., 34., 33.],\n",
       "           [37., 36., 37., 38., 39., 40., 39., 38.]],\n",
       " \n",
       "          [[42., 41., 42., 43., 44., 45., 44., 43.],\n",
       "           [47., 46., 47., 48., 49., 50., 49., 48.],\n",
       "           [52., 51., 52., 53., 54., 55., 54., 53.],\n",
       "           [57., 56., 57., 58., 59., 60., 59., 58.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 4, 8]))"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ReflectionPad2d((1, 2, 0, 0))\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[ 1.,  1.,  1.,  2.,  3.,  4.,  5.,  5.,  5.],\n",
       "           [ 1.,  1.,  1.,  2.,  3.,  4.,  5.,  5.,  5.],\n",
       "           [ 1.,  1.,  1.,  2.,  3.,  4.,  5.,  5.,  5.],\n",
       "           [ 6.,  6.,  6.,  7.,  8.,  9., 10., 10., 10.],\n",
       "           [11., 11., 11., 12., 13., 14., 15., 15., 15.],\n",
       "           [16., 16., 16., 17., 18., 19., 20., 20., 20.],\n",
       "           [16., 16., 16., 17., 18., 19., 20., 20., 20.],\n",
       "           [16., 16., 16., 17., 18., 19., 20., 20., 20.]],\n",
       " \n",
       "          [[21., 21., 21., 22., 23., 24., 25., 25., 25.],\n",
       "           [21., 21., 21., 22., 23., 24., 25., 25., 25.],\n",
       "           [21., 21., 21., 22., 23., 24., 25., 25., 25.],\n",
       "           [26., 26., 26., 27., 28., 29., 30., 30., 30.],\n",
       "           [31., 31., 31., 32., 33., 34., 35., 35., 35.],\n",
       "           [36., 36., 36., 37., 38., 39., 40., 40., 40.],\n",
       "           [36., 36., 36., 37., 38., 39., 40., 40., 40.],\n",
       "           [36., 36., 36., 37., 38., 39., 40., 40., 40.]],\n",
       " \n",
       "          [[41., 41., 41., 42., 43., 44., 45., 45., 45.],\n",
       "           [41., 41., 41., 42., 43., 44., 45., 45., 45.],\n",
       "           [41., 41., 41., 42., 43., 44., 45., 45., 45.],\n",
       "           [46., 46., 46., 47., 48., 49., 50., 50., 50.],\n",
       "           [51., 51., 51., 52., 53., 54., 55., 55., 55.],\n",
       "           [56., 56., 56., 57., 58., 59., 60., 60., 60.],\n",
       "           [56., 56., 56., 57., 58., 59., 60., 60., 60.],\n",
       "           [56., 56., 56., 57., 58., 59., 60., 60., 60.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 8, 9]))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ReplicationPad2d(2)\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[ 1.,  1.,  1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  6.,  6.,  7.,  8.,  9., 10.],\n",
       "           [11., 11., 11., 12., 13., 14., 15.],\n",
       "           [16., 16., 16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 21., 21., 22., 23., 24., 25.],\n",
       "           [26., 26., 26., 27., 28., 29., 30.],\n",
       "           [31., 31., 31., 32., 33., 34., 35.],\n",
       "           [36., 36., 36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 41., 41., 42., 43., 44., 45.],\n",
       "           [46., 46., 46., 47., 48., 49., 50.],\n",
       "           [51., 51., 51., 52., 53., 54., 55.],\n",
       "           [56., 56., 56., 57., 58., 59., 60.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 4, 7]))"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ReplicationPad2d((2, 0, 0, 0))\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  1.,  2.,  3.,  4.,  5.,  0.,  0.],\n",
       "           [ 0.,  0.,  6.,  7.,  8.,  9., 10.,  0.,  0.],\n",
       "           [ 0.,  0., 11., 12., 13., 14., 15.,  0.,  0.],\n",
       "           [ 0.,  0., 16., 17., 18., 19., 20.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0., 21., 22., 23., 24., 25.,  0.,  0.],\n",
       "           [ 0.,  0., 26., 27., 28., 29., 30.,  0.,  0.],\n",
       "           [ 0.,  0., 31., 32., 33., 34., 35.,  0.,  0.],\n",
       "           [ 0.,  0., 36., 37., 38., 39., 40.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]],\n",
       " \n",
       "          [[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0., 41., 42., 43., 44., 45.,  0.,  0.],\n",
       "           [ 0.,  0., 46., 47., 48., 49., 50.,  0.,  0.],\n",
       "           [ 0.,  0., 51., 52., 53., 54., 55.,  0.,  0.],\n",
       "           [ 0.,  0., 56., 57., 58., 59., 60.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "           [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 8, 9]))"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ZeroPad2d(2)\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[ 0.,  0.,  1.,  2.,  3.,  4.,  5.],\n",
       "           [ 0.,  0.,  6.,  7.,  8.,  9., 10.],\n",
       "           [ 0.,  0., 11., 12., 13., 14., 15.],\n",
       "           [ 0.,  0., 16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[ 0.,  0., 21., 22., 23., 24., 25.],\n",
       "           [ 0.,  0., 26., 27., 28., 29., 30.],\n",
       "           [ 0.,  0., 31., 32., 33., 34., 35.],\n",
       "           [ 0.,  0., 36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[ 0.,  0., 41., 42., 43., 44., 45.],\n",
       "           [ 0.,  0., 46., 47., 48., 49., 50.],\n",
       "           [ 0.,  0., 51., 52., 53., 54., 55.],\n",
       "           [ 0.,  0., 56., 57., 58., 59., 60.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 4, 7]))"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ZeroPad2d((2, 0, 0, 0))\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100.,    1.,    2.,    3.,    4.,    5., -100., -100.],\n",
       "           [-100., -100.,    6.,    7.,    8.,    9.,   10., -100., -100.],\n",
       "           [-100., -100.,   11.,   12.,   13.,   14.,   15., -100., -100.],\n",
       "           [-100., -100.,   16.,   17.,   18.,   19.,   20., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.]],\n",
       " \n",
       "          [[-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100.,   21.,   22.,   23.,   24.,   25., -100., -100.],\n",
       "           [-100., -100.,   26.,   27.,   28.,   29.,   30., -100., -100.],\n",
       "           [-100., -100.,   31.,   32.,   33.,   34.,   35., -100., -100.],\n",
       "           [-100., -100.,   36.,   37.,   38.,   39.,   40., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.]],\n",
       " \n",
       "          [[-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100.,   41.,   42.,   43.,   44.,   45., -100., -100.],\n",
       "           [-100., -100.,   46.,   47.,   48.,   49.,   50., -100., -100.],\n",
       "           [-100., -100.,   51.,   52.,   53.,   54.,   55., -100., -100.],\n",
       "           [-100., -100.,   56.,   57.,   58.,   59.,   60., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.],\n",
       "           [-100., -100., -100., -100., -100., -100., -100., -100., -100.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 8, 9]))"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ConstantPad2d(2, value=-100)\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.,  2.,  3.,  4.,  5.],\n",
       "           [ 6.,  7.,  8.,  9., 10.],\n",
       "           [11., 12., 13., 14., 15.],\n",
       "           [16., 17., 18., 19., 20.]],\n",
       " \n",
       "          [[21., 22., 23., 24., 25.],\n",
       "           [26., 27., 28., 29., 30.],\n",
       "           [31., 32., 33., 34., 35.],\n",
       "           [36., 37., 38., 39., 40.]],\n",
       " \n",
       "          [[41., 42., 43., 44., 45.],\n",
       "           [46., 47., 48., 49., 50.],\n",
       "           [51., 52., 53., 54., 55.],\n",
       "           [56., 57., 58., 59., 60.]]]]),\n",
       " tensor([[[[-100., -100., -100., -100., -100., -100.],\n",
       "           [-100.,    1.,    2.,    3.,    4.,    5.],\n",
       "           [-100.,    6.,    7.,    8.,    9.,   10.],\n",
       "           [-100.,   11.,   12.,   13.,   14.,   15.],\n",
       "           [-100.,   16.,   17.,   18.,   19.,   20.]],\n",
       " \n",
       "          [[-100., -100., -100., -100., -100., -100.],\n",
       "           [-100.,   21.,   22.,   23.,   24.,   25.],\n",
       "           [-100.,   26.,   27.,   28.,   29.,   30.],\n",
       "           [-100.,   31.,   32.,   33.,   34.,   35.],\n",
       "           [-100.,   36.,   37.,   38.,   39.,   40.]],\n",
       " \n",
       "          [[-100., -100., -100., -100., -100., -100.],\n",
       "           [-100.,   41.,   42.,   43.,   44.,   45.],\n",
       "           [-100.,   46.,   47.,   48.,   49.,   50.],\n",
       "           [-100.,   51.,   52.,   53.,   54.,   55.],\n",
       "           [-100.,   56.,   57.,   58.,   59.,   60.]]]]),\n",
       " torch.Size([1, 3, 4, 5]),\n",
       " torch.Size([1, 3, 5, 6]))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reflection 1d\n",
    "x = torch.arange(3*4*5, dtype=torch.float).reshape(1, 3, 4, 5) + 1\n",
    "pad2d = nn.ConstantPad2d((1, 0, 1, 0), value=-100)#left, right, top, bottom\n",
    "y = pad2d(x)\n",
    "x, y, x.size(), y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0374,  2.6822, -4.1152, -3.6797, -1.9258],\n",
       "         [ 1.3408, -0.0991,  3.9644, -0.4437,  1.3231],\n",
       "         [-1.5111, -0.9828, -4.7767, -3.3114, -2.0611],\n",
       "         [ 0.1852,  1.9767,  3.0001, -3.3897, -2.1773]]),\n",
       " tensor([[0.0000, 2.6822, 0.0000, 0.0000, 0.0000],\n",
       "         [1.3408, 0.0000, 3.9644, 0.0000, 1.3231],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1852, 1.9767, 3.0001, 0.0000, 0.0000]]),\n",
       " tensor([[0.0000, 2.6822, 0.0000, 0.0000, 0.0000],\n",
       "         [1.3408, 0.0000, 3.9644, 0.0000, 1.3231],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1852, 1.9767, 3.0001, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-5, 5)\n",
    "y = nn.ReLU()(x) # max(x, 0)\n",
    "z = F.relu(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0749,  5.3644, -8.2305, -7.3594, -3.8515],\n",
       "         [ 2.6816, -0.1981,  7.9289, -0.8874,  2.6461],\n",
       "         [-3.0221, -1.9657, -9.5535, -6.6228, -4.1222],\n",
       "         [ 0.3704,  3.9534,  6.0002, -6.7794, -4.3546]]),\n",
       " tensor([[-7.4868e-03,  5.3644e+00, -8.2305e-01, -7.3594e-01, -3.8515e-01],\n",
       "         [ 2.6816e+00, -1.9813e-02,  7.9289e+00, -8.8744e-02,  2.6461e+00],\n",
       "         [-3.0221e-01, -1.9657e-01, -9.5535e-01, -6.6228e-01, -4.1222e-01],\n",
       "         [ 3.7044e-01,  3.9534e+00,  6.0002e+00, -6.7794e-01, -4.3546e-01]]),\n",
       " tensor([[-7.4868e-03,  5.3644e+00, -8.2305e-01, -7.3594e-01, -3.8515e-01],\n",
       "         [ 2.6816e+00, -1.9813e-02,  7.9289e+00, -8.8744e-02,  2.6461e+00],\n",
       "         [-3.0221e-01, -1.9657e-01, -9.5535e-01, -6.6228e-01, -4.1222e-01],\n",
       "         [ 3.7044e-01,  3.9534e+00,  6.0002e+00, -6.7794e-01, -4.3546e-01]]))"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 10)\n",
    "y = nn.LeakyReLU(negative_slope=0.1)(x)  # max(0,x) + negative_slope  min(0,x)\n",
    "z = F.leaky_relu(x, negative_slope=0.1)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0374,  2.6822, -4.1152, -3.6797, -1.9258],\n",
       "         [ 1.3408, -0.0991,  3.9644, -0.4437,  1.3231],\n",
       "         [-1.5111, -0.9828, -4.7767, -3.3114, -2.0611],\n",
       "         [ 0.1852,  1.9767,  3.0001, -3.3897, -2.1773]]),\n",
       " tensor([[0.4906, 0.9360, 0.0161, 0.0246, 0.1272],\n",
       "         [0.7926, 0.4753, 0.9814, 0.3909, 0.7897],\n",
       "         [0.1808, 0.2723, 0.0084, 0.0352, 0.1129],\n",
       "         [0.5462, 0.8783, 0.9526, 0.0326, 0.1018]]),\n",
       " tensor([[0.4906, 0.9360, 0.0161, 0.0246, 0.1272],\n",
       "         [0.7926, 0.4753, 0.9814, 0.3909, 0.7897],\n",
       "         [0.1808, 0.2723, 0.0084, 0.0352, 0.1129],\n",
       "         [0.5462, 0.8783, 0.9526, 0.0326, 0.1018]]))"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-5, 5)\n",
    "y = nn.Sigmoid()(x)\n",
    "z = F.sigmoid(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0374,  2.6822, -4.1152, -3.6797, -1.9258],\n",
       "         [ 1.3408, -0.0991,  3.9644, -0.4437,  1.3231],\n",
       "         [-1.5111, -0.9828, -4.7767, -3.3114, -2.0611],\n",
       "         [ 0.1852,  1.9767,  3.0001, -3.3897, -2.1773]]),\n",
       " tensor([[-0.0374,  0.9907, -0.9995, -0.9987, -0.9584],\n",
       "         [ 0.8719, -0.0987,  0.9993, -0.4167,  0.8675],\n",
       "         [-0.9071, -0.7543, -0.9999, -0.9973, -0.9681],\n",
       "         [ 0.1831,  0.9623,  0.9951, -0.9977, -0.9746]]),\n",
       " tensor([[-0.0374,  0.9907, -0.9995, -0.9987, -0.9584],\n",
       "         [ 0.8719, -0.0987,  0.9993, -0.4167,  0.8675],\n",
       "         [-0.9071, -0.7543, -0.9999, -0.9973, -0.9681],\n",
       "         [ 0.1831,  0.9623,  0.9951, -0.9977, -0.9746]]))"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-5, 5)\n",
    "y = nn.Tanh()(x)\n",
    "z = F.tanh(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0374,  2.6822, -4.1152, -3.6797, -1.9258],\n",
       "         [ 1.3408, -0.0991,  3.9644, -0.4437,  1.3231],\n",
       "         [-1.5111, -0.9828, -4.7767, -3.3114, -2.0611],\n",
       "         [ 0.1852,  1.9767,  3.0001, -3.3897, -2.1773]]),\n",
       " tensor([[-0.7120, -0.0662, -4.1314, -3.7046, -2.0618],\n",
       "         [-0.2324, -0.7439, -0.0188, -0.9394, -0.2361],\n",
       "         [-1.7105, -1.3007, -4.7851, -3.3472, -2.1810],\n",
       "         [-0.6048, -0.1297, -0.0486, -3.4229, -2.2847]]),\n",
       " tensor([[-0.7120, -0.0662, -4.1314, -3.7046, -2.0618],\n",
       "         [-0.2324, -0.7439, -0.0188, -0.9394, -0.2361],\n",
       "         [-1.7105, -1.3007, -4.7851, -3.3472, -2.1810],\n",
       "         [-0.6048, -0.1297, -0.0486, -3.4229, -2.2847]]))"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-5, 5)\n",
    "y = nn.LogSigmoid()(x)\n",
    "z = F.logsigmoid(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0374,  2.6822, -4.1152, -3.6797, -1.9258],\n",
       "         [ 1.3408, -0.0991,  3.9644, -0.4437,  1.3231],\n",
       "         [-1.5111, -0.9828, -4.7767, -3.3114, -2.0611],\n",
       "         [ 0.1852,  1.9767,  3.0001, -3.3897, -2.1773]]),\n",
       " tensor([[-0.0367,  2.6822, -0.9837, -0.9748, -0.8542],\n",
       "         [ 1.3408, -0.0943,  3.9644, -0.3584,  1.3231],\n",
       "         [-0.7793, -0.6257, -0.9916, -0.9635, -0.8727],\n",
       "         [ 0.1852,  1.9767,  3.0001, -0.9663, -0.8867]]),\n",
       " tensor([[-0.0367,  2.6822, -0.9837, -0.9748, -0.8542],\n",
       "         [ 1.3408, -0.0943,  3.9644, -0.3584,  1.3231],\n",
       "         [-0.7793, -0.6257, -0.9916, -0.9635, -0.8727],\n",
       "         [ 0.1852,  1.9767,  3.0001, -0.9663, -0.8867]]))"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-5, 5)\n",
    "y = nn.ELU()(x) # x or a * (exp(x) - 1)\n",
    "z = F.elu(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[4.8877, 6.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [6.0000, 4.7028, 6.0000, 3.6688, 6.0000],\n",
       "         [0.4668, 2.0515, 0.0000, 0.0000, 0.0000],\n",
       "         [5.5557, 6.0000, 6.0000, 0.0000, 0.0000]]),\n",
       " tensor([[4.8877, 6.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [6.0000, 4.7028, 6.0000, 3.6688, 6.0000],\n",
       "         [0.4668, 2.0515, 0.0000, 0.0000, 0.0000],\n",
       "         [5.5557, 6.0000, 6.0000, 0.0000, 0.0000]]))"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.ReLU6()(x) #  min(max(0,x), 6)\n",
    "z = F.relu6(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 4.8877, 13.0467, -7.3457, -6.0391]),\n",
       " tensor([ 4.8877, 13.0467, -1.8364, -1.5098], grad_fn=<PreluKernelBackward0>),\n",
       " tensor([ 4.8877, 13.0467, -1.8364, -1.5098], grad_fn=<PreluKernelBackward0>),\n",
       " Parameter containing:\n",
       " tensor([0.2500], requires_grad=True))"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4).uniform_(-10, 20)\n",
    "prelu = nn.PReLU(1) # PReLU(x) = max(0, x) + a  min(0, x)\n",
    "y = prelu(x) \n",
    "z = F.prelu(x, prelu.weight)\n",
    "x, y, z, prelu.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.836425"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-7.3457 * 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4.8877, 13.0467],\n",
       "          [-7.3457, -6.0391],\n",
       "          [-0.7773,  9.0224]],\n",
       " \n",
       "         [[ 4.7028, 16.8933],\n",
       "          [ 3.6688,  8.9692],\n",
       "          [ 0.4668,  2.0515]],\n",
       " \n",
       "         [[-9.3302, -4.9342],\n",
       "          [-1.1833,  5.5557],\n",
       "          [10.9300, 14.0003]],\n",
       " \n",
       "         [[-5.1691, -1.5319],\n",
       "          [10.4483, 17.4558],\n",
       "          [ 1.9130, 16.2247]]]),\n",
       " tensor([[[ 4.8877, 13.0467],\n",
       "          [-2.0212, -1.6617],\n",
       "          [-0.2082,  9.0224]],\n",
       " \n",
       "         [[ 4.7028, 16.8933],\n",
       "          [ 3.6688,  8.9692],\n",
       "          [ 0.4668,  2.0515]],\n",
       " \n",
       "         [[-1.9982, -1.0568],\n",
       "          [-0.3256,  5.5557],\n",
       "          [10.9300, 14.0003]],\n",
       " \n",
       "         [[-1.1071, -0.3281],\n",
       "          [10.4483, 17.4558],\n",
       "          [ 1.9130, 16.2247]]], grad_fn=<PreluKernelBackward0>),\n",
       " tensor([[[ 4.8877, 13.0467],\n",
       "          [-2.0212, -1.6617],\n",
       "          [-0.2082,  9.0224]],\n",
       " \n",
       "         [[ 4.7028, 16.8933],\n",
       "          [ 3.6688,  8.9692],\n",
       "          [ 0.4668,  2.0515]],\n",
       " \n",
       "         [[-1.9982, -1.0568],\n",
       "          [-0.3256,  5.5557],\n",
       "          [10.9300, 14.0003]],\n",
       " \n",
       "         [[-1.1071, -0.3281],\n",
       "          [10.4483, 17.4558],\n",
       "          [ 1.9130, 16.2247]]], grad_fn=<PreluKernelBackward0>),\n",
       " Parameter containing:\n",
       " tensor([0.2142, 0.2752, 0.2678], requires_grad=True))"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 3, 2).uniform_(-10, 20)\n",
    "prelu = nn.PReLU(3)  # \n",
    "prelu.weight.data *= torch.randn(3).abs() \n",
    "y = prelu(x) \n",
    "z = F.prelu(x, prelu.weight)\n",
    "x, y, z, prelu.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3213787599999998"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-4.9342 * 0.2678"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[ 4.8877, 13.0467, -0.0000, -0.0000, -0.2880],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.2697,  1.7272, -0.0000, -0.0000, -0.3583],\n",
       "         [ 5.5557, 10.9300, 14.0003, -0.0000, -0.3748]]),\n",
       " tensor([[ 4.8877, 13.0467, -0.0000, -0.0000, -0.2880],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.2697,  1.7272, -0.0000, -0.0000, -0.3583],\n",
       "         [ 5.5557, 10.9300, 14.0003, -0.0000, -0.3748]]))"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.Hardswish()(x)\n",
    "z = F.hardswish(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[ 5.1355, 13.7081, -1.7570, -1.7539, -0.9500],\n",
       "         [ 9.4798,  4.9412, 17.7499,  3.8549,  9.4239],\n",
       "         [ 0.4905,  2.1555, -1.7579, -1.7454, -1.2197],\n",
       "         [ 5.8373, 11.4842, 14.7102, -1.7481, -1.3781]]),\n",
       " tensor([[ 5.1355, 13.7081, -1.7570, -1.7539, -0.9500],\n",
       "         [ 9.4798,  4.9412, 17.7499,  3.8549,  9.4239],\n",
       "         [ 0.4905,  2.1555, -1.7579, -1.7454, -1.2197],\n",
       "         [ 5.8373, 11.4842, 14.7102, -1.7481, -1.3781]]))"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.SELU()(x) # =scale(max(0,x)+min(0,(exp(x)1))) => scale * ELU(x)\n",
    "z = F.selu(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[ 4.8877, 13.0467, -0.9994, -0.9976, -0.5404],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -0.9999, -0.9928, -0.6937],\n",
       "         [ 5.5557, 10.9300, 14.0003, -0.9943, -0.7839]]),\n",
       " tensor([[ 4.8877, 13.0467, -0.9994, -0.9976, -0.5404],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -0.9999, -0.9928, -0.6937],\n",
       "         [ 5.5557, 10.9300, 14.0003, -0.9943, -0.7839]]))"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.CELU()(x) # =max(0,x)+min(0,(exp(x/)1))\n",
    "z = F.celu(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[ 4.8877e+00,  1.3047e+01,  0.0000e+00,  0.0000e+00, -1.6983e-01],\n",
       "         [ 9.0224e+00,  4.7028e+00,  1.6893e+01,  3.6684e+00,  8.9692e+00],\n",
       "         [ 3.1728e-01,  2.0103e+00,  0.0000e+00, -2.0587e-06, -1.4003e-01],\n",
       "         [ 5.5557e+00,  1.0930e+01,  1.4000e+01, -6.1621e-07, -9.6157e-02]]),\n",
       " tensor([[ 4.8877e+00,  1.3047e+01,  0.0000e+00,  0.0000e+00, -1.6983e-01],\n",
       "         [ 9.0224e+00,  4.7028e+00,  1.6893e+01,  3.6684e+00,  8.9692e+00],\n",
       "         [ 3.1728e-01,  2.0103e+00,  0.0000e+00, -2.0587e-06, -1.4003e-01],\n",
       "         [ 5.5557e+00,  1.0930e+01,  1.4000e+01, -6.1621e-07, -9.6157e-02]]))"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.GELU()(x) # GELU(x)=x(x)\n",
    "z = F.gelu(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[ 4.8511e+00,  1.3047e+01, -4.7377e-03, -1.4361e-02, -2.4478e-01],\n",
       "         [ 9.0213e+00,  4.6605e+00,  1.6893e+01,  3.5776e+00,  8.9680e+00],\n",
       "         [ 2.8691e-01,  1.8179e+00, -8.2754e-04, -3.5253e-02, -2.7744e-01],\n",
       "         [ 5.5343e+00,  1.0930e+01,  1.4000e+01, -2.9244e-02, -2.7224e-01]]),\n",
       " tensor([[ 4.8511e+00,  1.3047e+01, -4.7377e-03, -1.4361e-02, -2.4478e-01],\n",
       "         [ 9.0213e+00,  4.6605e+00,  1.6893e+01,  3.5776e+00,  8.9680e+00],\n",
       "         [ 2.8691e-01,  1.8179e+00, -8.2754e-04, -3.5253e-02, -2.7744e-01],\n",
       "         [ 5.5343e+00,  1.0930e+01,  1.4000e+01, -2.9244e-02, -2.7224e-01]]))"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.SiLU()(x) # SILU(x)=x(x)\n",
    "z = F.silu(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "         [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "         [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]]),\n",
       " tensor([[4.8952e+00, 1.3047e+01, 6.4517e-04, 2.3809e-03, 3.7819e-01],\n",
       "         [9.0225e+00, 4.7118e+00, 1.6893e+01, 3.6940e+00, 8.9693e+00],\n",
       "         [9.5354e-01, 2.1724e+00, 8.8698e-05, 7.1702e-03, 2.6716e-01],\n",
       "         [5.5595e+00, 1.0930e+01, 1.4000e+01, 5.6735e-03, 1.9566e-01]]),\n",
       " tensor([[4.8952e+00, 1.3047e+01, 6.4517e-04, 2.3809e-03, 3.7819e-01],\n",
       "         [9.0225e+00, 4.7118e+00, 1.6893e+01, 3.6940e+00, 8.9693e+00],\n",
       "         [9.5354e-01, 2.1724e+00, 8.8698e-05, 7.1702e-03, 2.6716e-01],\n",
       "         [5.5595e+00, 1.0930e+01, 1.4000e+01, 5.6735e-03, 1.9566e-01]]))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(4, 5).uniform_(-10, 20)\n",
    "y = nn.Softplus()(x) # Softplus(x) = (1/) log(1+exp(x))\n",
    "z = F.softplus(x)\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "          [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "          [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "          [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]],\n",
       " \n",
       "         [[10.4483, 17.4558,  1.9130, 16.2247,  2.5822],\n",
       "          [ 6.5872, 18.5821, -8.9151, -4.4431,  1.2025],\n",
       "          [-0.8470, 17.9600, -4.7227, -1.9050, -5.4796],\n",
       "          [-9.0484, -3.7561, 17.8940, 11.6933, 12.2701]]]),\n",
       " tensor([[[2.8608e-04, 9.9971e-01, 1.3919e-09, 5.1410e-09, 9.9129e-07],\n",
       "          [3.8137e-04, 5.0745e-06, 9.9925e-01, 1.8045e-06, 3.6162e-04],\n",
       "          [1.6462e-01, 8.0301e-01, 9.1557e-06, 7.4276e-04, 3.1611e-02],\n",
       "          [2.0546e-04, 4.4339e-02, 9.5545e-01, 4.5188e-09, 1.7164e-07]],\n",
       " \n",
       "         [[7.0000e-04, 7.7348e-01, 1.3749e-07, 2.2582e-01, 2.6850e-07],\n",
       "          [6.1754e-06, 9.9999e-01, 1.1432e-12, 1.0006e-10, 2.8322e-08],\n",
       "          [6.7954e-09, 1.0000e+00, 1.4094e-10, 2.3591e-09, 6.6115e-11],\n",
       "          [1.9798e-12, 3.9359e-10, 9.9439e-01, 2.0166e-03, 3.5904e-03]]]),\n",
       " tensor([[[2.8608e-04, 9.9971e-01, 1.3919e-09, 5.1410e-09, 9.9129e-07],\n",
       "          [3.8137e-04, 5.0745e-06, 9.9925e-01, 1.8045e-06, 3.6162e-04],\n",
       "          [1.6462e-01, 8.0301e-01, 9.1557e-06, 7.4276e-04, 3.1611e-02],\n",
       "          [2.0546e-04, 4.4339e-02, 9.5545e-01, 4.5188e-09, 1.7164e-07]],\n",
       " \n",
       "         [[7.0000e-04, 7.7348e-01, 1.3749e-07, 2.2582e-01, 2.6850e-07],\n",
       "          [6.1754e-06, 9.9999e-01, 1.1432e-12, 1.0006e-10, 2.8322e-08],\n",
       "          [6.7954e-09, 1.0000e+00, 1.4094e-10, 2.3591e-09, 6.6115e-11],\n",
       "          [1.9798e-12, 3.9359e-10, 9.9439e-01, 2.0166e-03, 3.5904e-03]]]),\n",
       " tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000]]))"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(2, 4, 5).uniform_(-10, 20)\n",
    "y = nn.Softmax(-1)(x)\n",
    "z = F.softmax(x, dim=-1)\n",
    "x, y, z, y.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "          [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692],\n",
       "          [ 0.4668,  2.0515, -9.3302, -4.9342, -1.1833],\n",
       "          [ 5.5557, 10.9300, 14.0003, -5.1691, -1.5319]],\n",
       " \n",
       "         [[10.4483, 17.4558,  1.9130, 16.2247,  2.5822],\n",
       "          [ 6.5872, 18.5821, -8.9151, -4.4431,  1.2025],\n",
       "          [-0.8470, 17.9600, -4.7227, -1.9050, -5.4796],\n",
       "          [-9.0484, -3.7561, 17.8940, 11.6933, 12.2701]]]),\n",
       " tensor([[[1.5283e-02, 8.9231e-01, 2.8165e-11, 6.0776e-05, 5.8492e-05],\n",
       "          [9.5473e-01, 2.1224e-04, 9.4750e-01, 9.9961e-01, 9.9987e-01],\n",
       "          [1.8376e-04, 1.4976e-05, 3.8710e-12, 1.8347e-04, 3.8972e-05],\n",
       "          [2.9806e-02, 1.0747e-01, 5.2501e-02, 1.4506e-04, 2.7502e-05]],\n",
       " \n",
       "         [[9.7938e-01, 1.7422e-01, 1.1470e-07, 9.8935e-01, 6.2029e-05],\n",
       "          [2.0612e-02, 5.3734e-01, 2.2750e-12, 1.0458e-09, 1.5609e-05],\n",
       "          [1.2175e-05, 2.8844e-01, 1.5056e-10, 1.3235e-08, 1.9560e-08],\n",
       "          [3.3393e-09, 1.0687e-10, 1.0000e+00, 1.0651e-02, 9.9992e-01]]]),\n",
       " tensor([[[1.5283e-02, 8.9231e-01, 2.8165e-11, 6.0776e-05, 5.8492e-05],\n",
       "          [9.5473e-01, 2.1224e-04, 9.4750e-01, 9.9961e-01, 9.9987e-01],\n",
       "          [1.8376e-04, 1.4976e-05, 3.8710e-12, 1.8347e-04, 3.8972e-05],\n",
       "          [2.9806e-02, 1.0747e-01, 5.2501e-02, 1.4506e-04, 2.7502e-05]],\n",
       " \n",
       "         [[9.7938e-01, 1.7422e-01, 1.1470e-07, 9.8935e-01, 6.2029e-05],\n",
       "          [2.0612e-02, 5.3734e-01, 2.2750e-12, 1.0458e-09, 1.5609e-05],\n",
       "          [1.2175e-05, 2.8844e-01, 1.5056e-10, 1.3235e-08, 1.9560e-08],\n",
       "          [3.3393e-09, 1.0687e-10, 1.0000e+00, 1.0651e-02, 9.9992e-01]]]),\n",
       " tensor([[1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
       "         [1.0000, 1.0000, 1.0000, 1.0000, 1.0000]]))"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(2, 4, 5).uniform_(-10, 20)\n",
    "y = nn.Softmax(-2)(x)\n",
    "z = F.softmax(x, dim=-2)\n",
    "x, y, z, y.sum(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692]]),\n",
       " tensor([[-8.1592e+00, -2.8701e-04, -2.0393e+01, -1.9086e+01, -1.3824e+01],\n",
       "         [-7.8717e+00, -1.2191e+01, -7.5014e-04, -1.3225e+01, -7.9249e+00]]),\n",
       " tensor([[-8.1592e+00, -2.8701e-04, -2.0393e+01, -1.9086e+01, -1.3824e+01],\n",
       "         [-7.8717e+00, -1.2191e+01, -7.5014e-04, -1.3225e+01, -7.9249e+00]]),\n",
       " tensor([[-8.1592e+00, -2.8704e-04, -2.0393e+01, -1.9086e+01, -1.3824e+01],\n",
       "         [-7.8717e+00, -1.2191e+01, -7.5017e-04, -1.3225e+01, -7.9249e+00]]))"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(2, 5).uniform_(-10, 20)\n",
    "y = nn.LogSoftmax(-1)(x)\n",
    "z = F.log_softmax(x, dim=-1) # log(Softmax(x)) \n",
    "x, y, z, (F.softmax(x, -1).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.8877, 13.0467, -7.3457, -6.0391, -0.7773],\n",
       "         [ 9.0224,  4.7028, 16.8933,  3.6688,  8.9692]]),\n",
       " tensor([[9.8424e-01, 2.3780e-04, 1.0000e+00, 9.9994e-01, 9.9994e-01],\n",
       "         [1.5756e-02, 9.9976e-01, 2.9725e-11, 6.0796e-05, 5.8495e-05]]),\n",
       " tensor([[9.8424e-01, 2.3780e-04, 1.0000e+00, 9.9994e-01, 9.9994e-01],\n",
       "         [1.5756e-02, 9.9976e-01, 2.9725e-11, 6.0796e-05, 5.8495e-05]]),\n",
       " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000]))"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(2,  5).uniform_(-10, 20)\n",
    "y = nn.Softmin(-2)(x)\n",
    "z = F.softmin(x, dim=-2)\n",
    "x, y, z, y.sum(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.5756e-02, 9.9976e-01, 2.9725e-11, 6.0796e-05, 5.8495e-05],\n",
       "         [9.8424e-01, 2.3780e-04, 1.0000e+00, 9.9994e-01, 9.9994e-01]]),\n",
       " tensor([[9.8424e-01, 2.3780e-04, 1.0000e+00, 9.9994e-01, 9.9994e-01],\n",
       "         [1.5756e-02, 9.9976e-01, 2.9725e-11, 6.0796e-05, 5.8495e-05]]))"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.empty(2,  5).uniform_(-10, 20)\n",
    "F.softmax(x, dim=-2), F.softmin(x, dim=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8508],\n",
       "        [-1.2494],\n",
       "        [ 0.1558],\n",
       "        [ 0.4321]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Linear(3, 5), nn.BatchNorm1d(5), nn.Linear(5, 1)) # Normalize per feature\n",
    "x = torch.randn(4, 3)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d = net[1]\n",
    "bn1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d.running_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0.], requires_grad=True))"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d.weight, bn1d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5796],\n",
       "        [-0.2985],\n",
       "        [-0.4648],\n",
       "        [-0.3327]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Conv1d(3, 16, 3), nn.BatchNorm1d(16), nn.Flatten(1, 2), nn.Linear(16*8, 1)) # Normalize per feature\n",
    "x = torch.randn(4, 3, 10)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d = net[1]\n",
    "bn1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d.weight, bn1d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.6580e-02, -2.3724e-02,  3.8010e-03,  7.1910e-03,  7.4824e-03,\n",
       "        -2.5950e-02, -2.6184e-02, -1.8934e-02,  2.5612e-02,  2.5042e-02,\n",
       "         3.6823e-02, -2.1588e-05,  1.9561e-02, -1.0119e-02, -1.7656e-02,\n",
       "        -2.9119e-02])"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn1d.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch normalized via per (C, H, W) over N batches\n",
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Conv2d(3, 16, 3), nn.BatchNorm2d(16), nn.Flatten(1, -1), nn.LazyLinear(1)) # Normalize per feature\n",
    "x = torch.randn(4, 3, 64, 64)\n",
    "net(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2d = net[1]\n",
    "bn2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2d.weight, bn2d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0170,  0.0032, -0.0127, -0.0071,  0.0042, -0.0151,  0.0101, -0.0169,\n",
       "        -0.0184, -0.0173, -0.0031,  0.0136, -0.0192,  0.0156, -0.0091,  0.0052])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn2d.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Identity(), nn.LayerNorm(64), nn.Flatten(1, -1), nn.LazyLinear(1)) # Normalize per feature\n",
    "x = torch.randn(4, 128, 64) # Seq: BxTxd\n",
    "net(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.weight, ln.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]), torch.Size([64]))"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.weight.size(), ln.bias.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtb/env/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch normalized via per (C, H, W) over N batches\n",
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Conv2d(3, 32, 3, padding=\"same\"), \n",
    "                    nn.LayerNorm([32, 64, 64]),  # Normalize per feature\n",
    "                    nn.Flatten(1, -1), \n",
    "                    nn.LazyLinear(1))\n",
    "x = torch.randn(4, 3, 64, 64) \n",
    "net(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64, 64]), torch.Size([32, 64, 64]))"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln.weight.shape, ln.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4504],\n",
       "        [-0.1148],\n",
       "        [-0.3610],\n",
       "        [-0.3393]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Conv1d(3, 16, 3), nn.InstanceNorm1d(16, affine=True), nn.Flatten(1, 2), nn.Linear(16*8, 1)) # Normalize per feature\n",
    "x = torch.randn(4, 3, 10)\n",
    "net(x)\n",
    "net(x)\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbn = net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InstanceNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbn.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtb/env/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch normalized via per (C, H, W) over N batches\n",
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Conv2d(3, 32, 3, padding=\"same\"), \n",
    "                    nn.InstanceNorm2d(32, affine=True),  # Normalize per feature\n",
    "                    nn.Flatten(1, -1), \n",
    "                    nn.LazyLinear(1))\n",
    "x = torch.randn(4, 3, 64, 64) \n",
    "net(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "inbn = net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inbn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtb/env/lib/python3.9/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch normalized via per (C, H, W) over N batches\n",
    "torch.manual_seed(0)\n",
    "net = nn.Sequential(nn.Conv2d(3, 32, 3, padding=\"same\"), \n",
    "                    nn.GroupNorm(4, 32, affine=True),  # Normalize per feature\n",
    "                    nn.Flatten(1, -1), \n",
    "                    nn.LazyLinear(1))\n",
    "x = torch.randn(4, 3, 64, 64) \n",
    "net(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpbn = net[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupNorm(4, 32, eps=1e-05, affine=True)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpbn.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpbn.bias.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "rnn = nn.RNN(input_size=5, hidden_size=15, num_layers=1,\n",
    "             nonlinearity=\"tanh\", bias=True, bidirectional=False, \n",
    "             batch_first=True)\n",
    "x = torch.randn(4, 10, 5)\n",
    "out, last_state = rnn(x) #out is h[1:t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10, 15]), torch.Size([1, 4, 15]))"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), last_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 15])"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[..., -1, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1031, -0.5137, -0.0354,  0.0951, -0.2973, -0.1689,  0.0404, -0.5558,\n",
       "          0.0197, -0.2016, -0.2240, -0.1106,  0.5820,  0.4665, -0.0272],\n",
       "        [ 0.1308,  0.1390, -0.0039, -0.0518,  0.2764,  0.1299, -0.0134,  0.0677,\n",
       "         -0.0610,  0.3481,  0.5619,  0.2291,  0.2706,  0.0643,  0.0280],\n",
       "        [-0.2806,  0.1678, -0.5192,  0.3800, -0.2179, -0.7108, -0.2451,  0.2495,\n",
       "          0.4239,  0.2261, -0.0591, -0.3125,  0.1801,  0.1598,  0.3343],\n",
       "        [ 0.2281,  0.1690, -0.3100,  0.5432, -0.3815, -0.3226, -0.1621, -0.0237,\n",
       "         -0.1821,  0.0645,  0.0245, -0.1639, -0.1053,  0.2882, -0.2862]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 724,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.select(dim=1, index=torch.tensor(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1031, -0.5137, -0.0354,  0.0951, -0.2973, -0.1689,  0.0404,\n",
       "          -0.5558,  0.0197, -0.2016, -0.2240, -0.1106,  0.5820,  0.4665,\n",
       "          -0.0272],\n",
       "         [ 0.1308,  0.1390, -0.0039, -0.0518,  0.2764,  0.1299, -0.0134,\n",
       "           0.0677, -0.0610,  0.3481,  0.5619,  0.2291,  0.2706,  0.0643,\n",
       "           0.0280],\n",
       "         [-0.2806,  0.1678, -0.5192,  0.3800, -0.2179, -0.7108, -0.2451,\n",
       "           0.2495,  0.4239,  0.2261, -0.0591, -0.3125,  0.1801,  0.1598,\n",
       "           0.3343],\n",
       "         [ 0.2281,  0.1690, -0.3100,  0.5432, -0.3815, -0.3226, -0.1621,\n",
       "          -0.0237, -0.1821,  0.0645,  0.0245, -0.1639, -0.1053,  0.2882,\n",
       "          -0.2862]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add initial state\n",
    "torch.manual_seed(0)\n",
    "rnn = nn.RNN(input_size=5, hidden_size=15, num_layers=1,\n",
    "             nonlinearity=\"tanh\", bias=True, bidirectional=False, \n",
    "             batch_first=True)\n",
    "x = torch.randn(4, 10, 5)\n",
    "h0 = torch.randn(1, 15).expand(1, 4, 15)\n",
    "out, last_state = rnn(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10, 15]), torch.Size([1, 4, 15]))"
      ]
     },
     "execution_count": 727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), last_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1039, -0.5126, -0.0375,  0.0973, -0.2966, -0.1689,  0.0414, -0.5548,\n",
       "          0.0192, -0.2014, -0.2252, -0.1116,  0.5806,  0.4662, -0.0261],\n",
       "        [ 0.1304,  0.1412, -0.0079, -0.0492,  0.2770,  0.1274, -0.0102,  0.0709,\n",
       "         -0.0611,  0.3497,  0.5600,  0.2267,  0.2676,  0.0621,  0.0294],\n",
       "        [-0.2853,  0.1707, -0.5246,  0.3821, -0.2171, -0.7135, -0.2385,  0.2545,\n",
       "          0.4260,  0.2320, -0.0649, -0.3162,  0.1750,  0.1533,  0.3349],\n",
       "        [ 0.2257,  0.1705, -0.3156,  0.5443, -0.3814, -0.3289, -0.1560, -0.0181,\n",
       "         -0.1811,  0.0684,  0.0195, -0.1682, -0.1094,  0.2835, -0.2848]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[..., -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1039, -0.5126, -0.0375,  0.0973, -0.2966, -0.1689,  0.0414,\n",
       "          -0.5548,  0.0192, -0.2014, -0.2252, -0.1116,  0.5806,  0.4662,\n",
       "          -0.0261],\n",
       "         [ 0.1304,  0.1412, -0.0079, -0.0492,  0.2770,  0.1274, -0.0102,\n",
       "           0.0709, -0.0611,  0.3497,  0.5600,  0.2267,  0.2676,  0.0621,\n",
       "           0.0294],\n",
       "         [-0.2853,  0.1707, -0.5246,  0.3821, -0.2171, -0.7135, -0.2385,\n",
       "           0.2545,  0.4260,  0.2320, -0.0649, -0.3162,  0.1750,  0.1533,\n",
       "           0.3349],\n",
       "         [ 0.2257,  0.1705, -0.3156,  0.5443, -0.3814, -0.3289, -0.1560,\n",
       "          -0.0181, -0.1811,  0.0684,  0.0195, -0.1682, -0.1094,  0.2835,\n",
       "          -0.2848]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dropout with 4 layers\n",
    "torch.manual_seed(0)\n",
    "net = nn.RNN(input_size=5, hidden_size=15, \n",
    "             num_layers=4,\n",
    "             nonlinearity=\"tanh\", bias=True, bidirectional=False, \n",
    "             batch_first=True, dropout=0.1)\n",
    "x = torch.randn(4, 10, 5)\n",
    "h0 = torch.randn(1, 15).expand(4, 4, 15) # (num_directions x num_layers) x N x hout\n",
    "out, last_state = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 15])"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 15])"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3555, -0.1993, -0.2419,  0.2056,  0.1020, -0.1344, -0.1263, -0.0382,\n",
       "         -0.2619,  0.1673, -0.3040,  0.3187,  0.3298, -0.3268, -0.3188],\n",
       "        [-0.3577, -0.4380, -0.1571,  0.2563,  0.2929,  0.0064, -0.0551,  0.3024,\n",
       "         -0.2987, -0.0031, -0.2763,  0.1839,  0.4808, -0.3969, -0.4387],\n",
       "        [-0.3215, -0.0402, -0.2281,  0.1372,  0.2479, -0.1711,  0.0812, -0.0707,\n",
       "         -0.0923, -0.0108, -0.3916,  0.2852,  0.2017, -0.2332, -0.3347],\n",
       "        [-0.2470, -0.4806, -0.0573,  0.2556,  0.2663, -0.1015, -0.3573,  0.2632,\n",
       "         -0.2112,  0.0563, -0.1438,  0.1009,  0.4365, -0.4586, -0.4787]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3555, -0.1993, -0.2419,  0.2056,  0.1020, -0.1344, -0.1263, -0.0382,\n",
       "         -0.2619,  0.1673, -0.3040,  0.3187,  0.3298, -0.3268, -0.3188],\n",
       "        [-0.3577, -0.4380, -0.1571,  0.2563,  0.2929,  0.0064, -0.0551,  0.3024,\n",
       "         -0.2987, -0.0031, -0.2763,  0.1839,  0.4808, -0.3969, -0.4387],\n",
       "        [-0.3215, -0.0402, -0.2281,  0.1372,  0.2479, -0.1711,  0.0812, -0.0707,\n",
       "         -0.0923, -0.0108, -0.3916,  0.2852,  0.2017, -0.2332, -0.3347],\n",
       "        [-0.2470, -0.4806, -0.0573,  0.2556,  0.2663, -0.1015, -0.3573,  0.2632,\n",
       "         -0.2112,  0.0563, -0.1438,  0.1009,  0.4365, -0.4586, -0.4787]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, -1, :] # HT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Bidirectional\n",
    "torch.manual_seed(0)\n",
    "rnn = nn.RNN(input_size=5, \n",
    "             hidden_size=3, \n",
    "             num_layers=3,\n",
    "             nonlinearity=\"tanh\", \n",
    "             bias=True, \n",
    "             bidirectional=True, \n",
    "             batch_first=True, \n",
    "            #  dropout=0.\n",
    "             )\n",
    "# \n",
    "x = torch.randn(4, 7, 5).abs()\n",
    "h0 = torch.randn(1, 3).expand(6, 4, 3) # (num_directions x num_layers) x N x hout\n",
    "out, last_state = rnn(x, h0) # concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 6]), torch.Size([6, 4, 3]))"
      ]
     },
     "execution_count": 826,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), last_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, -1, ...].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4133, -0.1093, -0.6090,  0.6467, -0.2729, -0.2605],\n",
       "        [ 0.2957, -0.0686, -0.5352,  0.6112, -0.2638, -0.2600],\n",
       "        [ 0.1930, -0.0527, -0.3886,  0.5614, -0.3590, -0.3354],\n",
       "        [ 0.3704, -0.0460, -0.5626,  0.6116, -0.0888, -0.1524]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 828,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, -1, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 829,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.select(dim=1, index=-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4133, -0.1093, -0.6090],\n",
       "        [ 0.2957, -0.0686, -0.5352],\n",
       "        [ 0.1930, -0.0527, -0.3886],\n",
       "        [ 0.3704, -0.0460, -0.5626]], grad_fn=<IndexSelectBackward0>)"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.select(dim=1, index=-1).index_select(dim=1, index=torch.tensor([0, 1, 2])) # forward last hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6467, -0.2729, -0.2605],\n",
       "        [ 0.6112, -0.2638, -0.2600],\n",
       "        [ 0.5614, -0.3590, -0.3354],\n",
       "        [ 0.6116, -0.0888, -0.1524]], grad_fn=<IndexSelectBackward0>)"
      ]
     },
     "execution_count": 831,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.select(dim=1, index=-1).index_select(dim=1, index=torch.tensor([3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 3])"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4133, -0.1093, -0.6090],\n",
       "        [ 0.2957, -0.0686, -0.5352],\n",
       "        [ 0.1930, -0.0527, -0.3886],\n",
       "        [ 0.3704, -0.0460, -0.5626]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 833,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last layer Forward last state from out\n",
    "hf_from_out = out.select(dim=1, index=-1)[:, 0:3]\n",
    "hf_from_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4133, -0.1093, -0.6090],\n",
       "        [ 0.2957, -0.0686, -0.5352],\n",
       "        [ 0.1930, -0.0527, -0.3886],\n",
       "        [ 0.3704, -0.0460, -0.5626]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_state.view(3, 2, 4, 3)[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4133, -0.1093, -0.6090],\n",
       "        [ 0.2957, -0.0686, -0.5352],\n",
       "        [ 0.1930, -0.0527, -0.3886],\n",
       "        [ 0.3704, -0.0460, -0.5626]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last layer Forward last state from out\n",
    "# Last state dim = (num_layer * 2, B, hz)\n",
    "hf_from_last_state = last_state.view(3, 2, 4, 3)[-1][0]\n",
    "hf_from_last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0892, -0.1868, -0.3310],\n",
       "        [-0.1399, -0.2370, -0.4548],\n",
       "        [ 0.0632, -0.2535, -0.5286],\n",
       "        [-0.1388, -0.0617, -0.4278]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last layer Backward \n",
    "hb_from_out = out.select(dim=1, index=0)[:, 3:]\n",
    "hb_from_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0892, -0.1868, -0.3310],\n",
       "        [-0.1399, -0.2370, -0.4548],\n",
       "        [ 0.0632, -0.2535, -0.5286],\n",
       "        [-0.1388, -0.0617, -0.4278]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 837,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last layer Backward \n",
    "hb_from_last_state =  last_state.view(3, 2, 4, 3)[-1][1]\n",
    "hb_from_last_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0043,  0.3097, -0.4752, -0.4249, -0.2224],\n",
       "        [ 0.1548, -0.0114,  0.4578, -0.0512,  0.1528],\n",
       "        [-0.1745, -0.1135, -0.5516, -0.3824, -0.2380]], requires_grad=True)"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2251,  0.4988, -0.3742, -0.2658, -0.4034],\n",
       "        [-0.5407, -0.3370,  0.4963,  0.2576,  0.2798],\n",
       "        [ 0.0304, -0.2960,  0.0977, -0.5391, -0.4172]], requires_grad=True)"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3, 5]), torch.Size([3]))"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0.size(), rnn.weight_ih_l0_reverse.size(), rnn.bias_ih_l0.size(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 6]), torch.Size([3, 6]), torch.Size([3]))"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l1.size(), rnn.weight_ih_l1_reverse.size(), rnn.bias_ih_l1.size(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 6]), torch.Size([3, 6]), torch.Size([3]))"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l2.size(), rnn.weight_ih_l2_reverse.size(), rnn.bias_ih_l2.size(),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "sz, bz, dz, hz = 10, 4, 5, 7\n",
    "lz = 3 # num_layers\n",
    "x = torch.randn(bz, sz, dz)\n",
    "h0 = torch.randn(hz).expand(lz * 2, bz, hz)\n",
    "c0 = h0.clone()\n",
    "lstm = nn.LSTM(input_size=dz,\n",
    "               hidden_size=hz,\n",
    "               num_layers=lz,\n",
    "               dropout=0.1,\n",
    "               bias=True,\n",
    "               bidirectional=True,\n",
    "               batch_first=True\n",
    "               )\n",
    "out, (hn, cn) = lstm(x, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 14])"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10, 7]), torch.Size([4, 10, 7]))"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_forward, out_backward = out.chunk(2, -1)\n",
    "out_forward.size(), out_backward.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4, 7])"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 5])"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.weight_ih_l0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ii, W_if, W_ig, W_io = lstm.weight_ih_l0.tensor_split(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2079,  0.2255,  0.2432, -0.2417, -0.2997],\n",
       "        [-0.0129,  0.1313,  0.1720, -0.2905,  0.3107],\n",
       "        [ 0.3659, -0.0297,  0.0599,  0.0659, -0.2803],\n",
       "        [-0.3596,  0.2339,  0.3048, -0.0097, -0.3287],\n",
       "        [ 0.0155, -0.2475,  0.1294,  0.3455,  0.3775],\n",
       "        [ 0.3115,  0.0868,  0.3712, -0.0731, -0.0125],\n",
       "        [-0.2596,  0.1572,  0.1477,  0.1531,  0.2721],\n",
       "        [ 0.3269, -0.3571, -0.1071, -0.3021,  0.2872],\n",
       "        [-0.0118, -0.3361,  0.1604, -0.2317, -0.0070],\n",
       "        [ 0.2016,  0.2102,  0.2349, -0.0068, -0.0368],\n",
       "        [-0.0175, -0.3725, -0.1343,  0.2876,  0.1934],\n",
       "        [-0.3458,  0.0943,  0.3473, -0.3005, -0.0379],\n",
       "        [-0.2031, -0.0054, -0.1649,  0.3311,  0.1962],\n",
       "        [-0.0732, -0.3273, -0.2011, -0.0399,  0.1017],\n",
       "        [-0.1528, -0.2315, -0.0464, -0.3007,  0.0841],\n",
       "        [-0.3395, -0.0643, -0.3166, -0.1481,  0.0041],\n",
       "        [-0.1831, -0.2477,  0.0426, -0.1919,  0.0207],\n",
       "        [ 0.0805, -0.0400, -0.3303, -0.1077, -0.0383],\n",
       "        [ 0.1118, -0.3049,  0.2628,  0.0921,  0.0433],\n",
       "        [ 0.0221, -0.0622,  0.1367,  0.2633, -0.0770],\n",
       "        [ 0.1615,  0.2202,  0.1550,  0.0018,  0.1312],\n",
       "        [ 0.0368,  0.2386, -0.1116,  0.0527,  0.0619],\n",
       "        [-0.3596,  0.0959, -0.2616,  0.1876, -0.0753],\n",
       "        [ 0.1007, -0.2954,  0.1703,  0.2436,  0.1349],\n",
       "        [ 0.1109, -0.2183,  0.3389,  0.1049, -0.3561],\n",
       "        [-0.0076,  0.0107,  0.1293,  0.0702,  0.2962],\n",
       "        [-0.0399, -0.0623, -0.0166,  0.2286, -0.3315],\n",
       "        [ 0.2952, -0.1440,  0.2060, -0.2543, -0.1361]], requires_grad=True)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.weight_ih_l0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2079,  0.2255,  0.2432, -0.2417, -0.2997],\n",
       "        [-0.0129,  0.1313,  0.1720, -0.2905,  0.3107],\n",
       "        [ 0.3659, -0.0297,  0.0599,  0.0659, -0.2803],\n",
       "        [-0.3596,  0.2339,  0.3048, -0.0097, -0.3287],\n",
       "        [ 0.0155, -0.2475,  0.1294,  0.3455,  0.3775],\n",
       "        [ 0.3115,  0.0868,  0.3712, -0.0731, -0.0125],\n",
       "        [-0.2596,  0.1572,  0.1477,  0.1531,  0.2721]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ii, W_if, W_ig, W_io = lstm.weight_ih_l1.tensor_split(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([28, 14]), torch.Size([7, 14]))"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.weight_ih_l1.size(), W_ii.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 14])"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.weight_ih_l1_reverse.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hi, W_hf, W_hg, W_ho = lstm.weight_hh_l1.tensor_split(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 7]), torch.Size([28, 7]))"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_hi.size(), lstm.weight_hh_l1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "torch.manual_seed(0)\n",
    "sz, bz, dz, hz = 10, 4, 5, 7\n",
    "lz = 1 # num_layers\n",
    "x = torch.randn(bz, sz, dz)\n",
    "h0 = torch.randn(hz).expand(1, bz, hz).clone()\n",
    "rnn = nn.RNN(input_size=dz,\n",
    "               hidden_size=hz,\n",
    "               bias=True,\n",
    "               nonlinearity=\"tanh\",\n",
    "               batch_first=True\n",
    "               )\n",
    "out, hn = rnn(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 10, 7]), torch.Size([4, 10, 5]))"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(), x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "rnn_cell = nn.RNNCell(dz, hz, bias=True, nonlinearity=\"tanh\")\n",
    "with torch.no_grad():\n",
    "    rnn_cell.weight_hh.data.copy_(rnn.weight_hh_l0,)\n",
    "    rnn_cell.weight_ih.data.copy_(rnn.weight_ih_l0)\n",
    "    rnn_cell.bias_ih.data.copy_(rnn.bias_ih_l0)\n",
    "    rnn_cell.bias_hh.data.copy_(rnn.bias_hh_l0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 7])\n"
     ]
    }
   ],
   "source": [
    "ht = h0.clone().squeeze(0)\n",
    "print(ht.size())\n",
    "out_cells = []\n",
    "h = []\n",
    "for t in range(sz):\n",
    "    cell_h = rnn_cell(x[:, t, :], ht)\n",
    "    out_cells.append(cell_h)\n",
    "    ht = cell_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 7])"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(out_cells, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4156e-07, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.stack(out_cells, 1) - out).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "lstm_cell = nn.LSTMCell(dz, hz, bias=True)\n",
    "h0 = torch.randn(hz).expand(bz, hz).clone()\n",
    "c0 = torch.randn(hz).expand(bz, hz).clone()\n",
    "\n",
    "ht = h0\n",
    "ct = c0\n",
    "\n",
    "hn_cells = []\n",
    "cn_cells = []\n",
    "\n",
    "for t in range(sz):\n",
    "    h_next, c_next = lstm_cell(x[:, t, :], (ht, ct))\n",
    "    hn_cells.append(h_next)\n",
    "    cn_cells.append(c_next)\n",
    "    ht = h_next\n",
    "    ct = c_next\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 7])"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(hn_cells, dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0028,  0.2028, -0.3111, -0.2782, -0.1456],\n",
       "        [ 0.1014, -0.0075,  0.2997, -0.0335,  0.1000],\n",
       "        [-0.1142, -0.0743, -0.3611, -0.2503, -0.1558],\n",
       "        [ 0.0140,  0.1494,  0.2268, -0.2562, -0.1646],\n",
       "        [ 0.1373,  0.3139, -0.0778,  0.2828, -0.0609],\n",
       "        [ 0.0400,  0.3422, -0.3506, -0.2379, -0.0957],\n",
       "        [-0.1473,  0.3266, -0.2450, -0.1740, -0.2641],\n",
       "        [-0.3540, -0.2206,  0.3249,  0.1687,  0.1832],\n",
       "        [ 0.0199, -0.1938,  0.0639, -0.3529, -0.2731],\n",
       "        [-0.1949,  0.2385,  0.2216, -0.1676, -0.0136],\n",
       "        [ 0.2417,  0.3757,  0.1500,  0.0511,  0.2534],\n",
       "        [-0.2225,  0.0704, -0.2930, -0.2620, -0.1953],\n",
       "        [ 0.1710,  0.1520, -0.2239,  0.1142,  0.2075],\n",
       "        [-0.0477,  0.0144,  0.0876,  0.2345,  0.3629],\n",
       "        [-0.2913, -0.1385,  0.1485,  0.3132,  0.3289],\n",
       "        [ 0.3335,  0.0752, -0.3287,  0.0348, -0.2365],\n",
       "        [-0.3522,  0.3358,  0.2874, -0.3770,  0.0707],\n",
       "        [-0.0637, -0.0622, -0.1730,  0.1453, -0.2239],\n",
       "        [ 0.1386,  0.1911,  0.2706,  0.1413, -0.3741],\n",
       "        [-0.2452,  0.1887,  0.0791, -0.2948, -0.2176],\n",
       "        [ 0.3556,  0.2547, -0.1648, -0.0951, -0.3600],\n",
       "        [-0.0068, -0.2846, -0.2915, -0.0208,  0.0567],\n",
       "        [-0.1548,  0.2243, -0.2300,  0.3430,  0.2590],\n",
       "        [-0.3187, -0.0941,  0.0171,  0.0551,  0.0896],\n",
       "        [ 0.1483,  0.0226, -0.1844,  0.1788, -0.3626],\n",
       "        [-0.2240, -0.0946, -0.1841, -0.1322, -0.3098],\n",
       "        [-0.0804,  0.0808, -0.2462, -0.0194,  0.2706],\n",
       "        [-0.0389,  0.0105, -0.0326,  0.0765,  0.2403]], requires_grad=True)"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_cell.weight_ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "torch.manual_seed(0)\n",
    "sz, bz, dz, hz = 10, 4, 5, 7\n",
    "lz = 1 # num_layers\n",
    "x = torch.randn(bz, sz, dz)\n",
    "lstm = nn.LSTM(input_size=dz,\n",
    "               hidden_size=hz,\n",
    "               bias=True,\n",
    "               batch_first=True\n",
    "               )\n",
    "out, (hn, cn) = lstm(x)\n",
    "# out and hn are the same !!! Careful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 7])"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0366,  0.0946,  0.0368,  0.0538,  0.0950,  0.3502, -0.5945],\n",
       "        [ 0.0688,  0.0639, -0.3101,  0.0012,  0.1544,  0.3090, -0.3091],\n",
       "        [ 0.0487,  0.0416,  0.0409,  0.2507,  0.2483,  0.1582, -0.4065],\n",
       "        [ 0.0980,  0.1033,  0.1533,  0.3093,  0.2307,  0.0691, -0.4459]],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0366,  0.0946,  0.0368,  0.0538,  0.0950,  0.3502, -0.5945],\n",
       "         [ 0.0688,  0.0639, -0.3101,  0.0012,  0.1544,  0.3090, -0.3091],\n",
       "         [ 0.0487,  0.0416,  0.0409,  0.2507,  0.2483,  0.1582, -0.4065],\n",
       "         [ 0.0980,  0.1033,  0.1533,  0.3093,  0.2307,  0.0691, -0.4459]]],\n",
       "       grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 10, 64)\n",
    "mask = torch.arange(0, 10).expand(4, 10, 10).clone()\n",
    "index_mask = torch.randint(5, 10, size=(4, 10, 10))\n",
    "mask = mask >= index_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_key_padding_mask = torch.arange(0, 10).expand(4, 10).clone()\n",
    "src_idx_mask = torch.randint(3, 10, size=(4,)).unsqueeze(1)\n",
    "src_key_padding_mask = src_key_padding_mask >= src_idx_mask\n",
    "src_key_padding_mask\n",
    "x[src_key_padding_mask] *= 0.\n",
    "# Additive attention for src\n",
    "src_mask = torch.randn(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[src_key_padding_mask].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 64])"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfm_enc_layer = nn.TransformerEncoderLayer(d_model=64, nhead=8,\n",
    "                                               dim_feedforward=128, dropout=0.1,\n",
    "                                               activation=F.gelu, batch_first=True, \n",
    "                                               norm_first=False\n",
    "                                               )\n",
    "y = tfm_enc_layer(x, src_key_padding_mask=src_key_padding_mask, src_mask=src_mask)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8958, -1.0957,  0.0394, -0.2223,  0.5634,  0.1066, -0.6516, -1.6670,\n",
       "         0.1621, -0.5294, -0.0759, -0.1421,  0.0188,  0.9326,  0.7924,  0.1720,\n",
       "        -1.3745, -1.7386, -0.0750,  1.1500,  0.5301, -2.0552, -0.5857,  1.3363,\n",
       "         0.4073, -0.6344, -0.0954,  0.3517,  0.9651,  1.4621,  0.8214, -0.7455,\n",
       "        -0.5382, -0.1444, -0.2969, -0.2163,  0.1266,  0.5564,  0.8943,  0.6638,\n",
       "        -0.4990, -0.3543, -0.6840, -0.0483,  0.4670,  2.4288, -1.5141, -1.0092,\n",
       "        -0.3794,  0.4454,  1.0467, -0.1036, -0.9263,  0.3585,  0.4240, -0.1514,\n",
       "        -0.2859,  0.4786,  0.9243,  3.6044, -2.1874, -1.5147,  1.5502, -0.3425],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 1000,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
       "         0.3223, -1.2633,  0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473,\n",
       "        -1.3527, -1.6959,  0.5667,  0.7935,  0.5988, -1.5551, -0.3414,  1.8530,\n",
       "         0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437,\n",
       "        -0.6136,  0.0316, -0.4927,  0.2484,  0.4397,  0.1124,  0.6408,  0.4412,\n",
       "        -0.1023,  0.7924, -0.2897,  0.0525,  0.5229,  2.3022, -1.4689, -1.5867,\n",
       "        -0.6731,  0.8728,  1.0554,  0.1778, -0.2303, -0.3918,  0.5433, -0.3952,\n",
       "        -0.4462,  0.7440,  1.5210,  3.4105, -1.5312, -1.2341,  1.8197, -0.5515])"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_enc = nn.TransformerEncoder(tfm_enc_layer, 2, nn.LayerNorm(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tfm_enc(x, src_key_padding_mask=src_key_padding_mask.bool(), mask=src_mask.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 64])"
      ]
     },
     "execution_count": 1019,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_dec_layer = nn.TransformerDecoderLayer(d_model=64, \n",
    "                                           nhead=8,\n",
    "                                           dim_feedforward=128, \n",
    "                                            dropout=0.1,\n",
    "                                            activation=F.gelu, \n",
    "                                            batch_first=True, \n",
    "                                            norm_first=False\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = torch.empty(5, 5).fill_(False).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask[torch.triu_indices(5, 5, offset=1).chunk(2)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True],\n",
       "        [False, False, False,  True,  True],\n",
       "        [False, False, False, False,  True],\n",
       "        [False, False, False, False, False]])"
      ]
     },
     "execution_count": 1080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_mask = tgt_mask.float()\n",
    "tgt_mask = tgt_mask.where(tgt_mask != 1.0, float(\"-inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = tfm_dec_layer(torch.randn(4, 5, 64),memory=y, \n",
    "                   memory_key_padding_mask=src_key_padding_mask,\n",
    "                   tgt_mask=tgt_mask\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 64])"
      ]
     },
     "execution_count": 1084,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm_dec = nn.TransformerDecoder(decoder_layer=tfm_dec_layer, num_layers=2, \n",
    "                                      norm=nn.LayerNorm(64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [],
   "source": [
    "zd = tfm_dec(torch.randn(4, 5, 64), memory=y, \n",
    "                   memory_key_padding_mask=src_key_padding_mask,\n",
    "                   tgt_mask=tgt_mask\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 64])"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = nn.Transformer(d_model=64, nhead=8, num_decoder_layers=2, num_encoder_layers=2,\n",
    "                     norm_first=False, batch_first=True, dropout=0.1, dim_feedforward=128, \n",
    "                     activation=F.gelu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm(x, torch.randn(4, 5, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 64])"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 10)\n",
    "drop_net = nn.Dropout(p=0.2)\n",
    "y = drop_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152,\n",
       "          0.3223, -1.2633],\n",
       "        [ 0.3500,  0.3081,  0.1198,  1.2377,  1.1168, -0.2473, -1.3527, -1.6959,\n",
       "          0.5667,  0.7935],\n",
       "        [ 0.5988, -1.5551, -0.3414,  1.8530, -0.2159, -0.7425,  0.5627,  0.2596,\n",
       "         -0.1740, -0.6787],\n",
       "        [ 0.9383,  0.4889,  1.2032,  0.0845, -1.2001, -0.0048, -0.5181, -0.3067,\n",
       "         -1.5810,  1.7066]])"
      ]
     },
     "execution_count": 1102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4073, -1.4405, -0.3132, -0.5423,  1.0609,  0.8650, -0.3950, -2.6440,\n",
       "          0.4028, -0.0000],\n",
       "        [ 0.0000,  0.3852,  0.1498,  1.5471,  1.3960, -0.3091, -1.6908, -2.1199,\n",
       "          0.0000,  0.9919],\n",
       "        [ 0.0000, -1.9439, -0.4267,  2.3163, -0.2698, -0.9282,  0.7034,  0.3245,\n",
       "         -0.2175, -0.8484],\n",
       "        [ 0.0000,  0.6111,  1.5040,  0.0000, -1.5002, -0.0060, -0.0000, -0.3834,\n",
       "         -1.9762,  2.1333]])"
      ]
     },
     "execution_count": 1103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1750)"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y==0).sum().float() / y.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.4073, -1.4405, -0.3132, -0.5423,  1.0609,  0.8650, -0.3950,\n",
       "          -2.6440,  0.4028, -1.5792],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "          -0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.7485, -1.9439, -0.4267,  2.3163,  0.9377, -0.7319, -0.2167,\n",
       "           0.2293,  1.7367,  1.9829],\n",
       "         [ 1.1829, -1.0546, -0.7670,  0.0395, -0.6158,  0.3105,  0.5496,\n",
       "           0.1405,  0.8010,  0.5514]],\n",
       "\n",
       "        [[-0.1279,  0.9906, -0.3621,  0.0656,  0.6536,  2.8778, -1.8361,\n",
       "          -1.9834, -0.8414,  1.0910],\n",
       "         [ 1.3192,  0.2223, -0.2879, -0.4897,  0.6791, -0.4939, -0.5578,\n",
       "           0.9300,  1.9012,  4.2631]],\n",
       "\n",
       "        [[-1.9140, -1.5427,  2.2747, -0.6894, -0.7116,  1.1500,  1.3885,\n",
       "           1.6123, -1.8477,  3.2090],\n",
       "         [-0.5914,  0.4194, -2.0367, -0.6872, -0.5998, -0.6246, -1.3337,\n",
       "           1.3937, -0.1758,  1.0072]]])"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(4, 2, 10)\n",
    "drop_net = nn.Dropout1d(p=0.2) # zero_out_channels\n",
    "y = drop_net(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.4073, -1.4405, -0.3132, -0.5423],\n",
       "          [ 1.0609,  0.8650, -0.3950, -2.6440],\n",
       "          [ 0.4028, -1.5792,  0.4375,  0.3852],\n",
       "          [ 0.1498,  1.5471,  1.3960, -0.3091]],\n",
       "\n",
       "         [[-1.6908, -2.1199,  0.7083,  0.9919],\n",
       "          [ 0.7485, -1.9439, -0.4267,  2.3163],\n",
       "          [ 0.9377, -0.7319, -0.2167,  0.2293],\n",
       "          [ 1.7367,  1.9829,  1.1829, -1.0546]],\n",
       "\n",
       "         [[-0.0000,  0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [-0.0000,  0.0000, -0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000, -0.0000, -0.0000]]]])"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(1, 3, 4, 4)\n",
    "drop_net = nn.Dropout2d(p=0.2) # zero_out entire channels\n",
    "y = drop_net(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6805, -0.7038, -1.2362, -0.0723],\n",
       "          [ 1.0550,  0.9172,  0.0313, -1.5500],\n",
       "          [ 0.5923, -0.8013,  0.6166,  0.5799],\n",
       "          [ 0.4144, -1.2362,  1.2906,  0.0917]],\n",
       "\n",
       "         [[-0.8798, -1.1815, -1.2362,  1.0065],\n",
       "          [ 0.8354, -1.0577,  0.0090,  1.9377],\n",
       "          [ 0.9684, -0.2056,  0.1566, -1.2362],\n",
       "          [ 1.5302,  1.7033,  1.1407, -0.4325]],\n",
       "\n",
       "         [[-0.2302, -1.2362, -0.1240, -1.2362],\n",
       "          [-1.2362,  0.4078,  0.8722,  0.6968],\n",
       "          [ 0.2191,  1.0055,  0.0544,  0.3552],\n",
       "          [ 0.7686,  2.3325, -0.9820, -1.0855]]]])"
      ]
     },
     "execution_count": 1118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(1, 3, 4, 4)\n",
    "drop_net = nn.AlphaDropout(p=0.2) # zero_out entire channels\n",
    "y = drop_net(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6805, -0.7038,  0.0888, -0.0723],\n",
       "          [ 1.0550,  0.9172,  0.0313, -1.5500],\n",
       "          [ 0.5923, -0.8013,  0.6166,  0.5799],\n",
       "          [ 0.4144,  1.3968,  1.2906,  0.0917]],\n",
       "\n",
       "         [[-0.8798, -1.1815,  0.8071,  1.0065],\n",
       "          [ 0.8354, -1.0577,  0.0090,  1.9377],\n",
       "          [ 0.9684, -0.2056,  0.1566,  0.4703],\n",
       "          [ 1.5302,  1.7033,  1.1407, -0.4325]],\n",
       "\n",
       "         [[-1.2362, -1.2362, -1.2362, -1.2362],\n",
       "          [-1.2362, -1.2362, -1.2362, -1.2362],\n",
       "          [-1.2362, -1.2362, -1.2362, -1.2362],\n",
       "          [-1.2362, -1.2362, -1.2362, -1.2362]]]])"
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(1, 3, 4, 4)\n",
    "drop_net = nn.FeatureAlphaDropout(p=0.2) \n",
    "y = drop_net(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 32]), True)"
      ]
     },
     "execution_count": 1187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "vocab_size = 16\n",
    "hz = 32\n",
    "bz, sz = 4, 10\n",
    "x = torch.randint(0, vocab_size, (bz, sz)).long()\n",
    "embed_net = nn.Embedding(num_embeddings=vocab_size, \n",
    "                         embedding_dim=hz, \n",
    "                         padding_idx=0, \n",
    "                         max_norm=torch.tensor(5.),                       \n",
    "                         )\n",
    "embed_net.weight.size(), embed_net.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_net.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1271, -0.0727,  0.4007,  ..., -0.0574, -0.2118,  0.2339],\n",
       "         [ 0.0945,  0.1797, -0.1597,  ..., -0.1739, -0.0697, -0.0282],\n",
       "         [ 0.0618,  0.0407, -0.5334,  ..., -0.0488, -0.0706,  0.3613],\n",
       "         ...,\n",
       "         [ 0.1210, -0.0345, -0.4667,  ..., -0.0368, -0.0038,  0.2037],\n",
       "         [-0.2074, -0.3122, -0.2486,  ..., -0.4168, -0.1128,  0.1280],\n",
       "         [-0.0828,  0.1933, -0.0249,  ...,  0.0547, -0.0310,  0.1621]],\n",
       "\n",
       "        [[ 0.0618,  0.0407, -0.5334,  ..., -0.0488, -0.0706,  0.3613],\n",
       "         [-0.2134,  0.1431,  0.4307,  ..., -0.0072,  0.1013, -0.1716],\n",
       "         [-0.0068, -0.0728, -0.0674,  ..., -0.2763,  0.0261,  0.2807],\n",
       "         ...,\n",
       "         [-0.1271, -0.0727,  0.4007,  ..., -0.0574, -0.2118,  0.2339],\n",
       "         [-0.0008,  0.2418,  0.1543,  ..., -0.0217, -0.0468, -0.2838],\n",
       "         [ 0.2170,  0.1506, -0.0501,  ...,  0.1598, -0.3104, -0.0642]],\n",
       "\n",
       "        [[ 0.2371,  0.4139, -0.3689,  ..., -0.1160, -0.1894,  0.4319],\n",
       "         [ 0.1210, -0.0345, -0.4667,  ..., -0.0368, -0.0038,  0.2037],\n",
       "         [ 0.1210, -0.0345, -0.4667,  ..., -0.0368, -0.0038,  0.2037],\n",
       "         ...,\n",
       "         [-0.2074, -0.3122, -0.2486,  ..., -0.4168, -0.1128,  0.1280],\n",
       "         [ 0.0096,  0.3715,  0.2974,  ...,  0.3066, -0.0029,  0.2437],\n",
       "         [-0.0889,  0.2251, -0.1570,  ...,  0.2349,  0.3285, -0.1508]],\n",
       "\n",
       "        [[-0.2074, -0.3122, -0.2486,  ..., -0.4168, -0.1128,  0.1280],\n",
       "         [-0.0068, -0.0728, -0.0674,  ..., -0.2763,  0.0261,  0.2807],\n",
       "         [-0.0828,  0.1933, -0.0249,  ...,  0.0547, -0.0310,  0.1621],\n",
       "         ...,\n",
       "         [ 0.0945,  0.1797, -0.1597,  ..., -0.1739, -0.0697, -0.0282],\n",
       "         [ 0.0945,  0.1797, -0.1597,  ..., -0.1739, -0.0697, -0.0282],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 1189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    nn.init.xavier_normal_(embed_net.weight.data)\n",
    "    nn.init.constant_(embed_net.weight[0], 0.0)\n",
    "y = embed_net(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 32])"
      ]
     },
     "execution_count": 1190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32])"
      ]
     },
     "execution_count": 1191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_net.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_net.weight[0].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_emb = nn.Embedding.from_pretrained(embed_net.weight, freeze=True, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_net.weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True])"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_net.weight[1] == pretrained_emb.weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_emb.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4112, -0.8971,  0.4201],\n",
       "         [-0.4604, -0.5416,  0.0212]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 1202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 1)\n",
    "x2 = torch.randn(2, 4, 3)\n",
    "cos_net = nn.CosineSimilarity(dim=1)\n",
    "y = cos_net(x1, x2)\n",
    "y, y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2.2233],\n",
       "          [2.1278],\n",
       "          [3.3366],\n",
       "          [1.2553]],\n",
       " \n",
       "         [[0.7609],\n",
       "          [1.4149],\n",
       "          [4.0384],\n",
       "          [1.5720]]]),\n",
       " torch.Size([2, 4, 1]))"
      ]
     },
     "execution_count": 1205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 3)\n",
    "x2 = torch.randn(2, 4, 1)\n",
    "pair_net = nn.PairwiseDistance(p=2, keepdim=True)\n",
    "y = pair_net(x1, x2)\n",
    "y, y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 3])"
      ]
     },
     "execution_count": 1220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 3)\n",
    "x2 = torch.randn(2, 4, 3)\n",
    "l1_loss = nn.L1Loss(reduction=\"none\")\n",
    "y = l1_loss(x1, x2)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mtb/env/lib/python3.9/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([2, 4, 1])) that is different to the input size (torch.Size([2, 4, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n",
      "/var/tmp/ipykernel_13394/1088307170.py:6: UserWarning: Using a target size (torch.Size([2, 4, 1])) that is different to the input size (torch.Size([2, 4, 3])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  y, y.size(), F.l1_loss(x1, x2, reduction=\"sum\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(25.0521), torch.Size([]), tensor(25.0521))"
      ]
     },
     "execution_count": 1219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 3)\n",
    "x2 = torch.randn(2, 4, 1)\n",
    "l1_loss = nn.L1Loss(reduction=\"sum\")\n",
    "y = l1_loss(x1, x2)\n",
    "y, y.size(), F.l1_loss(x1, x2, reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(54.4145), torch.Size([]), tensor(54.4145))"
      ]
     },
     "execution_count": 1221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 3)\n",
    "x2 = torch.randn(2, 4, 3)\n",
    "mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "y = mse_loss(x1, x2)\n",
    "y, y.size(), F.mse_loss(x1, x2, reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 3]), torch.Size([2, 4, 3]))"
      ]
     },
     "execution_count": 1222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 3)\n",
    "x2 = torch.randn(2, 4, 3)\n",
    "mse_loss = nn.MSELoss(reduction=\"none\")\n",
    "y = mse_loss(x1, x2)\n",
    "y.size(), F.mse_loss(x1, x2, reduction=\"none\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1487), tensor(2.1487))"
      ]
     },
     "execution_count": 1224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "input = torch.randn(2, 4)\n",
    "target = torch.randn(2, 4).softmax(-1).argmax(1)\n",
    "cross_ent_net = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "y = cross_ent_net(input, target)\n",
    "y, F.cross_entropy(input, target, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8516), tensor(0.8516))"
      ]
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "input = torch.randn(4, 2)\n",
    "target = torch.randn(4, 2).softmax(-1).argmax(1)\n",
    "cross_ent_net = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "y = cross_ent_net(input, target)\n",
    "y, F.cross_entropy(input, target, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 1, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.6411), tensor(0.6411), tensor(0.6411))"
      ]
     },
     "execution_count": 1253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "logits = torch.randn(4, 2)\n",
    "target = torch.randn(4, 2).softmax(-1).argmax(1)\n",
    "print(target)\n",
    "log_softmax = nn.LogSoftmax(dim=1)(logits)\n",
    "nlloss = nn.NLLLoss()\n",
    "y = nlloss(log_softmax, target)\n",
    "y, F.nll_loss(log_softmax, target, reduction=\"mean\"), F.cross_entropy(logits, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6411), tensor(0.6411))"
      ]
     },
     "execution_count": 1258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_binary = logits.softmax(1).select(dim=1, index=1)\n",
    "target_binary = target\n",
    "bce_loss = nn.BCELoss(reduction=\"mean\")\n",
    "y = bce_loss(input_binary, target_binary.float())\n",
    "y, F.binary_cross_entropy(input_binary, target_binary.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6411), tensor(0.6411))"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_binary = logits.softmax(1).select(dim=1, index=1).logit()\n",
    "target_binary = target\n",
    "bce_log_loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "y = bce_log_loss(logit_binary, target_binary.float())\n",
    "y, F.binary_cross_entropy_with_logits(logit_binary, target_binary.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5245), tensor(0.5245))"
      ]
     },
     "execution_count": 1269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x1 = torch.randn(2, 4, 3)\n",
    "x2 = torch.randn(2, 4, 3)\n",
    "hubert_loss = nn.HuberLoss(delta=0.5, reduction=\"mean\")\n",
    "y = hubert_loss(x1, x2)\n",
    "y, F.huber_loss(x1, x2, delta=0.5, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 9, 4, 4]), torch.Size([2, 1, 12, 12]))"
      ]
     },
     "execution_count": 1273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 9, 4, 4)\n",
    "net = nn.PixelShuffle(3)\n",
    "y = net(x)\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 12, 12]), torch.Size([2, 9, 4, 4]))"
      ]
     },
     "execution_count": 1275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 1, 12, 12)\n",
    "net = nn.PixelUnshuffle(3)\n",
    "y = net(x)\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 9, 4, 4]), torch.Size([2, 9, 8, 8]))"
      ]
     },
     "execution_count": 1278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 9, 4, 4)\n",
    "net = nn.Upsample((8, 8), mode=\"nearest\")\n",
    "y = net(x)\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 9, 4, 4]), torch.Size([2, 9, 8, 8]))"
      ]
     },
     "execution_count": 1279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 9, 4, 4)\n",
    "net = nn.Upsample((8, 8), mode=\"bilinear\")\n",
    "y = net(x)\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 9, 4, 4]), torch.Size([2, 9, 8, 8]))"
      ]
     },
     "execution_count": 1281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 9, 4, 4)\n",
    "net = nn.Upsample((8, 8), mode=\"bicubic\")\n",
    "y = net(x)\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 9, 4, 4]), torch.Size([2, 9, 16, 16]))"
      ]
     },
     "execution_count": 1282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "x = torch.randn(2, 9, 4, 4)\n",
    "net = nn.Upsample(scale_factor=4, mode=\"bicubic\")\n",
    "y = net(x)\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
