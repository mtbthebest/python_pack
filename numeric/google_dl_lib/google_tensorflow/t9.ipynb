{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 15:46:21.943173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/env_dl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-01-14 15:46:24.065950: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.088751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.089008: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import keras\n",
    "from keras import layers, optimizers, losses, metrics, callbacks, ops\n",
    "from PIL import Image\n",
    "gpus = tf.config.experimental.list_physical_devices(device_type=\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "DATASET_PATH = \"/mnt/dl/datasets/Oxford102FlowersSplits/\"\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "LABELS = {i: k.strip() for i, k in enumerate(open(os.path.join(DATASET_PATH, \"names.txt\")))}\n",
    "batch_size = 64\n",
    "img_size = 224\n",
    "SIZE = 128\n",
    "batch_size = 32\n",
    "num_classes = len(LABELS)\n",
    "patch_size = 16\n",
    "num_patches = img_size ** 2 / patch_size **2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(split):\n",
    "    \n",
    "    def load_img(img_fname):\n",
    "        img_bytes = tf.io.read_file(img_fname)\n",
    "        img = tf.io.decode_jpeg(img_bytes)\n",
    "        img = tf.image.resize(img, (img_size, img_size))\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        return img\n",
    "        \n",
    "    path = os.path.join(DATASET_PATH, split, )\n",
    "    img_files = os.listdir(os.path.join(path, \"jpeg\"))\n",
    "    img_files = sorted(img_files, key=lambda x: int(x.replace(\".jpeg\", \"\")))\n",
    "    img_files = list(img_files)[:SIZE]\n",
    "    \n",
    "    labels = list(open(os.path.join(path, \"label\", \"label.txt\"),))\n",
    "    labels = [int(l.strip()) for l in labels][:SIZE]\n",
    "    \n",
    "    img_files = [os.path.join(path, \"jpeg\", name) for name in img_files]\n",
    "    \n",
    "    img_ds = tf.data.Dataset.from_tensor_slices(img_files).map(load_img).cache()\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(labels).cache()\n",
    "    ds = tf.data.Dataset.zip((img_ds, label_ds))\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-14 15:46:24.226129: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.226370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.226519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.863604: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.863824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.863980: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-14 15:46:24.864118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20762 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:0a:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset(\"train\")\n",
    "validation_ds = load_dataset(\"validation\")\n",
    "test_ds = load_dataset(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_layers = [layers.RandomRotation(0.1), layers.RandomFlip()]\n",
    "\n",
    "def preprocess(img, label, training):\n",
    "    if training:\n",
    "        for aug in aug_layers:\n",
    "            img = aug(img)\n",
    "    return tf.cast(img, tf.float32), label\n",
    "    \n",
    "train_ds = train_ds.shuffle(buffer_size=2048, seed=0).map(lambda img, label: preprocess(img, label, training=True)).batch(batch_size)\n",
    "validation_ds = validation_ds.map(lambda img, label: preprocess(img, label, training=False), num_parallel_calls=5).batch(batch_size)\n",
    "test_ds = test_ds.map(lambda img, label: preprocess(img, label, training=False), num_parallel_calls=5).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actnorm(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        h, w, c = input_shape[1:]\n",
    "        self.hw = h * w\n",
    "        \n",
    "        self.s = self.add_variable(shape=(1, 1, 1, c,), \n",
    "                                   initializer=keras.initializers.glorot_uniform(),\n",
    "                                   name=\"s\",\n",
    "                                   trainable=True)\n",
    "        self.b = self.add_variable(shape=(c,), \n",
    "                                   initializer=keras.initializers.glorot_uniform(),\n",
    "                                   name=\"b\",\n",
    "                                   trainable=True)\n",
    "        return super().build(input_shape)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x * self.s + self.b\n",
    "    \n",
    "    def reverse(self, y):\n",
    "        return ops.divide(y - self.b, self.s)\n",
    "    \n",
    "    def call(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            y = self.forward(x)\n",
    "        else:\n",
    "            y = self.reverse(x)\n",
    "        log_det =  self.hw * ops.sum(ops.log(ops.abs(self.s)))\n",
    "        return y, log_det\n",
    "    \n",
    "# Actnorm()(input)\n",
    "# Actnorm()(np.random.normal(size=(2, 16, 16, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Invertible1x1Conv(layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        h, w, c = input_shape[1:]\n",
    "        self.hw = h * w\n",
    "        weight,  *_ = np.linalg.qr(np.random.normal(size=(c, c),).astype(np.float32))\n",
    "        P, L, U = scipy.linalg.lu(weight)\n",
    "\n",
    "        u_diag = np.diagonal(U)\n",
    "        s = np.eye(c, dtype=np.float32)\n",
    "        s = s * u_diag\n",
    "        U -= s\n",
    "        self.P = P\n",
    "        \n",
    "        self.L = self.add_variable(shape=(c, c),\n",
    "                                   initializer=lambda args, dtype: tf.convert_to_tensor(L, dtype=tf.float32),\n",
    "                                   trainable=True,\n",
    "                                   dtype=tf.float32\n",
    "                                   )\n",
    "        \n",
    "        self.l_mask = np.tril(np.ones((c, c), dtype=np.float32), -1)\n",
    "        self.u_mask = np.triu(np.ones((c, c), dtype=np.float32), 1)\n",
    "        self.diag_mask = np.eye(c, dtype=np.float32)\n",
    "        \n",
    "        self.U = self.add_variable(shape=(c, c),\n",
    "                                   initializer=lambda args, dtype: tf.convert_to_tensor(U, dtype=tf.float32),\n",
    "                                   trainable=True,\n",
    "                                   dtype=tf.float32\n",
    "                                   )\n",
    "\n",
    "        self.s = self.add_variable(shape=(c, c),\n",
    "                                   initializer=lambda args, dtype: tf.convert_to_tensor(s, dtype=tf.float32),\n",
    "                                   trainable=True,\n",
    "                                   dtype=tf.float32\n",
    "                                   )\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def forward(self, x, W):\n",
    "        cin, cout = W.shape\n",
    "        filters = tf.reshape(W, (1, 1, cin, cout))\n",
    "        return tf.nn.conv2d(x, filters, (1, 1, 1, 1), padding=\"SAME\")\n",
    "    \n",
    "    def reverse(self, y, W):\n",
    "        cin, cout = W.shape\n",
    "        w_inv = tf.linalg.inv(W)\n",
    "        filters = tf.reshape(w_inv, (1, 1, cin, cout))\n",
    "        return tf.nn.conv2d(y, filters, (1, 1, 1, 1), padding=\"SAME\")\n",
    "    \n",
    "    def get_weights(self):\n",
    "        P = self.P\n",
    "        L = self.L * self.l_mask + self.diag_mask\n",
    "        U = tf.multiply(self.U, self.u_mask)\n",
    "        s = tf.multiply(self.s, self.diag_mask)\n",
    "        W  =  P @ L @ (U + s)\n",
    "        return W\n",
    "    \n",
    "    def call(self, x, reverse=False):\n",
    "        W = self.get_weights()\n",
    "        if not reverse:\n",
    "            y = self.forward(x, W)\n",
    "        else:\n",
    "            y = self.reverse(x, W)\n",
    "        return y, self.hw #*  tf.abs(tf.linalg.det(W))\n",
    "# Invertible1x1Conv()(np.random.normal(size=(2, 4, 4, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineCouplingLayer(layers.Layer):\n",
    "    def __init__(self, dim=512, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.dim = dim\n",
    "    def build(self, input_shape):\n",
    "        c = input_shape[-1]\n",
    "        self.nn = keras.Sequential([\n",
    "            layers.Conv2D(self.dim, 3, padding=\"SAME\"),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.Conv2D(self.dim, 1),\n",
    "            layers.Activation(\"relu\"),\n",
    "            layers.Conv2D(c, 3, padding=\"SAME\", \n",
    "                        #   kernel_initializer=keras.initializers.zeros(),\n",
    "                        #   bias_initializer=keras.initializers.zeros(),\n",
    "                          ),\n",
    "        ])\n",
    "    \n",
    "        super().build(input_shape)\n",
    "\n",
    "    \n",
    "    def split(self, x):\n",
    "        c = x.shape[-1]\n",
    "        # s = c // 2\n",
    "        xa = ops.take(x, range(0, c//2), axis=-1)\n",
    "        xb = ops.take(x, range(c // 2, c), axis=-1)\n",
    "        return xa, xb\n",
    "    \n",
    "    def concat(self, *args):\n",
    "        return ops.concatenate(args, axis=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        xa, xb = self.split(x)\n",
    "        nn_out = self.nn(xb)\n",
    "        log_s, t = self.split(nn_out)\n",
    "        s = ops.exp(log_s)\n",
    "        ya = s * xa + t\n",
    "        yb = xb\n",
    "        y = self.concat(ya, yb)\n",
    "        \n",
    "        return y, s\n",
    "    \n",
    "    def reverse(self, y):\n",
    "        ya, yb = self.split(y)\n",
    "        nn_out = self.nn(yb)\n",
    "        log_s, t = self.split(nn_out)\n",
    "        s = ops.exp(log_s)\n",
    "        xa = (ya - t) / s\n",
    "        xb = yb\n",
    "        x = self.concat(xa, xb)\n",
    "        return x, s\n",
    "    \n",
    "    def call(self, x, reverse=False):\n",
    "        bz, *_ = ops.shape(x)\n",
    "        if not reverse:\n",
    "            y, s = self.forward(x)\n",
    "        else:\n",
    "            y, s = self.reverse(x)\n",
    "    \n",
    "        return  y, ops.sum(ops.reshape(ops.log(ops.abs(s)), (bz, -1)), -1)\n",
    "\n",
    "# AffineCouplingLayer()(np.random.normal(size=(2, 4, 4, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowStep(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.act_norm = Actnorm()\n",
    "        self.inv_conv = Invertible1x1Conv()\n",
    "        self.affine_coupling = AffineCouplingLayer()\n",
    "        \n",
    "    def call(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            y, log_det = self.forward(x)\n",
    "        else:\n",
    "            y, log_det = self.reverse(x)\n",
    "        \n",
    "        return y, log_det\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, log_det1 = self.act_norm(x, reverse=False)\n",
    "        x, log_det2 = self.inv_conv(x, reverse=False)\n",
    "        x, log_det3 = self.affine_coupling(x, reverse=False)\n",
    "\n",
    "        return x, log_det1 + log_det2 + log_det3\n",
    "        \n",
    "    \n",
    "    def reverse(self, x):\n",
    "        x, log_det3 = self.affine_coupling(x, reverse=True)\n",
    "        x, log_det2 = self.inv_conv(x, reverse=True)\n",
    "        x, log_det1 = self.act_norm(x, reverse=True)\n",
    "        \n",
    "        return x, log_det1 + log_det2 + log_det3\n",
    "\n",
    "# FlowStep()(np.random.normal(size=(10, 400, 400, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squeeze(layers.Layer):\n",
    "    \n",
    "    def call(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            return self.forward(x)\n",
    "        else:\n",
    "            return self.reverse(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        bz, h, w, c = ops.shape(x)\n",
    "        sqz_x = ops.reshape(x, (bz, h//2, 2, w//2, 2, c))\n",
    "        sqz_x = ops.transpose(sqz_x, (0, 1, 3, 2, 4, 5))\n",
    "        sqz_x = ops.reshape(sqz_x, tuple(ops.shape(sqz_x)[:3]) + (4*c, ))\n",
    "        return sqz_x\n",
    "\n",
    "    def reverse(self, x):\n",
    "        bz, h, w, c = ops.shape(x)\n",
    "        unsqz_x = ops.reshape(x, (bz, h, w, 2, 2, c // 4))\n",
    "        unsqz_x = ops.transpose(unsqz_x, (0, 1, 3, 2, 4, 5))\n",
    "        unsqz_x = ops.reshape(unsqz_x, (bz, 2*h, 2*w, unsqz_x.shape[-1]))\n",
    "        return unsqz_x        \n",
    "        \n",
    "    \n",
    "# Squeeze()(np.arange(2* 40 * 60 * 3).reshape((2, 40, 60, 3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_logp(x, mean, log_std):\n",
    "    return -0.5 * ops.log(2 * np.pi) - log_std - 0.5 * ops.square(x - mean) / ops.exp(2*log_std)\n",
    "\n",
    "def gaussian_sample(mean, log_std, eps=None):\n",
    "    if eps is None:\n",
    "        eps = tf.random.normal(ops.shape(log_std))\n",
    "    return mean + ops.exp(log_std) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Split(layers.Layer):\n",
    "    \n",
    "    def __init__(self,  split=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._split = split\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        h, w, c = input_shape[1:]\n",
    "        nc = c if self._split else  2*c\n",
    "        self.conv_net = layers.Conv2D(nc, 3, padding=\"SAME\")\n",
    "    \n",
    "    def call(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            y, z, log_p = self.forward(x)\n",
    "        else:\n",
    "            y, z, log_p = self.reverse(x)\n",
    "            \n",
    "        return y, z, log_p \n",
    "\n",
    "    def forward(self, x):\n",
    "        bz, *_ = ops.shape(x)\n",
    "        if self._split:\n",
    "            out, z = ops.split(x, 2, axis=-1)\n",
    "            mean, log_std = ops.split(self.conv_net(out), 2, -1)\n",
    "        else:\n",
    "            zeros = ops.zeros_like(x)\n",
    "            z, out = x, x\n",
    "            mean, log_std =  ops.split(self.conv_net(zeros), 2, -1)\n",
    "            \n",
    "        log_p = gaussian_logp(z, mean, log_std)\n",
    "        log_p = ops.sum(ops.reshape(log_p, (bz, -1)), -1)\n",
    "        return out, z, log_p\n",
    "    \n",
    "    def reverse(self, z):\n",
    "        if self._split:\n",
    "            mean, log_std =  ops.split(self.conv_net(z), 2, -1)\n",
    "            z_sample = gaussian_sample(mean, log_std)\n",
    "            z_sample = ops.concatenate([z, z_sample], axis=-1)\n",
    "        else:\n",
    "            zeros = ops.zeros_like(z)\n",
    "            mean, log_std =  ops.split(self.conv_net(zeros), 2, -1)\n",
    "            # TODO\n",
    "            z_sample = gaussian_sample(mean, log_std)\n",
    "        \n",
    "        return z_sample, None, None\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(layers.Layer):\n",
    "    \n",
    "    def __init__(self, flow_steps, channel, split=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.flow_steps = flow_steps\n",
    "        self.channel = channel\n",
    "        self._split = split\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.squeeze= Squeeze()\n",
    "        self.flow_step = [FlowStep() for _ in range(self.flow_steps)]\n",
    "        self.split = Split(self._split) \n",
    "            \n",
    "    def call(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            return self.forward(x)\n",
    "        else:\n",
    "            return self.reverse(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.squeeze(x, reverse=False)\n",
    "        log_det = 0.\n",
    "        for i in range(self.flow_steps):\n",
    "            out, flow_log_det = self.flow_step[i](out, reverse=False)\n",
    "            \n",
    "            log_det = log_det + flow_log_det\n",
    "        out, z, log_p = self.split(out, reverse=False)\n",
    "        return out, z, log_p, log_det\n",
    "\n",
    "    def reverse(self, z):\n",
    "        z, *_ = self.split(z, reverse=True)\n",
    "        for i in reversed(range(self.flow_steps)):\n",
    "            z, *_ = self.flow_step[i](z, reverse=True)\n",
    "        z = self.squeeze(z, reverse=True)\n",
    "        return z, None, None, None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NFModel(keras.Model):\n",
    "    \n",
    "    def __init__(self, flow_steps, num_layers,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.flow_steps = flow_steps\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        h, w, c = input_shape[1:]\n",
    "        channels = [np.power(2, i) * 3 for i in range(self.num_layers)]\n",
    "        self.z_shapes = [(h // np.power(2, i), w // np.power(2, i), \n",
    "                          ( 6 * 2**i if i == self.num_layers else 3*2**i)) for i in range(self.num_layers, 0, -1)]\n",
    "        self.blocks = [\n",
    "            Block(self.flow_steps, channels[i], \n",
    "                  split= i != (self.num_layers - 1)) \n",
    "            for i in range(self.num_layers)\n",
    "        ]\n",
    "        return super().build(input_shape)\n",
    "        \n",
    "    def compile(self, optimizer: optimizers.Optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        return super().compile(loss=None)\n",
    "    \n",
    "    def train_step(self, x):\n",
    "        img, _ = x\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            out, z_list, log_p, log_det = self(img, reverse=False)\n",
    "            losses = -tf.reduce_mean(log_p + log_det)\n",
    "        # TODO\n",
    "        if tf.math.is_nan(losses):\n",
    "            losses = 0.0\n",
    "        else:\n",
    "            grads = tape.gradient(losses, self.trainable_variables)\n",
    "            clipped_grads = [tf.clip_by_norm(g, 5.) for g in grads]\n",
    "            self.optimizer.apply_gradients(zip(clipped_grads, self.trainable_variables))\n",
    "            self.add_loss(losses)\n",
    "            return {\"loss\": tf.constant(0.)}\n",
    "        \n",
    "    def compute_loss(self,  x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False ):\n",
    "        return 0.0\n",
    "    \n",
    "    def call(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            return self.forward(x)\n",
    "        else:\n",
    "            return self.reverse(x)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = x \n",
    "        z_list = []\n",
    "        log_det = 0.\n",
    "        log_p = 0.\n",
    "        for block_fn in self.blocks:\n",
    "            out, z, block_log_p, block_log_det = block_fn(out, reverse=False)\n",
    "            log_p = log_p + block_log_p\n",
    "            log_det = log_det + block_log_det\n",
    "            z_list.append(z)\n",
    "\n",
    "        return out, z_list, log_p, log_det\n",
    "\n",
    "    def reverse(self, z):\n",
    "        for i, block_fn in enumerate(self.blocks[::-1]):\n",
    "            z, *_ = block_fn(z, reverse=True)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor shape=(None, 28, 28, 48), dtype=float32, sparse=False, name=keras_tensor_596>,\n",
       " [<KerasTensor shape=(None, 112, 112, 6), dtype=float32, sparse=False, name=keras_tensor_597>,\n",
       "  <KerasTensor shape=(None, 56, 56, 12), dtype=float32, sparse=False, name=keras_tensor_598>,\n",
       "  <KerasTensor shape=(None, 28, 28, 48), dtype=float32, sparse=False, name=keras_tensor_599>],\n",
       " <KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_600>,\n",
       " <KerasTensor shape=(None,), dtype=float32, sparse=False, name=keras_tensor_601>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = keras.Input((img_size, img_size, 3))\n",
    "nf_model = NFModel(2, 3)\n",
    "nf_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"nf_model_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"nf_model_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">    Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ block_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                │ ?                         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">693,820</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                │ ?                         │    <span style=\"color: #00af00; text-decoration-color: #00af00\">864,328</span> │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Block</span>)                │ ?                         │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,245,568</span> │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ block_39 (\u001b[38;5;33mBlock\u001b[0m)                │ ?                         │    \u001b[38;5;34m693,820\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_40 (\u001b[38;5;33mBlock\u001b[0m)                │ ?                         │    \u001b[38;5;34m864,328\u001b[0m │\n",
       "├─────────────────────────────────┼───────────────────────────┼────────────┤\n",
       "│ block_41 (\u001b[38;5;33mBlock\u001b[0m)                │ ?                         │  \u001b[38;5;34m1,245,568\u001b[0m │\n",
       "└─────────────────────────────────┴───────────────────────────┴────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,803,716</span> (10.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,803,716\u001b[0m (10.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,803,716</span> (10.70 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,803,716\u001b[0m (10.70 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/env_dl/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[88], line 30\u001b[0m, in \u001b[0;36mNFModel.train_step\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m     out, z_list, log_p, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(img, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtf\u001b[38;5;241m.\u001b[39mreduce_mean(log_p \u001b[38;5;241m+\u001b[39m log_det)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce_any\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_nan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m():\n\u001b[1;32m     31\u001b[0m     losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "nf_model.fit(train_ds, validation_data=validation_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[0:1]\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_max(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, z_list, log_p, log_det = nf_model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_img = nf_model.reverse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.reduce_max(rec_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(np.clip(img.numpy() * 255., a_min=0, a_max=255).astype(np.uint8)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
